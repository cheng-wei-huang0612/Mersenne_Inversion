proc main (%v1, %v12, %v16, %v17, %v3, %v4, %v5, %v6, L0xffffc68e16e0, L0xffffc68e16e8, L0xffffc68e16f0, L0xffffc68e16f8, L0xffffc68e1700, L0xffffc68e1708, L0xffffc68e1710, L0xffffc68e1718, L0xffffc68e1720, L0xffffc68e1728, L0xffffc68e1730, L0xffffc68e1738, L0xffffc68e1740, L0xffffc68e1748, L0xffffc68e1750, L0xffffc68e1758, L0xffffc68e1808, L0xffffc68e1810, L0xffffc68e1818, L0xffffc68e1820, carry, sp, x10_neg, x11, x13, x15, x17, x19, x2, x20, x21, x22, x23, x24, x25, x26, x27, x28, x29, x30, x3_neg, x6, x7, x8) =
{
  true
  &&
  true
}

(* #! -> SP = 0xffffc68e17c0 *)
#! 0xffffc68e17c0 = 0xffffc68e17c0;
(* stp	x29, x30, [sp, #-16]!                       #! EA = L0xffffc68e17b0; PC = 0xaaaabe370e88 *)
mov L0xffffc68e17b0 x29; mov L0xffffc68e17b8 x30;
(* mov	x29, sp                                     #! PC = 0xaaaabe370e8c *)
mov x29 sp;
(* stp	x19, x20, [sp, #-16]!                       #! EA = L0xffffc68e17a0; PC = 0xaaaabe370e90 *)
mov L0xffffc68e17a0 x19; mov L0xffffc68e17a8 x20;
(* stp	x21, x22, [sp, #-16]!                       #! EA = L0xffffc68e1790; PC = 0xaaaabe370e94 *)
mov L0xffffc68e1790 x21; mov L0xffffc68e1798 x22;
(* stp	x23, x24, [sp, #-16]!                       #! EA = L0xffffc68e1780; PC = 0xaaaabe370e98 *)
mov L0xffffc68e1780 x23; mov L0xffffc68e1788 x24;
(* stp	x25, x26, [sp, #-16]!                       #! EA = L0xffffc68e1770; PC = 0xaaaabe370e9c *)
mov L0xffffc68e1770 x25; mov L0xffffc68e1778 x26;
(* stp	x27, x28, [sp, #-16]!                       #! EA = L0xffffc68e1760; PC = 0xaaaabe370ea0 *)
mov L0xffffc68e1760 x27; mov L0xffffc68e1768 x28;
(* stp	q8, q9, [sp, #-32]!                         #! EA = L0xffffc68e1740; PC = 0xaaaabe370ea4 *)
mov [L0xffffc68e1740, L0xffffc68e1748] %v8;
mov [L0xffffc68e1750, L0xffffc68e1758] %v9;
(* stp	q10, q11, [sp, #-32]!                       #! EA = L0xffffc68e1720; PC = 0xaaaabe370ea8 *)
mov [L0xffffc68e1720, L0xffffc68e1728] %v10;
mov [L0xffffc68e1730, L0xffffc68e1738] %v11;
(* stp	q12, q13, [sp, #-32]!                       #! EA = L0xffffc68e1700; PC = 0xaaaabe370eac *)
mov [L0xffffc68e1700, L0xffffc68e1708] %v12;
mov [L0xffffc68e1710, L0xffffc68e1718] %v13;
(* stp	q14, q15, [sp, #-32]!                       #! EA = L0xffffc68e16e0; PC = 0xaaaabe370eb0 *)
mov [L0xffffc68e16e0, L0xffffc68e16e8] %v14;
mov [L0xffffc68e16f0, L0xffffc68e16f8] %v15;
(* ldp	x5, x22, [x1]                               #! EA = L0xffffc68e1808; Value = 0x0000000000000000; PC = 0xaaaabe370eb4 *)
mov x5 L0xffffc68e1808; mov x22 L0xffffc68e1810;
(* ldp	x4, x21, [x1, #16]                          #! EA = L0xffffc68e1818; Value = 0x0000000000000000; PC = 0xaaaabe370eb8 *)
mov x4 L0xffffc68e1818; mov x21 L0xffffc68e1820;
(* mov	x2, #0x13                  	// #19          #! PC = 0xaaaabe370ebc *)
mov x2 0x13@uint64;
(* lsr	x3, x21, #63                                #! PC = 0xaaaabe370ec0 *)
split x3 dcL x21 63;
(* madd	x3, x2, x3, x2                             #! PC = 0xaaaabe370ec4 *)
mull dcH mul_tmp x2 x3;
adds dc x3 mul_tmp x2;
(* adds	x5, x5, x3                                 #! PC = 0xaaaabe370ec8 *)
adds carry x5 x5 x3;
(* adcs	x22, x22, xzr                              #! PC = 0xaaaabe370ecc *)
adcs carry x22 x22 0@uint64 carry;
(* adcs	x4, x4, xzr                                #! PC = 0xaaaabe370ed0 *)
adcs carry x4 x4 0@uint64 carry;
(* orr	x21, x21, #0x8000000000000000               #! PC = 0xaaaabe370ed4 *)
or x21@uint64 x21 0x8000000000000000@uint64;
(* adcs	x21, x21, xzr                              #! PC = 0xaaaabe370ed8 *)
adcs carry x21 x21 0@uint64 carry;
(* csel	x3, x2, xzr, cc	// cc = lo, ul, last       #! PC = 0xaaaabe370edc *)
cmov x3 carry 0@uint64 x2;
(* subs	x5, x5, x3                                 #! PC = 0xaaaabe370ee0 *)
subc carry x5 x5 x3;
(* sbcs	x22, x22, xzr                              #! PC = 0xaaaabe370ee4 *)
sbcs carry x22 x22 0@uint64 carry;
(* sbcs	x4, x4, xzr                                #! PC = 0xaaaabe370ee8 *)
sbcs carry x4 x4 0@uint64 carry;
(* sbc	x21, x21, xzr                               #! PC = 0xaaaabe370eec *)
sbc x21 x21 0@uint64 carry;
(* and	x21, x21, #0x7fffffffffffffff               #! PC = 0xaaaabe370ef0 *)
and x21@uint64 x21 0x7fffffffffffffff@uint64;
(* mov	v5.d[0], x5                                 #! PC = 0xaaaabe370ef4 *)
mov %v5 [x5, %v5[1]];
(* mov	v5.d[1], x22                                #! PC = 0xaaaabe370ef8 *)
mov %v5 [%v5[0], x22];
(* mov	v6.d[0], x4                                 #! PC = 0xaaaabe370efc *)
mov %v6 [x4, %v6[1]];
(* mov	v6.d[1], x21                                #! PC = 0xaaaabe370f00 *)
mov %v6 [%v6[0], x21];
(* movi	v4.2d, #0xffffffffffffffff                 #! PC = 0xaaaabe370f04 *)
broadcast %v4 2 [0xffffffffffffffff@uint64];
(* mov	x2, #0xffffffffffffffff    	// #-1          #! PC = 0xaaaabe370f08 *)
mov x2 0xffffffffffffffff@uint64;
(* lsr	x2, x2, #1                                  #! PC = 0xaaaabe370f0c *)
split x2 dcL x2 1;
(* mov	v3.d[1], x2                                 #! PC = 0xaaaabe370f10 *)
mov %v3 [%v3[0], x2];
(* mov	x2, #0xffffffffffffffed    	// #-19         #! PC = 0xaaaabe370f14 *)
mov x2 0xffffffffffffffed@uint64;
(* mov	v3.d[0], x2                                 #! PC = 0xaaaabe370f18 *)
mov %v3 [x2, %v3[1]];
(* zip1	v8.2d, v3.2d, v5.2d                        #! PC = 0xaaaabe370f1c *)
mov %v8 [%v3[0], %v5[0]];
(* zip2	v9.2d, v4.2d, v5.2d                        #! PC = 0xaaaabe370f20 *)
mov %v9 [%v4[1], %v5[1]];
(* zip1	v10.2d, v4.2d, v6.2d                       #! PC = 0xaaaabe370f24 *)
mov %v10 [%v4[0], %v6[0]];
(* zip2	v11.2d, v3.2d, v6.2d                       #! PC = 0xaaaabe370f28 *)
mov %v11 [%v3[1], %v6[1]];
(* ushr	v1.2d, v4.2d, #34                          #! PC = 0xaaaabe370f2c *)
shrs %v1 %dc %v4 [34, 34];
(* and	v3.16b, v8.16b, v1.16b                      #! PC = 0xaaaabe370f30 *)
and %v3@uint64[2] %v8 %v1;
(* ushr	v12.2d, v8.2d, #30                         #! PC = 0xaaaabe370f34 *)
shrs %v12 %dc %v8 [30, 30];
(* and	v12.16b, v12.16b, v1.16b                    #! PC = 0xaaaabe370f38 *)
and %v12@uint64[2] %v12 %v1;
(* sli	v3.2d, v12.2d, #32                          #! PC = 0xaaaabe370f3c *)
split %dc %slil %v12 (64-32); shl %slih %v12 [32@uint64, 32@uint64];
split %dc %v3 %v3 32; or %v3@uint64[2] %slih %v3;
(* ushr	v4.2d, v8.2d, #60                          #! PC = 0xaaaabe370f40 *)
shrs %v4 %dc %v8 [60, 60];
(* shl	v12.2d, v9.2d, #4                           #! PC = 0xaaaabe370f44 *)
shls %dc %v12 %v9 [4, 4];
(* and	v12.16b, v12.16b, v1.16b                    #! PC = 0xaaaabe370f48 *)
and %v12@uint64[2] %v12 %v1;
(* orr	v4.16b, v4.16b, v12.16b                     #! PC = 0xaaaabe370f4c *)
or %v4@uint64[2] %v4 %v12;
(* ushr	v12.2d, v9.2d, #26                         #! PC = 0xaaaabe370f50 *)
shrs %v12 %dc %v9 [26, 26];
(* and	v12.16b, v12.16b, v1.16b                    #! PC = 0xaaaabe370f54 *)
and %v12@uint64[2] %v12 %v1;
(* sli	v4.2d, v12.2d, #32                          #! PC = 0xaaaabe370f58 *)
split %dc %slil %v12 (64-32); shl %slih %v12 [32@uint64, 32@uint64];
split %dc %v4 %v4 32; or %v4@uint64[2] %slih %v4;
(* ushr	v5.2d, v9.2d, #56                          #! PC = 0xaaaabe370f5c *)
shrs %v5 %dc %v9 [56, 56];
(* shl	v12.2d, v10.2d, #8                          #! PC = 0xaaaabe370f60 *)
shls %dc %v12 %v10 [8, 8];
(* and	v12.16b, v12.16b, v1.16b                    #! PC = 0xaaaabe370f64 *)
and %v12@uint64[2] %v12 %v1;
(* orr	v5.16b, v5.16b, v12.16b                     #! PC = 0xaaaabe370f68 *)
or %v5@uint64[2] %v5 %v12;
(* ushr	v12.2d, v10.2d, #22                        #! PC = 0xaaaabe370f6c *)
shrs %v12 %dc %v10 [22, 22];
(* and	v12.16b, v12.16b, v1.16b                    #! PC = 0xaaaabe370f70 *)
and %v12@uint64[2] %v12 %v1;
(* sli	v5.2d, v12.2d, #32                          #! PC = 0xaaaabe370f74 *)
split %dc %slil %v12 (64-32); shl %slih %v12 [32@uint64, 32@uint64];
split %dc %v5 %v5 32; or %v5@uint64[2] %slih %v5;
(* ushr	v6.2d, v10.2d, #52                         #! PC = 0xaaaabe370f78 *)
shrs %v6 %dc %v10 [52, 52];
(* shl	v12.2d, v11.2d, #12                         #! PC = 0xaaaabe370f7c *)
shls %dc %v12 %v11 [12, 12];
(* and	v12.16b, v12.16b, v1.16b                    #! PC = 0xaaaabe370f80 *)
and %v12@uint64[2] %v12 %v1;
(* orr	v6.16b, v6.16b, v12.16b                     #! PC = 0xaaaabe370f84 *)
or %v6@uint64[2] %v6 %v12;
(* ushr	v12.2d, v11.2d, #18                        #! PC = 0xaaaabe370f88 *)
shrs %v12 %dc %v11 [18, 18];
(* and	v12.16b, v12.16b, v1.16b                    #! PC = 0xaaaabe370f8c *)
and %v12@uint64[2] %v12 %v1;
(* sli	v6.2d, v12.2d, #32                          #! PC = 0xaaaabe370f90 *)
split %dc %slil %v12 (64-32); shl %slih %v12 [32@uint64, 32@uint64];
split %dc %v6 %v6 32; or %v6@uint64[2] %slih %v6;
(* ushr	v7.2d, v11.2d, #48                         #! PC = 0xaaaabe370f94 *)
shrs %v7 %dc %v11 [48, 48];
(* movi	v8.2d, #0x0                                #! PC = 0xaaaabe370f98 *)
broadcast %v8 2 [0x0@uint64];
(* mov	x2, #0x1                   	// #1           #! PC = 0xaaaabe370f9c *)
mov x2 0x1@uint64;
(* mov	v8.d[1], x2                                 #! PC = 0xaaaabe370fa0 *)
mov %v8 [%v8[0], x2];
(* movi	v9.2d, #0x0                                #! PC = 0xaaaabe370fa4 *)
broadcast %v9 2 [0x0@uint64];
(* movi	v10.2d, #0x0                               #! PC = 0xaaaabe370fa8 *)
broadcast %v10 2 [0x0@uint64];
(* movi	v11.2d, #0x0                               #! PC = 0xaaaabe370fac *)
broadcast %v11 2 [0x0@uint64];
(* movi	v12.2d, #0x0                               #! PC = 0xaaaabe370fb0 *)
broadcast %v12 2 [0x0@uint64];
(* uzp1	v2.4s, v1.4s, v1.4s                        #! PC = 0xaaaabe370fb4 *)
mov %v2 [%v1[0], %v1[2], %v1[0], %v1[2]];
(* mov	x4, #0xffffffffffffffed    	// #-19         #! PC = 0xaaaabe370fb8 *)
mov x4 0xffffffffffffffed@uint64;
(* mov	x21, #0xffffffffffffffff    	// #-1         #! PC = 0xaaaabe370fbc *)
mov x21 0xffffffffffffffff@uint64;
(* mov	x1, x4                                      #! PC = 0xaaaabe370fc0 *)
mov x1 x4;
(* mov	x2, x5                                      #! PC = 0xaaaabe370fc4 *)
mov x2 x5;
(* mov	x3, #0x1                   	// #1           #! PC = 0xaaaabe370fc8 *)
mov x3 0x1@uint64;
(* mov	x6, #0x20000000000         	// #2199023255552#! PC = 0xaaaabe370fcc *)
mov x6 0x20000000000@uint64;
(* add	x6, x6, #0x100, lsl #12                     #! PC = 0xaaaabe370fd0 *)
add x6 x6 0x100@sint64, lsl;
(* mov	x7, #0x286b0000            	// #678100992   #! PC = 0xaaaabe370fd4 *)
mov x7 0x286b0000@uint64;
(* movk	x7, #0xca1b                                #! PC = 0xaaaabe370fd8 *)
movk	%%x7, #0xca1b                                #! 0xaaaabe370fd8 = 0xaaaabe370fd8;
(* dup	v15.4s, w7                                  #! PC = 0xaaaabe370fdc *)
cast w7@sint32 x7;
mov %v15 [w7,w7,w7,w7];
(* and	x7, x1, #0xfffff                            #! PC = 0xaaaabe370fe0 *)
and x7@uint64 x1 0xfffff@uint64;
(* and	x8, x2, #0xfffff                            #! PC = 0xaaaabe370fe4 *)
and x8@uint64 x2 0xfffff@uint64;
(* orr	x7, x7, #0xfffffe0000000000                 #! PC = 0xaaaabe370fe8 *)
or x7@uint64 x7 0xfffffe0000000000@uint64;
(* orr	x8, x8, #0xc000000000000000                 #! PC = 0xaaaabe370fec *)
or x8@uint64 x8 0xc000000000000000@uint64;
(* tst	x8, #0x1                                    #! PC = 0xaaaabe370ff0 *)
spl dc x8_lo x8 1;
and ne@bit x8_lo 1@bit;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe370ff4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe370ff8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe370ffc *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371000 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371004 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371008 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37100c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371010 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371014 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371018 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37101c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371020 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371024 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371028 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37102c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371030 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371034 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371038 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37103c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371040 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371044 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371048 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37104c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371050 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371054 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371058 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37105c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371060 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371064 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371068 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37106c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371070 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371074 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371078 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37107c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371080 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371084 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371088 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37108c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371090 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371094 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371098 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37109c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3710a0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3710a4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3710a8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3710ac *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3710b0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3710b4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3710b8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3710bc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3710c0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3710c4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3710c8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3710cc *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3710d0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3710d4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3710d8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3710dc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3710e0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3710e4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3710e8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3710ec *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3710f0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3710f4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3710f8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3710fc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371100 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371104 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371108 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37110c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371110 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371114 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371118 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37111c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371120 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371124 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371128 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37112c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371130 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371134 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371138 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37113c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371140 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371144 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371148 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37114c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371150 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371154 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371158 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37115c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371160 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371164 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371168 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37116c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371170 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371174 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371178 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37117c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371180 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371184 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371188 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37118c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371190 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371194 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371198 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37119c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3711a0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3711a4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3711a8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3711ac *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3711b0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3711b4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3711b8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3711bc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3711c0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3711c4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3711c8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3711cc *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3711d0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3711d4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3711d8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3711dc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3711e0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3711e4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3711e8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3711ec *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3711f0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3711f4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3711f8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3711fc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371200 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371204 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371208 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37120c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371210 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371214 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371218 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37121c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371220 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371224 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371228 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37122c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371230 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371234 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371238 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37123c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371240 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371244 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371248 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37124c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371250 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371254 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371258 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37125c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371260 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371264 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371268 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37126c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371270 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371274 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371278 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37127c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371280 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371284 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371288 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37128c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371290 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371294 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371298 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37129c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3712a0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3712a4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3712a8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3712ac *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3712b0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3712b4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3712b8 *)
add x3 x3 0x2@sint64;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3712bc *)
ssplit x8 dcL x8 1;
(* add	x12, x7, x6                                 #! PC = 0xaaaabe3712c0 *)
add x12 x7 x6;
(* asr	x12, x12, #42                               #! PC = 0xaaaabe3712c4 *)
ssplit x12 dcL x12 42;
(* add	x11, x7, #0x100, lsl #12                    #! PC = 0xaaaabe3712c8 *)
add x11 x7 0x100@sint64, lsl;
(* lsl	x11, x11, #22                               #! PC = 0xaaaabe3712cc *)
split dcH x11 x11 (64-22); shl x11 x11 22;
(* asr	x11, x11, #43                               #! PC = 0xaaaabe3712d0 *)
ssplit x11 dcL x11 43;
(* add	x14, x8, x6                                 #! PC = 0xaaaabe3712d4 *)
add x14 x8 x6;
(* asr	x14, x14, #42                               #! PC = 0xaaaabe3712d8 *)
ssplit x14 dcL x14 42;
(* add	x13, x8, #0x100, lsl #12                    #! PC = 0xaaaabe3712dc *)
add x13 x8 0x100@sint64, lsl;
(* lsl	x13, x13, #22                               #! PC = 0xaaaabe3712e0 *)
split dcH x13 x13 (64-22); shl x13 x13 22;
(* asr	x13, x13, #43                               #! PC = 0xaaaabe3712e4 *)
ssplit x13 dcL x13 43;
(* mul	x9, x11, x1                                 #! PC = 0xaaaabe3712e8 *)
mull dcH x9 x11 x1;
(* madd	x9, x12, x2, x9                            #! PC = 0xaaaabe3712ec *)
mull dcH mul_tmp x12 x2;
adds dc x9 mul_tmp x9;
(* asr	x9, x9, #20                                 #! PC = 0xaaaabe3712f0 *)
ssplit x9 dcL x9 20;
(* mul	x10, x13, x1                                #! PC = 0xaaaabe3712f4 *)
mull dcH x10 x13 x1;
(* madd	x10, x14, x2, x10                          #! PC = 0xaaaabe3712f8 *)
mull dcH mul_tmp x14 x2;
adds dc x10 mul_tmp x10;
(* asr	x2, x10, #20                                #! PC = 0xaaaabe3712fc *)
ssplit x2 dcL x10 20;
(* mov	x1, x9                                      #! PC = 0xaaaabe371300 *)
mov x1 x9;
(* and	x7, x1, #0xfffff                            #! PC = 0xaaaabe371304 *)
and x7@uint64 x1 0xfffff@uint64;
(* and	x8, x2, #0xfffff                            #! PC = 0xaaaabe371308 *)
and x8@uint64 x2 0xfffff@uint64;
(* orr	x7, x7, #0xfffffe0000000000                 #! PC = 0xaaaabe37130c *)
or x7@uint64 x7 0xfffffe0000000000@uint64;
(* orr	x8, x8, #0xc000000000000000                 #! PC = 0xaaaabe371310 *)
or x8@uint64 x8 0xc000000000000000@uint64;
(* tst	x8, #0x1                                    #! PC = 0xaaaabe371314 *)
spl dc x8_lo x8 1;
and ne@bit x8_lo 1@bit;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371318 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37131c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371320 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371324 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371328 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37132c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371330 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371334 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371338 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37133c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371340 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371344 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371348 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37134c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371350 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371354 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371358 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37135c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371360 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371364 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371368 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37136c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371370 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371374 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371378 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37137c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371380 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371384 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371388 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37138c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371390 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371394 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371398 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37139c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3713a0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3713a4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3713a8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3713ac *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3713b0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3713b4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3713b8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3713bc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3713c0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3713c4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3713c8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3713cc *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3713d0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3713d4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3713d8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3713dc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3713e0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3713e4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3713e8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3713ec *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3713f0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3713f4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3713f8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3713fc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371400 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371404 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371408 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37140c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371410 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371414 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371418 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37141c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371420 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371424 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371428 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37142c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371430 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371434 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371438 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37143c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371440 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371444 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371448 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37144c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371450 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371454 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371458 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37145c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371460 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371464 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371468 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37146c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371470 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371474 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371478 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37147c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371480 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371484 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371488 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37148c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371490 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371494 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371498 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37149c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3714a0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3714a4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3714a8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3714ac *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3714b0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3714b4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3714b8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3714bc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3714c0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3714c4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3714c8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3714cc *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3714d0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3714d4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3714d8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3714dc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3714e0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3714e4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3714e8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3714ec *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3714f0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3714f4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3714f8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3714fc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371500 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371504 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371508 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37150c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371510 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371514 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371518 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37151c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371520 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371524 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371528 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37152c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371530 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371534 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371538 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37153c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371540 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371544 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371548 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37154c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371550 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371554 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371558 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37155c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371560 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371564 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371568 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37156c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371570 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371574 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371578 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37157c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371580 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371584 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371588 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37158c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371590 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371594 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371598 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37159c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3715a0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3715a4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3715a8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3715ac *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3715b0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3715b4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3715b8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3715bc *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3715c0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3715c4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3715c8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3715cc *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3715d0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3715d4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3715d8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3715dc *)
add x3 x3 0x2@sint64;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3715e0 *)
ssplit x8 dcL x8 1;
(* add	x16, x7, x6                                 #! PC = 0xaaaabe3715e4 *)
add x16 x7 x6;
(* asr	x16, x16, #42                               #! PC = 0xaaaabe3715e8 *)
ssplit x16 dcL x16 42;
(* add	x15, x7, #0x100, lsl #12                    #! PC = 0xaaaabe3715ec *)
add x15 x7 0x100@sint64, lsl;
(* lsl	x15, x15, #22                               #! PC = 0xaaaabe3715f0 *)
split dcH x15 x15 (64-22); shl x15 x15 22;
(* asr	x15, x15, #43                               #! PC = 0xaaaabe3715f4 *)
ssplit x15 dcL x15 43;
(* add	x20, x8, x6                                 #! PC = 0xaaaabe3715f8 *)
add x20 x8 x6;
(* asr	x20, x20, #42                               #! PC = 0xaaaabe3715fc *)
ssplit x20 dcL x20 42;
(* add	x17, x8, #0x100, lsl #12                    #! PC = 0xaaaabe371600 *)
add x17 x8 0x100@sint64, lsl;
(* lsl	x17, x17, #22                               #! PC = 0xaaaabe371604 *)
split dcH x17 x17 (64-22); shl x17 x17 22;
(* asr	x17, x17, #43                               #! PC = 0xaaaabe371608 *)
ssplit x17 dcL x17 43;
(* mul	x9, x15, x1                                 #! PC = 0xaaaabe37160c *)
mull dcH x9 x15 x1;
(* madd	x9, x16, x2, x9                            #! PC = 0xaaaabe371610 *)
mull dcH mul_tmp x16 x2;
adds dc x9 mul_tmp x9;
(* asr	x9, x9, #20                                 #! PC = 0xaaaabe371614 *)
ssplit x9 dcL x9 20;
(* mul	x10, x17, x1                                #! PC = 0xaaaabe371618 *)
mull dcH x10 x17 x1;
(* madd	x10, x20, x2, x10                          #! PC = 0xaaaabe37161c *)
mull dcH mul_tmp x20 x2;
adds dc x10 mul_tmp x10;
(* asr	x2, x10, #20                                #! PC = 0xaaaabe371620 *)
ssplit x2 dcL x10 20;
(* mov	x1, x9                                      #! PC = 0xaaaabe371624 *)
mov x1 x9;
(* mul	x9, x15, x11                                #! PC = 0xaaaabe371628 *)
mull dcH x9 x15 x11;
(* madd	x10, x16, x13, x9                          #! PC = 0xaaaabe37162c *)
mull dcH mul_tmp x16 x13;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x11                                #! PC = 0xaaaabe371630 *)
mull dcH x9 x17 x11;
(* madd	x13, x20, x13, x9                          #! PC = 0xaaaabe371634 *)
mull dcH mul_tmp x20 x13;
adds dc x13 mul_tmp x9;
(* mov	x11, x10                                    #! PC = 0xaaaabe371638 *)
mov x11 x10;
(* mul	x9, x15, x12                                #! PC = 0xaaaabe37163c *)
mull dcH x9 x15 x12;
(* madd	x10, x16, x14, x9                          #! PC = 0xaaaabe371640 *)
mull dcH mul_tmp x16 x14;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x12                                #! PC = 0xaaaabe371644 *)
mull dcH x9 x17 x12;
(* madd	x14, x20, x14, x9                          #! PC = 0xaaaabe371648 *)
mull dcH mul_tmp x20 x14;
adds dc x14 mul_tmp x9;
(* mov	x12, x10                                    #! PC = 0xaaaabe37164c *)
mov x12 x10;
(* and	x7, x1, #0xfffff                            #! PC = 0xaaaabe371650 *)
and x7@uint64 x1 0xfffff@uint64;
(* and	x8, x2, #0xfffff                            #! PC = 0xaaaabe371654 *)
and x8@uint64 x2 0xfffff@uint64;
(* orr	x7, x7, #0xfffffe0000000000                 #! PC = 0xaaaabe371658 *)
or x7@uint64 x7 0xfffffe0000000000@uint64;
(* orr	x8, x8, #0xc000000000000000                 #! PC = 0xaaaabe37165c *)
or x8@uint64 x8 0xc000000000000000@uint64;
(* tst	x8, #0x1                                    #! PC = 0xaaaabe371660 *)
spl dc x8_lo x8 1;
and ne@bit x8_lo 1@bit;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371664 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371668 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37166c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371670 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371674 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371678 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37167c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371680 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371684 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371688 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37168c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371690 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371694 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371698 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37169c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3716a0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3716a4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3716a8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3716ac *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3716b0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3716b4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3716b8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3716bc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3716c0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3716c4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3716c8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3716cc *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3716d0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3716d4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3716d8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3716dc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3716e0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3716e4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3716e8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3716ec *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3716f0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3716f4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3716f8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3716fc *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371700 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371704 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371708 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37170c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371710 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371714 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371718 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37171c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371720 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371724 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371728 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37172c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371730 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371734 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371738 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37173c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371740 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371744 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371748 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37174c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371750 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371754 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371758 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37175c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371760 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371764 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371768 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37176c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371770 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371774 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371778 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37177c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371780 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371784 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371788 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37178c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371790 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371794 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371798 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37179c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3717a0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3717a4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3717a8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3717ac *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3717b0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3717b4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3717b8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3717bc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3717c0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3717c4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3717c8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3717cc *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3717d0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3717d4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3717d8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3717dc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3717e0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3717e4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3717e8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3717ec *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3717f0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3717f4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3717f8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3717fc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371800 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371804 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371808 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37180c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371810 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371814 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371818 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37181c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371820 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371824 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371828 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37182c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371830 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371834 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371838 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37183c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371840 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371844 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371848 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37184c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371850 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371854 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371858 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37185c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371860 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371864 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371868 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37186c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371870 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371874 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371878 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37187c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371880 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371884 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371888 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37188c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371890 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371894 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371898 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37189c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3718a0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3718a4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3718a8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3718ac *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3718b0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3718b4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3718b8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3718bc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3718c0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3718c4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3718c8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3718cc *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3718d0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3718d4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3718d8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3718dc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3718e0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3718e4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3718e8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3718ec *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3718f0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3718f4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3718f8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3718fc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371900 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371904 *)
add x3 x3 0x2@sint64;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371908 *)
ssplit x8 dcL x8 1;
(* add	x16, x7, x6                                 #! PC = 0xaaaabe37190c *)
add x16 x7 x6;
(* asr	x16, x16, #42                               #! PC = 0xaaaabe371910 *)
ssplit x16 dcL x16 42;
(* add	x15, x7, #0x100, lsl #12                    #! PC = 0xaaaabe371914 *)
add x15 x7 0x100@sint64, lsl;
(* lsl	x15, x15, #22                               #! PC = 0xaaaabe371918 *)
split dcH x15 x15 (64-22); shl x15 x15 22;
(* asr	x15, x15, #43                               #! PC = 0xaaaabe37191c *)
ssplit x15 dcL x15 43;
(* add	x20, x8, x6                                 #! PC = 0xaaaabe371920 *)
add x20 x8 x6;
(* asr	x20, x20, #42                               #! PC = 0xaaaabe371924 *)
ssplit x20 dcL x20 42;
(* add	x17, x8, #0x100, lsl #12                    #! PC = 0xaaaabe371928 *)
add x17 x8 0x100@sint64, lsl;
(* lsl	x17, x17, #22                               #! PC = 0xaaaabe37192c *)
split dcH x17 x17 (64-22); shl x17 x17 22;
(* asr	x17, x17, #43                               #! PC = 0xaaaabe371930 *)
ssplit x17 dcL x17 43;
(* mul	x9, x15, x11                                #! PC = 0xaaaabe371934 *)
mull dcH x9 x15 x11;
(* madd	x10, x16, x13, x9                          #! PC = 0xaaaabe371938 *)
mull dcH mul_tmp x16 x13;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x11                                #! PC = 0xaaaabe37193c *)
mull dcH x9 x17 x11;
(* madd	x13, x20, x13, x9                          #! PC = 0xaaaabe371940 *)
mull dcH mul_tmp x20 x13;
adds dc x13 mul_tmp x9;
(* mov	x11, x10                                    #! PC = 0xaaaabe371944 *)
mov x11 x10;
(* mul	x9, x15, x12                                #! PC = 0xaaaabe371948 *)
mull dcH x9 x15 x12;
(* madd	x10, x16, x14, x9                          #! PC = 0xaaaabe37194c *)
mull dcH mul_tmp x16 x14;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x12                                #! PC = 0xaaaabe371950 *)
mull dcH x9 x17 x12;
(* madd	x14, x20, x14, x9                          #! PC = 0xaaaabe371954 *)
mull dcH mul_tmp x20 x14;
adds dc x14 mul_tmp x9;
(* mov	x12, x10                                    #! PC = 0xaaaabe371958 *)
mov x12 x10;
(* mov	x19, #0x9                   	// #9          #! PC = 0xaaaabe37195c *)
mov x19 0x9@uint64;
(* mov	v16.d[0], x11                               #! PC = 0xaaaabe371960 *)
mov %v16 [x11, %v16[1]];
(* mov	v16.d[1], x13                               #! PC = 0xaaaabe371964 *)
mov %v16 [%v16[0], x13];
(* mov	v17.d[0], x12                               #! PC = 0xaaaabe371968 *)
mov %v17 [x12, %v17[1]];
(* mov	v17.d[1], x14                               #! PC = 0xaaaabe37196c *)
mov %v17 [%v17[0], x14];
(* uzp1	v13.4s, v16.4s, v17.4s                     #! PC = 0xaaaabe371970 *)
mov %v13 [%v16[0], %v16[2], %v17[0], %v17[2]];
(* and	v13.16b, v13.16b, v2.16b                    #! PC = 0xaaaabe371974 *)
and %v13@uint64[2] %v13 %v2;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371978 *)
split %v16 %dc %v16 30;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe37197c *)
split %v17 %dc %v17 30;
(* uzp1	v14.4s, v16.4s, v17.4s                     #! PC = 0xaaaabe371980 *)
mov %v14 [%v16[0], %v16[2], %v17[0], %v17[2]];
(* cmp	x11, xzr                                    #! PC = 0xaaaabe371984 *)
subc zero dc 0@uint64 x11;
(* csetm	x23, mi	// mi = first                     #! PC = 0xaaaabe371988 *)
csetm	%%x23, mi	// mi = first                     #! 0xaaaabe371988 = 0xaaaabe371988;
(* cneg	x11, x11, mi	// mi = first                 #! PC = 0xaaaabe37198c *)
cneg	%%x11, %%x11, mi	// mi = first                 #! 0xaaaabe37198c = 0xaaaabe37198c;
(* cmp	x12, xzr                                    #! PC = 0xaaaabe371990 *)
subc zero dc 0@uint64 x12;
(* csetm	x24, mi	// mi = first                     #! PC = 0xaaaabe371994 *)
csetm	%%x24, mi	// mi = first                     #! 0xaaaabe371994 = 0xaaaabe371994;
(* cneg	x12, x12, mi	// mi = first                 #! PC = 0xaaaabe371998 *)
cneg	%%x12, %%x12, mi	// mi = first                 #! 0xaaaabe371998 = 0xaaaabe371998;
(* cmp	x13, xzr                                    #! PC = 0xaaaabe37199c *)
subc zero dc 0@uint64 x13;
(* csetm	x25, mi	// mi = first                     #! PC = 0xaaaabe3719a0 *)
csetm	%%x25, mi	// mi = first                     #! 0xaaaabe3719a0 = 0xaaaabe3719a0;
(* cneg	x13, x13, mi	// mi = first                 #! PC = 0xaaaabe3719a4 *)
cneg	%%x13, %%x13, mi	// mi = first                 #! 0xaaaabe3719a4 = 0xaaaabe3719a4;
(* cmp	x14, xzr                                    #! PC = 0xaaaabe3719a8 *)
subc zero dc 0@uint64 x14;
(* csetm	x26, mi	// mi = first                     #! PC = 0xaaaabe3719ac *)
csetm	%%x26, mi	// mi = first                     #! 0xaaaabe3719ac = 0xaaaabe3719ac;
(* cneg	x14, x14, mi	// mi = first                 #! PC = 0xaaaabe3719b0 *)
cneg	%%x14, %%x14, mi	// mi = first                 #! 0xaaaabe3719b0 = 0xaaaabe3719b0;
(* and	x27, x11, x23                               #! PC = 0xaaaabe3719b4 *)
and x27@uint64 x11 x23;
(* and	x28, x12, x24                               #! PC = 0xaaaabe3719b8 *)
and x28@uint64 x12 x24;
(* add	x15, x27, x28                               #! PC = 0xaaaabe3719bc *)
add x15 x27 x28;
(* eor	x27, x4, x23                                #! PC = 0xaaaabe3719c0 *)
xor x27@uint64 x4 x23;
(* mul	x9, x27, x11                                #! PC = 0xaaaabe3719c4 *)
mull dcH x9 x27 x11;
(* umulh	x10, x27, x11                             #! PC = 0xaaaabe3719c8 *)
mull x10 dcL x27 x11;
(* adds	x15, x9, x15                               #! PC = 0xaaaabe3719cc *)
adds carry x15 x9 x15;
(* adc	x16, x10, xzr                               #! PC = 0xaaaabe3719d0 *)
adc x16 x10 0@uint64 carry;
(* eor	x27, x21, x23                               #! PC = 0xaaaabe3719d4 *)
xor x27@uint64 x21 x23;
(* mul	x9, x27, x11                                #! PC = 0xaaaabe3719d8 *)
mull dcH x9 x27 x11;
(* add	x16, x16, x9                                #! PC = 0xaaaabe3719dc *)
add x16 x16 x9;
(* eor	x27, x5, x24                                #! PC = 0xaaaabe3719e0 *)
xor x27@uint64 x5 x24;
(* mul	x9, x27, x12                                #! PC = 0xaaaabe3719e4 *)
mull dcH x9 x27 x12;
(* umulh	x10, x27, x12                             #! PC = 0xaaaabe3719e8 *)
mull x10 dcL x27 x12;
(* adds	x15, x9, x15                               #! PC = 0xaaaabe3719ec *)
adds carry x15 x9 x15;
(* adc	x16, x10, x16                               #! PC = 0xaaaabe3719f0 *)
adc x16 x10 x16 carry;
(* eor	x27, x22, x24                               #! PC = 0xaaaabe3719f4 *)
xor x27@uint64 x22 x24;
(* mul	x9, x27, x12                                #! PC = 0xaaaabe3719f8 *)
mull dcH x9 x27 x12;
(* add	x16, x16, x9                                #! PC = 0xaaaabe3719fc *)
add x16 x16 x9;
(* extr	x1, x16, x15, #60                          #! PC = 0xaaaabe371a00 *)
spl dc extr_H x16 60; spl extr_L dc x15 60; join x1 extr_H extr_L;
(* and	x27, x13, x25                               #! PC = 0xaaaabe371a04 *)
and x27@uint64 x13 x25;
(* and	x28, x14, x26                               #! PC = 0xaaaabe371a08 *)
and x28@uint64 x14 x26;
(* add	x17, x27, x28                               #! PC = 0xaaaabe371a0c *)
add x17 x27 x28;
(* eor	x27, x4, x25                                #! PC = 0xaaaabe371a10 *)
xor x27@uint64 x4 x25;
(* mul	x9, x27, x13                                #! PC = 0xaaaabe371a14 *)
mull dcH x9 x27 x13;
(* umulh	x10, x27, x13                             #! PC = 0xaaaabe371a18 *)
mull x10 dcL x27 x13;
(* adds	x17, x9, x17                               #! PC = 0xaaaabe371a1c *)
adds carry x17 x9 x17;
(* adc	x20, x10, xzr                               #! PC = 0xaaaabe371a20 *)
adc x20 x10 0@uint64 carry;
(* eor	x27, x21, x25                               #! PC = 0xaaaabe371a24 *)
xor x27@uint64 x21 x25;
(* mul	x9, x27, x13                                #! PC = 0xaaaabe371a28 *)
mull dcH x9 x27 x13;
(* add	x20, x20, x9                                #! PC = 0xaaaabe371a2c *)
add x20 x20 x9;
(* eor	x27, x5, x26                                #! PC = 0xaaaabe371a30 *)
xor x27@uint64 x5 x26;
(* mul	x9, x27, x14                                #! PC = 0xaaaabe371a34 *)
mull dcH x9 x27 x14;
(* umulh	x10, x27, x14                             #! PC = 0xaaaabe371a38 *)
mull x10 dcL x27 x14;
(* adds	x17, x9, x17                               #! PC = 0xaaaabe371a3c *)
adds carry x17 x9 x17;
(* adc	x20, x10, x20                               #! PC = 0xaaaabe371a40 *)
adc x20 x10 x20 carry;
(* eor	x27, x22, x26                               #! PC = 0xaaaabe371a44 *)
xor x27@uint64 x22 x26;
(* mul	x9, x27, x14                                #! PC = 0xaaaabe371a48 *)
mull dcH x9 x27 x14;
(* add	x20, x20, x9                                #! PC = 0xaaaabe371a4c *)
add x20 x20 x9;
(* extr	x2, x20, x17, #60                          #! PC = 0xaaaabe371a50 *)
spl dc extr_H x20 60; spl extr_L dc x17 60; join x2 extr_H extr_L;
(* smull	v16.2d, v13.2s, v3.s[0]                   #! PC = 0xaaaabe371a54 *)
smull	%%v16.2d, %%v13.2s, %%v3.s[0]                   #! 0xaaaabe371a54 = 0xaaaabe371a54;
(* smlal2	v16.2d, v13.4s, v3.s[2]                  #! PC = 0xaaaabe371a58 *)
smlal2	%%v16.2d, %%v13.4s, %%v3.s[2]                  #! 0xaaaabe371a58 = 0xaaaabe371a58;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371a5c *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v3.s[0]                   #! PC = 0xaaaabe371a60 *)
smlal	%%v16.2d, %%v14.2s, %%v3.s[0]                   #! 0xaaaabe371a60 = 0xaaaabe371a60;
(* smlal2	v16.2d, v14.4s, v3.s[2]                  #! PC = 0xaaaabe371a64 *)
smlal2	%%v16.2d, %%v14.4s, %%v3.s[2]                  #! 0xaaaabe371a64 = 0xaaaabe371a64;
(* smlal	v16.2d, v13.2s, v3.s[1]                   #! PC = 0xaaaabe371a68 *)
smlal	%%v16.2d, %%v13.2s, %%v3.s[1]                   #! 0xaaaabe371a68 = 0xaaaabe371a68;
(* smlal2	v16.2d, v13.4s, v3.s[3]                  #! PC = 0xaaaabe371a6c *)
smlal2	%%v16.2d, %%v13.4s, %%v3.s[3]                  #! 0xaaaabe371a6c = 0xaaaabe371a6c;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371a70 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v3.s[1]                   #! PC = 0xaaaabe371a74 *)
smlal	%%v16.2d, %%v14.2s, %%v3.s[1]                   #! 0xaaaabe371a74 = 0xaaaabe371a74;
(* smlal2	v16.2d, v14.4s, v3.s[3]                  #! PC = 0xaaaabe371a78 *)
smlal2	%%v16.2d, %%v14.4s, %%v3.s[3]                  #! 0xaaaabe371a78 = 0xaaaabe371a78;
(* smlal	v16.2d, v13.2s, v4.s[0]                   #! PC = 0xaaaabe371a7c *)
smlal	%%v16.2d, %%v13.2s, %%v4.s[0]                   #! 0xaaaabe371a7c = 0xaaaabe371a7c;
(* smlal2	v16.2d, v13.4s, v4.s[2]                  #! PC = 0xaaaabe371a80 *)
smlal2	%%v16.2d, %%v13.4s, %%v4.s[2]                  #! 0xaaaabe371a80 = 0xaaaabe371a80;
(* and	v3.16b, v16.16b, v1.16b                     #! PC = 0xaaaabe371a84 *)
and %v3@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371a88 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v4.s[0]                   #! PC = 0xaaaabe371a8c *)
smlal	%%v16.2d, %%v14.2s, %%v4.s[0]                   #! 0xaaaabe371a8c = 0xaaaabe371a8c;
(* smlal2	v16.2d, v14.4s, v4.s[2]                  #! PC = 0xaaaabe371a90 *)
smlal2	%%v16.2d, %%v14.4s, %%v4.s[2]                  #! 0xaaaabe371a90 = 0xaaaabe371a90;
(* smlal	v16.2d, v13.2s, v4.s[1]                   #! PC = 0xaaaabe371a94 *)
smlal	%%v16.2d, %%v13.2s, %%v4.s[1]                   #! 0xaaaabe371a94 = 0xaaaabe371a94;
(* smlal2	v16.2d, v13.4s, v4.s[3]                  #! PC = 0xaaaabe371a98 *)
smlal2	%%v16.2d, %%v13.4s, %%v4.s[3]                  #! 0xaaaabe371a98 = 0xaaaabe371a98;
(* and	v17.16b, v16.16b, v1.16b                    #! PC = 0xaaaabe371a9c *)
and %v17@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371aa0 *)
split %v16 %dc %v16 30;
(* shl	v17.2d, v17.2d, #32                         #! PC = 0xaaaabe371aa4 *)
shls %dc %v17 %v17 [32, 32];
(* orr	v3.16b, v3.16b, v17.16b                     #! PC = 0xaaaabe371aa8 *)
or %v3@uint64[2] %v3 %v17;
(* smlal	v16.2d, v14.2s, v4.s[1]                   #! PC = 0xaaaabe371aac *)
smlal	%%v16.2d, %%v14.2s, %%v4.s[1]                   #! 0xaaaabe371aac = 0xaaaabe371aac;
(* smlal2	v16.2d, v14.4s, v4.s[3]                  #! PC = 0xaaaabe371ab0 *)
smlal2	%%v16.2d, %%v14.4s, %%v4.s[3]                  #! 0xaaaabe371ab0 = 0xaaaabe371ab0;
(* smlal	v16.2d, v13.2s, v5.s[0]                   #! PC = 0xaaaabe371ab4 *)
smlal	%%v16.2d, %%v13.2s, %%v5.s[0]                   #! 0xaaaabe371ab4 = 0xaaaabe371ab4;
(* smlal2	v16.2d, v13.4s, v5.s[2]                  #! PC = 0xaaaabe371ab8 *)
smlal2	%%v16.2d, %%v13.4s, %%v5.s[2]                  #! 0xaaaabe371ab8 = 0xaaaabe371ab8;
(* and	v4.16b, v16.16b, v1.16b                     #! PC = 0xaaaabe371abc *)
and %v4@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371ac0 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v5.s[0]                   #! PC = 0xaaaabe371ac4 *)
smlal	%%v16.2d, %%v14.2s, %%v5.s[0]                   #! 0xaaaabe371ac4 = 0xaaaabe371ac4;
(* smlal2	v16.2d, v14.4s, v5.s[2]                  #! PC = 0xaaaabe371ac8 *)
smlal2	%%v16.2d, %%v14.4s, %%v5.s[2]                  #! 0xaaaabe371ac8 = 0xaaaabe371ac8;
(* smlal	v16.2d, v13.2s, v5.s[1]                   #! PC = 0xaaaabe371acc *)
smlal	%%v16.2d, %%v13.2s, %%v5.s[1]                   #! 0xaaaabe371acc = 0xaaaabe371acc;
(* smlal2	v16.2d, v13.4s, v5.s[3]                  #! PC = 0xaaaabe371ad0 *)
smlal2	%%v16.2d, %%v13.4s, %%v5.s[3]                  #! 0xaaaabe371ad0 = 0xaaaabe371ad0;
(* and	v17.16b, v16.16b, v1.16b                    #! PC = 0xaaaabe371ad4 *)
and %v17@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371ad8 *)
split %v16 %dc %v16 30;
(* shl	v17.2d, v17.2d, #32                         #! PC = 0xaaaabe371adc *)
shls %dc %v17 %v17 [32, 32];
(* orr	v4.16b, v4.16b, v17.16b                     #! PC = 0xaaaabe371ae0 *)
or %v4@uint64[2] %v4 %v17;
(* smlal	v16.2d, v14.2s, v5.s[1]                   #! PC = 0xaaaabe371ae4 *)
smlal	%%v16.2d, %%v14.2s, %%v5.s[1]                   #! 0xaaaabe371ae4 = 0xaaaabe371ae4;
(* smlal2	v16.2d, v14.4s, v5.s[3]                  #! PC = 0xaaaabe371ae8 *)
smlal2	%%v16.2d, %%v14.4s, %%v5.s[3]                  #! 0xaaaabe371ae8 = 0xaaaabe371ae8;
(* smlal	v16.2d, v13.2s, v6.s[0]                   #! PC = 0xaaaabe371aec *)
smlal	%%v16.2d, %%v13.2s, %%v6.s[0]                   #! 0xaaaabe371aec = 0xaaaabe371aec;
(* smlal2	v16.2d, v13.4s, v6.s[2]                  #! PC = 0xaaaabe371af0 *)
smlal2	%%v16.2d, %%v13.4s, %%v6.s[2]                  #! 0xaaaabe371af0 = 0xaaaabe371af0;
(* and	v5.16b, v16.16b, v1.16b                     #! PC = 0xaaaabe371af4 *)
and %v5@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371af8 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v6.s[0]                   #! PC = 0xaaaabe371afc *)
smlal	%%v16.2d, %%v14.2s, %%v6.s[0]                   #! 0xaaaabe371afc = 0xaaaabe371afc;
(* smlal2	v16.2d, v14.4s, v6.s[2]                  #! PC = 0xaaaabe371b00 *)
smlal2	%%v16.2d, %%v14.4s, %%v6.s[2]                  #! 0xaaaabe371b00 = 0xaaaabe371b00;
(* smlal	v16.2d, v13.2s, v6.s[1]                   #! PC = 0xaaaabe371b04 *)
smlal	%%v16.2d, %%v13.2s, %%v6.s[1]                   #! 0xaaaabe371b04 = 0xaaaabe371b04;
(* smlal2	v16.2d, v13.4s, v6.s[3]                  #! PC = 0xaaaabe371b08 *)
smlal2	%%v16.2d, %%v13.4s, %%v6.s[3]                  #! 0xaaaabe371b08 = 0xaaaabe371b08;
(* and	v17.16b, v16.16b, v1.16b                    #! PC = 0xaaaabe371b0c *)
and %v17@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371b10 *)
split %v16 %dc %v16 30;
(* shl	v17.2d, v17.2d, #32                         #! PC = 0xaaaabe371b14 *)
shls %dc %v17 %v17 [32, 32];
(* orr	v5.16b, v5.16b, v17.16b                     #! PC = 0xaaaabe371b18 *)
or %v5@uint64[2] %v5 %v17;
(* smlal	v16.2d, v14.2s, v6.s[1]                   #! PC = 0xaaaabe371b1c *)
smlal	%%v16.2d, %%v14.2s, %%v6.s[1]                   #! 0xaaaabe371b1c = 0xaaaabe371b1c;
(* smlal2	v16.2d, v14.4s, v6.s[3]                  #! PC = 0xaaaabe371b20 *)
smlal2	%%v16.2d, %%v14.4s, %%v6.s[3]                  #! 0xaaaabe371b20 = 0xaaaabe371b20;
(* smlal	v16.2d, v13.2s, v7.s[0]                   #! PC = 0xaaaabe371b24 *)
smlal	%%v16.2d, %%v13.2s, %%v7.s[0]                   #! 0xaaaabe371b24 = 0xaaaabe371b24;
(* smlal2	v16.2d, v13.4s, v7.s[2]                  #! PC = 0xaaaabe371b28 *)
smlal2	%%v16.2d, %%v13.4s, %%v7.s[2]                  #! 0xaaaabe371b28 = 0xaaaabe371b28;
(* and	v6.16b, v16.16b, v1.16b                     #! PC = 0xaaaabe371b2c *)
and %v6@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371b30 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v7.s[0]                   #! PC = 0xaaaabe371b34 *)
smlal	%%v16.2d, %%v14.2s, %%v7.s[0]                   #! 0xaaaabe371b34 = 0xaaaabe371b34;
(* smlal2	v16.2d, v14.4s, v7.s[2]                  #! PC = 0xaaaabe371b38 *)
smlal2	%%v16.2d, %%v14.4s, %%v7.s[2]                  #! 0xaaaabe371b38 = 0xaaaabe371b38;
(* and	v17.16b, v16.16b, v1.16b                    #! PC = 0xaaaabe371b3c *)
and %v17@uint64[2] %v16 %v1;
(* sshr	v7.2d, v16.2d, #30                         #! PC = 0xaaaabe371b40 *)
split %v7 %dc %v16 30;
(* shl	v17.2d, v17.2d, #32                         #! PC = 0xaaaabe371b44 *)
shls %dc %v17 %v17 [32, 32];
(* orr	v6.16b, v6.16b, v17.16b                     #! PC = 0xaaaabe371b48 *)
or %v6@uint64[2] %v6 %v17;
(* and	x7, x1, #0xfffff                            #! PC = 0xaaaabe371b4c *)
and x7@uint64 x1 0xfffff@uint64;
(* and	x8, x2, #0xfffff                            #! PC = 0xaaaabe371b50 *)
and x8@uint64 x2 0xfffff@uint64;
(* orr	x7, x7, #0xfffffe0000000000                 #! PC = 0xaaaabe371b54 *)
or x7@uint64 x7 0xfffffe0000000000@uint64;
(* orr	x8, x8, #0xc000000000000000                 #! PC = 0xaaaabe371b58 *)
or x8@uint64 x8 0xc000000000000000@uint64;
(* tst	x8, #0x1                                    #! PC = 0xaaaabe371b5c *)
spl dc x8_lo x8 1;
and ne@bit x8_lo 1@bit;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371b60 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371b64 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371b68 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371b6c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371b70 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371b74 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371b78 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371b7c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371b80 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371b84 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371b88 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371b8c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371b90 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371b94 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371b98 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371b9c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371ba0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371ba4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371ba8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371bac *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371bb0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371bb4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371bb8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371bbc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371bc0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371bc4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371bc8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371bcc *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371bd0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371bd4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371bd8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371bdc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371be0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371be4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371be8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371bec *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371bf0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371bf4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371bf8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371bfc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c00 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c04 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c08 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c0c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371c10 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371c14 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371c18 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371c1c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371c20 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c24 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c28 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c2c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c30 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371c34 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371c38 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371c3c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371c40 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371c44 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c48 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c4c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c50 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c54 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371c58 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371c5c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371c60 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371c64 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371c68 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c6c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c70 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c74 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c78 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371c7c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371c80 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371c84 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371c88 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371c8c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c90 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c94 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c98 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c9c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371ca0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371ca4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371ca8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371cac *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371cb0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371cb4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371cb8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371cbc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371cc0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371cc4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371cc8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371ccc *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371cd0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371cd4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371cd8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371cdc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371ce0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371ce4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371ce8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371cec *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371cf0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371cf4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371cf8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371cfc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d00 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d04 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d08 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d0c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371d10 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371d14 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371d18 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371d1c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371d20 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d24 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d28 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d2c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d30 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371d34 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371d38 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371d3c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371d40 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371d44 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d48 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d4c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d50 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d54 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371d58 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371d5c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371d60 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371d64 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371d68 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d6c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d70 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d74 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d78 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371d7c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371d80 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371d84 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371d88 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371d8c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d90 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d94 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d98 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d9c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371da0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371da4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371da8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371dac *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371db0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371db4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371db8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371dbc *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371dc0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371dc4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371dc8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371dcc *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371dd0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371dd4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371dd8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371ddc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371de0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371de4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371de8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371dec *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371df0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371df4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371df8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371dfc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371e00 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371e04 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371e08 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371e0c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371e10 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371e14 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371e18 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371e1c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371e20 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371e24 *)
add x3 x3 0x2@sint64;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371e28 *)
ssplit x8 dcL x8 1;
(* add	x12, x7, x6                                 #! PC = 0xaaaabe371e2c *)
add x12 x7 x6;
(* asr	x12, x12, #42                               #! PC = 0xaaaabe371e30 *)
ssplit x12 dcL x12 42;
(* add	x11, x7, #0x100, lsl #12                    #! PC = 0xaaaabe371e34 *)
add x11 x7 0x100@sint64, lsl;
(* lsl	x11, x11, #22                               #! PC = 0xaaaabe371e38 *)
split dcH x11 x11 (64-22); shl x11 x11 22;
(* asr	x11, x11, #43                               #! PC = 0xaaaabe371e3c *)
ssplit x11 dcL x11 43;
(* add	x14, x8, x6                                 #! PC = 0xaaaabe371e40 *)
add x14 x8 x6;
(* asr	x14, x14, #42                               #! PC = 0xaaaabe371e44 *)
ssplit x14 dcL x14 42;
(* add	x13, x8, #0x100, lsl #12                    #! PC = 0xaaaabe371e48 *)
add x13 x8 0x100@sint64, lsl;
(* lsl	x13, x13, #22                               #! PC = 0xaaaabe371e4c *)
split dcH x13 x13 (64-22); shl x13 x13 22;
(* asr	x13, x13, #43                               #! PC = 0xaaaabe371e50 *)
ssplit x13 dcL x13 43;
(* mul	x9, x11, x1                                 #! PC = 0xaaaabe371e54 *)
mull dcH x9 x11 x1;
(* madd	x9, x12, x2, x9                            #! PC = 0xaaaabe371e58 *)
mull dcH mul_tmp x12 x2;
adds dc x9 mul_tmp x9;
(* asr	x9, x9, #20                                 #! PC = 0xaaaabe371e5c *)
ssplit x9 dcL x9 20;
(* mul	x10, x13, x1                                #! PC = 0xaaaabe371e60 *)
mull dcH x10 x13 x1;
(* madd	x10, x14, x2, x10                          #! PC = 0xaaaabe371e64 *)
mull dcH mul_tmp x14 x2;
adds dc x10 mul_tmp x10;
(* asr	x2, x10, #20                                #! PC = 0xaaaabe371e68 *)
ssplit x2 dcL x10 20;
(* mov	x1, x9                                      #! PC = 0xaaaabe371e6c *)
mov x1 x9;
(* mov	w4, v3.s[0]                                 #! PC = 0xaaaabe371e70 *)
mov w4 v3.s[0];
(* mov	w27, v3.s[1]                                #! PC = 0xaaaabe371e74 *)
mov w27 v3.s[1];
(* add	x4, x4, x27, lsl #30                        #! PC = 0xaaaabe371e78 *)
add x4 x4 x27, lsl;
(* mov	w27, v4.s[0]                                #! PC = 0xaaaabe371e7c *)
mov w27 v4.s[0];
(* add	x4, x4, x27, lsl #60                        #! PC = 0xaaaabe371e80 *)
add x4 x4 x27, lsl;
(* add	x21, xzr, x27, lsr #4                       #! PC = 0xaaaabe371e84 *)
add	%%x21, xzr, %%x27, lsr #4                       #! 0xaaaabe371e84 = 0xaaaabe371e84;
(* mov	w27, v4.s[1]                                #! PC = 0xaaaabe371e88 *)
mov w27 v4.s[1];
(* add	x21, x21, x27, lsl #26                      #! PC = 0xaaaabe371e8c *)
add x21 x21 x27, lsl;
(* mov	w5, v3.s[2]                                 #! PC = 0xaaaabe371e90 *)
mov w5 v3.s[2];
(* mov	w27, v3.s[3]                                #! PC = 0xaaaabe371e94 *)
mov w27 v3.s[3];
(* add	x5, x5, x27, lsl #30                        #! PC = 0xaaaabe371e98 *)
add x5 x5 x27, lsl;
(* mov	w27, v4.s[2]                                #! PC = 0xaaaabe371e9c *)
mov w27 v4.s[2];
(* add	x5, x5, x27, lsl #60                        #! PC = 0xaaaabe371ea0 *)
add x5 x5 x27, lsl;
(* add	x22, xzr, x27, lsr #4                       #! PC = 0xaaaabe371ea4 *)
add	%%x22, xzr, %%x27, lsr #4                       #! 0xaaaabe371ea4 = 0xaaaabe371ea4;
(* mov	w27, v4.s[3]                                #! PC = 0xaaaabe371ea8 *)
mov w27 v4.s[3];
(* add	x22, x22, x27, lsl #26                      #! PC = 0xaaaabe371eac *)
add x22 x22 x27, lsl;
(* and	x7, x1, #0xfffff                            #! PC = 0xaaaabe371eb0 *)
and x7@uint64 x1 0xfffff@uint64;
(* and	x8, x2, #0xfffff                            #! PC = 0xaaaabe371eb4 *)
and x8@uint64 x2 0xfffff@uint64;
(* orr	x7, x7, #0xfffffe0000000000                 #! PC = 0xaaaabe371eb8 *)
or x7@uint64 x7 0xfffffe0000000000@uint64;
(* orr	x8, x8, #0xc000000000000000                 #! PC = 0xaaaabe371ebc *)
or x8@uint64 x8 0xc000000000000000@uint64;
(* tst	x8, #0x1                                    #! PC = 0xaaaabe371ec0 *)
spl dc x8_lo x8 1;
and ne@bit x8_lo 1@bit;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371ec4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371ec8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371ecc *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371ed0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371ed4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371ed8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371edc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371ee0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371ee4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371ee8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371eec *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371ef0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371ef4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371ef8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371efc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f00 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f04 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f08 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f0c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371f10 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371f14 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371f18 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371f1c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371f20 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f24 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f28 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f2c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f30 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371f34 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371f38 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371f3c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371f40 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371f44 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f48 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f4c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f50 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f54 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371f58 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371f5c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371f60 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371f64 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371f68 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f6c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f70 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f74 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f78 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371f7c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371f80 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371f84 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371f88 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371f8c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f90 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f94 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f98 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f9c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371fa0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371fa4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371fa8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371fac *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371fb0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371fb4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371fb8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371fbc *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371fc0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371fc4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371fc8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371fcc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371fd0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371fd4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371fd8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371fdc *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371fe0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371fe4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371fe8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371fec *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371ff0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371ff4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371ff8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371ffc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372000 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372004 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372008 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37200c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372010 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372014 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372018 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37201c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372020 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372024 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372028 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37202c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372030 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372034 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372038 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37203c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372040 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372044 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372048 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37204c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372050 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372054 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372058 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37205c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372060 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372064 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372068 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37206c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372070 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372074 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372078 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37207c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372080 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372084 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372088 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37208c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372090 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372094 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372098 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37209c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3720a0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3720a4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3720a8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3720ac *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3720b0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3720b4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3720b8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3720bc *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3720c0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3720c4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3720c8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3720cc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3720d0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3720d4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3720d8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3720dc *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3720e0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3720e4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3720e8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3720ec *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3720f0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3720f4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3720f8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3720fc *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372100 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372104 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372108 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37210c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372110 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372114 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372118 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37211c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372120 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372124 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372128 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37212c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372130 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372134 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372138 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37213c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372140 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372144 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372148 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37214c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372150 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372154 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372158 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37215c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372160 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372164 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372168 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37216c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372170 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372174 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372178 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37217c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372180 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372184 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372188 *)
add x3 x3 0x2@sint64;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37218c *)
ssplit x8 dcL x8 1;
(* add	x16, x7, x6                                 #! PC = 0xaaaabe372190 *)
add x16 x7 x6;
(* asr	x16, x16, #42                               #! PC = 0xaaaabe372194 *)
ssplit x16 dcL x16 42;
(* add	x15, x7, #0x100, lsl #12                    #! PC = 0xaaaabe372198 *)
add x15 x7 0x100@sint64, lsl;
(* lsl	x15, x15, #22                               #! PC = 0xaaaabe37219c *)
split dcH x15 x15 (64-22); shl x15 x15 22;
(* asr	x15, x15, #43                               #! PC = 0xaaaabe3721a0 *)
ssplit x15 dcL x15 43;
(* add	x20, x8, x6                                 #! PC = 0xaaaabe3721a4 *)
add x20 x8 x6;
(* asr	x20, x20, #42                               #! PC = 0xaaaabe3721a8 *)
ssplit x20 dcL x20 42;
(* add	x17, x8, #0x100, lsl #12                    #! PC = 0xaaaabe3721ac *)
add x17 x8 0x100@sint64, lsl;
(* lsl	x17, x17, #22                               #! PC = 0xaaaabe3721b0 *)
split dcH x17 x17 (64-22); shl x17 x17 22;
(* asr	x17, x17, #43                               #! PC = 0xaaaabe3721b4 *)
ssplit x17 dcL x17 43;
(* mul	x9, x15, x1                                 #! PC = 0xaaaabe3721b8 *)
mull dcH x9 x15 x1;
(* madd	x9, x16, x2, x9                            #! PC = 0xaaaabe3721bc *)
mull dcH mul_tmp x16 x2;
adds dc x9 mul_tmp x9;
(* asr	x9, x9, #20                                 #! PC = 0xaaaabe3721c0 *)
ssplit x9 dcL x9 20;
(* mul	x10, x17, x1                                #! PC = 0xaaaabe3721c4 *)
mull dcH x10 x17 x1;
(* madd	x10, x20, x2, x10                          #! PC = 0xaaaabe3721c8 *)
mull dcH mul_tmp x20 x2;
adds dc x10 mul_tmp x10;
(* asr	x2, x10, #20                                #! PC = 0xaaaabe3721cc *)
ssplit x2 dcL x10 20;
(* mov	x1, x9                                      #! PC = 0xaaaabe3721d0 *)
mov x1 x9;
(* mul	x9, x15, x11                                #! PC = 0xaaaabe3721d4 *)
mull dcH x9 x15 x11;
(* madd	x10, x16, x13, x9                          #! PC = 0xaaaabe3721d8 *)
mull dcH mul_tmp x16 x13;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x11                                #! PC = 0xaaaabe3721dc *)
mull dcH x9 x17 x11;
(* madd	x13, x20, x13, x9                          #! PC = 0xaaaabe3721e0 *)
mull dcH mul_tmp x20 x13;
adds dc x13 mul_tmp x9;
(* mov	x11, x10                                    #! PC = 0xaaaabe3721e4 *)
mov x11 x10;
(* mul	x9, x15, x12                                #! PC = 0xaaaabe3721e8 *)
mull dcH x9 x15 x12;
(* madd	x10, x16, x14, x9                          #! PC = 0xaaaabe3721ec *)
mull dcH mul_tmp x16 x14;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x12                                #! PC = 0xaaaabe3721f0 *)
mull dcH x9 x17 x12;
(* madd	x14, x20, x14, x9                          #! PC = 0xaaaabe3721f4 *)
mull dcH mul_tmp x20 x14;
adds dc x14 mul_tmp x9;
(* mov	x12, x10                                    #! PC = 0xaaaabe3721f8 *)
mov x12 x10;
(* mov	x9, #0x13                  	// #19          #! PC = 0xaaaabe3721fc *)
mov x9 0x13@uint64;
(* dup	v16.2d, x9                                  #! PC = 0xaaaabe372200 *)
mov %v16 [x9,x9];
(* smull	v17.2d, v13.2s, v8.s[0]                   #! PC = 0xaaaabe372204 *)
smull	%%v17.2d, %%v13.2s, %%v8.s[0]                   #! 0xaaaabe372204 = 0xaaaabe372204;
(* smlal2	v17.2d, v13.4s, v8.s[2]                  #! PC = 0xaaaabe372208 *)
smlal2	%%v17.2d, %%v13.4s, %%v8.s[2]                  #! 0xaaaabe372208 = 0xaaaabe372208;
(* mul	v19.4s, v17.4s, v15.4s                      #! PC = 0xaaaabe37220c *)
mul %v19 %v17 %v15;
(* and	v19.16b, v19.16b, v1.16b                    #! PC = 0xaaaabe372210 *)
and %v19@uint64[2] %v19 %v1;
(* uzp1	v19.4s, v19.4s, v19.4s                     #! PC = 0xaaaabe372214 *)
mov %v19 [%v19[0], %v19[2], %v19[0], %v19[2]];
(* smlsl	v17.2d, v19.2s, v16.s[0]                  #! PC = 0xaaaabe372218 *)
smlsl	%%v17.2d, %%v19.2s, %%v16.s[0]                  #! 0xaaaabe372218 = 0xaaaabe372218;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe37221c *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v8.s[0]                   #! PC = 0xaaaabe372220 *)
smlal	%%v17.2d, %%v14.2s, %%v8.s[0]                   #! 0xaaaabe372220 = 0xaaaabe372220;
(* smlal2	v17.2d, v14.4s, v8.s[2]                  #! PC = 0xaaaabe372224 *)
smlal2	%%v17.2d, %%v14.4s, %%v8.s[2]                  #! 0xaaaabe372224 = 0xaaaabe372224;
(* smlal	v17.2d, v13.2s, v8.s[1]                   #! PC = 0xaaaabe372228 *)
smlal	%%v17.2d, %%v13.2s, %%v8.s[1]                   #! 0xaaaabe372228 = 0xaaaabe372228;
(* smlal2	v17.2d, v13.4s, v8.s[3]                  #! PC = 0xaaaabe37222c *)
smlal2	%%v17.2d, %%v13.4s, %%v8.s[3]                  #! 0xaaaabe37222c = 0xaaaabe37222c;
(* mul	v20.4s, v17.4s, v15.4s                      #! PC = 0xaaaabe372230 *)
mul %v20 %v17 %v15;
(* and	v20.16b, v20.16b, v1.16b                    #! PC = 0xaaaabe372234 *)
and %v20@uint64[2] %v20 %v1;
(* uzp1	v20.4s, v20.4s, v20.4s                     #! PC = 0xaaaabe372238 *)
mov %v20 [%v20[0], %v20[2], %v20[0], %v20[2]];
(* smlsl	v17.2d, v20.2s, v16.s[0]                  #! PC = 0xaaaabe37223c *)
smlsl	%%v17.2d, %%v20.2s, %%v16.s[0]                  #! 0xaaaabe37223c = 0xaaaabe37223c;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe372240 *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v8.s[1]                   #! PC = 0xaaaabe372244 *)
smlal	%%v17.2d, %%v14.2s, %%v8.s[1]                   #! 0xaaaabe372244 = 0xaaaabe372244;
(* smlal2	v17.2d, v14.4s, v8.s[3]                  #! PC = 0xaaaabe372248 *)
smlal2	%%v17.2d, %%v14.4s, %%v8.s[3]                  #! 0xaaaabe372248 = 0xaaaabe372248;
(* smlal	v17.2d, v13.2s, v9.s[0]                   #! PC = 0xaaaabe37224c *)
smlal	%%v17.2d, %%v13.2s, %%v9.s[0]                   #! 0xaaaabe37224c = 0xaaaabe37224c;
(* smlal2	v17.2d, v13.4s, v9.s[2]                  #! PC = 0xaaaabe372250 *)
smlal2	%%v17.2d, %%v13.4s, %%v9.s[2]                  #! 0xaaaabe372250 = 0xaaaabe372250;
(* and	v8.16b, v17.16b, v1.16b                     #! PC = 0xaaaabe372254 *)
and %v8@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe372258 *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v9.s[0]                   #! PC = 0xaaaabe37225c *)
smlal	%%v17.2d, %%v14.2s, %%v9.s[0]                   #! 0xaaaabe37225c = 0xaaaabe37225c;
(* smlal2	v17.2d, v14.4s, v9.s[2]                  #! PC = 0xaaaabe372260 *)
smlal2	%%v17.2d, %%v14.4s, %%v9.s[2]                  #! 0xaaaabe372260 = 0xaaaabe372260;
(* smlal	v17.2d, v13.2s, v9.s[1]                   #! PC = 0xaaaabe372264 *)
smlal	%%v17.2d, %%v13.2s, %%v9.s[1]                   #! 0xaaaabe372264 = 0xaaaabe372264;
(* smlal2	v17.2d, v13.4s, v9.s[3]                  #! PC = 0xaaaabe372268 *)
smlal2	%%v17.2d, %%v13.4s, %%v9.s[3]                  #! 0xaaaabe372268 = 0xaaaabe372268;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe37226c *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe372270 *)
split %v17 %dc %v17 30;
(* sli	v8.2d, v18.2d, #32                          #! PC = 0xaaaabe372274 *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v8 %v8 32; or %v8@uint64[2] %slih %v8;
(* smlal	v17.2d, v14.2s, v9.s[1]                   #! PC = 0xaaaabe372278 *)
smlal	%%v17.2d, %%v14.2s, %%v9.s[1]                   #! 0xaaaabe372278 = 0xaaaabe372278;
(* smlal2	v17.2d, v14.4s, v9.s[3]                  #! PC = 0xaaaabe37227c *)
smlal2	%%v17.2d, %%v14.4s, %%v9.s[3]                  #! 0xaaaabe37227c = 0xaaaabe37227c;
(* smlal	v17.2d, v13.2s, v10.s[0]                  #! PC = 0xaaaabe372280 *)
smlal	%%v17.2d, %%v13.2s, %%v10.s[0]                  #! 0xaaaabe372280 = 0xaaaabe372280;
(* smlal2	v17.2d, v13.4s, v10.s[2]                 #! PC = 0xaaaabe372284 *)
smlal2	%%v17.2d, %%v13.4s, %%v10.s[2]                 #! 0xaaaabe372284 = 0xaaaabe372284;
(* and	v9.16b, v17.16b, v1.16b                     #! PC = 0xaaaabe372288 *)
and %v9@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe37228c *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v10.s[0]                  #! PC = 0xaaaabe372290 *)
smlal	%%v17.2d, %%v14.2s, %%v10.s[0]                  #! 0xaaaabe372290 = 0xaaaabe372290;
(* smlal2	v17.2d, v14.4s, v10.s[2]                 #! PC = 0xaaaabe372294 *)
smlal2	%%v17.2d, %%v14.4s, %%v10.s[2]                 #! 0xaaaabe372294 = 0xaaaabe372294;
(* smlal	v17.2d, v13.2s, v10.s[1]                  #! PC = 0xaaaabe372298 *)
smlal	%%v17.2d, %%v13.2s, %%v10.s[1]                  #! 0xaaaabe372298 = 0xaaaabe372298;
(* smlal2	v17.2d, v13.4s, v10.s[3]                 #! PC = 0xaaaabe37229c *)
smlal2	%%v17.2d, %%v13.4s, %%v10.s[3]                 #! 0xaaaabe37229c = 0xaaaabe37229c;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe3722a0 *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3722a4 *)
split %v17 %dc %v17 30;
(* sli	v9.2d, v18.2d, #32                          #! PC = 0xaaaabe3722a8 *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v9 %v9 32; or %v9@uint64[2] %slih %v9;
(* smlal	v17.2d, v14.2s, v10.s[1]                  #! PC = 0xaaaabe3722ac *)
smlal	%%v17.2d, %%v14.2s, %%v10.s[1]                  #! 0xaaaabe3722ac = 0xaaaabe3722ac;
(* smlal2	v17.2d, v14.4s, v10.s[3]                 #! PC = 0xaaaabe3722b0 *)
smlal2	%%v17.2d, %%v14.4s, %%v10.s[3]                 #! 0xaaaabe3722b0 = 0xaaaabe3722b0;
(* smlal	v17.2d, v13.2s, v11.s[0]                  #! PC = 0xaaaabe3722b4 *)
smlal	%%v17.2d, %%v13.2s, %%v11.s[0]                  #! 0xaaaabe3722b4 = 0xaaaabe3722b4;
(* smlal2	v17.2d, v13.4s, v11.s[2]                 #! PC = 0xaaaabe3722b8 *)
smlal2	%%v17.2d, %%v13.4s, %%v11.s[2]                 #! 0xaaaabe3722b8 = 0xaaaabe3722b8;
(* and	v10.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe3722bc *)
and %v10@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3722c0 *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v11.s[0]                  #! PC = 0xaaaabe3722c4 *)
smlal	%%v17.2d, %%v14.2s, %%v11.s[0]                  #! 0xaaaabe3722c4 = 0xaaaabe3722c4;
(* smlal2	v17.2d, v14.4s, v11.s[2]                 #! PC = 0xaaaabe3722c8 *)
smlal2	%%v17.2d, %%v14.4s, %%v11.s[2]                 #! 0xaaaabe3722c8 = 0xaaaabe3722c8;
(* smlal	v17.2d, v13.2s, v11.s[1]                  #! PC = 0xaaaabe3722cc *)
smlal	%%v17.2d, %%v13.2s, %%v11.s[1]                  #! 0xaaaabe3722cc = 0xaaaabe3722cc;
(* smlal2	v17.2d, v13.4s, v11.s[3]                 #! PC = 0xaaaabe3722d0 *)
smlal2	%%v17.2d, %%v13.4s, %%v11.s[3]                 #! 0xaaaabe3722d0 = 0xaaaabe3722d0;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe3722d4 *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3722d8 *)
split %v17 %dc %v17 30;
(* sli	v10.2d, v18.2d, #32                         #! PC = 0xaaaabe3722dc *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v10 %v10 32; or %v10@uint64[2] %slih %v10;
(* smlal	v17.2d, v14.2s, v11.s[1]                  #! PC = 0xaaaabe3722e0 *)
smlal	%%v17.2d, %%v14.2s, %%v11.s[1]                  #! 0xaaaabe3722e0 = 0xaaaabe3722e0;
(* smlal2	v17.2d, v14.4s, v11.s[3]                 #! PC = 0xaaaabe3722e4 *)
smlal2	%%v17.2d, %%v14.4s, %%v11.s[3]                 #! 0xaaaabe3722e4 = 0xaaaabe3722e4;
(* smlal	v17.2d, v13.2s, v12.s[0]                  #! PC = 0xaaaabe3722e8 *)
smlal	%%v17.2d, %%v13.2s, %%v12.s[0]                  #! 0xaaaabe3722e8 = 0xaaaabe3722e8;
(* smlal2	v17.2d, v13.4s, v12.s[2]                 #! PC = 0xaaaabe3722ec *)
smlal2	%%v17.2d, %%v13.4s, %%v12.s[2]                 #! 0xaaaabe3722ec = 0xaaaabe3722ec;
(* ushll	v19.2d, v19.2s, #15                       #! PC = 0xaaaabe3722f0 *)
ushll	%%v19.2d, %%v19.2s, #15                       #! 0xaaaabe3722f0 = 0xaaaabe3722f0;
(* add	v17.2d, v17.2d, v19.2d                      #! PC = 0xaaaabe3722f4 *)
add	%%v17.2d, %%v17.2d, %%v19.2d                      #! 0xaaaabe3722f4 = 0xaaaabe3722f4;
(* and	v11.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe3722f8 *)
and %v11@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3722fc *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v12.s[0]                  #! PC = 0xaaaabe372300 *)
smlal	%%v17.2d, %%v14.2s, %%v12.s[0]                  #! 0xaaaabe372300 = 0xaaaabe372300;
(* smlal2	v17.2d, v14.4s, v12.s[2]                 #! PC = 0xaaaabe372304 *)
smlal2	%%v17.2d, %%v14.4s, %%v12.s[2]                 #! 0xaaaabe372304 = 0xaaaabe372304;
(* ushll	v20.2d, v20.2s, #15                       #! PC = 0xaaaabe372308 *)
ushll	%%v20.2d, %%v20.2s, #15                       #! 0xaaaabe372308 = 0xaaaabe372308;
(* add	v17.2d, v17.2d, v20.2d                      #! PC = 0xaaaabe37230c *)
add	%%v17.2d, %%v17.2d, %%v20.2d                      #! 0xaaaabe37230c = 0xaaaabe37230c;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe372310 *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v12.2d, v17.2d, #30                        #! PC = 0xaaaabe372314 *)
split %v12 %dc %v17 30;
(* sli	v11.2d, v18.2d, #32                         #! PC = 0xaaaabe372318 *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v11 %v11 32; or %v11@uint64[2] %slih %v11;
(* sshr	v18.2d, v12.2d, #15                        #! PC = 0xaaaabe37231c *)
split %v18 %dc %v12 15;
(* shl	v17.2d, v18.2d, #15                         #! PC = 0xaaaabe372320 *)
shls %dc %v17 %v18 [15, 15];
(* sub	v12.2d, v12.2d, v17.2d                      #! PC = 0xaaaabe372324 *)
sub	%%v12.2d, %%v12.2d, %%v17.2d                      #! 0xaaaabe372324 = 0xaaaabe372324;
(* mla	v8.4s, v18.4s, v16.4s                       #! PC = 0xaaaabe372328 *)
mull %dc %mla %v18 %v16; add %v8 %v8 %mla;
(* and	x7, x1, #0xfffff                            #! PC = 0xaaaabe37232c *)
and x7@uint64 x1 0xfffff@uint64;
(* and	x8, x2, #0xfffff                            #! PC = 0xaaaabe372330 *)
and x8@uint64 x2 0xfffff@uint64;
(* orr	x7, x7, #0xfffffe0000000000                 #! PC = 0xaaaabe372334 *)
or x7@uint64 x7 0xfffffe0000000000@uint64;
(* orr	x8, x8, #0xc000000000000000                 #! PC = 0xaaaabe372338 *)
or x8@uint64 x8 0xc000000000000000@uint64;
(* tst	x8, #0x1                                    #! PC = 0xaaaabe37233c *)
spl dc x8_lo x8 1;
and ne@bit x8_lo 1@bit;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372340 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372344 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372348 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37234c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372350 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372354 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372358 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37235c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372360 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372364 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372368 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37236c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372370 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372374 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372378 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37237c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372380 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372384 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372388 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37238c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372390 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372394 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372398 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37239c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3723a0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3723a4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3723a8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3723ac *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3723b0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3723b4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3723b8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3723bc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3723c0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3723c4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3723c8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3723cc *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3723d0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3723d4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3723d8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3723dc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3723e0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3723e4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3723e8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3723ec *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3723f0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3723f4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3723f8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3723fc *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372400 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372404 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372408 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37240c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372410 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372414 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372418 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37241c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372420 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372424 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372428 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37242c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372430 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372434 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372438 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37243c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372440 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372444 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372448 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37244c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372450 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372454 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372458 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37245c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372460 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372464 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372468 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37246c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372470 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372474 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372478 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37247c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372480 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372484 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372488 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37248c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372490 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372494 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372498 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37249c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3724a0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3724a4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3724a8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3724ac *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3724b0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3724b4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3724b8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3724bc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3724c0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3724c4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3724c8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3724cc *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3724d0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3724d4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3724d8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3724dc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3724e0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3724e4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3724e8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3724ec *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3724f0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3724f4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3724f8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3724fc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372500 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372504 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372508 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37250c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372510 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372514 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372518 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37251c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372520 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372524 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372528 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37252c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372530 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372534 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372538 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37253c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372540 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372544 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372548 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37254c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372550 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372554 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372558 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37255c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372560 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372564 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372568 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37256c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372570 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372574 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372578 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37257c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372580 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372584 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372588 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37258c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372590 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372594 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372598 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37259c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3725a0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3725a4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3725a8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3725ac *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3725b0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3725b4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3725b8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3725bc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3725c0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3725c4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3725c8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3725cc *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3725d0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3725d4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3725d8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3725dc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3725e0 *)
add x3 x3 0x2@sint64;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3725e4 *)
ssplit x8 dcL x8 1;
(* add	x16, x7, x6                                 #! PC = 0xaaaabe3725e8 *)
add x16 x7 x6;
(* asr	x16, x16, #42                               #! PC = 0xaaaabe3725ec *)
ssplit x16 dcL x16 42;
(* add	x15, x7, #0x100, lsl #12                    #! PC = 0xaaaabe3725f0 *)
add x15 x7 0x100@sint64, lsl;
(* lsl	x15, x15, #22                               #! PC = 0xaaaabe3725f4 *)
split dcH x15 x15 (64-22); shl x15 x15 22;
(* asr	x15, x15, #43                               #! PC = 0xaaaabe3725f8 *)
ssplit x15 dcL x15 43;
(* add	x20, x8, x6                                 #! PC = 0xaaaabe3725fc *)
add x20 x8 x6;
(* asr	x20, x20, #42                               #! PC = 0xaaaabe372600 *)
ssplit x20 dcL x20 42;
(* add	x17, x8, #0x100, lsl #12                    #! PC = 0xaaaabe372604 *)
add x17 x8 0x100@sint64, lsl;
(* lsl	x17, x17, #22                               #! PC = 0xaaaabe372608 *)
split dcH x17 x17 (64-22); shl x17 x17 22;
(* asr	x17, x17, #43                               #! PC = 0xaaaabe37260c *)
ssplit x17 dcL x17 43;
(* mul	x9, x15, x11                                #! PC = 0xaaaabe372610 *)
mull dcH x9 x15 x11;
(* madd	x10, x16, x13, x9                          #! PC = 0xaaaabe372614 *)
mull dcH mul_tmp x16 x13;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x11                                #! PC = 0xaaaabe372618 *)
mull dcH x9 x17 x11;
(* madd	x13, x20, x13, x9                          #! PC = 0xaaaabe37261c *)
mull dcH mul_tmp x20 x13;
adds dc x13 mul_tmp x9;
(* mov	x11, x10                                    #! PC = 0xaaaabe372620 *)
mov x11 x10;
(* mul	x9, x15, x12                                #! PC = 0xaaaabe372624 *)
mull dcH x9 x15 x12;
(* madd	x10, x16, x14, x9                          #! PC = 0xaaaabe372628 *)
mull dcH mul_tmp x16 x14;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x12                                #! PC = 0xaaaabe37262c *)
mull dcH x9 x17 x12;
(* madd	x14, x20, x14, x9                          #! PC = 0xaaaabe372630 *)
mull dcH mul_tmp x20 x14;
adds dc x14 mul_tmp x9;
(* mov	x12, x10                                    #! PC = 0xaaaabe372634 *)
mov x12 x10;
(* subs	x19, x19, #0x1                             #! PC = 0xaaaabe372638 *)
subc carry x19 x19 0x1@uint64;
(* #cbnz	x19, 0xaaaabe371960 <Lbig_loop>           #! PC = 0xaaaabe37263c *)
#cbnz	%%x19, 0xaaaabe371960 <Lbig_loop>           #! 0xaaaabe37263c = 0xaaaabe37263c;
(* mov	v16.d[0], x11                               #! PC = 0xaaaabe371960 *)
mov %v16 [x11, %v16[1]];
(* mov	v16.d[1], x13                               #! PC = 0xaaaabe371964 *)
mov %v16 [%v16[0], x13];
(* mov	v17.d[0], x12                               #! PC = 0xaaaabe371968 *)
mov %v17 [x12, %v17[1]];
(* mov	v17.d[1], x14                               #! PC = 0xaaaabe37196c *)
mov %v17 [%v17[0], x14];
(* uzp1	v13.4s, v16.4s, v17.4s                     #! PC = 0xaaaabe371970 *)
mov %v13 [%v16[0], %v16[2], %v17[0], %v17[2]];
(* and	v13.16b, v13.16b, v2.16b                    #! PC = 0xaaaabe371974 *)
and %v13@uint64[2] %v13 %v2;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371978 *)
split %v16 %dc %v16 30;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe37197c *)
split %v17 %dc %v17 30;
(* uzp1	v14.4s, v16.4s, v17.4s                     #! PC = 0xaaaabe371980 *)
mov %v14 [%v16[0], %v16[2], %v17[0], %v17[2]];
(* cmp	x11, xzr                                    #! PC = 0xaaaabe371984 *)
subc zero dc 0@uint64 x11;
(* csetm	x23, mi	// mi = first                     #! PC = 0xaaaabe371988 *)
csetm	%%x23, mi	// mi = first                     #! 0xaaaabe371988 = 0xaaaabe371988;
(* cneg	x11, x11, mi	// mi = first                 #! PC = 0xaaaabe37198c *)
cneg	%%x11, %%x11, mi	// mi = first                 #! 0xaaaabe37198c = 0xaaaabe37198c;
(* cmp	x12, xzr                                    #! PC = 0xaaaabe371990 *)
subc zero dc 0@uint64 x12;
(* csetm	x24, mi	// mi = first                     #! PC = 0xaaaabe371994 *)
csetm	%%x24, mi	// mi = first                     #! 0xaaaabe371994 = 0xaaaabe371994;
(* cneg	x12, x12, mi	// mi = first                 #! PC = 0xaaaabe371998 *)
cneg	%%x12, %%x12, mi	// mi = first                 #! 0xaaaabe371998 = 0xaaaabe371998;
(* cmp	x13, xzr                                    #! PC = 0xaaaabe37199c *)
subc zero dc 0@uint64 x13;
(* csetm	x25, mi	// mi = first                     #! PC = 0xaaaabe3719a0 *)
csetm	%%x25, mi	// mi = first                     #! 0xaaaabe3719a0 = 0xaaaabe3719a0;
(* cneg	x13, x13, mi	// mi = first                 #! PC = 0xaaaabe3719a4 *)
cneg	%%x13, %%x13, mi	// mi = first                 #! 0xaaaabe3719a4 = 0xaaaabe3719a4;
(* cmp	x14, xzr                                    #! PC = 0xaaaabe3719a8 *)
subc zero dc 0@uint64 x14;
(* csetm	x26, mi	// mi = first                     #! PC = 0xaaaabe3719ac *)
csetm	%%x26, mi	// mi = first                     #! 0xaaaabe3719ac = 0xaaaabe3719ac;
(* cneg	x14, x14, mi	// mi = first                 #! PC = 0xaaaabe3719b0 *)
cneg	%%x14, %%x14, mi	// mi = first                 #! 0xaaaabe3719b0 = 0xaaaabe3719b0;
(* and	x27, x11, x23                               #! PC = 0xaaaabe3719b4 *)
and x27@uint64 x11 x23;
(* and	x28, x12, x24                               #! PC = 0xaaaabe3719b8 *)
and x28@uint64 x12 x24;
(* add	x15, x27, x28                               #! PC = 0xaaaabe3719bc *)
add x15 x27 x28;
(* eor	x27, x4, x23                                #! PC = 0xaaaabe3719c0 *)
xor x27@uint64 x4 x23;
(* mul	x9, x27, x11                                #! PC = 0xaaaabe3719c4 *)
mull dcH x9 x27 x11;
(* umulh	x10, x27, x11                             #! PC = 0xaaaabe3719c8 *)
mull x10 dcL x27 x11;
(* adds	x15, x9, x15                               #! PC = 0xaaaabe3719cc *)
adds carry x15 x9 x15;
(* adc	x16, x10, xzr                               #! PC = 0xaaaabe3719d0 *)
adc x16 x10 0@uint64 carry;
(* eor	x27, x21, x23                               #! PC = 0xaaaabe3719d4 *)
xor x27@uint64 x21 x23;
(* mul	x9, x27, x11                                #! PC = 0xaaaabe3719d8 *)
mull dcH x9 x27 x11;
(* add	x16, x16, x9                                #! PC = 0xaaaabe3719dc *)
add x16 x16 x9;
(* eor	x27, x5, x24                                #! PC = 0xaaaabe3719e0 *)
xor x27@uint64 x5 x24;
(* mul	x9, x27, x12                                #! PC = 0xaaaabe3719e4 *)
mull dcH x9 x27 x12;
(* umulh	x10, x27, x12                             #! PC = 0xaaaabe3719e8 *)
mull x10 dcL x27 x12;
(* adds	x15, x9, x15                               #! PC = 0xaaaabe3719ec *)
adds carry x15 x9 x15;
(* adc	x16, x10, x16                               #! PC = 0xaaaabe3719f0 *)
adc x16 x10 x16 carry;
(* eor	x27, x22, x24                               #! PC = 0xaaaabe3719f4 *)
xor x27@uint64 x22 x24;
(* mul	x9, x27, x12                                #! PC = 0xaaaabe3719f8 *)
mull dcH x9 x27 x12;
(* add	x16, x16, x9                                #! PC = 0xaaaabe3719fc *)
add x16 x16 x9;
(* extr	x1, x16, x15, #60                          #! PC = 0xaaaabe371a00 *)
spl dc extr_H x16 60; spl extr_L dc x15 60; join x1 extr_H extr_L;
(* and	x27, x13, x25                               #! PC = 0xaaaabe371a04 *)
and x27@uint64 x13 x25;
(* and	x28, x14, x26                               #! PC = 0xaaaabe371a08 *)
and x28@uint64 x14 x26;
(* add	x17, x27, x28                               #! PC = 0xaaaabe371a0c *)
add x17 x27 x28;
(* eor	x27, x4, x25                                #! PC = 0xaaaabe371a10 *)
xor x27@uint64 x4 x25;
(* mul	x9, x27, x13                                #! PC = 0xaaaabe371a14 *)
mull dcH x9 x27 x13;
(* umulh	x10, x27, x13                             #! PC = 0xaaaabe371a18 *)
mull x10 dcL x27 x13;
(* adds	x17, x9, x17                               #! PC = 0xaaaabe371a1c *)
adds carry x17 x9 x17;
(* adc	x20, x10, xzr                               #! PC = 0xaaaabe371a20 *)
adc x20 x10 0@uint64 carry;
(* eor	x27, x21, x25                               #! PC = 0xaaaabe371a24 *)
xor x27@uint64 x21 x25;
(* mul	x9, x27, x13                                #! PC = 0xaaaabe371a28 *)
mull dcH x9 x27 x13;
(* add	x20, x20, x9                                #! PC = 0xaaaabe371a2c *)
add x20 x20 x9;
(* eor	x27, x5, x26                                #! PC = 0xaaaabe371a30 *)
xor x27@uint64 x5 x26;
(* mul	x9, x27, x14                                #! PC = 0xaaaabe371a34 *)
mull dcH x9 x27 x14;
(* umulh	x10, x27, x14                             #! PC = 0xaaaabe371a38 *)
mull x10 dcL x27 x14;
(* adds	x17, x9, x17                               #! PC = 0xaaaabe371a3c *)
adds carry x17 x9 x17;
(* adc	x20, x10, x20                               #! PC = 0xaaaabe371a40 *)
adc x20 x10 x20 carry;
(* eor	x27, x22, x26                               #! PC = 0xaaaabe371a44 *)
xor x27@uint64 x22 x26;
(* mul	x9, x27, x14                                #! PC = 0xaaaabe371a48 *)
mull dcH x9 x27 x14;
(* add	x20, x20, x9                                #! PC = 0xaaaabe371a4c *)
add x20 x20 x9;
(* extr	x2, x20, x17, #60                          #! PC = 0xaaaabe371a50 *)
spl dc extr_H x20 60; spl extr_L dc x17 60; join x2 extr_H extr_L;
(* smull	v16.2d, v13.2s, v3.s[0]                   #! PC = 0xaaaabe371a54 *)
smull	%%v16.2d, %%v13.2s, %%v3.s[0]                   #! 0xaaaabe371a54 = 0xaaaabe371a54;
(* smlal2	v16.2d, v13.4s, v3.s[2]                  #! PC = 0xaaaabe371a58 *)
smlal2	%%v16.2d, %%v13.4s, %%v3.s[2]                  #! 0xaaaabe371a58 = 0xaaaabe371a58;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371a5c *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v3.s[0]                   #! PC = 0xaaaabe371a60 *)
smlal	%%v16.2d, %%v14.2s, %%v3.s[0]                   #! 0xaaaabe371a60 = 0xaaaabe371a60;
(* smlal2	v16.2d, v14.4s, v3.s[2]                  #! PC = 0xaaaabe371a64 *)
smlal2	%%v16.2d, %%v14.4s, %%v3.s[2]                  #! 0xaaaabe371a64 = 0xaaaabe371a64;
(* smlal	v16.2d, v13.2s, v3.s[1]                   #! PC = 0xaaaabe371a68 *)
smlal	%%v16.2d, %%v13.2s, %%v3.s[1]                   #! 0xaaaabe371a68 = 0xaaaabe371a68;
(* smlal2	v16.2d, v13.4s, v3.s[3]                  #! PC = 0xaaaabe371a6c *)
smlal2	%%v16.2d, %%v13.4s, %%v3.s[3]                  #! 0xaaaabe371a6c = 0xaaaabe371a6c;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371a70 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v3.s[1]                   #! PC = 0xaaaabe371a74 *)
smlal	%%v16.2d, %%v14.2s, %%v3.s[1]                   #! 0xaaaabe371a74 = 0xaaaabe371a74;
(* smlal2	v16.2d, v14.4s, v3.s[3]                  #! PC = 0xaaaabe371a78 *)
smlal2	%%v16.2d, %%v14.4s, %%v3.s[3]                  #! 0xaaaabe371a78 = 0xaaaabe371a78;
(* smlal	v16.2d, v13.2s, v4.s[0]                   #! PC = 0xaaaabe371a7c *)
smlal	%%v16.2d, %%v13.2s, %%v4.s[0]                   #! 0xaaaabe371a7c = 0xaaaabe371a7c;
(* smlal2	v16.2d, v13.4s, v4.s[2]                  #! PC = 0xaaaabe371a80 *)
smlal2	%%v16.2d, %%v13.4s, %%v4.s[2]                  #! 0xaaaabe371a80 = 0xaaaabe371a80;
(* and	v3.16b, v16.16b, v1.16b                     #! PC = 0xaaaabe371a84 *)
and %v3@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371a88 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v4.s[0]                   #! PC = 0xaaaabe371a8c *)
smlal	%%v16.2d, %%v14.2s, %%v4.s[0]                   #! 0xaaaabe371a8c = 0xaaaabe371a8c;
(* smlal2	v16.2d, v14.4s, v4.s[2]                  #! PC = 0xaaaabe371a90 *)
smlal2	%%v16.2d, %%v14.4s, %%v4.s[2]                  #! 0xaaaabe371a90 = 0xaaaabe371a90;
(* smlal	v16.2d, v13.2s, v4.s[1]                   #! PC = 0xaaaabe371a94 *)
smlal	%%v16.2d, %%v13.2s, %%v4.s[1]                   #! 0xaaaabe371a94 = 0xaaaabe371a94;
(* smlal2	v16.2d, v13.4s, v4.s[3]                  #! PC = 0xaaaabe371a98 *)
smlal2	%%v16.2d, %%v13.4s, %%v4.s[3]                  #! 0xaaaabe371a98 = 0xaaaabe371a98;
(* and	v17.16b, v16.16b, v1.16b                    #! PC = 0xaaaabe371a9c *)
and %v17@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371aa0 *)
split %v16 %dc %v16 30;
(* shl	v17.2d, v17.2d, #32                         #! PC = 0xaaaabe371aa4 *)
shls %dc %v17 %v17 [32, 32];
(* orr	v3.16b, v3.16b, v17.16b                     #! PC = 0xaaaabe371aa8 *)
or %v3@uint64[2] %v3 %v17;
(* smlal	v16.2d, v14.2s, v4.s[1]                   #! PC = 0xaaaabe371aac *)
smlal	%%v16.2d, %%v14.2s, %%v4.s[1]                   #! 0xaaaabe371aac = 0xaaaabe371aac;
(* smlal2	v16.2d, v14.4s, v4.s[3]                  #! PC = 0xaaaabe371ab0 *)
smlal2	%%v16.2d, %%v14.4s, %%v4.s[3]                  #! 0xaaaabe371ab0 = 0xaaaabe371ab0;
(* smlal	v16.2d, v13.2s, v5.s[0]                   #! PC = 0xaaaabe371ab4 *)
smlal	%%v16.2d, %%v13.2s, %%v5.s[0]                   #! 0xaaaabe371ab4 = 0xaaaabe371ab4;
(* smlal2	v16.2d, v13.4s, v5.s[2]                  #! PC = 0xaaaabe371ab8 *)
smlal2	%%v16.2d, %%v13.4s, %%v5.s[2]                  #! 0xaaaabe371ab8 = 0xaaaabe371ab8;
(* and	v4.16b, v16.16b, v1.16b                     #! PC = 0xaaaabe371abc *)
and %v4@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371ac0 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v5.s[0]                   #! PC = 0xaaaabe371ac4 *)
smlal	%%v16.2d, %%v14.2s, %%v5.s[0]                   #! 0xaaaabe371ac4 = 0xaaaabe371ac4;
(* smlal2	v16.2d, v14.4s, v5.s[2]                  #! PC = 0xaaaabe371ac8 *)
smlal2	%%v16.2d, %%v14.4s, %%v5.s[2]                  #! 0xaaaabe371ac8 = 0xaaaabe371ac8;
(* smlal	v16.2d, v13.2s, v5.s[1]                   #! PC = 0xaaaabe371acc *)
smlal	%%v16.2d, %%v13.2s, %%v5.s[1]                   #! 0xaaaabe371acc = 0xaaaabe371acc;
(* smlal2	v16.2d, v13.4s, v5.s[3]                  #! PC = 0xaaaabe371ad0 *)
smlal2	%%v16.2d, %%v13.4s, %%v5.s[3]                  #! 0xaaaabe371ad0 = 0xaaaabe371ad0;
(* and	v17.16b, v16.16b, v1.16b                    #! PC = 0xaaaabe371ad4 *)
and %v17@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371ad8 *)
split %v16 %dc %v16 30;
(* shl	v17.2d, v17.2d, #32                         #! PC = 0xaaaabe371adc *)
shls %dc %v17 %v17 [32, 32];
(* orr	v4.16b, v4.16b, v17.16b                     #! PC = 0xaaaabe371ae0 *)
or %v4@uint64[2] %v4 %v17;
(* smlal	v16.2d, v14.2s, v5.s[1]                   #! PC = 0xaaaabe371ae4 *)
smlal	%%v16.2d, %%v14.2s, %%v5.s[1]                   #! 0xaaaabe371ae4 = 0xaaaabe371ae4;
(* smlal2	v16.2d, v14.4s, v5.s[3]                  #! PC = 0xaaaabe371ae8 *)
smlal2	%%v16.2d, %%v14.4s, %%v5.s[3]                  #! 0xaaaabe371ae8 = 0xaaaabe371ae8;
(* smlal	v16.2d, v13.2s, v6.s[0]                   #! PC = 0xaaaabe371aec *)
smlal	%%v16.2d, %%v13.2s, %%v6.s[0]                   #! 0xaaaabe371aec = 0xaaaabe371aec;
(* smlal2	v16.2d, v13.4s, v6.s[2]                  #! PC = 0xaaaabe371af0 *)
smlal2	%%v16.2d, %%v13.4s, %%v6.s[2]                  #! 0xaaaabe371af0 = 0xaaaabe371af0;
(* and	v5.16b, v16.16b, v1.16b                     #! PC = 0xaaaabe371af4 *)
and %v5@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371af8 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v6.s[0]                   #! PC = 0xaaaabe371afc *)
smlal	%%v16.2d, %%v14.2s, %%v6.s[0]                   #! 0xaaaabe371afc = 0xaaaabe371afc;
(* smlal2	v16.2d, v14.4s, v6.s[2]                  #! PC = 0xaaaabe371b00 *)
smlal2	%%v16.2d, %%v14.4s, %%v6.s[2]                  #! 0xaaaabe371b00 = 0xaaaabe371b00;
(* smlal	v16.2d, v13.2s, v6.s[1]                   #! PC = 0xaaaabe371b04 *)
smlal	%%v16.2d, %%v13.2s, %%v6.s[1]                   #! 0xaaaabe371b04 = 0xaaaabe371b04;
(* smlal2	v16.2d, v13.4s, v6.s[3]                  #! PC = 0xaaaabe371b08 *)
smlal2	%%v16.2d, %%v13.4s, %%v6.s[3]                  #! 0xaaaabe371b08 = 0xaaaabe371b08;
(* and	v17.16b, v16.16b, v1.16b                    #! PC = 0xaaaabe371b0c *)
and %v17@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371b10 *)
split %v16 %dc %v16 30;
(* shl	v17.2d, v17.2d, #32                         #! PC = 0xaaaabe371b14 *)
shls %dc %v17 %v17 [32, 32];
(* orr	v5.16b, v5.16b, v17.16b                     #! PC = 0xaaaabe371b18 *)
or %v5@uint64[2] %v5 %v17;
(* smlal	v16.2d, v14.2s, v6.s[1]                   #! PC = 0xaaaabe371b1c *)
smlal	%%v16.2d, %%v14.2s, %%v6.s[1]                   #! 0xaaaabe371b1c = 0xaaaabe371b1c;
(* smlal2	v16.2d, v14.4s, v6.s[3]                  #! PC = 0xaaaabe371b20 *)
smlal2	%%v16.2d, %%v14.4s, %%v6.s[3]                  #! 0xaaaabe371b20 = 0xaaaabe371b20;
(* smlal	v16.2d, v13.2s, v7.s[0]                   #! PC = 0xaaaabe371b24 *)
smlal	%%v16.2d, %%v13.2s, %%v7.s[0]                   #! 0xaaaabe371b24 = 0xaaaabe371b24;
(* smlal2	v16.2d, v13.4s, v7.s[2]                  #! PC = 0xaaaabe371b28 *)
smlal2	%%v16.2d, %%v13.4s, %%v7.s[2]                  #! 0xaaaabe371b28 = 0xaaaabe371b28;
(* and	v6.16b, v16.16b, v1.16b                     #! PC = 0xaaaabe371b2c *)
and %v6@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371b30 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v7.s[0]                   #! PC = 0xaaaabe371b34 *)
smlal	%%v16.2d, %%v14.2s, %%v7.s[0]                   #! 0xaaaabe371b34 = 0xaaaabe371b34;
(* smlal2	v16.2d, v14.4s, v7.s[2]                  #! PC = 0xaaaabe371b38 *)
smlal2	%%v16.2d, %%v14.4s, %%v7.s[2]                  #! 0xaaaabe371b38 = 0xaaaabe371b38;
(* and	v17.16b, v16.16b, v1.16b                    #! PC = 0xaaaabe371b3c *)
and %v17@uint64[2] %v16 %v1;
(* sshr	v7.2d, v16.2d, #30                         #! PC = 0xaaaabe371b40 *)
split %v7 %dc %v16 30;
(* shl	v17.2d, v17.2d, #32                         #! PC = 0xaaaabe371b44 *)
shls %dc %v17 %v17 [32, 32];
(* orr	v6.16b, v6.16b, v17.16b                     #! PC = 0xaaaabe371b48 *)
or %v6@uint64[2] %v6 %v17;
(* and	x7, x1, #0xfffff                            #! PC = 0xaaaabe371b4c *)
and x7@uint64 x1 0xfffff@uint64;
(* and	x8, x2, #0xfffff                            #! PC = 0xaaaabe371b50 *)
and x8@uint64 x2 0xfffff@uint64;
(* orr	x7, x7, #0xfffffe0000000000                 #! PC = 0xaaaabe371b54 *)
or x7@uint64 x7 0xfffffe0000000000@uint64;
(* orr	x8, x8, #0xc000000000000000                 #! PC = 0xaaaabe371b58 *)
or x8@uint64 x8 0xc000000000000000@uint64;
(* tst	x8, #0x1                                    #! PC = 0xaaaabe371b5c *)
spl dc x8_lo x8 1;
and ne@bit x8_lo 1@bit;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371b60 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371b64 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371b68 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371b6c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371b70 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371b74 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371b78 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371b7c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371b80 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371b84 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371b88 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371b8c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371b90 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371b94 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371b98 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371b9c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371ba0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371ba4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371ba8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371bac *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371bb0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371bb4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371bb8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371bbc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371bc0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371bc4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371bc8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371bcc *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371bd0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371bd4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371bd8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371bdc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371be0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371be4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371be8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371bec *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371bf0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371bf4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371bf8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371bfc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c00 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c04 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c08 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c0c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371c10 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371c14 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371c18 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371c1c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371c20 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c24 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c28 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c2c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c30 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371c34 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371c38 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371c3c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371c40 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371c44 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c48 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c4c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c50 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c54 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371c58 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371c5c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371c60 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371c64 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371c68 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c6c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c70 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c74 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c78 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371c7c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371c80 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371c84 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371c88 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371c8c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c90 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c94 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c98 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c9c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371ca0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371ca4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371ca8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371cac *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371cb0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371cb4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371cb8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371cbc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371cc0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371cc4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371cc8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371ccc *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371cd0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371cd4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371cd8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371cdc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371ce0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371ce4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371ce8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371cec *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371cf0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371cf4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371cf8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371cfc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d00 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d04 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d08 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d0c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371d10 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371d14 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371d18 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371d1c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371d20 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d24 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d28 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d2c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d30 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371d34 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371d38 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371d3c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371d40 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371d44 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d48 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d4c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d50 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d54 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371d58 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371d5c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371d60 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371d64 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371d68 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d6c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d70 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d74 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d78 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371d7c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371d80 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371d84 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371d88 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371d8c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d90 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d94 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d98 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d9c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371da0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371da4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371da8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371dac *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371db0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371db4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371db8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371dbc *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371dc0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371dc4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371dc8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371dcc *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371dd0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371dd4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371dd8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371ddc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371de0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371de4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371de8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371dec *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371df0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371df4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371df8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371dfc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371e00 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371e04 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371e08 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371e0c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371e10 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371e14 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371e18 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371e1c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371e20 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371e24 *)
add x3 x3 0x2@sint64;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371e28 *)
ssplit x8 dcL x8 1;
(* add	x12, x7, x6                                 #! PC = 0xaaaabe371e2c *)
add x12 x7 x6;
(* asr	x12, x12, #42                               #! PC = 0xaaaabe371e30 *)
ssplit x12 dcL x12 42;
(* add	x11, x7, #0x100, lsl #12                    #! PC = 0xaaaabe371e34 *)
add x11 x7 0x100@sint64, lsl;
(* lsl	x11, x11, #22                               #! PC = 0xaaaabe371e38 *)
split dcH x11 x11 (64-22); shl x11 x11 22;
(* asr	x11, x11, #43                               #! PC = 0xaaaabe371e3c *)
ssplit x11 dcL x11 43;
(* add	x14, x8, x6                                 #! PC = 0xaaaabe371e40 *)
add x14 x8 x6;
(* asr	x14, x14, #42                               #! PC = 0xaaaabe371e44 *)
ssplit x14 dcL x14 42;
(* add	x13, x8, #0x100, lsl #12                    #! PC = 0xaaaabe371e48 *)
add x13 x8 0x100@sint64, lsl;
(* lsl	x13, x13, #22                               #! PC = 0xaaaabe371e4c *)
split dcH x13 x13 (64-22); shl x13 x13 22;
(* asr	x13, x13, #43                               #! PC = 0xaaaabe371e50 *)
ssplit x13 dcL x13 43;
(* mul	x9, x11, x1                                 #! PC = 0xaaaabe371e54 *)
mull dcH x9 x11 x1;
(* madd	x9, x12, x2, x9                            #! PC = 0xaaaabe371e58 *)
mull dcH mul_tmp x12 x2;
adds dc x9 mul_tmp x9;
(* asr	x9, x9, #20                                 #! PC = 0xaaaabe371e5c *)
ssplit x9 dcL x9 20;
(* mul	x10, x13, x1                                #! PC = 0xaaaabe371e60 *)
mull dcH x10 x13 x1;
(* madd	x10, x14, x2, x10                          #! PC = 0xaaaabe371e64 *)
mull dcH mul_tmp x14 x2;
adds dc x10 mul_tmp x10;
(* asr	x2, x10, #20                                #! PC = 0xaaaabe371e68 *)
ssplit x2 dcL x10 20;
(* mov	x1, x9                                      #! PC = 0xaaaabe371e6c *)
mov x1 x9;
(* mov	w4, v3.s[0]                                 #! PC = 0xaaaabe371e70 *)
mov w4 v3.s[0];
(* mov	w27, v3.s[1]                                #! PC = 0xaaaabe371e74 *)
mov w27 v3.s[1];
(* add	x4, x4, x27, lsl #30                        #! PC = 0xaaaabe371e78 *)
add x4 x4 x27, lsl;
(* mov	w27, v4.s[0]                                #! PC = 0xaaaabe371e7c *)
mov w27 v4.s[0];
(* add	x4, x4, x27, lsl #60                        #! PC = 0xaaaabe371e80 *)
add x4 x4 x27, lsl;
(* add	x21, xzr, x27, lsr #4                       #! PC = 0xaaaabe371e84 *)
add	%%x21, xzr, %%x27, lsr #4                       #! 0xaaaabe371e84 = 0xaaaabe371e84;
(* mov	w27, v4.s[1]                                #! PC = 0xaaaabe371e88 *)
mov w27 v4.s[1];
(* add	x21, x21, x27, lsl #26                      #! PC = 0xaaaabe371e8c *)
add x21 x21 x27, lsl;
(* mov	w5, v3.s[2]                                 #! PC = 0xaaaabe371e90 *)
mov w5 v3.s[2];
(* mov	w27, v3.s[3]                                #! PC = 0xaaaabe371e94 *)
mov w27 v3.s[3];
(* add	x5, x5, x27, lsl #30                        #! PC = 0xaaaabe371e98 *)
add x5 x5 x27, lsl;
(* mov	w27, v4.s[2]                                #! PC = 0xaaaabe371e9c *)
mov w27 v4.s[2];
(* add	x5, x5, x27, lsl #60                        #! PC = 0xaaaabe371ea0 *)
add x5 x5 x27, lsl;
(* add	x22, xzr, x27, lsr #4                       #! PC = 0xaaaabe371ea4 *)
add	%%x22, xzr, %%x27, lsr #4                       #! 0xaaaabe371ea4 = 0xaaaabe371ea4;
(* mov	w27, v4.s[3]                                #! PC = 0xaaaabe371ea8 *)
mov w27 v4.s[3];
(* add	x22, x22, x27, lsl #26                      #! PC = 0xaaaabe371eac *)
add x22 x22 x27, lsl;
(* and	x7, x1, #0xfffff                            #! PC = 0xaaaabe371eb0 *)
and x7@uint64 x1 0xfffff@uint64;
(* and	x8, x2, #0xfffff                            #! PC = 0xaaaabe371eb4 *)
and x8@uint64 x2 0xfffff@uint64;
(* orr	x7, x7, #0xfffffe0000000000                 #! PC = 0xaaaabe371eb8 *)
or x7@uint64 x7 0xfffffe0000000000@uint64;
(* orr	x8, x8, #0xc000000000000000                 #! PC = 0xaaaabe371ebc *)
or x8@uint64 x8 0xc000000000000000@uint64;
(* tst	x8, #0x1                                    #! PC = 0xaaaabe371ec0 *)
spl dc x8_lo x8 1;
and ne@bit x8_lo 1@bit;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371ec4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371ec8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371ecc *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371ed0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371ed4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371ed8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371edc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371ee0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371ee4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371ee8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371eec *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371ef0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371ef4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371ef8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371efc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f00 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f04 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f08 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f0c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371f10 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371f14 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371f18 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371f1c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371f20 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f24 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f28 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f2c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f30 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371f34 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371f38 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371f3c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371f40 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371f44 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f48 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f4c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f50 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f54 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371f58 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371f5c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371f60 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371f64 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371f68 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f6c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f70 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f74 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f78 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371f7c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371f80 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371f84 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371f88 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371f8c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f90 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f94 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f98 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f9c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371fa0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371fa4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371fa8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371fac *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371fb0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371fb4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371fb8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371fbc *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371fc0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371fc4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371fc8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371fcc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371fd0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371fd4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371fd8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371fdc *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371fe0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371fe4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371fe8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371fec *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371ff0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371ff4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371ff8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371ffc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372000 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372004 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372008 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37200c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372010 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372014 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372018 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37201c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372020 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372024 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372028 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37202c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372030 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372034 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372038 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37203c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372040 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372044 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372048 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37204c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372050 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372054 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372058 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37205c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372060 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372064 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372068 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37206c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372070 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372074 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372078 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37207c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372080 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372084 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372088 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37208c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372090 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372094 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372098 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37209c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3720a0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3720a4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3720a8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3720ac *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3720b0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3720b4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3720b8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3720bc *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3720c0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3720c4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3720c8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3720cc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3720d0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3720d4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3720d8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3720dc *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3720e0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3720e4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3720e8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3720ec *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3720f0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3720f4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3720f8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3720fc *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372100 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372104 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372108 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37210c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372110 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372114 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372118 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37211c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372120 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372124 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372128 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37212c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372130 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372134 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372138 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37213c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372140 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372144 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372148 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37214c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372150 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372154 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372158 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37215c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372160 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372164 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372168 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37216c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372170 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372174 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372178 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37217c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372180 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372184 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372188 *)
add x3 x3 0x2@sint64;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37218c *)
ssplit x8 dcL x8 1;
(* add	x16, x7, x6                                 #! PC = 0xaaaabe372190 *)
add x16 x7 x6;
(* asr	x16, x16, #42                               #! PC = 0xaaaabe372194 *)
ssplit x16 dcL x16 42;
(* add	x15, x7, #0x100, lsl #12                    #! PC = 0xaaaabe372198 *)
add x15 x7 0x100@sint64, lsl;
(* lsl	x15, x15, #22                               #! PC = 0xaaaabe37219c *)
split dcH x15 x15 (64-22); shl x15 x15 22;
(* asr	x15, x15, #43                               #! PC = 0xaaaabe3721a0 *)
ssplit x15 dcL x15 43;
(* add	x20, x8, x6                                 #! PC = 0xaaaabe3721a4 *)
add x20 x8 x6;
(* asr	x20, x20, #42                               #! PC = 0xaaaabe3721a8 *)
ssplit x20 dcL x20 42;
(* add	x17, x8, #0x100, lsl #12                    #! PC = 0xaaaabe3721ac *)
add x17 x8 0x100@sint64, lsl;
(* lsl	x17, x17, #22                               #! PC = 0xaaaabe3721b0 *)
split dcH x17 x17 (64-22); shl x17 x17 22;
(* asr	x17, x17, #43                               #! PC = 0xaaaabe3721b4 *)
ssplit x17 dcL x17 43;
(* mul	x9, x15, x1                                 #! PC = 0xaaaabe3721b8 *)
mull dcH x9 x15 x1;
(* madd	x9, x16, x2, x9                            #! PC = 0xaaaabe3721bc *)
mull dcH mul_tmp x16 x2;
adds dc x9 mul_tmp x9;
(* asr	x9, x9, #20                                 #! PC = 0xaaaabe3721c0 *)
ssplit x9 dcL x9 20;
(* mul	x10, x17, x1                                #! PC = 0xaaaabe3721c4 *)
mull dcH x10 x17 x1;
(* madd	x10, x20, x2, x10                          #! PC = 0xaaaabe3721c8 *)
mull dcH mul_tmp x20 x2;
adds dc x10 mul_tmp x10;
(* asr	x2, x10, #20                                #! PC = 0xaaaabe3721cc *)
ssplit x2 dcL x10 20;
(* mov	x1, x9                                      #! PC = 0xaaaabe3721d0 *)
mov x1 x9;
(* mul	x9, x15, x11                                #! PC = 0xaaaabe3721d4 *)
mull dcH x9 x15 x11;
(* madd	x10, x16, x13, x9                          #! PC = 0xaaaabe3721d8 *)
mull dcH mul_tmp x16 x13;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x11                                #! PC = 0xaaaabe3721dc *)
mull dcH x9 x17 x11;
(* madd	x13, x20, x13, x9                          #! PC = 0xaaaabe3721e0 *)
mull dcH mul_tmp x20 x13;
adds dc x13 mul_tmp x9;
(* mov	x11, x10                                    #! PC = 0xaaaabe3721e4 *)
mov x11 x10;
(* mul	x9, x15, x12                                #! PC = 0xaaaabe3721e8 *)
mull dcH x9 x15 x12;
(* madd	x10, x16, x14, x9                          #! PC = 0xaaaabe3721ec *)
mull dcH mul_tmp x16 x14;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x12                                #! PC = 0xaaaabe3721f0 *)
mull dcH x9 x17 x12;
(* madd	x14, x20, x14, x9                          #! PC = 0xaaaabe3721f4 *)
mull dcH mul_tmp x20 x14;
adds dc x14 mul_tmp x9;
(* mov	x12, x10                                    #! PC = 0xaaaabe3721f8 *)
mov x12 x10;
(* mov	x9, #0x13                  	// #19          #! PC = 0xaaaabe3721fc *)
mov x9 0x13@uint64;
(* dup	v16.2d, x9                                  #! PC = 0xaaaabe372200 *)
mov %v16 [x9,x9];
(* smull	v17.2d, v13.2s, v8.s[0]                   #! PC = 0xaaaabe372204 *)
smull	%%v17.2d, %%v13.2s, %%v8.s[0]                   #! 0xaaaabe372204 = 0xaaaabe372204;
(* smlal2	v17.2d, v13.4s, v8.s[2]                  #! PC = 0xaaaabe372208 *)
smlal2	%%v17.2d, %%v13.4s, %%v8.s[2]                  #! 0xaaaabe372208 = 0xaaaabe372208;
(* mul	v19.4s, v17.4s, v15.4s                      #! PC = 0xaaaabe37220c *)
mul %v19 %v17 %v15;
(* and	v19.16b, v19.16b, v1.16b                    #! PC = 0xaaaabe372210 *)
and %v19@uint64[2] %v19 %v1;
(* uzp1	v19.4s, v19.4s, v19.4s                     #! PC = 0xaaaabe372214 *)
mov %v19 [%v19[0], %v19[2], %v19[0], %v19[2]];
(* smlsl	v17.2d, v19.2s, v16.s[0]                  #! PC = 0xaaaabe372218 *)
smlsl	%%v17.2d, %%v19.2s, %%v16.s[0]                  #! 0xaaaabe372218 = 0xaaaabe372218;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe37221c *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v8.s[0]                   #! PC = 0xaaaabe372220 *)
smlal	%%v17.2d, %%v14.2s, %%v8.s[0]                   #! 0xaaaabe372220 = 0xaaaabe372220;
(* smlal2	v17.2d, v14.4s, v8.s[2]                  #! PC = 0xaaaabe372224 *)
smlal2	%%v17.2d, %%v14.4s, %%v8.s[2]                  #! 0xaaaabe372224 = 0xaaaabe372224;
(* smlal	v17.2d, v13.2s, v8.s[1]                   #! PC = 0xaaaabe372228 *)
smlal	%%v17.2d, %%v13.2s, %%v8.s[1]                   #! 0xaaaabe372228 = 0xaaaabe372228;
(* smlal2	v17.2d, v13.4s, v8.s[3]                  #! PC = 0xaaaabe37222c *)
smlal2	%%v17.2d, %%v13.4s, %%v8.s[3]                  #! 0xaaaabe37222c = 0xaaaabe37222c;
(* mul	v20.4s, v17.4s, v15.4s                      #! PC = 0xaaaabe372230 *)
mul %v20 %v17 %v15;
(* and	v20.16b, v20.16b, v1.16b                    #! PC = 0xaaaabe372234 *)
and %v20@uint64[2] %v20 %v1;
(* uzp1	v20.4s, v20.4s, v20.4s                     #! PC = 0xaaaabe372238 *)
mov %v20 [%v20[0], %v20[2], %v20[0], %v20[2]];
(* smlsl	v17.2d, v20.2s, v16.s[0]                  #! PC = 0xaaaabe37223c *)
smlsl	%%v17.2d, %%v20.2s, %%v16.s[0]                  #! 0xaaaabe37223c = 0xaaaabe37223c;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe372240 *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v8.s[1]                   #! PC = 0xaaaabe372244 *)
smlal	%%v17.2d, %%v14.2s, %%v8.s[1]                   #! 0xaaaabe372244 = 0xaaaabe372244;
(* smlal2	v17.2d, v14.4s, v8.s[3]                  #! PC = 0xaaaabe372248 *)
smlal2	%%v17.2d, %%v14.4s, %%v8.s[3]                  #! 0xaaaabe372248 = 0xaaaabe372248;
(* smlal	v17.2d, v13.2s, v9.s[0]                   #! PC = 0xaaaabe37224c *)
smlal	%%v17.2d, %%v13.2s, %%v9.s[0]                   #! 0xaaaabe37224c = 0xaaaabe37224c;
(* smlal2	v17.2d, v13.4s, v9.s[2]                  #! PC = 0xaaaabe372250 *)
smlal2	%%v17.2d, %%v13.4s, %%v9.s[2]                  #! 0xaaaabe372250 = 0xaaaabe372250;
(* and	v8.16b, v17.16b, v1.16b                     #! PC = 0xaaaabe372254 *)
and %v8@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe372258 *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v9.s[0]                   #! PC = 0xaaaabe37225c *)
smlal	%%v17.2d, %%v14.2s, %%v9.s[0]                   #! 0xaaaabe37225c = 0xaaaabe37225c;
(* smlal2	v17.2d, v14.4s, v9.s[2]                  #! PC = 0xaaaabe372260 *)
smlal2	%%v17.2d, %%v14.4s, %%v9.s[2]                  #! 0xaaaabe372260 = 0xaaaabe372260;
(* smlal	v17.2d, v13.2s, v9.s[1]                   #! PC = 0xaaaabe372264 *)
smlal	%%v17.2d, %%v13.2s, %%v9.s[1]                   #! 0xaaaabe372264 = 0xaaaabe372264;
(* smlal2	v17.2d, v13.4s, v9.s[3]                  #! PC = 0xaaaabe372268 *)
smlal2	%%v17.2d, %%v13.4s, %%v9.s[3]                  #! 0xaaaabe372268 = 0xaaaabe372268;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe37226c *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe372270 *)
split %v17 %dc %v17 30;
(* sli	v8.2d, v18.2d, #32                          #! PC = 0xaaaabe372274 *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v8 %v8 32; or %v8@uint64[2] %slih %v8;
(* smlal	v17.2d, v14.2s, v9.s[1]                   #! PC = 0xaaaabe372278 *)
smlal	%%v17.2d, %%v14.2s, %%v9.s[1]                   #! 0xaaaabe372278 = 0xaaaabe372278;
(* smlal2	v17.2d, v14.4s, v9.s[3]                  #! PC = 0xaaaabe37227c *)
smlal2	%%v17.2d, %%v14.4s, %%v9.s[3]                  #! 0xaaaabe37227c = 0xaaaabe37227c;
(* smlal	v17.2d, v13.2s, v10.s[0]                  #! PC = 0xaaaabe372280 *)
smlal	%%v17.2d, %%v13.2s, %%v10.s[0]                  #! 0xaaaabe372280 = 0xaaaabe372280;
(* smlal2	v17.2d, v13.4s, v10.s[2]                 #! PC = 0xaaaabe372284 *)
smlal2	%%v17.2d, %%v13.4s, %%v10.s[2]                 #! 0xaaaabe372284 = 0xaaaabe372284;
(* and	v9.16b, v17.16b, v1.16b                     #! PC = 0xaaaabe372288 *)
and %v9@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe37228c *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v10.s[0]                  #! PC = 0xaaaabe372290 *)
smlal	%%v17.2d, %%v14.2s, %%v10.s[0]                  #! 0xaaaabe372290 = 0xaaaabe372290;
(* smlal2	v17.2d, v14.4s, v10.s[2]                 #! PC = 0xaaaabe372294 *)
smlal2	%%v17.2d, %%v14.4s, %%v10.s[2]                 #! 0xaaaabe372294 = 0xaaaabe372294;
(* smlal	v17.2d, v13.2s, v10.s[1]                  #! PC = 0xaaaabe372298 *)
smlal	%%v17.2d, %%v13.2s, %%v10.s[1]                  #! 0xaaaabe372298 = 0xaaaabe372298;
(* smlal2	v17.2d, v13.4s, v10.s[3]                 #! PC = 0xaaaabe37229c *)
smlal2	%%v17.2d, %%v13.4s, %%v10.s[3]                 #! 0xaaaabe37229c = 0xaaaabe37229c;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe3722a0 *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3722a4 *)
split %v17 %dc %v17 30;
(* sli	v9.2d, v18.2d, #32                          #! PC = 0xaaaabe3722a8 *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v9 %v9 32; or %v9@uint64[2] %slih %v9;
(* smlal	v17.2d, v14.2s, v10.s[1]                  #! PC = 0xaaaabe3722ac *)
smlal	%%v17.2d, %%v14.2s, %%v10.s[1]                  #! 0xaaaabe3722ac = 0xaaaabe3722ac;
(* smlal2	v17.2d, v14.4s, v10.s[3]                 #! PC = 0xaaaabe3722b0 *)
smlal2	%%v17.2d, %%v14.4s, %%v10.s[3]                 #! 0xaaaabe3722b0 = 0xaaaabe3722b0;
(* smlal	v17.2d, v13.2s, v11.s[0]                  #! PC = 0xaaaabe3722b4 *)
smlal	%%v17.2d, %%v13.2s, %%v11.s[0]                  #! 0xaaaabe3722b4 = 0xaaaabe3722b4;
(* smlal2	v17.2d, v13.4s, v11.s[2]                 #! PC = 0xaaaabe3722b8 *)
smlal2	%%v17.2d, %%v13.4s, %%v11.s[2]                 #! 0xaaaabe3722b8 = 0xaaaabe3722b8;
(* and	v10.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe3722bc *)
and %v10@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3722c0 *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v11.s[0]                  #! PC = 0xaaaabe3722c4 *)
smlal	%%v17.2d, %%v14.2s, %%v11.s[0]                  #! 0xaaaabe3722c4 = 0xaaaabe3722c4;
(* smlal2	v17.2d, v14.4s, v11.s[2]                 #! PC = 0xaaaabe3722c8 *)
smlal2	%%v17.2d, %%v14.4s, %%v11.s[2]                 #! 0xaaaabe3722c8 = 0xaaaabe3722c8;
(* smlal	v17.2d, v13.2s, v11.s[1]                  #! PC = 0xaaaabe3722cc *)
smlal	%%v17.2d, %%v13.2s, %%v11.s[1]                  #! 0xaaaabe3722cc = 0xaaaabe3722cc;
(* smlal2	v17.2d, v13.4s, v11.s[3]                 #! PC = 0xaaaabe3722d0 *)
smlal2	%%v17.2d, %%v13.4s, %%v11.s[3]                 #! 0xaaaabe3722d0 = 0xaaaabe3722d0;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe3722d4 *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3722d8 *)
split %v17 %dc %v17 30;
(* sli	v10.2d, v18.2d, #32                         #! PC = 0xaaaabe3722dc *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v10 %v10 32; or %v10@uint64[2] %slih %v10;
(* smlal	v17.2d, v14.2s, v11.s[1]                  #! PC = 0xaaaabe3722e0 *)
smlal	%%v17.2d, %%v14.2s, %%v11.s[1]                  #! 0xaaaabe3722e0 = 0xaaaabe3722e0;
(* smlal2	v17.2d, v14.4s, v11.s[3]                 #! PC = 0xaaaabe3722e4 *)
smlal2	%%v17.2d, %%v14.4s, %%v11.s[3]                 #! 0xaaaabe3722e4 = 0xaaaabe3722e4;
(* smlal	v17.2d, v13.2s, v12.s[0]                  #! PC = 0xaaaabe3722e8 *)
smlal	%%v17.2d, %%v13.2s, %%v12.s[0]                  #! 0xaaaabe3722e8 = 0xaaaabe3722e8;
(* smlal2	v17.2d, v13.4s, v12.s[2]                 #! PC = 0xaaaabe3722ec *)
smlal2	%%v17.2d, %%v13.4s, %%v12.s[2]                 #! 0xaaaabe3722ec = 0xaaaabe3722ec;
(* ushll	v19.2d, v19.2s, #15                       #! PC = 0xaaaabe3722f0 *)
ushll	%%v19.2d, %%v19.2s, #15                       #! 0xaaaabe3722f0 = 0xaaaabe3722f0;
(* add	v17.2d, v17.2d, v19.2d                      #! PC = 0xaaaabe3722f4 *)
add	%%v17.2d, %%v17.2d, %%v19.2d                      #! 0xaaaabe3722f4 = 0xaaaabe3722f4;
(* and	v11.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe3722f8 *)
and %v11@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3722fc *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v12.s[0]                  #! PC = 0xaaaabe372300 *)
smlal	%%v17.2d, %%v14.2s, %%v12.s[0]                  #! 0xaaaabe372300 = 0xaaaabe372300;
(* smlal2	v17.2d, v14.4s, v12.s[2]                 #! PC = 0xaaaabe372304 *)
smlal2	%%v17.2d, %%v14.4s, %%v12.s[2]                 #! 0xaaaabe372304 = 0xaaaabe372304;
(* ushll	v20.2d, v20.2s, #15                       #! PC = 0xaaaabe372308 *)
ushll	%%v20.2d, %%v20.2s, #15                       #! 0xaaaabe372308 = 0xaaaabe372308;
(* add	v17.2d, v17.2d, v20.2d                      #! PC = 0xaaaabe37230c *)
add	%%v17.2d, %%v17.2d, %%v20.2d                      #! 0xaaaabe37230c = 0xaaaabe37230c;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe372310 *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v12.2d, v17.2d, #30                        #! PC = 0xaaaabe372314 *)
split %v12 %dc %v17 30;
(* sli	v11.2d, v18.2d, #32                         #! PC = 0xaaaabe372318 *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v11 %v11 32; or %v11@uint64[2] %slih %v11;
(* sshr	v18.2d, v12.2d, #15                        #! PC = 0xaaaabe37231c *)
split %v18 %dc %v12 15;
(* shl	v17.2d, v18.2d, #15                         #! PC = 0xaaaabe372320 *)
shls %dc %v17 %v18 [15, 15];
(* sub	v12.2d, v12.2d, v17.2d                      #! PC = 0xaaaabe372324 *)
sub	%%v12.2d, %%v12.2d, %%v17.2d                      #! 0xaaaabe372324 = 0xaaaabe372324;
(* mla	v8.4s, v18.4s, v16.4s                       #! PC = 0xaaaabe372328 *)
mull %dc %mla %v18 %v16; add %v8 %v8 %mla;
(* and	x7, x1, #0xfffff                            #! PC = 0xaaaabe37232c *)
and x7@uint64 x1 0xfffff@uint64;
(* and	x8, x2, #0xfffff                            #! PC = 0xaaaabe372330 *)
and x8@uint64 x2 0xfffff@uint64;
(* orr	x7, x7, #0xfffffe0000000000                 #! PC = 0xaaaabe372334 *)
or x7@uint64 x7 0xfffffe0000000000@uint64;
(* orr	x8, x8, #0xc000000000000000                 #! PC = 0xaaaabe372338 *)
or x8@uint64 x8 0xc000000000000000@uint64;
(* tst	x8, #0x1                                    #! PC = 0xaaaabe37233c *)
spl dc x8_lo x8 1;
and ne@bit x8_lo 1@bit;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372340 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372344 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372348 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37234c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372350 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372354 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372358 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37235c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372360 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372364 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372368 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37236c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372370 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372374 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372378 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37237c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372380 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372384 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372388 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37238c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372390 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372394 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372398 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37239c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3723a0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3723a4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3723a8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3723ac *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3723b0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3723b4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3723b8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3723bc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3723c0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3723c4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3723c8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3723cc *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3723d0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3723d4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3723d8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3723dc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3723e0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3723e4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3723e8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3723ec *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3723f0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3723f4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3723f8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3723fc *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372400 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372404 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372408 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37240c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372410 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372414 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372418 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37241c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372420 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372424 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372428 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37242c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372430 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372434 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372438 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37243c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372440 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372444 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372448 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37244c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372450 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372454 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372458 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37245c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372460 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372464 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372468 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37246c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372470 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372474 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372478 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37247c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372480 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372484 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372488 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37248c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372490 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372494 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372498 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37249c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3724a0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3724a4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3724a8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3724ac *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3724b0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3724b4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3724b8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3724bc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3724c0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3724c4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3724c8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3724cc *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3724d0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3724d4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3724d8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3724dc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3724e0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3724e4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3724e8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3724ec *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3724f0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3724f4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3724f8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3724fc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372500 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372504 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372508 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37250c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372510 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372514 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372518 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37251c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372520 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372524 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372528 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37252c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372530 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372534 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372538 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37253c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372540 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372544 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372548 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37254c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372550 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372554 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372558 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37255c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372560 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372564 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372568 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37256c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372570 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372574 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372578 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37257c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372580 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372584 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372588 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37258c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372590 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372594 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372598 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37259c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3725a0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3725a4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3725a8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3725ac *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3725b0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3725b4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3725b8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3725bc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3725c0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3725c4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3725c8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3725cc *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3725d0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3725d4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3725d8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3725dc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3725e0 *)
add x3 x3 0x2@sint64;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3725e4 *)
ssplit x8 dcL x8 1;
(* add	x16, x7, x6                                 #! PC = 0xaaaabe3725e8 *)
add x16 x7 x6;
(* asr	x16, x16, #42                               #! PC = 0xaaaabe3725ec *)
ssplit x16 dcL x16 42;
(* add	x15, x7, #0x100, lsl #12                    #! PC = 0xaaaabe3725f0 *)
add x15 x7 0x100@sint64, lsl;
(* lsl	x15, x15, #22                               #! PC = 0xaaaabe3725f4 *)
split dcH x15 x15 (64-22); shl x15 x15 22;
(* asr	x15, x15, #43                               #! PC = 0xaaaabe3725f8 *)
ssplit x15 dcL x15 43;
(* add	x20, x8, x6                                 #! PC = 0xaaaabe3725fc *)
add x20 x8 x6;
(* asr	x20, x20, #42                               #! PC = 0xaaaabe372600 *)
ssplit x20 dcL x20 42;
(* add	x17, x8, #0x100, lsl #12                    #! PC = 0xaaaabe372604 *)
add x17 x8 0x100@sint64, lsl;
(* lsl	x17, x17, #22                               #! PC = 0xaaaabe372608 *)
split dcH x17 x17 (64-22); shl x17 x17 22;
(* asr	x17, x17, #43                               #! PC = 0xaaaabe37260c *)
ssplit x17 dcL x17 43;
(* mul	x9, x15, x11                                #! PC = 0xaaaabe372610 *)
mull dcH x9 x15 x11;
(* madd	x10, x16, x13, x9                          #! PC = 0xaaaabe372614 *)
mull dcH mul_tmp x16 x13;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x11                                #! PC = 0xaaaabe372618 *)
mull dcH x9 x17 x11;
(* madd	x13, x20, x13, x9                          #! PC = 0xaaaabe37261c *)
mull dcH mul_tmp x20 x13;
adds dc x13 mul_tmp x9;
(* mov	x11, x10                                    #! PC = 0xaaaabe372620 *)
mov x11 x10;
(* mul	x9, x15, x12                                #! PC = 0xaaaabe372624 *)
mull dcH x9 x15 x12;
(* madd	x10, x16, x14, x9                          #! PC = 0xaaaabe372628 *)
mull dcH mul_tmp x16 x14;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x12                                #! PC = 0xaaaabe37262c *)
mull dcH x9 x17 x12;
(* madd	x14, x20, x14, x9                          #! PC = 0xaaaabe372630 *)
mull dcH mul_tmp x20 x14;
adds dc x14 mul_tmp x9;
(* mov	x12, x10                                    #! PC = 0xaaaabe372634 *)
mov x12 x10;
(* subs	x19, x19, #0x1                             #! PC = 0xaaaabe372638 *)
subc carry x19 x19 0x1@uint64;
(* #cbnz	x19, 0xaaaabe371960 <Lbig_loop>           #! PC = 0xaaaabe37263c *)
#cbnz	%%x19, 0xaaaabe371960 <Lbig_loop>           #! 0xaaaabe37263c = 0xaaaabe37263c;
(* mov	v16.d[0], x11                               #! PC = 0xaaaabe371960 *)
mov %v16 [x11, %v16[1]];
(* mov	v16.d[1], x13                               #! PC = 0xaaaabe371964 *)
mov %v16 [%v16[0], x13];
(* mov	v17.d[0], x12                               #! PC = 0xaaaabe371968 *)
mov %v17 [x12, %v17[1]];
(* mov	v17.d[1], x14                               #! PC = 0xaaaabe37196c *)
mov %v17 [%v17[0], x14];
(* uzp1	v13.4s, v16.4s, v17.4s                     #! PC = 0xaaaabe371970 *)
mov %v13 [%v16[0], %v16[2], %v17[0], %v17[2]];
(* and	v13.16b, v13.16b, v2.16b                    #! PC = 0xaaaabe371974 *)
and %v13@uint64[2] %v13 %v2;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371978 *)
split %v16 %dc %v16 30;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe37197c *)
split %v17 %dc %v17 30;
(* uzp1	v14.4s, v16.4s, v17.4s                     #! PC = 0xaaaabe371980 *)
mov %v14 [%v16[0], %v16[2], %v17[0], %v17[2]];
(* cmp	x11, xzr                                    #! PC = 0xaaaabe371984 *)
subc zero dc 0@uint64 x11;
(* csetm	x23, mi	// mi = first                     #! PC = 0xaaaabe371988 *)
csetm	%%x23, mi	// mi = first                     #! 0xaaaabe371988 = 0xaaaabe371988;
(* cneg	x11, x11, mi	// mi = first                 #! PC = 0xaaaabe37198c *)
cneg	%%x11, %%x11, mi	// mi = first                 #! 0xaaaabe37198c = 0xaaaabe37198c;
(* cmp	x12, xzr                                    #! PC = 0xaaaabe371990 *)
subc zero dc 0@uint64 x12;
(* csetm	x24, mi	// mi = first                     #! PC = 0xaaaabe371994 *)
csetm	%%x24, mi	// mi = first                     #! 0xaaaabe371994 = 0xaaaabe371994;
(* cneg	x12, x12, mi	// mi = first                 #! PC = 0xaaaabe371998 *)
cneg	%%x12, %%x12, mi	// mi = first                 #! 0xaaaabe371998 = 0xaaaabe371998;
(* cmp	x13, xzr                                    #! PC = 0xaaaabe37199c *)
subc zero dc 0@uint64 x13;
(* csetm	x25, mi	// mi = first                     #! PC = 0xaaaabe3719a0 *)
csetm	%%x25, mi	// mi = first                     #! 0xaaaabe3719a0 = 0xaaaabe3719a0;
(* cneg	x13, x13, mi	// mi = first                 #! PC = 0xaaaabe3719a4 *)
cneg	%%x13, %%x13, mi	// mi = first                 #! 0xaaaabe3719a4 = 0xaaaabe3719a4;
(* cmp	x14, xzr                                    #! PC = 0xaaaabe3719a8 *)
subc zero dc 0@uint64 x14;
(* csetm	x26, mi	// mi = first                     #! PC = 0xaaaabe3719ac *)
csetm	%%x26, mi	// mi = first                     #! 0xaaaabe3719ac = 0xaaaabe3719ac;
(* cneg	x14, x14, mi	// mi = first                 #! PC = 0xaaaabe3719b0 *)
cneg	%%x14, %%x14, mi	// mi = first                 #! 0xaaaabe3719b0 = 0xaaaabe3719b0;
(* and	x27, x11, x23                               #! PC = 0xaaaabe3719b4 *)
and x27@uint64 x11 x23;
(* and	x28, x12, x24                               #! PC = 0xaaaabe3719b8 *)
and x28@uint64 x12 x24;
(* add	x15, x27, x28                               #! PC = 0xaaaabe3719bc *)
add x15 x27 x28;
(* eor	x27, x4, x23                                #! PC = 0xaaaabe3719c0 *)
xor x27@uint64 x4 x23;
(* mul	x9, x27, x11                                #! PC = 0xaaaabe3719c4 *)
mull dcH x9 x27 x11;
(* umulh	x10, x27, x11                             #! PC = 0xaaaabe3719c8 *)
mull x10 dcL x27 x11;
(* adds	x15, x9, x15                               #! PC = 0xaaaabe3719cc *)
adds carry x15 x9 x15;
(* adc	x16, x10, xzr                               #! PC = 0xaaaabe3719d0 *)
adc x16 x10 0@uint64 carry;
(* eor	x27, x21, x23                               #! PC = 0xaaaabe3719d4 *)
xor x27@uint64 x21 x23;
(* mul	x9, x27, x11                                #! PC = 0xaaaabe3719d8 *)
mull dcH x9 x27 x11;
(* add	x16, x16, x9                                #! PC = 0xaaaabe3719dc *)
add x16 x16 x9;
(* eor	x27, x5, x24                                #! PC = 0xaaaabe3719e0 *)
xor x27@uint64 x5 x24;
(* mul	x9, x27, x12                                #! PC = 0xaaaabe3719e4 *)
mull dcH x9 x27 x12;
(* umulh	x10, x27, x12                             #! PC = 0xaaaabe3719e8 *)
mull x10 dcL x27 x12;
(* adds	x15, x9, x15                               #! PC = 0xaaaabe3719ec *)
adds carry x15 x9 x15;
(* adc	x16, x10, x16                               #! PC = 0xaaaabe3719f0 *)
adc x16 x10 x16 carry;
(* eor	x27, x22, x24                               #! PC = 0xaaaabe3719f4 *)
xor x27@uint64 x22 x24;
(* mul	x9, x27, x12                                #! PC = 0xaaaabe3719f8 *)
mull dcH x9 x27 x12;
(* add	x16, x16, x9                                #! PC = 0xaaaabe3719fc *)
add x16 x16 x9;
(* extr	x1, x16, x15, #60                          #! PC = 0xaaaabe371a00 *)
spl dc extr_H x16 60; spl extr_L dc x15 60; join x1 extr_H extr_L;
(* and	x27, x13, x25                               #! PC = 0xaaaabe371a04 *)
and x27@uint64 x13 x25;
(* and	x28, x14, x26                               #! PC = 0xaaaabe371a08 *)
and x28@uint64 x14 x26;
(* add	x17, x27, x28                               #! PC = 0xaaaabe371a0c *)
add x17 x27 x28;
(* eor	x27, x4, x25                                #! PC = 0xaaaabe371a10 *)
xor x27@uint64 x4 x25;
(* mul	x9, x27, x13                                #! PC = 0xaaaabe371a14 *)
mull dcH x9 x27 x13;
(* umulh	x10, x27, x13                             #! PC = 0xaaaabe371a18 *)
mull x10 dcL x27 x13;
(* adds	x17, x9, x17                               #! PC = 0xaaaabe371a1c *)
adds carry x17 x9 x17;
(* adc	x20, x10, xzr                               #! PC = 0xaaaabe371a20 *)
adc x20 x10 0@uint64 carry;
(* eor	x27, x21, x25                               #! PC = 0xaaaabe371a24 *)
xor x27@uint64 x21 x25;
(* mul	x9, x27, x13                                #! PC = 0xaaaabe371a28 *)
mull dcH x9 x27 x13;
(* add	x20, x20, x9                                #! PC = 0xaaaabe371a2c *)
add x20 x20 x9;
(* eor	x27, x5, x26                                #! PC = 0xaaaabe371a30 *)
xor x27@uint64 x5 x26;
(* mul	x9, x27, x14                                #! PC = 0xaaaabe371a34 *)
mull dcH x9 x27 x14;
(* umulh	x10, x27, x14                             #! PC = 0xaaaabe371a38 *)
mull x10 dcL x27 x14;
(* adds	x17, x9, x17                               #! PC = 0xaaaabe371a3c *)
adds carry x17 x9 x17;
(* adc	x20, x10, x20                               #! PC = 0xaaaabe371a40 *)
adc x20 x10 x20 carry;
(* eor	x27, x22, x26                               #! PC = 0xaaaabe371a44 *)
xor x27@uint64 x22 x26;
(* mul	x9, x27, x14                                #! PC = 0xaaaabe371a48 *)
mull dcH x9 x27 x14;
(* add	x20, x20, x9                                #! PC = 0xaaaabe371a4c *)
add x20 x20 x9;
(* extr	x2, x20, x17, #60                          #! PC = 0xaaaabe371a50 *)
spl dc extr_H x20 60; spl extr_L dc x17 60; join x2 extr_H extr_L;
(* smull	v16.2d, v13.2s, v3.s[0]                   #! PC = 0xaaaabe371a54 *)
smull	%%v16.2d, %%v13.2s, %%v3.s[0]                   #! 0xaaaabe371a54 = 0xaaaabe371a54;
(* smlal2	v16.2d, v13.4s, v3.s[2]                  #! PC = 0xaaaabe371a58 *)
smlal2	%%v16.2d, %%v13.4s, %%v3.s[2]                  #! 0xaaaabe371a58 = 0xaaaabe371a58;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371a5c *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v3.s[0]                   #! PC = 0xaaaabe371a60 *)
smlal	%%v16.2d, %%v14.2s, %%v3.s[0]                   #! 0xaaaabe371a60 = 0xaaaabe371a60;
(* smlal2	v16.2d, v14.4s, v3.s[2]                  #! PC = 0xaaaabe371a64 *)
smlal2	%%v16.2d, %%v14.4s, %%v3.s[2]                  #! 0xaaaabe371a64 = 0xaaaabe371a64;
(* smlal	v16.2d, v13.2s, v3.s[1]                   #! PC = 0xaaaabe371a68 *)
smlal	%%v16.2d, %%v13.2s, %%v3.s[1]                   #! 0xaaaabe371a68 = 0xaaaabe371a68;
(* smlal2	v16.2d, v13.4s, v3.s[3]                  #! PC = 0xaaaabe371a6c *)
smlal2	%%v16.2d, %%v13.4s, %%v3.s[3]                  #! 0xaaaabe371a6c = 0xaaaabe371a6c;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371a70 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v3.s[1]                   #! PC = 0xaaaabe371a74 *)
smlal	%%v16.2d, %%v14.2s, %%v3.s[1]                   #! 0xaaaabe371a74 = 0xaaaabe371a74;
(* smlal2	v16.2d, v14.4s, v3.s[3]                  #! PC = 0xaaaabe371a78 *)
smlal2	%%v16.2d, %%v14.4s, %%v3.s[3]                  #! 0xaaaabe371a78 = 0xaaaabe371a78;
(* smlal	v16.2d, v13.2s, v4.s[0]                   #! PC = 0xaaaabe371a7c *)
smlal	%%v16.2d, %%v13.2s, %%v4.s[0]                   #! 0xaaaabe371a7c = 0xaaaabe371a7c;
(* smlal2	v16.2d, v13.4s, v4.s[2]                  #! PC = 0xaaaabe371a80 *)
smlal2	%%v16.2d, %%v13.4s, %%v4.s[2]                  #! 0xaaaabe371a80 = 0xaaaabe371a80;
(* and	v3.16b, v16.16b, v1.16b                     #! PC = 0xaaaabe371a84 *)
and %v3@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371a88 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v4.s[0]                   #! PC = 0xaaaabe371a8c *)
smlal	%%v16.2d, %%v14.2s, %%v4.s[0]                   #! 0xaaaabe371a8c = 0xaaaabe371a8c;
(* smlal2	v16.2d, v14.4s, v4.s[2]                  #! PC = 0xaaaabe371a90 *)
smlal2	%%v16.2d, %%v14.4s, %%v4.s[2]                  #! 0xaaaabe371a90 = 0xaaaabe371a90;
(* smlal	v16.2d, v13.2s, v4.s[1]                   #! PC = 0xaaaabe371a94 *)
smlal	%%v16.2d, %%v13.2s, %%v4.s[1]                   #! 0xaaaabe371a94 = 0xaaaabe371a94;
(* smlal2	v16.2d, v13.4s, v4.s[3]                  #! PC = 0xaaaabe371a98 *)
smlal2	%%v16.2d, %%v13.4s, %%v4.s[3]                  #! 0xaaaabe371a98 = 0xaaaabe371a98;
(* and	v17.16b, v16.16b, v1.16b                    #! PC = 0xaaaabe371a9c *)
and %v17@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371aa0 *)
split %v16 %dc %v16 30;
(* shl	v17.2d, v17.2d, #32                         #! PC = 0xaaaabe371aa4 *)
shls %dc %v17 %v17 [32, 32];
(* orr	v3.16b, v3.16b, v17.16b                     #! PC = 0xaaaabe371aa8 *)
or %v3@uint64[2] %v3 %v17;
(* smlal	v16.2d, v14.2s, v4.s[1]                   #! PC = 0xaaaabe371aac *)
smlal	%%v16.2d, %%v14.2s, %%v4.s[1]                   #! 0xaaaabe371aac = 0xaaaabe371aac;
(* smlal2	v16.2d, v14.4s, v4.s[3]                  #! PC = 0xaaaabe371ab0 *)
smlal2	%%v16.2d, %%v14.4s, %%v4.s[3]                  #! 0xaaaabe371ab0 = 0xaaaabe371ab0;
(* smlal	v16.2d, v13.2s, v5.s[0]                   #! PC = 0xaaaabe371ab4 *)
smlal	%%v16.2d, %%v13.2s, %%v5.s[0]                   #! 0xaaaabe371ab4 = 0xaaaabe371ab4;
(* smlal2	v16.2d, v13.4s, v5.s[2]                  #! PC = 0xaaaabe371ab8 *)
smlal2	%%v16.2d, %%v13.4s, %%v5.s[2]                  #! 0xaaaabe371ab8 = 0xaaaabe371ab8;
(* and	v4.16b, v16.16b, v1.16b                     #! PC = 0xaaaabe371abc *)
and %v4@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371ac0 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v5.s[0]                   #! PC = 0xaaaabe371ac4 *)
smlal	%%v16.2d, %%v14.2s, %%v5.s[0]                   #! 0xaaaabe371ac4 = 0xaaaabe371ac4;
(* smlal2	v16.2d, v14.4s, v5.s[2]                  #! PC = 0xaaaabe371ac8 *)
smlal2	%%v16.2d, %%v14.4s, %%v5.s[2]                  #! 0xaaaabe371ac8 = 0xaaaabe371ac8;
(* smlal	v16.2d, v13.2s, v5.s[1]                   #! PC = 0xaaaabe371acc *)
smlal	%%v16.2d, %%v13.2s, %%v5.s[1]                   #! 0xaaaabe371acc = 0xaaaabe371acc;
(* smlal2	v16.2d, v13.4s, v5.s[3]                  #! PC = 0xaaaabe371ad0 *)
smlal2	%%v16.2d, %%v13.4s, %%v5.s[3]                  #! 0xaaaabe371ad0 = 0xaaaabe371ad0;
(* and	v17.16b, v16.16b, v1.16b                    #! PC = 0xaaaabe371ad4 *)
and %v17@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371ad8 *)
split %v16 %dc %v16 30;
(* shl	v17.2d, v17.2d, #32                         #! PC = 0xaaaabe371adc *)
shls %dc %v17 %v17 [32, 32];
(* orr	v4.16b, v4.16b, v17.16b                     #! PC = 0xaaaabe371ae0 *)
or %v4@uint64[2] %v4 %v17;
(* smlal	v16.2d, v14.2s, v5.s[1]                   #! PC = 0xaaaabe371ae4 *)
smlal	%%v16.2d, %%v14.2s, %%v5.s[1]                   #! 0xaaaabe371ae4 = 0xaaaabe371ae4;
(* smlal2	v16.2d, v14.4s, v5.s[3]                  #! PC = 0xaaaabe371ae8 *)
smlal2	%%v16.2d, %%v14.4s, %%v5.s[3]                  #! 0xaaaabe371ae8 = 0xaaaabe371ae8;
(* smlal	v16.2d, v13.2s, v6.s[0]                   #! PC = 0xaaaabe371aec *)
smlal	%%v16.2d, %%v13.2s, %%v6.s[0]                   #! 0xaaaabe371aec = 0xaaaabe371aec;
(* smlal2	v16.2d, v13.4s, v6.s[2]                  #! PC = 0xaaaabe371af0 *)
smlal2	%%v16.2d, %%v13.4s, %%v6.s[2]                  #! 0xaaaabe371af0 = 0xaaaabe371af0;
(* and	v5.16b, v16.16b, v1.16b                     #! PC = 0xaaaabe371af4 *)
and %v5@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371af8 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v6.s[0]                   #! PC = 0xaaaabe371afc *)
smlal	%%v16.2d, %%v14.2s, %%v6.s[0]                   #! 0xaaaabe371afc = 0xaaaabe371afc;
(* smlal2	v16.2d, v14.4s, v6.s[2]                  #! PC = 0xaaaabe371b00 *)
smlal2	%%v16.2d, %%v14.4s, %%v6.s[2]                  #! 0xaaaabe371b00 = 0xaaaabe371b00;
(* smlal	v16.2d, v13.2s, v6.s[1]                   #! PC = 0xaaaabe371b04 *)
smlal	%%v16.2d, %%v13.2s, %%v6.s[1]                   #! 0xaaaabe371b04 = 0xaaaabe371b04;
(* smlal2	v16.2d, v13.4s, v6.s[3]                  #! PC = 0xaaaabe371b08 *)
smlal2	%%v16.2d, %%v13.4s, %%v6.s[3]                  #! 0xaaaabe371b08 = 0xaaaabe371b08;
(* and	v17.16b, v16.16b, v1.16b                    #! PC = 0xaaaabe371b0c *)
and %v17@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371b10 *)
split %v16 %dc %v16 30;
(* shl	v17.2d, v17.2d, #32                         #! PC = 0xaaaabe371b14 *)
shls %dc %v17 %v17 [32, 32];
(* orr	v5.16b, v5.16b, v17.16b                     #! PC = 0xaaaabe371b18 *)
or %v5@uint64[2] %v5 %v17;
(* smlal	v16.2d, v14.2s, v6.s[1]                   #! PC = 0xaaaabe371b1c *)
smlal	%%v16.2d, %%v14.2s, %%v6.s[1]                   #! 0xaaaabe371b1c = 0xaaaabe371b1c;
(* smlal2	v16.2d, v14.4s, v6.s[3]                  #! PC = 0xaaaabe371b20 *)
smlal2	%%v16.2d, %%v14.4s, %%v6.s[3]                  #! 0xaaaabe371b20 = 0xaaaabe371b20;
(* smlal	v16.2d, v13.2s, v7.s[0]                   #! PC = 0xaaaabe371b24 *)
smlal	%%v16.2d, %%v13.2s, %%v7.s[0]                   #! 0xaaaabe371b24 = 0xaaaabe371b24;
(* smlal2	v16.2d, v13.4s, v7.s[2]                  #! PC = 0xaaaabe371b28 *)
smlal2	%%v16.2d, %%v13.4s, %%v7.s[2]                  #! 0xaaaabe371b28 = 0xaaaabe371b28;
(* and	v6.16b, v16.16b, v1.16b                     #! PC = 0xaaaabe371b2c *)
and %v6@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371b30 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v7.s[0]                   #! PC = 0xaaaabe371b34 *)
smlal	%%v16.2d, %%v14.2s, %%v7.s[0]                   #! 0xaaaabe371b34 = 0xaaaabe371b34;
(* smlal2	v16.2d, v14.4s, v7.s[2]                  #! PC = 0xaaaabe371b38 *)
smlal2	%%v16.2d, %%v14.4s, %%v7.s[2]                  #! 0xaaaabe371b38 = 0xaaaabe371b38;
(* and	v17.16b, v16.16b, v1.16b                    #! PC = 0xaaaabe371b3c *)
and %v17@uint64[2] %v16 %v1;
(* sshr	v7.2d, v16.2d, #30                         #! PC = 0xaaaabe371b40 *)
split %v7 %dc %v16 30;
(* shl	v17.2d, v17.2d, #32                         #! PC = 0xaaaabe371b44 *)
shls %dc %v17 %v17 [32, 32];
(* orr	v6.16b, v6.16b, v17.16b                     #! PC = 0xaaaabe371b48 *)
or %v6@uint64[2] %v6 %v17;
(* and	x7, x1, #0xfffff                            #! PC = 0xaaaabe371b4c *)
and x7@uint64 x1 0xfffff@uint64;
(* and	x8, x2, #0xfffff                            #! PC = 0xaaaabe371b50 *)
and x8@uint64 x2 0xfffff@uint64;
(* orr	x7, x7, #0xfffffe0000000000                 #! PC = 0xaaaabe371b54 *)
or x7@uint64 x7 0xfffffe0000000000@uint64;
(* orr	x8, x8, #0xc000000000000000                 #! PC = 0xaaaabe371b58 *)
or x8@uint64 x8 0xc000000000000000@uint64;
(* tst	x8, #0x1                                    #! PC = 0xaaaabe371b5c *)
spl dc x8_lo x8 1;
and ne@bit x8_lo 1@bit;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371b60 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371b64 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371b68 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371b6c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371b70 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371b74 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371b78 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371b7c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371b80 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371b84 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371b88 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371b8c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371b90 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371b94 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371b98 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371b9c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371ba0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371ba4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371ba8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371bac *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371bb0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371bb4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371bb8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371bbc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371bc0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371bc4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371bc8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371bcc *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371bd0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371bd4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371bd8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371bdc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371be0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371be4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371be8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371bec *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371bf0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371bf4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371bf8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371bfc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c00 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c04 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c08 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c0c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371c10 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371c14 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371c18 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371c1c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371c20 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c24 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c28 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c2c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c30 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371c34 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371c38 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371c3c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371c40 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371c44 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c48 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c4c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c50 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c54 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371c58 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371c5c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371c60 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371c64 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371c68 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c6c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c70 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c74 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c78 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371c7c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371c80 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371c84 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371c88 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371c8c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c90 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c94 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c98 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c9c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371ca0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371ca4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371ca8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371cac *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371cb0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371cb4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371cb8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371cbc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371cc0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371cc4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371cc8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371ccc *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371cd0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371cd4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371cd8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371cdc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371ce0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371ce4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371ce8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371cec *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371cf0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371cf4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371cf8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371cfc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d00 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d04 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d08 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d0c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371d10 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371d14 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371d18 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371d1c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371d20 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d24 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d28 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d2c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d30 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371d34 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371d38 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371d3c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371d40 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371d44 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d48 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d4c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d50 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d54 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371d58 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371d5c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371d60 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371d64 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371d68 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d6c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d70 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d74 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d78 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371d7c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371d80 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371d84 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371d88 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371d8c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d90 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d94 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d98 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d9c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371da0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371da4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371da8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371dac *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371db0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371db4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371db8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371dbc *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371dc0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371dc4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371dc8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371dcc *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371dd0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371dd4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371dd8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371ddc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371de0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371de4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371de8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371dec *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371df0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371df4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371df8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371dfc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371e00 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371e04 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371e08 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371e0c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371e10 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371e14 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371e18 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371e1c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371e20 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371e24 *)
add x3 x3 0x2@sint64;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371e28 *)
ssplit x8 dcL x8 1;
(* add	x12, x7, x6                                 #! PC = 0xaaaabe371e2c *)
add x12 x7 x6;
(* asr	x12, x12, #42                               #! PC = 0xaaaabe371e30 *)
ssplit x12 dcL x12 42;
(* add	x11, x7, #0x100, lsl #12                    #! PC = 0xaaaabe371e34 *)
add x11 x7 0x100@sint64, lsl;
(* lsl	x11, x11, #22                               #! PC = 0xaaaabe371e38 *)
split dcH x11 x11 (64-22); shl x11 x11 22;
(* asr	x11, x11, #43                               #! PC = 0xaaaabe371e3c *)
ssplit x11 dcL x11 43;
(* add	x14, x8, x6                                 #! PC = 0xaaaabe371e40 *)
add x14 x8 x6;
(* asr	x14, x14, #42                               #! PC = 0xaaaabe371e44 *)
ssplit x14 dcL x14 42;
(* add	x13, x8, #0x100, lsl #12                    #! PC = 0xaaaabe371e48 *)
add x13 x8 0x100@sint64, lsl;
(* lsl	x13, x13, #22                               #! PC = 0xaaaabe371e4c *)
split dcH x13 x13 (64-22); shl x13 x13 22;
(* asr	x13, x13, #43                               #! PC = 0xaaaabe371e50 *)
ssplit x13 dcL x13 43;
(* mul	x9, x11, x1                                 #! PC = 0xaaaabe371e54 *)
mull dcH x9 x11 x1;
(* madd	x9, x12, x2, x9                            #! PC = 0xaaaabe371e58 *)
mull dcH mul_tmp x12 x2;
adds dc x9 mul_tmp x9;
(* asr	x9, x9, #20                                 #! PC = 0xaaaabe371e5c *)
ssplit x9 dcL x9 20;
(* mul	x10, x13, x1                                #! PC = 0xaaaabe371e60 *)
mull dcH x10 x13 x1;
(* madd	x10, x14, x2, x10                          #! PC = 0xaaaabe371e64 *)
mull dcH mul_tmp x14 x2;
adds dc x10 mul_tmp x10;
(* asr	x2, x10, #20                                #! PC = 0xaaaabe371e68 *)
ssplit x2 dcL x10 20;
(* mov	x1, x9                                      #! PC = 0xaaaabe371e6c *)
mov x1 x9;
(* mov	w4, v3.s[0]                                 #! PC = 0xaaaabe371e70 *)
mov w4 v3.s[0];
(* mov	w27, v3.s[1]                                #! PC = 0xaaaabe371e74 *)
mov w27 v3.s[1];
(* add	x4, x4, x27, lsl #30                        #! PC = 0xaaaabe371e78 *)
add x4 x4 x27, lsl;
(* mov	w27, v4.s[0]                                #! PC = 0xaaaabe371e7c *)
mov w27 v4.s[0];
(* add	x4, x4, x27, lsl #60                        #! PC = 0xaaaabe371e80 *)
add x4 x4 x27, lsl;
(* add	x21, xzr, x27, lsr #4                       #! PC = 0xaaaabe371e84 *)
add	%%x21, xzr, %%x27, lsr #4                       #! 0xaaaabe371e84 = 0xaaaabe371e84;
(* mov	w27, v4.s[1]                                #! PC = 0xaaaabe371e88 *)
mov w27 v4.s[1];
(* add	x21, x21, x27, lsl #26                      #! PC = 0xaaaabe371e8c *)
add x21 x21 x27, lsl;
(* mov	w5, v3.s[2]                                 #! PC = 0xaaaabe371e90 *)
mov w5 v3.s[2];
(* mov	w27, v3.s[3]                                #! PC = 0xaaaabe371e94 *)
mov w27 v3.s[3];
(* add	x5, x5, x27, lsl #30                        #! PC = 0xaaaabe371e98 *)
add x5 x5 x27, lsl;
(* mov	w27, v4.s[2]                                #! PC = 0xaaaabe371e9c *)
mov w27 v4.s[2];
(* add	x5, x5, x27, lsl #60                        #! PC = 0xaaaabe371ea0 *)
add x5 x5 x27, lsl;
(* add	x22, xzr, x27, lsr #4                       #! PC = 0xaaaabe371ea4 *)
add	%%x22, xzr, %%x27, lsr #4                       #! 0xaaaabe371ea4 = 0xaaaabe371ea4;
(* mov	w27, v4.s[3]                                #! PC = 0xaaaabe371ea8 *)
mov w27 v4.s[3];
(* add	x22, x22, x27, lsl #26                      #! PC = 0xaaaabe371eac *)
add x22 x22 x27, lsl;
(* and	x7, x1, #0xfffff                            #! PC = 0xaaaabe371eb0 *)
and x7@uint64 x1 0xfffff@uint64;
(* and	x8, x2, #0xfffff                            #! PC = 0xaaaabe371eb4 *)
and x8@uint64 x2 0xfffff@uint64;
(* orr	x7, x7, #0xfffffe0000000000                 #! PC = 0xaaaabe371eb8 *)
or x7@uint64 x7 0xfffffe0000000000@uint64;
(* orr	x8, x8, #0xc000000000000000                 #! PC = 0xaaaabe371ebc *)
or x8@uint64 x8 0xc000000000000000@uint64;
(* tst	x8, #0x1                                    #! PC = 0xaaaabe371ec0 *)
spl dc x8_lo x8 1;
and ne@bit x8_lo 1@bit;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371ec4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371ec8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371ecc *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371ed0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371ed4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371ed8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371edc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371ee0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371ee4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371ee8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371eec *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371ef0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371ef4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371ef8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371efc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f00 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f04 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f08 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f0c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371f10 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371f14 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371f18 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371f1c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371f20 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f24 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f28 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f2c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f30 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371f34 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371f38 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371f3c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371f40 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371f44 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f48 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f4c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f50 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f54 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371f58 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371f5c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371f60 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371f64 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371f68 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f6c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f70 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f74 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f78 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371f7c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371f80 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371f84 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371f88 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371f8c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f90 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f94 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f98 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f9c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371fa0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371fa4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371fa8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371fac *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371fb0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371fb4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371fb8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371fbc *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371fc0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371fc4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371fc8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371fcc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371fd0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371fd4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371fd8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371fdc *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371fe0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371fe4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371fe8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371fec *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371ff0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371ff4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371ff8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371ffc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372000 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372004 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372008 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37200c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372010 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372014 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372018 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37201c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372020 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372024 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372028 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37202c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372030 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372034 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372038 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37203c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372040 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372044 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372048 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37204c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372050 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372054 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372058 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37205c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372060 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372064 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372068 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37206c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372070 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372074 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372078 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37207c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372080 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372084 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372088 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37208c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372090 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372094 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372098 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37209c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3720a0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3720a4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3720a8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3720ac *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3720b0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3720b4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3720b8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3720bc *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3720c0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3720c4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3720c8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3720cc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3720d0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3720d4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3720d8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3720dc *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3720e0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3720e4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3720e8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3720ec *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3720f0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3720f4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3720f8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3720fc *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372100 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372104 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372108 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37210c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372110 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372114 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372118 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37211c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372120 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372124 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372128 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37212c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372130 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372134 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372138 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37213c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372140 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372144 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372148 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37214c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372150 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372154 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372158 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37215c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372160 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372164 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372168 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37216c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372170 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372174 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372178 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37217c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372180 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372184 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372188 *)
add x3 x3 0x2@sint64;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37218c *)
ssplit x8 dcL x8 1;
(* add	x16, x7, x6                                 #! PC = 0xaaaabe372190 *)
add x16 x7 x6;
(* asr	x16, x16, #42                               #! PC = 0xaaaabe372194 *)
ssplit x16 dcL x16 42;
(* add	x15, x7, #0x100, lsl #12                    #! PC = 0xaaaabe372198 *)
add x15 x7 0x100@sint64, lsl;
(* lsl	x15, x15, #22                               #! PC = 0xaaaabe37219c *)
split dcH x15 x15 (64-22); shl x15 x15 22;
(* asr	x15, x15, #43                               #! PC = 0xaaaabe3721a0 *)
ssplit x15 dcL x15 43;
(* add	x20, x8, x6                                 #! PC = 0xaaaabe3721a4 *)
add x20 x8 x6;
(* asr	x20, x20, #42                               #! PC = 0xaaaabe3721a8 *)
ssplit x20 dcL x20 42;
(* add	x17, x8, #0x100, lsl #12                    #! PC = 0xaaaabe3721ac *)
add x17 x8 0x100@sint64, lsl;
(* lsl	x17, x17, #22                               #! PC = 0xaaaabe3721b0 *)
split dcH x17 x17 (64-22); shl x17 x17 22;
(* asr	x17, x17, #43                               #! PC = 0xaaaabe3721b4 *)
ssplit x17 dcL x17 43;
(* mul	x9, x15, x1                                 #! PC = 0xaaaabe3721b8 *)
mull dcH x9 x15 x1;
(* madd	x9, x16, x2, x9                            #! PC = 0xaaaabe3721bc *)
mull dcH mul_tmp x16 x2;
adds dc x9 mul_tmp x9;
(* asr	x9, x9, #20                                 #! PC = 0xaaaabe3721c0 *)
ssplit x9 dcL x9 20;
(* mul	x10, x17, x1                                #! PC = 0xaaaabe3721c4 *)
mull dcH x10 x17 x1;
(* madd	x10, x20, x2, x10                          #! PC = 0xaaaabe3721c8 *)
mull dcH mul_tmp x20 x2;
adds dc x10 mul_tmp x10;
(* asr	x2, x10, #20                                #! PC = 0xaaaabe3721cc *)
ssplit x2 dcL x10 20;
(* mov	x1, x9                                      #! PC = 0xaaaabe3721d0 *)
mov x1 x9;
(* mul	x9, x15, x11                                #! PC = 0xaaaabe3721d4 *)
mull dcH x9 x15 x11;
(* madd	x10, x16, x13, x9                          #! PC = 0xaaaabe3721d8 *)
mull dcH mul_tmp x16 x13;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x11                                #! PC = 0xaaaabe3721dc *)
mull dcH x9 x17 x11;
(* madd	x13, x20, x13, x9                          #! PC = 0xaaaabe3721e0 *)
mull dcH mul_tmp x20 x13;
adds dc x13 mul_tmp x9;
(* mov	x11, x10                                    #! PC = 0xaaaabe3721e4 *)
mov x11 x10;
(* mul	x9, x15, x12                                #! PC = 0xaaaabe3721e8 *)
mull dcH x9 x15 x12;
(* madd	x10, x16, x14, x9                          #! PC = 0xaaaabe3721ec *)
mull dcH mul_tmp x16 x14;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x12                                #! PC = 0xaaaabe3721f0 *)
mull dcH x9 x17 x12;
(* madd	x14, x20, x14, x9                          #! PC = 0xaaaabe3721f4 *)
mull dcH mul_tmp x20 x14;
adds dc x14 mul_tmp x9;
(* mov	x12, x10                                    #! PC = 0xaaaabe3721f8 *)
mov x12 x10;
(* mov	x9, #0x13                  	// #19          #! PC = 0xaaaabe3721fc *)
mov x9 0x13@uint64;
(* dup	v16.2d, x9                                  #! PC = 0xaaaabe372200 *)
mov %v16 [x9,x9];
(* smull	v17.2d, v13.2s, v8.s[0]                   #! PC = 0xaaaabe372204 *)
smull	%%v17.2d, %%v13.2s, %%v8.s[0]                   #! 0xaaaabe372204 = 0xaaaabe372204;
(* smlal2	v17.2d, v13.4s, v8.s[2]                  #! PC = 0xaaaabe372208 *)
smlal2	%%v17.2d, %%v13.4s, %%v8.s[2]                  #! 0xaaaabe372208 = 0xaaaabe372208;
(* mul	v19.4s, v17.4s, v15.4s                      #! PC = 0xaaaabe37220c *)
mul %v19 %v17 %v15;
(* and	v19.16b, v19.16b, v1.16b                    #! PC = 0xaaaabe372210 *)
and %v19@uint64[2] %v19 %v1;
(* uzp1	v19.4s, v19.4s, v19.4s                     #! PC = 0xaaaabe372214 *)
mov %v19 [%v19[0], %v19[2], %v19[0], %v19[2]];
(* smlsl	v17.2d, v19.2s, v16.s[0]                  #! PC = 0xaaaabe372218 *)
smlsl	%%v17.2d, %%v19.2s, %%v16.s[0]                  #! 0xaaaabe372218 = 0xaaaabe372218;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe37221c *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v8.s[0]                   #! PC = 0xaaaabe372220 *)
smlal	%%v17.2d, %%v14.2s, %%v8.s[0]                   #! 0xaaaabe372220 = 0xaaaabe372220;
(* smlal2	v17.2d, v14.4s, v8.s[2]                  #! PC = 0xaaaabe372224 *)
smlal2	%%v17.2d, %%v14.4s, %%v8.s[2]                  #! 0xaaaabe372224 = 0xaaaabe372224;
(* smlal	v17.2d, v13.2s, v8.s[1]                   #! PC = 0xaaaabe372228 *)
smlal	%%v17.2d, %%v13.2s, %%v8.s[1]                   #! 0xaaaabe372228 = 0xaaaabe372228;
(* smlal2	v17.2d, v13.4s, v8.s[3]                  #! PC = 0xaaaabe37222c *)
smlal2	%%v17.2d, %%v13.4s, %%v8.s[3]                  #! 0xaaaabe37222c = 0xaaaabe37222c;
(* mul	v20.4s, v17.4s, v15.4s                      #! PC = 0xaaaabe372230 *)
mul %v20 %v17 %v15;
(* and	v20.16b, v20.16b, v1.16b                    #! PC = 0xaaaabe372234 *)
and %v20@uint64[2] %v20 %v1;
(* uzp1	v20.4s, v20.4s, v20.4s                     #! PC = 0xaaaabe372238 *)
mov %v20 [%v20[0], %v20[2], %v20[0], %v20[2]];
(* smlsl	v17.2d, v20.2s, v16.s[0]                  #! PC = 0xaaaabe37223c *)
smlsl	%%v17.2d, %%v20.2s, %%v16.s[0]                  #! 0xaaaabe37223c = 0xaaaabe37223c;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe372240 *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v8.s[1]                   #! PC = 0xaaaabe372244 *)
smlal	%%v17.2d, %%v14.2s, %%v8.s[1]                   #! 0xaaaabe372244 = 0xaaaabe372244;
(* smlal2	v17.2d, v14.4s, v8.s[3]                  #! PC = 0xaaaabe372248 *)
smlal2	%%v17.2d, %%v14.4s, %%v8.s[3]                  #! 0xaaaabe372248 = 0xaaaabe372248;
(* smlal	v17.2d, v13.2s, v9.s[0]                   #! PC = 0xaaaabe37224c *)
smlal	%%v17.2d, %%v13.2s, %%v9.s[0]                   #! 0xaaaabe37224c = 0xaaaabe37224c;
(* smlal2	v17.2d, v13.4s, v9.s[2]                  #! PC = 0xaaaabe372250 *)
smlal2	%%v17.2d, %%v13.4s, %%v9.s[2]                  #! 0xaaaabe372250 = 0xaaaabe372250;
(* and	v8.16b, v17.16b, v1.16b                     #! PC = 0xaaaabe372254 *)
and %v8@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe372258 *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v9.s[0]                   #! PC = 0xaaaabe37225c *)
smlal	%%v17.2d, %%v14.2s, %%v9.s[0]                   #! 0xaaaabe37225c = 0xaaaabe37225c;
(* smlal2	v17.2d, v14.4s, v9.s[2]                  #! PC = 0xaaaabe372260 *)
smlal2	%%v17.2d, %%v14.4s, %%v9.s[2]                  #! 0xaaaabe372260 = 0xaaaabe372260;
(* smlal	v17.2d, v13.2s, v9.s[1]                   #! PC = 0xaaaabe372264 *)
smlal	%%v17.2d, %%v13.2s, %%v9.s[1]                   #! 0xaaaabe372264 = 0xaaaabe372264;
(* smlal2	v17.2d, v13.4s, v9.s[3]                  #! PC = 0xaaaabe372268 *)
smlal2	%%v17.2d, %%v13.4s, %%v9.s[3]                  #! 0xaaaabe372268 = 0xaaaabe372268;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe37226c *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe372270 *)
split %v17 %dc %v17 30;
(* sli	v8.2d, v18.2d, #32                          #! PC = 0xaaaabe372274 *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v8 %v8 32; or %v8@uint64[2] %slih %v8;
(* smlal	v17.2d, v14.2s, v9.s[1]                   #! PC = 0xaaaabe372278 *)
smlal	%%v17.2d, %%v14.2s, %%v9.s[1]                   #! 0xaaaabe372278 = 0xaaaabe372278;
(* smlal2	v17.2d, v14.4s, v9.s[3]                  #! PC = 0xaaaabe37227c *)
smlal2	%%v17.2d, %%v14.4s, %%v9.s[3]                  #! 0xaaaabe37227c = 0xaaaabe37227c;
(* smlal	v17.2d, v13.2s, v10.s[0]                  #! PC = 0xaaaabe372280 *)
smlal	%%v17.2d, %%v13.2s, %%v10.s[0]                  #! 0xaaaabe372280 = 0xaaaabe372280;
(* smlal2	v17.2d, v13.4s, v10.s[2]                 #! PC = 0xaaaabe372284 *)
smlal2	%%v17.2d, %%v13.4s, %%v10.s[2]                 #! 0xaaaabe372284 = 0xaaaabe372284;
(* and	v9.16b, v17.16b, v1.16b                     #! PC = 0xaaaabe372288 *)
and %v9@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe37228c *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v10.s[0]                  #! PC = 0xaaaabe372290 *)
smlal	%%v17.2d, %%v14.2s, %%v10.s[0]                  #! 0xaaaabe372290 = 0xaaaabe372290;
(* smlal2	v17.2d, v14.4s, v10.s[2]                 #! PC = 0xaaaabe372294 *)
smlal2	%%v17.2d, %%v14.4s, %%v10.s[2]                 #! 0xaaaabe372294 = 0xaaaabe372294;
(* smlal	v17.2d, v13.2s, v10.s[1]                  #! PC = 0xaaaabe372298 *)
smlal	%%v17.2d, %%v13.2s, %%v10.s[1]                  #! 0xaaaabe372298 = 0xaaaabe372298;
(* smlal2	v17.2d, v13.4s, v10.s[3]                 #! PC = 0xaaaabe37229c *)
smlal2	%%v17.2d, %%v13.4s, %%v10.s[3]                 #! 0xaaaabe37229c = 0xaaaabe37229c;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe3722a0 *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3722a4 *)
split %v17 %dc %v17 30;
(* sli	v9.2d, v18.2d, #32                          #! PC = 0xaaaabe3722a8 *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v9 %v9 32; or %v9@uint64[2] %slih %v9;
(* smlal	v17.2d, v14.2s, v10.s[1]                  #! PC = 0xaaaabe3722ac *)
smlal	%%v17.2d, %%v14.2s, %%v10.s[1]                  #! 0xaaaabe3722ac = 0xaaaabe3722ac;
(* smlal2	v17.2d, v14.4s, v10.s[3]                 #! PC = 0xaaaabe3722b0 *)
smlal2	%%v17.2d, %%v14.4s, %%v10.s[3]                 #! 0xaaaabe3722b0 = 0xaaaabe3722b0;
(* smlal	v17.2d, v13.2s, v11.s[0]                  #! PC = 0xaaaabe3722b4 *)
smlal	%%v17.2d, %%v13.2s, %%v11.s[0]                  #! 0xaaaabe3722b4 = 0xaaaabe3722b4;
(* smlal2	v17.2d, v13.4s, v11.s[2]                 #! PC = 0xaaaabe3722b8 *)
smlal2	%%v17.2d, %%v13.4s, %%v11.s[2]                 #! 0xaaaabe3722b8 = 0xaaaabe3722b8;
(* and	v10.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe3722bc *)
and %v10@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3722c0 *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v11.s[0]                  #! PC = 0xaaaabe3722c4 *)
smlal	%%v17.2d, %%v14.2s, %%v11.s[0]                  #! 0xaaaabe3722c4 = 0xaaaabe3722c4;
(* smlal2	v17.2d, v14.4s, v11.s[2]                 #! PC = 0xaaaabe3722c8 *)
smlal2	%%v17.2d, %%v14.4s, %%v11.s[2]                 #! 0xaaaabe3722c8 = 0xaaaabe3722c8;
(* smlal	v17.2d, v13.2s, v11.s[1]                  #! PC = 0xaaaabe3722cc *)
smlal	%%v17.2d, %%v13.2s, %%v11.s[1]                  #! 0xaaaabe3722cc = 0xaaaabe3722cc;
(* smlal2	v17.2d, v13.4s, v11.s[3]                 #! PC = 0xaaaabe3722d0 *)
smlal2	%%v17.2d, %%v13.4s, %%v11.s[3]                 #! 0xaaaabe3722d0 = 0xaaaabe3722d0;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe3722d4 *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3722d8 *)
split %v17 %dc %v17 30;
(* sli	v10.2d, v18.2d, #32                         #! PC = 0xaaaabe3722dc *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v10 %v10 32; or %v10@uint64[2] %slih %v10;
(* smlal	v17.2d, v14.2s, v11.s[1]                  #! PC = 0xaaaabe3722e0 *)
smlal	%%v17.2d, %%v14.2s, %%v11.s[1]                  #! 0xaaaabe3722e0 = 0xaaaabe3722e0;
(* smlal2	v17.2d, v14.4s, v11.s[3]                 #! PC = 0xaaaabe3722e4 *)
smlal2	%%v17.2d, %%v14.4s, %%v11.s[3]                 #! 0xaaaabe3722e4 = 0xaaaabe3722e4;
(* smlal	v17.2d, v13.2s, v12.s[0]                  #! PC = 0xaaaabe3722e8 *)
smlal	%%v17.2d, %%v13.2s, %%v12.s[0]                  #! 0xaaaabe3722e8 = 0xaaaabe3722e8;
(* smlal2	v17.2d, v13.4s, v12.s[2]                 #! PC = 0xaaaabe3722ec *)
smlal2	%%v17.2d, %%v13.4s, %%v12.s[2]                 #! 0xaaaabe3722ec = 0xaaaabe3722ec;
(* ushll	v19.2d, v19.2s, #15                       #! PC = 0xaaaabe3722f0 *)
ushll	%%v19.2d, %%v19.2s, #15                       #! 0xaaaabe3722f0 = 0xaaaabe3722f0;
(* add	v17.2d, v17.2d, v19.2d                      #! PC = 0xaaaabe3722f4 *)
add	%%v17.2d, %%v17.2d, %%v19.2d                      #! 0xaaaabe3722f4 = 0xaaaabe3722f4;
(* and	v11.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe3722f8 *)
and %v11@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3722fc *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v12.s[0]                  #! PC = 0xaaaabe372300 *)
smlal	%%v17.2d, %%v14.2s, %%v12.s[0]                  #! 0xaaaabe372300 = 0xaaaabe372300;
(* smlal2	v17.2d, v14.4s, v12.s[2]                 #! PC = 0xaaaabe372304 *)
smlal2	%%v17.2d, %%v14.4s, %%v12.s[2]                 #! 0xaaaabe372304 = 0xaaaabe372304;
(* ushll	v20.2d, v20.2s, #15                       #! PC = 0xaaaabe372308 *)
ushll	%%v20.2d, %%v20.2s, #15                       #! 0xaaaabe372308 = 0xaaaabe372308;
(* add	v17.2d, v17.2d, v20.2d                      #! PC = 0xaaaabe37230c *)
add	%%v17.2d, %%v17.2d, %%v20.2d                      #! 0xaaaabe37230c = 0xaaaabe37230c;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe372310 *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v12.2d, v17.2d, #30                        #! PC = 0xaaaabe372314 *)
split %v12 %dc %v17 30;
(* sli	v11.2d, v18.2d, #32                         #! PC = 0xaaaabe372318 *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v11 %v11 32; or %v11@uint64[2] %slih %v11;
(* sshr	v18.2d, v12.2d, #15                        #! PC = 0xaaaabe37231c *)
split %v18 %dc %v12 15;
(* shl	v17.2d, v18.2d, #15                         #! PC = 0xaaaabe372320 *)
shls %dc %v17 %v18 [15, 15];
(* sub	v12.2d, v12.2d, v17.2d                      #! PC = 0xaaaabe372324 *)
sub	%%v12.2d, %%v12.2d, %%v17.2d                      #! 0xaaaabe372324 = 0xaaaabe372324;
(* mla	v8.4s, v18.4s, v16.4s                       #! PC = 0xaaaabe372328 *)
mull %dc %mla %v18 %v16; add %v8 %v8 %mla;
(* and	x7, x1, #0xfffff                            #! PC = 0xaaaabe37232c *)
and x7@uint64 x1 0xfffff@uint64;
(* and	x8, x2, #0xfffff                            #! PC = 0xaaaabe372330 *)
and x8@uint64 x2 0xfffff@uint64;
(* orr	x7, x7, #0xfffffe0000000000                 #! PC = 0xaaaabe372334 *)
or x7@uint64 x7 0xfffffe0000000000@uint64;
(* orr	x8, x8, #0xc000000000000000                 #! PC = 0xaaaabe372338 *)
or x8@uint64 x8 0xc000000000000000@uint64;
(* tst	x8, #0x1                                    #! PC = 0xaaaabe37233c *)
spl dc x8_lo x8 1;
and ne@bit x8_lo 1@bit;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372340 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372344 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372348 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37234c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372350 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372354 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372358 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37235c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372360 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372364 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372368 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37236c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372370 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372374 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372378 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37237c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372380 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372384 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372388 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37238c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372390 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372394 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372398 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37239c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3723a0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3723a4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3723a8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3723ac *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3723b0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3723b4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3723b8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3723bc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3723c0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3723c4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3723c8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3723cc *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3723d0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3723d4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3723d8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3723dc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3723e0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3723e4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3723e8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3723ec *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3723f0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3723f4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3723f8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3723fc *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372400 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372404 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372408 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37240c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372410 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372414 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372418 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37241c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372420 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372424 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372428 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37242c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372430 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372434 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372438 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37243c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372440 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372444 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372448 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37244c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372450 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372454 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372458 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37245c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372460 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372464 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372468 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37246c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372470 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372474 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372478 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37247c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372480 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372484 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372488 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37248c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372490 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372494 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372498 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37249c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3724a0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3724a4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3724a8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3724ac *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3724b0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3724b4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3724b8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3724bc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3724c0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3724c4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3724c8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3724cc *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3724d0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3724d4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3724d8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3724dc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3724e0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3724e4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3724e8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3724ec *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3724f0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3724f4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3724f8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3724fc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372500 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372504 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372508 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37250c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372510 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372514 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372518 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37251c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372520 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372524 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372528 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37252c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372530 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372534 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372538 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37253c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372540 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372544 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372548 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37254c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372550 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372554 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372558 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37255c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372560 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372564 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372568 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37256c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372570 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372574 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372578 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37257c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372580 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372584 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372588 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37258c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372590 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372594 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372598 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37259c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3725a0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3725a4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3725a8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3725ac *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3725b0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3725b4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3725b8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3725bc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3725c0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3725c4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3725c8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3725cc *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3725d0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3725d4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3725d8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3725dc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3725e0 *)
add x3 x3 0x2@sint64;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3725e4 *)
ssplit x8 dcL x8 1;
(* add	x16, x7, x6                                 #! PC = 0xaaaabe3725e8 *)
add x16 x7 x6;
(* asr	x16, x16, #42                               #! PC = 0xaaaabe3725ec *)
ssplit x16 dcL x16 42;
(* add	x15, x7, #0x100, lsl #12                    #! PC = 0xaaaabe3725f0 *)
add x15 x7 0x100@sint64, lsl;
(* lsl	x15, x15, #22                               #! PC = 0xaaaabe3725f4 *)
split dcH x15 x15 (64-22); shl x15 x15 22;
(* asr	x15, x15, #43                               #! PC = 0xaaaabe3725f8 *)
ssplit x15 dcL x15 43;
(* add	x20, x8, x6                                 #! PC = 0xaaaabe3725fc *)
add x20 x8 x6;
(* asr	x20, x20, #42                               #! PC = 0xaaaabe372600 *)
ssplit x20 dcL x20 42;
(* add	x17, x8, #0x100, lsl #12                    #! PC = 0xaaaabe372604 *)
add x17 x8 0x100@sint64, lsl;
(* lsl	x17, x17, #22                               #! PC = 0xaaaabe372608 *)
split dcH x17 x17 (64-22); shl x17 x17 22;
(* asr	x17, x17, #43                               #! PC = 0xaaaabe37260c *)
ssplit x17 dcL x17 43;
(* mul	x9, x15, x11                                #! PC = 0xaaaabe372610 *)
mull dcH x9 x15 x11;
(* madd	x10, x16, x13, x9                          #! PC = 0xaaaabe372614 *)
mull dcH mul_tmp x16 x13;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x11                                #! PC = 0xaaaabe372618 *)
mull dcH x9 x17 x11;
(* madd	x13, x20, x13, x9                          #! PC = 0xaaaabe37261c *)
mull dcH mul_tmp x20 x13;
adds dc x13 mul_tmp x9;
(* mov	x11, x10                                    #! PC = 0xaaaabe372620 *)
mov x11 x10;
(* mul	x9, x15, x12                                #! PC = 0xaaaabe372624 *)
mull dcH x9 x15 x12;
(* madd	x10, x16, x14, x9                          #! PC = 0xaaaabe372628 *)
mull dcH mul_tmp x16 x14;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x12                                #! PC = 0xaaaabe37262c *)
mull dcH x9 x17 x12;
(* madd	x14, x20, x14, x9                          #! PC = 0xaaaabe372630 *)
mull dcH mul_tmp x20 x14;
adds dc x14 mul_tmp x9;
(* mov	x12, x10                                    #! PC = 0xaaaabe372634 *)
mov x12 x10;
(* subs	x19, x19, #0x1                             #! PC = 0xaaaabe372638 *)
subc carry x19 x19 0x1@uint64;
(* #cbnz	x19, 0xaaaabe371960 <Lbig_loop>           #! PC = 0xaaaabe37263c *)
#cbnz	%%x19, 0xaaaabe371960 <Lbig_loop>           #! 0xaaaabe37263c = 0xaaaabe37263c;
(* mov	v16.d[0], x11                               #! PC = 0xaaaabe371960 *)
mov %v16 [x11, %v16[1]];
(* mov	v16.d[1], x13                               #! PC = 0xaaaabe371964 *)
mov %v16 [%v16[0], x13];
(* mov	v17.d[0], x12                               #! PC = 0xaaaabe371968 *)
mov %v17 [x12, %v17[1]];
(* mov	v17.d[1], x14                               #! PC = 0xaaaabe37196c *)
mov %v17 [%v17[0], x14];
(* uzp1	v13.4s, v16.4s, v17.4s                     #! PC = 0xaaaabe371970 *)
mov %v13 [%v16[0], %v16[2], %v17[0], %v17[2]];
(* and	v13.16b, v13.16b, v2.16b                    #! PC = 0xaaaabe371974 *)
and %v13@uint64[2] %v13 %v2;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371978 *)
split %v16 %dc %v16 30;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe37197c *)
split %v17 %dc %v17 30;
(* uzp1	v14.4s, v16.4s, v17.4s                     #! PC = 0xaaaabe371980 *)
mov %v14 [%v16[0], %v16[2], %v17[0], %v17[2]];
(* cmp	x11, xzr                                    #! PC = 0xaaaabe371984 *)
subc zero dc 0@uint64 x11;
(* csetm	x23, mi	// mi = first                     #! PC = 0xaaaabe371988 *)
csetm	%%x23, mi	// mi = first                     #! 0xaaaabe371988 = 0xaaaabe371988;
(* cneg	x11, x11, mi	// mi = first                 #! PC = 0xaaaabe37198c *)
cneg	%%x11, %%x11, mi	// mi = first                 #! 0xaaaabe37198c = 0xaaaabe37198c;
(* cmp	x12, xzr                                    #! PC = 0xaaaabe371990 *)
subc zero dc 0@uint64 x12;
(* csetm	x24, mi	// mi = first                     #! PC = 0xaaaabe371994 *)
csetm	%%x24, mi	// mi = first                     #! 0xaaaabe371994 = 0xaaaabe371994;
(* cneg	x12, x12, mi	// mi = first                 #! PC = 0xaaaabe371998 *)
cneg	%%x12, %%x12, mi	// mi = first                 #! 0xaaaabe371998 = 0xaaaabe371998;
(* cmp	x13, xzr                                    #! PC = 0xaaaabe37199c *)
subc zero dc 0@uint64 x13;
(* csetm	x25, mi	// mi = first                     #! PC = 0xaaaabe3719a0 *)
csetm	%%x25, mi	// mi = first                     #! 0xaaaabe3719a0 = 0xaaaabe3719a0;
(* cneg	x13, x13, mi	// mi = first                 #! PC = 0xaaaabe3719a4 *)
cneg	%%x13, %%x13, mi	// mi = first                 #! 0xaaaabe3719a4 = 0xaaaabe3719a4;
(* cmp	x14, xzr                                    #! PC = 0xaaaabe3719a8 *)
subc zero dc 0@uint64 x14;
(* csetm	x26, mi	// mi = first                     #! PC = 0xaaaabe3719ac *)
csetm	%%x26, mi	// mi = first                     #! 0xaaaabe3719ac = 0xaaaabe3719ac;
(* cneg	x14, x14, mi	// mi = first                 #! PC = 0xaaaabe3719b0 *)
cneg	%%x14, %%x14, mi	// mi = first                 #! 0xaaaabe3719b0 = 0xaaaabe3719b0;
(* and	x27, x11, x23                               #! PC = 0xaaaabe3719b4 *)
and x27@uint64 x11 x23;
(* and	x28, x12, x24                               #! PC = 0xaaaabe3719b8 *)
and x28@uint64 x12 x24;
(* add	x15, x27, x28                               #! PC = 0xaaaabe3719bc *)
add x15 x27 x28;
(* eor	x27, x4, x23                                #! PC = 0xaaaabe3719c0 *)
xor x27@uint64 x4 x23;
(* mul	x9, x27, x11                                #! PC = 0xaaaabe3719c4 *)
mull dcH x9 x27 x11;
(* umulh	x10, x27, x11                             #! PC = 0xaaaabe3719c8 *)
mull x10 dcL x27 x11;
(* adds	x15, x9, x15                               #! PC = 0xaaaabe3719cc *)
adds carry x15 x9 x15;
(* adc	x16, x10, xzr                               #! PC = 0xaaaabe3719d0 *)
adc x16 x10 0@uint64 carry;
(* eor	x27, x21, x23                               #! PC = 0xaaaabe3719d4 *)
xor x27@uint64 x21 x23;
(* mul	x9, x27, x11                                #! PC = 0xaaaabe3719d8 *)
mull dcH x9 x27 x11;
(* add	x16, x16, x9                                #! PC = 0xaaaabe3719dc *)
add x16 x16 x9;
(* eor	x27, x5, x24                                #! PC = 0xaaaabe3719e0 *)
xor x27@uint64 x5 x24;
(* mul	x9, x27, x12                                #! PC = 0xaaaabe3719e4 *)
mull dcH x9 x27 x12;
(* umulh	x10, x27, x12                             #! PC = 0xaaaabe3719e8 *)
mull x10 dcL x27 x12;
(* adds	x15, x9, x15                               #! PC = 0xaaaabe3719ec *)
adds carry x15 x9 x15;
(* adc	x16, x10, x16                               #! PC = 0xaaaabe3719f0 *)
adc x16 x10 x16 carry;
(* eor	x27, x22, x24                               #! PC = 0xaaaabe3719f4 *)
xor x27@uint64 x22 x24;
(* mul	x9, x27, x12                                #! PC = 0xaaaabe3719f8 *)
mull dcH x9 x27 x12;
(* add	x16, x16, x9                                #! PC = 0xaaaabe3719fc *)
add x16 x16 x9;
(* extr	x1, x16, x15, #60                          #! PC = 0xaaaabe371a00 *)
spl dc extr_H x16 60; spl extr_L dc x15 60; join x1 extr_H extr_L;
(* and	x27, x13, x25                               #! PC = 0xaaaabe371a04 *)
and x27@uint64 x13 x25;
(* and	x28, x14, x26                               #! PC = 0xaaaabe371a08 *)
and x28@uint64 x14 x26;
(* add	x17, x27, x28                               #! PC = 0xaaaabe371a0c *)
add x17 x27 x28;
(* eor	x27, x4, x25                                #! PC = 0xaaaabe371a10 *)
xor x27@uint64 x4 x25;
(* mul	x9, x27, x13                                #! PC = 0xaaaabe371a14 *)
mull dcH x9 x27 x13;
(* umulh	x10, x27, x13                             #! PC = 0xaaaabe371a18 *)
mull x10 dcL x27 x13;
(* adds	x17, x9, x17                               #! PC = 0xaaaabe371a1c *)
adds carry x17 x9 x17;
(* adc	x20, x10, xzr                               #! PC = 0xaaaabe371a20 *)
adc x20 x10 0@uint64 carry;
(* eor	x27, x21, x25                               #! PC = 0xaaaabe371a24 *)
xor x27@uint64 x21 x25;
(* mul	x9, x27, x13                                #! PC = 0xaaaabe371a28 *)
mull dcH x9 x27 x13;
(* add	x20, x20, x9                                #! PC = 0xaaaabe371a2c *)
add x20 x20 x9;
(* eor	x27, x5, x26                                #! PC = 0xaaaabe371a30 *)
xor x27@uint64 x5 x26;
(* mul	x9, x27, x14                                #! PC = 0xaaaabe371a34 *)
mull dcH x9 x27 x14;
(* umulh	x10, x27, x14                             #! PC = 0xaaaabe371a38 *)
mull x10 dcL x27 x14;
(* adds	x17, x9, x17                               #! PC = 0xaaaabe371a3c *)
adds carry x17 x9 x17;
(* adc	x20, x10, x20                               #! PC = 0xaaaabe371a40 *)
adc x20 x10 x20 carry;
(* eor	x27, x22, x26                               #! PC = 0xaaaabe371a44 *)
xor x27@uint64 x22 x26;
(* mul	x9, x27, x14                                #! PC = 0xaaaabe371a48 *)
mull dcH x9 x27 x14;
(* add	x20, x20, x9                                #! PC = 0xaaaabe371a4c *)
add x20 x20 x9;
(* extr	x2, x20, x17, #60                          #! PC = 0xaaaabe371a50 *)
spl dc extr_H x20 60; spl extr_L dc x17 60; join x2 extr_H extr_L;
(* smull	v16.2d, v13.2s, v3.s[0]                   #! PC = 0xaaaabe371a54 *)
smull	%%v16.2d, %%v13.2s, %%v3.s[0]                   #! 0xaaaabe371a54 = 0xaaaabe371a54;
(* smlal2	v16.2d, v13.4s, v3.s[2]                  #! PC = 0xaaaabe371a58 *)
smlal2	%%v16.2d, %%v13.4s, %%v3.s[2]                  #! 0xaaaabe371a58 = 0xaaaabe371a58;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371a5c *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v3.s[0]                   #! PC = 0xaaaabe371a60 *)
smlal	%%v16.2d, %%v14.2s, %%v3.s[0]                   #! 0xaaaabe371a60 = 0xaaaabe371a60;
(* smlal2	v16.2d, v14.4s, v3.s[2]                  #! PC = 0xaaaabe371a64 *)
smlal2	%%v16.2d, %%v14.4s, %%v3.s[2]                  #! 0xaaaabe371a64 = 0xaaaabe371a64;
(* smlal	v16.2d, v13.2s, v3.s[1]                   #! PC = 0xaaaabe371a68 *)
smlal	%%v16.2d, %%v13.2s, %%v3.s[1]                   #! 0xaaaabe371a68 = 0xaaaabe371a68;
(* smlal2	v16.2d, v13.4s, v3.s[3]                  #! PC = 0xaaaabe371a6c *)
smlal2	%%v16.2d, %%v13.4s, %%v3.s[3]                  #! 0xaaaabe371a6c = 0xaaaabe371a6c;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371a70 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v3.s[1]                   #! PC = 0xaaaabe371a74 *)
smlal	%%v16.2d, %%v14.2s, %%v3.s[1]                   #! 0xaaaabe371a74 = 0xaaaabe371a74;
(* smlal2	v16.2d, v14.4s, v3.s[3]                  #! PC = 0xaaaabe371a78 *)
smlal2	%%v16.2d, %%v14.4s, %%v3.s[3]                  #! 0xaaaabe371a78 = 0xaaaabe371a78;
(* smlal	v16.2d, v13.2s, v4.s[0]                   #! PC = 0xaaaabe371a7c *)
smlal	%%v16.2d, %%v13.2s, %%v4.s[0]                   #! 0xaaaabe371a7c = 0xaaaabe371a7c;
(* smlal2	v16.2d, v13.4s, v4.s[2]                  #! PC = 0xaaaabe371a80 *)
smlal2	%%v16.2d, %%v13.4s, %%v4.s[2]                  #! 0xaaaabe371a80 = 0xaaaabe371a80;
(* and	v3.16b, v16.16b, v1.16b                     #! PC = 0xaaaabe371a84 *)
and %v3@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371a88 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v4.s[0]                   #! PC = 0xaaaabe371a8c *)
smlal	%%v16.2d, %%v14.2s, %%v4.s[0]                   #! 0xaaaabe371a8c = 0xaaaabe371a8c;
(* smlal2	v16.2d, v14.4s, v4.s[2]                  #! PC = 0xaaaabe371a90 *)
smlal2	%%v16.2d, %%v14.4s, %%v4.s[2]                  #! 0xaaaabe371a90 = 0xaaaabe371a90;
(* smlal	v16.2d, v13.2s, v4.s[1]                   #! PC = 0xaaaabe371a94 *)
smlal	%%v16.2d, %%v13.2s, %%v4.s[1]                   #! 0xaaaabe371a94 = 0xaaaabe371a94;
(* smlal2	v16.2d, v13.4s, v4.s[3]                  #! PC = 0xaaaabe371a98 *)
smlal2	%%v16.2d, %%v13.4s, %%v4.s[3]                  #! 0xaaaabe371a98 = 0xaaaabe371a98;
(* and	v17.16b, v16.16b, v1.16b                    #! PC = 0xaaaabe371a9c *)
and %v17@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371aa0 *)
split %v16 %dc %v16 30;
(* shl	v17.2d, v17.2d, #32                         #! PC = 0xaaaabe371aa4 *)
shls %dc %v17 %v17 [32, 32];
(* orr	v3.16b, v3.16b, v17.16b                     #! PC = 0xaaaabe371aa8 *)
or %v3@uint64[2] %v3 %v17;
(* smlal	v16.2d, v14.2s, v4.s[1]                   #! PC = 0xaaaabe371aac *)
smlal	%%v16.2d, %%v14.2s, %%v4.s[1]                   #! 0xaaaabe371aac = 0xaaaabe371aac;
(* smlal2	v16.2d, v14.4s, v4.s[3]                  #! PC = 0xaaaabe371ab0 *)
smlal2	%%v16.2d, %%v14.4s, %%v4.s[3]                  #! 0xaaaabe371ab0 = 0xaaaabe371ab0;
(* smlal	v16.2d, v13.2s, v5.s[0]                   #! PC = 0xaaaabe371ab4 *)
smlal	%%v16.2d, %%v13.2s, %%v5.s[0]                   #! 0xaaaabe371ab4 = 0xaaaabe371ab4;
(* smlal2	v16.2d, v13.4s, v5.s[2]                  #! PC = 0xaaaabe371ab8 *)
smlal2	%%v16.2d, %%v13.4s, %%v5.s[2]                  #! 0xaaaabe371ab8 = 0xaaaabe371ab8;
(* and	v4.16b, v16.16b, v1.16b                     #! PC = 0xaaaabe371abc *)
and %v4@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371ac0 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v5.s[0]                   #! PC = 0xaaaabe371ac4 *)
smlal	%%v16.2d, %%v14.2s, %%v5.s[0]                   #! 0xaaaabe371ac4 = 0xaaaabe371ac4;
(* smlal2	v16.2d, v14.4s, v5.s[2]                  #! PC = 0xaaaabe371ac8 *)
smlal2	%%v16.2d, %%v14.4s, %%v5.s[2]                  #! 0xaaaabe371ac8 = 0xaaaabe371ac8;
(* smlal	v16.2d, v13.2s, v5.s[1]                   #! PC = 0xaaaabe371acc *)
smlal	%%v16.2d, %%v13.2s, %%v5.s[1]                   #! 0xaaaabe371acc = 0xaaaabe371acc;
(* smlal2	v16.2d, v13.4s, v5.s[3]                  #! PC = 0xaaaabe371ad0 *)
smlal2	%%v16.2d, %%v13.4s, %%v5.s[3]                  #! 0xaaaabe371ad0 = 0xaaaabe371ad0;
(* and	v17.16b, v16.16b, v1.16b                    #! PC = 0xaaaabe371ad4 *)
and %v17@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371ad8 *)
split %v16 %dc %v16 30;
(* shl	v17.2d, v17.2d, #32                         #! PC = 0xaaaabe371adc *)
shls %dc %v17 %v17 [32, 32];
(* orr	v4.16b, v4.16b, v17.16b                     #! PC = 0xaaaabe371ae0 *)
or %v4@uint64[2] %v4 %v17;
(* smlal	v16.2d, v14.2s, v5.s[1]                   #! PC = 0xaaaabe371ae4 *)
smlal	%%v16.2d, %%v14.2s, %%v5.s[1]                   #! 0xaaaabe371ae4 = 0xaaaabe371ae4;
(* smlal2	v16.2d, v14.4s, v5.s[3]                  #! PC = 0xaaaabe371ae8 *)
smlal2	%%v16.2d, %%v14.4s, %%v5.s[3]                  #! 0xaaaabe371ae8 = 0xaaaabe371ae8;
(* smlal	v16.2d, v13.2s, v6.s[0]                   #! PC = 0xaaaabe371aec *)
smlal	%%v16.2d, %%v13.2s, %%v6.s[0]                   #! 0xaaaabe371aec = 0xaaaabe371aec;
(* smlal2	v16.2d, v13.4s, v6.s[2]                  #! PC = 0xaaaabe371af0 *)
smlal2	%%v16.2d, %%v13.4s, %%v6.s[2]                  #! 0xaaaabe371af0 = 0xaaaabe371af0;
(* and	v5.16b, v16.16b, v1.16b                     #! PC = 0xaaaabe371af4 *)
and %v5@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371af8 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v6.s[0]                   #! PC = 0xaaaabe371afc *)
smlal	%%v16.2d, %%v14.2s, %%v6.s[0]                   #! 0xaaaabe371afc = 0xaaaabe371afc;
(* smlal2	v16.2d, v14.4s, v6.s[2]                  #! PC = 0xaaaabe371b00 *)
smlal2	%%v16.2d, %%v14.4s, %%v6.s[2]                  #! 0xaaaabe371b00 = 0xaaaabe371b00;
(* smlal	v16.2d, v13.2s, v6.s[1]                   #! PC = 0xaaaabe371b04 *)
smlal	%%v16.2d, %%v13.2s, %%v6.s[1]                   #! 0xaaaabe371b04 = 0xaaaabe371b04;
(* smlal2	v16.2d, v13.4s, v6.s[3]                  #! PC = 0xaaaabe371b08 *)
smlal2	%%v16.2d, %%v13.4s, %%v6.s[3]                  #! 0xaaaabe371b08 = 0xaaaabe371b08;
(* and	v17.16b, v16.16b, v1.16b                    #! PC = 0xaaaabe371b0c *)
and %v17@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371b10 *)
split %v16 %dc %v16 30;
(* shl	v17.2d, v17.2d, #32                         #! PC = 0xaaaabe371b14 *)
shls %dc %v17 %v17 [32, 32];
(* orr	v5.16b, v5.16b, v17.16b                     #! PC = 0xaaaabe371b18 *)
or %v5@uint64[2] %v5 %v17;
(* smlal	v16.2d, v14.2s, v6.s[1]                   #! PC = 0xaaaabe371b1c *)
smlal	%%v16.2d, %%v14.2s, %%v6.s[1]                   #! 0xaaaabe371b1c = 0xaaaabe371b1c;
(* smlal2	v16.2d, v14.4s, v6.s[3]                  #! PC = 0xaaaabe371b20 *)
smlal2	%%v16.2d, %%v14.4s, %%v6.s[3]                  #! 0xaaaabe371b20 = 0xaaaabe371b20;
(* smlal	v16.2d, v13.2s, v7.s[0]                   #! PC = 0xaaaabe371b24 *)
smlal	%%v16.2d, %%v13.2s, %%v7.s[0]                   #! 0xaaaabe371b24 = 0xaaaabe371b24;
(* smlal2	v16.2d, v13.4s, v7.s[2]                  #! PC = 0xaaaabe371b28 *)
smlal2	%%v16.2d, %%v13.4s, %%v7.s[2]                  #! 0xaaaabe371b28 = 0xaaaabe371b28;
(* and	v6.16b, v16.16b, v1.16b                     #! PC = 0xaaaabe371b2c *)
and %v6@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371b30 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v7.s[0]                   #! PC = 0xaaaabe371b34 *)
smlal	%%v16.2d, %%v14.2s, %%v7.s[0]                   #! 0xaaaabe371b34 = 0xaaaabe371b34;
(* smlal2	v16.2d, v14.4s, v7.s[2]                  #! PC = 0xaaaabe371b38 *)
smlal2	%%v16.2d, %%v14.4s, %%v7.s[2]                  #! 0xaaaabe371b38 = 0xaaaabe371b38;
(* and	v17.16b, v16.16b, v1.16b                    #! PC = 0xaaaabe371b3c *)
and %v17@uint64[2] %v16 %v1;
(* sshr	v7.2d, v16.2d, #30                         #! PC = 0xaaaabe371b40 *)
split %v7 %dc %v16 30;
(* shl	v17.2d, v17.2d, #32                         #! PC = 0xaaaabe371b44 *)
shls %dc %v17 %v17 [32, 32];
(* orr	v6.16b, v6.16b, v17.16b                     #! PC = 0xaaaabe371b48 *)
or %v6@uint64[2] %v6 %v17;
(* and	x7, x1, #0xfffff                            #! PC = 0xaaaabe371b4c *)
and x7@uint64 x1 0xfffff@uint64;
(* and	x8, x2, #0xfffff                            #! PC = 0xaaaabe371b50 *)
and x8@uint64 x2 0xfffff@uint64;
(* orr	x7, x7, #0xfffffe0000000000                 #! PC = 0xaaaabe371b54 *)
or x7@uint64 x7 0xfffffe0000000000@uint64;
(* orr	x8, x8, #0xc000000000000000                 #! PC = 0xaaaabe371b58 *)
or x8@uint64 x8 0xc000000000000000@uint64;
(* tst	x8, #0x1                                    #! PC = 0xaaaabe371b5c *)
spl dc x8_lo x8 1;
and ne@bit x8_lo 1@bit;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371b60 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371b64 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371b68 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371b6c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371b70 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371b74 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371b78 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371b7c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371b80 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371b84 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371b88 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371b8c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371b90 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371b94 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371b98 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371b9c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371ba0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371ba4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371ba8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371bac *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371bb0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371bb4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371bb8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371bbc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371bc0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371bc4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371bc8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371bcc *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371bd0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371bd4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371bd8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371bdc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371be0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371be4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371be8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371bec *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371bf0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371bf4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371bf8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371bfc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c00 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c04 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c08 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c0c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371c10 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371c14 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371c18 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371c1c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371c20 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c24 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c28 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c2c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c30 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371c34 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371c38 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371c3c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371c40 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371c44 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c48 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c4c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c50 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c54 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371c58 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371c5c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371c60 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371c64 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371c68 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c6c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c70 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c74 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c78 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371c7c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371c80 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371c84 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371c88 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371c8c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c90 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c94 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c98 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c9c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371ca0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371ca4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371ca8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371cac *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371cb0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371cb4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371cb8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371cbc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371cc0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371cc4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371cc8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371ccc *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371cd0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371cd4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371cd8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371cdc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371ce0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371ce4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371ce8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371cec *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371cf0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371cf4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371cf8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371cfc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d00 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d04 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d08 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d0c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371d10 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371d14 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371d18 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371d1c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371d20 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d24 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d28 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d2c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d30 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371d34 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371d38 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371d3c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371d40 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371d44 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d48 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d4c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d50 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d54 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371d58 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371d5c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371d60 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371d64 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371d68 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d6c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d70 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d74 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d78 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371d7c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371d80 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371d84 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371d88 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371d8c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d90 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d94 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d98 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d9c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371da0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371da4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371da8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371dac *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371db0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371db4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371db8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371dbc *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371dc0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371dc4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371dc8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371dcc *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371dd0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371dd4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371dd8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371ddc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371de0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371de4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371de8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371dec *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371df0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371df4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371df8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371dfc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371e00 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371e04 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371e08 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371e0c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371e10 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371e14 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371e18 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371e1c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371e20 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371e24 *)
add x3 x3 0x2@sint64;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371e28 *)
ssplit x8 dcL x8 1;
(* add	x12, x7, x6                                 #! PC = 0xaaaabe371e2c *)
add x12 x7 x6;
(* asr	x12, x12, #42                               #! PC = 0xaaaabe371e30 *)
ssplit x12 dcL x12 42;
(* add	x11, x7, #0x100, lsl #12                    #! PC = 0xaaaabe371e34 *)
add x11 x7 0x100@sint64, lsl;
(* lsl	x11, x11, #22                               #! PC = 0xaaaabe371e38 *)
split dcH x11 x11 (64-22); shl x11 x11 22;
(* asr	x11, x11, #43                               #! PC = 0xaaaabe371e3c *)
ssplit x11 dcL x11 43;
(* add	x14, x8, x6                                 #! PC = 0xaaaabe371e40 *)
add x14 x8 x6;
(* asr	x14, x14, #42                               #! PC = 0xaaaabe371e44 *)
ssplit x14 dcL x14 42;
(* add	x13, x8, #0x100, lsl #12                    #! PC = 0xaaaabe371e48 *)
add x13 x8 0x100@sint64, lsl;
(* lsl	x13, x13, #22                               #! PC = 0xaaaabe371e4c *)
split dcH x13 x13 (64-22); shl x13 x13 22;
(* asr	x13, x13, #43                               #! PC = 0xaaaabe371e50 *)
ssplit x13 dcL x13 43;
(* mul	x9, x11, x1                                 #! PC = 0xaaaabe371e54 *)
mull dcH x9 x11 x1;
(* madd	x9, x12, x2, x9                            #! PC = 0xaaaabe371e58 *)
mull dcH mul_tmp x12 x2;
adds dc x9 mul_tmp x9;
(* asr	x9, x9, #20                                 #! PC = 0xaaaabe371e5c *)
ssplit x9 dcL x9 20;
(* mul	x10, x13, x1                                #! PC = 0xaaaabe371e60 *)
mull dcH x10 x13 x1;
(* madd	x10, x14, x2, x10                          #! PC = 0xaaaabe371e64 *)
mull dcH mul_tmp x14 x2;
adds dc x10 mul_tmp x10;
(* asr	x2, x10, #20                                #! PC = 0xaaaabe371e68 *)
ssplit x2 dcL x10 20;
(* mov	x1, x9                                      #! PC = 0xaaaabe371e6c *)
mov x1 x9;
(* mov	w4, v3.s[0]                                 #! PC = 0xaaaabe371e70 *)
mov w4 v3.s[0];
(* mov	w27, v3.s[1]                                #! PC = 0xaaaabe371e74 *)
mov w27 v3.s[1];
(* add	x4, x4, x27, lsl #30                        #! PC = 0xaaaabe371e78 *)
add x4 x4 x27, lsl;
(* mov	w27, v4.s[0]                                #! PC = 0xaaaabe371e7c *)
mov w27 v4.s[0];
(* add	x4, x4, x27, lsl #60                        #! PC = 0xaaaabe371e80 *)
add x4 x4 x27, lsl;
(* add	x21, xzr, x27, lsr #4                       #! PC = 0xaaaabe371e84 *)
add	%%x21, xzr, %%x27, lsr #4                       #! 0xaaaabe371e84 = 0xaaaabe371e84;
(* mov	w27, v4.s[1]                                #! PC = 0xaaaabe371e88 *)
mov w27 v4.s[1];
(* add	x21, x21, x27, lsl #26                      #! PC = 0xaaaabe371e8c *)
add x21 x21 x27, lsl;
(* mov	w5, v3.s[2]                                 #! PC = 0xaaaabe371e90 *)
mov w5 v3.s[2];
(* mov	w27, v3.s[3]                                #! PC = 0xaaaabe371e94 *)
mov w27 v3.s[3];
(* add	x5, x5, x27, lsl #30                        #! PC = 0xaaaabe371e98 *)
add x5 x5 x27, lsl;
(* mov	w27, v4.s[2]                                #! PC = 0xaaaabe371e9c *)
mov w27 v4.s[2];
(* add	x5, x5, x27, lsl #60                        #! PC = 0xaaaabe371ea0 *)
add x5 x5 x27, lsl;
(* add	x22, xzr, x27, lsr #4                       #! PC = 0xaaaabe371ea4 *)
add	%%x22, xzr, %%x27, lsr #4                       #! 0xaaaabe371ea4 = 0xaaaabe371ea4;
(* mov	w27, v4.s[3]                                #! PC = 0xaaaabe371ea8 *)
mov w27 v4.s[3];
(* add	x22, x22, x27, lsl #26                      #! PC = 0xaaaabe371eac *)
add x22 x22 x27, lsl;
(* and	x7, x1, #0xfffff                            #! PC = 0xaaaabe371eb0 *)
and x7@uint64 x1 0xfffff@uint64;
(* and	x8, x2, #0xfffff                            #! PC = 0xaaaabe371eb4 *)
and x8@uint64 x2 0xfffff@uint64;
(* orr	x7, x7, #0xfffffe0000000000                 #! PC = 0xaaaabe371eb8 *)
or x7@uint64 x7 0xfffffe0000000000@uint64;
(* orr	x8, x8, #0xc000000000000000                 #! PC = 0xaaaabe371ebc *)
or x8@uint64 x8 0xc000000000000000@uint64;
(* tst	x8, #0x1                                    #! PC = 0xaaaabe371ec0 *)
spl dc x8_lo x8 1;
and ne@bit x8_lo 1@bit;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371ec4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371ec8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371ecc *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371ed0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371ed4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371ed8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371edc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371ee0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371ee4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371ee8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371eec *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371ef0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371ef4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371ef8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371efc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f00 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f04 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f08 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f0c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371f10 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371f14 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371f18 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371f1c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371f20 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f24 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f28 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f2c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f30 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371f34 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371f38 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371f3c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371f40 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371f44 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f48 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f4c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f50 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f54 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371f58 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371f5c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371f60 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371f64 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371f68 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f6c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f70 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f74 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f78 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371f7c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371f80 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371f84 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371f88 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371f8c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f90 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f94 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f98 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f9c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371fa0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371fa4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371fa8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371fac *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371fb0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371fb4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371fb8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371fbc *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371fc0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371fc4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371fc8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371fcc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371fd0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371fd4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371fd8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371fdc *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371fe0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371fe4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371fe8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371fec *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371ff0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371ff4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371ff8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371ffc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372000 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372004 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372008 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37200c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372010 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372014 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372018 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37201c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372020 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372024 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372028 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37202c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372030 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372034 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372038 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37203c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372040 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372044 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372048 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37204c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372050 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372054 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372058 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37205c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372060 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372064 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372068 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37206c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372070 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372074 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372078 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37207c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372080 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372084 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372088 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37208c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372090 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372094 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372098 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37209c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3720a0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3720a4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3720a8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3720ac *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3720b0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3720b4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3720b8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3720bc *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3720c0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3720c4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3720c8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3720cc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3720d0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3720d4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3720d8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3720dc *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3720e0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3720e4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3720e8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3720ec *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3720f0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3720f4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3720f8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3720fc *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372100 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372104 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372108 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37210c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372110 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372114 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372118 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37211c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372120 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372124 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372128 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37212c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372130 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372134 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372138 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37213c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372140 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372144 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372148 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37214c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372150 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372154 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372158 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37215c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372160 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372164 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372168 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37216c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372170 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372174 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372178 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37217c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372180 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372184 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372188 *)
add x3 x3 0x2@sint64;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37218c *)
ssplit x8 dcL x8 1;
(* add	x16, x7, x6                                 #! PC = 0xaaaabe372190 *)
add x16 x7 x6;
(* asr	x16, x16, #42                               #! PC = 0xaaaabe372194 *)
ssplit x16 dcL x16 42;
(* add	x15, x7, #0x100, lsl #12                    #! PC = 0xaaaabe372198 *)
add x15 x7 0x100@sint64, lsl;
(* lsl	x15, x15, #22                               #! PC = 0xaaaabe37219c *)
split dcH x15 x15 (64-22); shl x15 x15 22;
(* asr	x15, x15, #43                               #! PC = 0xaaaabe3721a0 *)
ssplit x15 dcL x15 43;
(* add	x20, x8, x6                                 #! PC = 0xaaaabe3721a4 *)
add x20 x8 x6;
(* asr	x20, x20, #42                               #! PC = 0xaaaabe3721a8 *)
ssplit x20 dcL x20 42;
(* add	x17, x8, #0x100, lsl #12                    #! PC = 0xaaaabe3721ac *)
add x17 x8 0x100@sint64, lsl;
(* lsl	x17, x17, #22                               #! PC = 0xaaaabe3721b0 *)
split dcH x17 x17 (64-22); shl x17 x17 22;
(* asr	x17, x17, #43                               #! PC = 0xaaaabe3721b4 *)
ssplit x17 dcL x17 43;
(* mul	x9, x15, x1                                 #! PC = 0xaaaabe3721b8 *)
mull dcH x9 x15 x1;
(* madd	x9, x16, x2, x9                            #! PC = 0xaaaabe3721bc *)
mull dcH mul_tmp x16 x2;
adds dc x9 mul_tmp x9;
(* asr	x9, x9, #20                                 #! PC = 0xaaaabe3721c0 *)
ssplit x9 dcL x9 20;
(* mul	x10, x17, x1                                #! PC = 0xaaaabe3721c4 *)
mull dcH x10 x17 x1;
(* madd	x10, x20, x2, x10                          #! PC = 0xaaaabe3721c8 *)
mull dcH mul_tmp x20 x2;
adds dc x10 mul_tmp x10;
(* asr	x2, x10, #20                                #! PC = 0xaaaabe3721cc *)
ssplit x2 dcL x10 20;
(* mov	x1, x9                                      #! PC = 0xaaaabe3721d0 *)
mov x1 x9;
(* mul	x9, x15, x11                                #! PC = 0xaaaabe3721d4 *)
mull dcH x9 x15 x11;
(* madd	x10, x16, x13, x9                          #! PC = 0xaaaabe3721d8 *)
mull dcH mul_tmp x16 x13;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x11                                #! PC = 0xaaaabe3721dc *)
mull dcH x9 x17 x11;
(* madd	x13, x20, x13, x9                          #! PC = 0xaaaabe3721e0 *)
mull dcH mul_tmp x20 x13;
adds dc x13 mul_tmp x9;
(* mov	x11, x10                                    #! PC = 0xaaaabe3721e4 *)
mov x11 x10;
(* mul	x9, x15, x12                                #! PC = 0xaaaabe3721e8 *)
mull dcH x9 x15 x12;
(* madd	x10, x16, x14, x9                          #! PC = 0xaaaabe3721ec *)
mull dcH mul_tmp x16 x14;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x12                                #! PC = 0xaaaabe3721f0 *)
mull dcH x9 x17 x12;
(* madd	x14, x20, x14, x9                          #! PC = 0xaaaabe3721f4 *)
mull dcH mul_tmp x20 x14;
adds dc x14 mul_tmp x9;
(* mov	x12, x10                                    #! PC = 0xaaaabe3721f8 *)
mov x12 x10;
(* mov	x9, #0x13                  	// #19          #! PC = 0xaaaabe3721fc *)
mov x9 0x13@uint64;
(* dup	v16.2d, x9                                  #! PC = 0xaaaabe372200 *)
mov %v16 [x9,x9];
(* smull	v17.2d, v13.2s, v8.s[0]                   #! PC = 0xaaaabe372204 *)
smull	%%v17.2d, %%v13.2s, %%v8.s[0]                   #! 0xaaaabe372204 = 0xaaaabe372204;
(* smlal2	v17.2d, v13.4s, v8.s[2]                  #! PC = 0xaaaabe372208 *)
smlal2	%%v17.2d, %%v13.4s, %%v8.s[2]                  #! 0xaaaabe372208 = 0xaaaabe372208;
(* mul	v19.4s, v17.4s, v15.4s                      #! PC = 0xaaaabe37220c *)
mul %v19 %v17 %v15;
(* and	v19.16b, v19.16b, v1.16b                    #! PC = 0xaaaabe372210 *)
and %v19@uint64[2] %v19 %v1;
(* uzp1	v19.4s, v19.4s, v19.4s                     #! PC = 0xaaaabe372214 *)
mov %v19 [%v19[0], %v19[2], %v19[0], %v19[2]];
(* smlsl	v17.2d, v19.2s, v16.s[0]                  #! PC = 0xaaaabe372218 *)
smlsl	%%v17.2d, %%v19.2s, %%v16.s[0]                  #! 0xaaaabe372218 = 0xaaaabe372218;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe37221c *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v8.s[0]                   #! PC = 0xaaaabe372220 *)
smlal	%%v17.2d, %%v14.2s, %%v8.s[0]                   #! 0xaaaabe372220 = 0xaaaabe372220;
(* smlal2	v17.2d, v14.4s, v8.s[2]                  #! PC = 0xaaaabe372224 *)
smlal2	%%v17.2d, %%v14.4s, %%v8.s[2]                  #! 0xaaaabe372224 = 0xaaaabe372224;
(* smlal	v17.2d, v13.2s, v8.s[1]                   #! PC = 0xaaaabe372228 *)
smlal	%%v17.2d, %%v13.2s, %%v8.s[1]                   #! 0xaaaabe372228 = 0xaaaabe372228;
(* smlal2	v17.2d, v13.4s, v8.s[3]                  #! PC = 0xaaaabe37222c *)
smlal2	%%v17.2d, %%v13.4s, %%v8.s[3]                  #! 0xaaaabe37222c = 0xaaaabe37222c;
(* mul	v20.4s, v17.4s, v15.4s                      #! PC = 0xaaaabe372230 *)
mul %v20 %v17 %v15;
(* and	v20.16b, v20.16b, v1.16b                    #! PC = 0xaaaabe372234 *)
and %v20@uint64[2] %v20 %v1;
(* uzp1	v20.4s, v20.4s, v20.4s                     #! PC = 0xaaaabe372238 *)
mov %v20 [%v20[0], %v20[2], %v20[0], %v20[2]];
(* smlsl	v17.2d, v20.2s, v16.s[0]                  #! PC = 0xaaaabe37223c *)
smlsl	%%v17.2d, %%v20.2s, %%v16.s[0]                  #! 0xaaaabe37223c = 0xaaaabe37223c;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe372240 *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v8.s[1]                   #! PC = 0xaaaabe372244 *)
smlal	%%v17.2d, %%v14.2s, %%v8.s[1]                   #! 0xaaaabe372244 = 0xaaaabe372244;
(* smlal2	v17.2d, v14.4s, v8.s[3]                  #! PC = 0xaaaabe372248 *)
smlal2	%%v17.2d, %%v14.4s, %%v8.s[3]                  #! 0xaaaabe372248 = 0xaaaabe372248;
(* smlal	v17.2d, v13.2s, v9.s[0]                   #! PC = 0xaaaabe37224c *)
smlal	%%v17.2d, %%v13.2s, %%v9.s[0]                   #! 0xaaaabe37224c = 0xaaaabe37224c;
(* smlal2	v17.2d, v13.4s, v9.s[2]                  #! PC = 0xaaaabe372250 *)
smlal2	%%v17.2d, %%v13.4s, %%v9.s[2]                  #! 0xaaaabe372250 = 0xaaaabe372250;
(* and	v8.16b, v17.16b, v1.16b                     #! PC = 0xaaaabe372254 *)
and %v8@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe372258 *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v9.s[0]                   #! PC = 0xaaaabe37225c *)
smlal	%%v17.2d, %%v14.2s, %%v9.s[0]                   #! 0xaaaabe37225c = 0xaaaabe37225c;
(* smlal2	v17.2d, v14.4s, v9.s[2]                  #! PC = 0xaaaabe372260 *)
smlal2	%%v17.2d, %%v14.4s, %%v9.s[2]                  #! 0xaaaabe372260 = 0xaaaabe372260;
(* smlal	v17.2d, v13.2s, v9.s[1]                   #! PC = 0xaaaabe372264 *)
smlal	%%v17.2d, %%v13.2s, %%v9.s[1]                   #! 0xaaaabe372264 = 0xaaaabe372264;
(* smlal2	v17.2d, v13.4s, v9.s[3]                  #! PC = 0xaaaabe372268 *)
smlal2	%%v17.2d, %%v13.4s, %%v9.s[3]                  #! 0xaaaabe372268 = 0xaaaabe372268;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe37226c *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe372270 *)
split %v17 %dc %v17 30;
(* sli	v8.2d, v18.2d, #32                          #! PC = 0xaaaabe372274 *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v8 %v8 32; or %v8@uint64[2] %slih %v8;
(* smlal	v17.2d, v14.2s, v9.s[1]                   #! PC = 0xaaaabe372278 *)
smlal	%%v17.2d, %%v14.2s, %%v9.s[1]                   #! 0xaaaabe372278 = 0xaaaabe372278;
(* smlal2	v17.2d, v14.4s, v9.s[3]                  #! PC = 0xaaaabe37227c *)
smlal2	%%v17.2d, %%v14.4s, %%v9.s[3]                  #! 0xaaaabe37227c = 0xaaaabe37227c;
(* smlal	v17.2d, v13.2s, v10.s[0]                  #! PC = 0xaaaabe372280 *)
smlal	%%v17.2d, %%v13.2s, %%v10.s[0]                  #! 0xaaaabe372280 = 0xaaaabe372280;
(* smlal2	v17.2d, v13.4s, v10.s[2]                 #! PC = 0xaaaabe372284 *)
smlal2	%%v17.2d, %%v13.4s, %%v10.s[2]                 #! 0xaaaabe372284 = 0xaaaabe372284;
(* and	v9.16b, v17.16b, v1.16b                     #! PC = 0xaaaabe372288 *)
and %v9@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe37228c *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v10.s[0]                  #! PC = 0xaaaabe372290 *)
smlal	%%v17.2d, %%v14.2s, %%v10.s[0]                  #! 0xaaaabe372290 = 0xaaaabe372290;
(* smlal2	v17.2d, v14.4s, v10.s[2]                 #! PC = 0xaaaabe372294 *)
smlal2	%%v17.2d, %%v14.4s, %%v10.s[2]                 #! 0xaaaabe372294 = 0xaaaabe372294;
(* smlal	v17.2d, v13.2s, v10.s[1]                  #! PC = 0xaaaabe372298 *)
smlal	%%v17.2d, %%v13.2s, %%v10.s[1]                  #! 0xaaaabe372298 = 0xaaaabe372298;
(* smlal2	v17.2d, v13.4s, v10.s[3]                 #! PC = 0xaaaabe37229c *)
smlal2	%%v17.2d, %%v13.4s, %%v10.s[3]                 #! 0xaaaabe37229c = 0xaaaabe37229c;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe3722a0 *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3722a4 *)
split %v17 %dc %v17 30;
(* sli	v9.2d, v18.2d, #32                          #! PC = 0xaaaabe3722a8 *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v9 %v9 32; or %v9@uint64[2] %slih %v9;
(* smlal	v17.2d, v14.2s, v10.s[1]                  #! PC = 0xaaaabe3722ac *)
smlal	%%v17.2d, %%v14.2s, %%v10.s[1]                  #! 0xaaaabe3722ac = 0xaaaabe3722ac;
(* smlal2	v17.2d, v14.4s, v10.s[3]                 #! PC = 0xaaaabe3722b0 *)
smlal2	%%v17.2d, %%v14.4s, %%v10.s[3]                 #! 0xaaaabe3722b0 = 0xaaaabe3722b0;
(* smlal	v17.2d, v13.2s, v11.s[0]                  #! PC = 0xaaaabe3722b4 *)
smlal	%%v17.2d, %%v13.2s, %%v11.s[0]                  #! 0xaaaabe3722b4 = 0xaaaabe3722b4;
(* smlal2	v17.2d, v13.4s, v11.s[2]                 #! PC = 0xaaaabe3722b8 *)
smlal2	%%v17.2d, %%v13.4s, %%v11.s[2]                 #! 0xaaaabe3722b8 = 0xaaaabe3722b8;
(* and	v10.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe3722bc *)
and %v10@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3722c0 *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v11.s[0]                  #! PC = 0xaaaabe3722c4 *)
smlal	%%v17.2d, %%v14.2s, %%v11.s[0]                  #! 0xaaaabe3722c4 = 0xaaaabe3722c4;
(* smlal2	v17.2d, v14.4s, v11.s[2]                 #! PC = 0xaaaabe3722c8 *)
smlal2	%%v17.2d, %%v14.4s, %%v11.s[2]                 #! 0xaaaabe3722c8 = 0xaaaabe3722c8;
(* smlal	v17.2d, v13.2s, v11.s[1]                  #! PC = 0xaaaabe3722cc *)
smlal	%%v17.2d, %%v13.2s, %%v11.s[1]                  #! 0xaaaabe3722cc = 0xaaaabe3722cc;
(* smlal2	v17.2d, v13.4s, v11.s[3]                 #! PC = 0xaaaabe3722d0 *)
smlal2	%%v17.2d, %%v13.4s, %%v11.s[3]                 #! 0xaaaabe3722d0 = 0xaaaabe3722d0;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe3722d4 *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3722d8 *)
split %v17 %dc %v17 30;
(* sli	v10.2d, v18.2d, #32                         #! PC = 0xaaaabe3722dc *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v10 %v10 32; or %v10@uint64[2] %slih %v10;
(* smlal	v17.2d, v14.2s, v11.s[1]                  #! PC = 0xaaaabe3722e0 *)
smlal	%%v17.2d, %%v14.2s, %%v11.s[1]                  #! 0xaaaabe3722e0 = 0xaaaabe3722e0;
(* smlal2	v17.2d, v14.4s, v11.s[3]                 #! PC = 0xaaaabe3722e4 *)
smlal2	%%v17.2d, %%v14.4s, %%v11.s[3]                 #! 0xaaaabe3722e4 = 0xaaaabe3722e4;
(* smlal	v17.2d, v13.2s, v12.s[0]                  #! PC = 0xaaaabe3722e8 *)
smlal	%%v17.2d, %%v13.2s, %%v12.s[0]                  #! 0xaaaabe3722e8 = 0xaaaabe3722e8;
(* smlal2	v17.2d, v13.4s, v12.s[2]                 #! PC = 0xaaaabe3722ec *)
smlal2	%%v17.2d, %%v13.4s, %%v12.s[2]                 #! 0xaaaabe3722ec = 0xaaaabe3722ec;
(* ushll	v19.2d, v19.2s, #15                       #! PC = 0xaaaabe3722f0 *)
ushll	%%v19.2d, %%v19.2s, #15                       #! 0xaaaabe3722f0 = 0xaaaabe3722f0;
(* add	v17.2d, v17.2d, v19.2d                      #! PC = 0xaaaabe3722f4 *)
add	%%v17.2d, %%v17.2d, %%v19.2d                      #! 0xaaaabe3722f4 = 0xaaaabe3722f4;
(* and	v11.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe3722f8 *)
and %v11@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3722fc *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v12.s[0]                  #! PC = 0xaaaabe372300 *)
smlal	%%v17.2d, %%v14.2s, %%v12.s[0]                  #! 0xaaaabe372300 = 0xaaaabe372300;
(* smlal2	v17.2d, v14.4s, v12.s[2]                 #! PC = 0xaaaabe372304 *)
smlal2	%%v17.2d, %%v14.4s, %%v12.s[2]                 #! 0xaaaabe372304 = 0xaaaabe372304;
(* ushll	v20.2d, v20.2s, #15                       #! PC = 0xaaaabe372308 *)
ushll	%%v20.2d, %%v20.2s, #15                       #! 0xaaaabe372308 = 0xaaaabe372308;
(* add	v17.2d, v17.2d, v20.2d                      #! PC = 0xaaaabe37230c *)
add	%%v17.2d, %%v17.2d, %%v20.2d                      #! 0xaaaabe37230c = 0xaaaabe37230c;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe372310 *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v12.2d, v17.2d, #30                        #! PC = 0xaaaabe372314 *)
split %v12 %dc %v17 30;
(* sli	v11.2d, v18.2d, #32                         #! PC = 0xaaaabe372318 *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v11 %v11 32; or %v11@uint64[2] %slih %v11;
(* sshr	v18.2d, v12.2d, #15                        #! PC = 0xaaaabe37231c *)
split %v18 %dc %v12 15;
(* shl	v17.2d, v18.2d, #15                         #! PC = 0xaaaabe372320 *)
shls %dc %v17 %v18 [15, 15];
(* sub	v12.2d, v12.2d, v17.2d                      #! PC = 0xaaaabe372324 *)
sub	%%v12.2d, %%v12.2d, %%v17.2d                      #! 0xaaaabe372324 = 0xaaaabe372324;
(* mla	v8.4s, v18.4s, v16.4s                       #! PC = 0xaaaabe372328 *)
mull %dc %mla %v18 %v16; add %v8 %v8 %mla;
(* and	x7, x1, #0xfffff                            #! PC = 0xaaaabe37232c *)
and x7@uint64 x1 0xfffff@uint64;
(* and	x8, x2, #0xfffff                            #! PC = 0xaaaabe372330 *)
and x8@uint64 x2 0xfffff@uint64;
(* orr	x7, x7, #0xfffffe0000000000                 #! PC = 0xaaaabe372334 *)
or x7@uint64 x7 0xfffffe0000000000@uint64;
(* orr	x8, x8, #0xc000000000000000                 #! PC = 0xaaaabe372338 *)
or x8@uint64 x8 0xc000000000000000@uint64;
(* tst	x8, #0x1                                    #! PC = 0xaaaabe37233c *)
spl dc x8_lo x8 1;
and ne@bit x8_lo 1@bit;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372340 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372344 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372348 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37234c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372350 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372354 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372358 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37235c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372360 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372364 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372368 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37236c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372370 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372374 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372378 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37237c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372380 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372384 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372388 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37238c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372390 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372394 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372398 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37239c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3723a0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3723a4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3723a8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3723ac *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3723b0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3723b4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3723b8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3723bc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3723c0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3723c4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3723c8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3723cc *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3723d0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3723d4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3723d8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3723dc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3723e0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3723e4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3723e8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3723ec *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3723f0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3723f4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3723f8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3723fc *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372400 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372404 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372408 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37240c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372410 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372414 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372418 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37241c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372420 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372424 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372428 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37242c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372430 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372434 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372438 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37243c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372440 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372444 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372448 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37244c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372450 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372454 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372458 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37245c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372460 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372464 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372468 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37246c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372470 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372474 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372478 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37247c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372480 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372484 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372488 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37248c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372490 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372494 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372498 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37249c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3724a0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3724a4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3724a8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3724ac *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3724b0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3724b4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3724b8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3724bc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3724c0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3724c4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3724c8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3724cc *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3724d0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3724d4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3724d8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3724dc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3724e0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3724e4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3724e8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3724ec *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3724f0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3724f4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3724f8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3724fc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372500 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372504 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372508 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37250c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372510 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372514 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372518 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37251c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372520 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372524 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372528 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37252c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372530 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372534 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372538 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37253c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372540 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372544 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372548 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37254c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372550 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372554 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372558 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37255c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372560 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372564 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372568 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37256c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372570 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372574 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372578 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37257c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372580 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372584 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372588 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37258c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372590 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372594 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372598 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37259c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3725a0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3725a4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3725a8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3725ac *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3725b0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3725b4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3725b8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3725bc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3725c0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3725c4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3725c8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3725cc *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3725d0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3725d4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3725d8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3725dc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3725e0 *)
add x3 x3 0x2@sint64;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3725e4 *)
ssplit x8 dcL x8 1;
(* add	x16, x7, x6                                 #! PC = 0xaaaabe3725e8 *)
add x16 x7 x6;
(* asr	x16, x16, #42                               #! PC = 0xaaaabe3725ec *)
ssplit x16 dcL x16 42;
(* add	x15, x7, #0x100, lsl #12                    #! PC = 0xaaaabe3725f0 *)
add x15 x7 0x100@sint64, lsl;
(* lsl	x15, x15, #22                               #! PC = 0xaaaabe3725f4 *)
split dcH x15 x15 (64-22); shl x15 x15 22;
(* asr	x15, x15, #43                               #! PC = 0xaaaabe3725f8 *)
ssplit x15 dcL x15 43;
(* add	x20, x8, x6                                 #! PC = 0xaaaabe3725fc *)
add x20 x8 x6;
(* asr	x20, x20, #42                               #! PC = 0xaaaabe372600 *)
ssplit x20 dcL x20 42;
(* add	x17, x8, #0x100, lsl #12                    #! PC = 0xaaaabe372604 *)
add x17 x8 0x100@sint64, lsl;
(* lsl	x17, x17, #22                               #! PC = 0xaaaabe372608 *)
split dcH x17 x17 (64-22); shl x17 x17 22;
(* asr	x17, x17, #43                               #! PC = 0xaaaabe37260c *)
ssplit x17 dcL x17 43;
(* mul	x9, x15, x11                                #! PC = 0xaaaabe372610 *)
mull dcH x9 x15 x11;
(* madd	x10, x16, x13, x9                          #! PC = 0xaaaabe372614 *)
mull dcH mul_tmp x16 x13;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x11                                #! PC = 0xaaaabe372618 *)
mull dcH x9 x17 x11;
(* madd	x13, x20, x13, x9                          #! PC = 0xaaaabe37261c *)
mull dcH mul_tmp x20 x13;
adds dc x13 mul_tmp x9;
(* mov	x11, x10                                    #! PC = 0xaaaabe372620 *)
mov x11 x10;
(* mul	x9, x15, x12                                #! PC = 0xaaaabe372624 *)
mull dcH x9 x15 x12;
(* madd	x10, x16, x14, x9                          #! PC = 0xaaaabe372628 *)
mull dcH mul_tmp x16 x14;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x12                                #! PC = 0xaaaabe37262c *)
mull dcH x9 x17 x12;
(* madd	x14, x20, x14, x9                          #! PC = 0xaaaabe372630 *)
mull dcH mul_tmp x20 x14;
adds dc x14 mul_tmp x9;
(* mov	x12, x10                                    #! PC = 0xaaaabe372634 *)
mov x12 x10;
(* subs	x19, x19, #0x1                             #! PC = 0xaaaabe372638 *)
subc carry x19 x19 0x1@uint64;
(* #cbnz	x19, 0xaaaabe371960 <Lbig_loop>           #! PC = 0xaaaabe37263c *)
#cbnz	%%x19, 0xaaaabe371960 <Lbig_loop>           #! 0xaaaabe37263c = 0xaaaabe37263c;
(* mov	v16.d[0], x11                               #! PC = 0xaaaabe371960 *)
mov %v16 [x11, %v16[1]];
(* mov	v16.d[1], x13                               #! PC = 0xaaaabe371964 *)
mov %v16 [%v16[0], x13];
(* mov	v17.d[0], x12                               #! PC = 0xaaaabe371968 *)
mov %v17 [x12, %v17[1]];
(* mov	v17.d[1], x14                               #! PC = 0xaaaabe37196c *)
mov %v17 [%v17[0], x14];
(* uzp1	v13.4s, v16.4s, v17.4s                     #! PC = 0xaaaabe371970 *)
mov %v13 [%v16[0], %v16[2], %v17[0], %v17[2]];
(* and	v13.16b, v13.16b, v2.16b                    #! PC = 0xaaaabe371974 *)
and %v13@uint64[2] %v13 %v2;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371978 *)
split %v16 %dc %v16 30;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe37197c *)
split %v17 %dc %v17 30;
(* uzp1	v14.4s, v16.4s, v17.4s                     #! PC = 0xaaaabe371980 *)
mov %v14 [%v16[0], %v16[2], %v17[0], %v17[2]];
(* cmp	x11, xzr                                    #! PC = 0xaaaabe371984 *)
subc zero dc 0@uint64 x11;
(* csetm	x23, mi	// mi = first                     #! PC = 0xaaaabe371988 *)
csetm	%%x23, mi	// mi = first                     #! 0xaaaabe371988 = 0xaaaabe371988;
(* cneg	x11, x11, mi	// mi = first                 #! PC = 0xaaaabe37198c *)
cneg	%%x11, %%x11, mi	// mi = first                 #! 0xaaaabe37198c = 0xaaaabe37198c;
(* cmp	x12, xzr                                    #! PC = 0xaaaabe371990 *)
subc zero dc 0@uint64 x12;
(* csetm	x24, mi	// mi = first                     #! PC = 0xaaaabe371994 *)
csetm	%%x24, mi	// mi = first                     #! 0xaaaabe371994 = 0xaaaabe371994;
(* cneg	x12, x12, mi	// mi = first                 #! PC = 0xaaaabe371998 *)
cneg	%%x12, %%x12, mi	// mi = first                 #! 0xaaaabe371998 = 0xaaaabe371998;
(* cmp	x13, xzr                                    #! PC = 0xaaaabe37199c *)
subc zero dc 0@uint64 x13;
(* csetm	x25, mi	// mi = first                     #! PC = 0xaaaabe3719a0 *)
csetm	%%x25, mi	// mi = first                     #! 0xaaaabe3719a0 = 0xaaaabe3719a0;
(* cneg	x13, x13, mi	// mi = first                 #! PC = 0xaaaabe3719a4 *)
cneg	%%x13, %%x13, mi	// mi = first                 #! 0xaaaabe3719a4 = 0xaaaabe3719a4;
(* cmp	x14, xzr                                    #! PC = 0xaaaabe3719a8 *)
subc zero dc 0@uint64 x14;
(* csetm	x26, mi	// mi = first                     #! PC = 0xaaaabe3719ac *)
csetm	%%x26, mi	// mi = first                     #! 0xaaaabe3719ac = 0xaaaabe3719ac;
(* cneg	x14, x14, mi	// mi = first                 #! PC = 0xaaaabe3719b0 *)
cneg	%%x14, %%x14, mi	// mi = first                 #! 0xaaaabe3719b0 = 0xaaaabe3719b0;
(* and	x27, x11, x23                               #! PC = 0xaaaabe3719b4 *)
and x27@uint64 x11 x23;
(* and	x28, x12, x24                               #! PC = 0xaaaabe3719b8 *)
and x28@uint64 x12 x24;
(* add	x15, x27, x28                               #! PC = 0xaaaabe3719bc *)
add x15 x27 x28;
(* eor	x27, x4, x23                                #! PC = 0xaaaabe3719c0 *)
xor x27@uint64 x4 x23;
(* mul	x9, x27, x11                                #! PC = 0xaaaabe3719c4 *)
mull dcH x9 x27 x11;
(* umulh	x10, x27, x11                             #! PC = 0xaaaabe3719c8 *)
mull x10 dcL x27 x11;
(* adds	x15, x9, x15                               #! PC = 0xaaaabe3719cc *)
adds carry x15 x9 x15;
(* adc	x16, x10, xzr                               #! PC = 0xaaaabe3719d0 *)
adc x16 x10 0@uint64 carry;
(* eor	x27, x21, x23                               #! PC = 0xaaaabe3719d4 *)
xor x27@uint64 x21 x23;
(* mul	x9, x27, x11                                #! PC = 0xaaaabe3719d8 *)
mull dcH x9 x27 x11;
(* add	x16, x16, x9                                #! PC = 0xaaaabe3719dc *)
add x16 x16 x9;
(* eor	x27, x5, x24                                #! PC = 0xaaaabe3719e0 *)
xor x27@uint64 x5 x24;
(* mul	x9, x27, x12                                #! PC = 0xaaaabe3719e4 *)
mull dcH x9 x27 x12;
(* umulh	x10, x27, x12                             #! PC = 0xaaaabe3719e8 *)
mull x10 dcL x27 x12;
(* adds	x15, x9, x15                               #! PC = 0xaaaabe3719ec *)
adds carry x15 x9 x15;
(* adc	x16, x10, x16                               #! PC = 0xaaaabe3719f0 *)
adc x16 x10 x16 carry;
(* eor	x27, x22, x24                               #! PC = 0xaaaabe3719f4 *)
xor x27@uint64 x22 x24;
(* mul	x9, x27, x12                                #! PC = 0xaaaabe3719f8 *)
mull dcH x9 x27 x12;
(* add	x16, x16, x9                                #! PC = 0xaaaabe3719fc *)
add x16 x16 x9;
(* extr	x1, x16, x15, #60                          #! PC = 0xaaaabe371a00 *)
spl dc extr_H x16 60; spl extr_L dc x15 60; join x1 extr_H extr_L;
(* and	x27, x13, x25                               #! PC = 0xaaaabe371a04 *)
and x27@uint64 x13 x25;
(* and	x28, x14, x26                               #! PC = 0xaaaabe371a08 *)
and x28@uint64 x14 x26;
(* add	x17, x27, x28                               #! PC = 0xaaaabe371a0c *)
add x17 x27 x28;
(* eor	x27, x4, x25                                #! PC = 0xaaaabe371a10 *)
xor x27@uint64 x4 x25;
(* mul	x9, x27, x13                                #! PC = 0xaaaabe371a14 *)
mull dcH x9 x27 x13;
(* umulh	x10, x27, x13                             #! PC = 0xaaaabe371a18 *)
mull x10 dcL x27 x13;
(* adds	x17, x9, x17                               #! PC = 0xaaaabe371a1c *)
adds carry x17 x9 x17;
(* adc	x20, x10, xzr                               #! PC = 0xaaaabe371a20 *)
adc x20 x10 0@uint64 carry;
(* eor	x27, x21, x25                               #! PC = 0xaaaabe371a24 *)
xor x27@uint64 x21 x25;
(* mul	x9, x27, x13                                #! PC = 0xaaaabe371a28 *)
mull dcH x9 x27 x13;
(* add	x20, x20, x9                                #! PC = 0xaaaabe371a2c *)
add x20 x20 x9;
(* eor	x27, x5, x26                                #! PC = 0xaaaabe371a30 *)
xor x27@uint64 x5 x26;
(* mul	x9, x27, x14                                #! PC = 0xaaaabe371a34 *)
mull dcH x9 x27 x14;
(* umulh	x10, x27, x14                             #! PC = 0xaaaabe371a38 *)
mull x10 dcL x27 x14;
(* adds	x17, x9, x17                               #! PC = 0xaaaabe371a3c *)
adds carry x17 x9 x17;
(* adc	x20, x10, x20                               #! PC = 0xaaaabe371a40 *)
adc x20 x10 x20 carry;
(* eor	x27, x22, x26                               #! PC = 0xaaaabe371a44 *)
xor x27@uint64 x22 x26;
(* mul	x9, x27, x14                                #! PC = 0xaaaabe371a48 *)
mull dcH x9 x27 x14;
(* add	x20, x20, x9                                #! PC = 0xaaaabe371a4c *)
add x20 x20 x9;
(* extr	x2, x20, x17, #60                          #! PC = 0xaaaabe371a50 *)
spl dc extr_H x20 60; spl extr_L dc x17 60; join x2 extr_H extr_L;
(* smull	v16.2d, v13.2s, v3.s[0]                   #! PC = 0xaaaabe371a54 *)
smull	%%v16.2d, %%v13.2s, %%v3.s[0]                   #! 0xaaaabe371a54 = 0xaaaabe371a54;
(* smlal2	v16.2d, v13.4s, v3.s[2]                  #! PC = 0xaaaabe371a58 *)
smlal2	%%v16.2d, %%v13.4s, %%v3.s[2]                  #! 0xaaaabe371a58 = 0xaaaabe371a58;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371a5c *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v3.s[0]                   #! PC = 0xaaaabe371a60 *)
smlal	%%v16.2d, %%v14.2s, %%v3.s[0]                   #! 0xaaaabe371a60 = 0xaaaabe371a60;
(* smlal2	v16.2d, v14.4s, v3.s[2]                  #! PC = 0xaaaabe371a64 *)
smlal2	%%v16.2d, %%v14.4s, %%v3.s[2]                  #! 0xaaaabe371a64 = 0xaaaabe371a64;
(* smlal	v16.2d, v13.2s, v3.s[1]                   #! PC = 0xaaaabe371a68 *)
smlal	%%v16.2d, %%v13.2s, %%v3.s[1]                   #! 0xaaaabe371a68 = 0xaaaabe371a68;
(* smlal2	v16.2d, v13.4s, v3.s[3]                  #! PC = 0xaaaabe371a6c *)
smlal2	%%v16.2d, %%v13.4s, %%v3.s[3]                  #! 0xaaaabe371a6c = 0xaaaabe371a6c;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371a70 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v3.s[1]                   #! PC = 0xaaaabe371a74 *)
smlal	%%v16.2d, %%v14.2s, %%v3.s[1]                   #! 0xaaaabe371a74 = 0xaaaabe371a74;
(* smlal2	v16.2d, v14.4s, v3.s[3]                  #! PC = 0xaaaabe371a78 *)
smlal2	%%v16.2d, %%v14.4s, %%v3.s[3]                  #! 0xaaaabe371a78 = 0xaaaabe371a78;
(* smlal	v16.2d, v13.2s, v4.s[0]                   #! PC = 0xaaaabe371a7c *)
smlal	%%v16.2d, %%v13.2s, %%v4.s[0]                   #! 0xaaaabe371a7c = 0xaaaabe371a7c;
(* smlal2	v16.2d, v13.4s, v4.s[2]                  #! PC = 0xaaaabe371a80 *)
smlal2	%%v16.2d, %%v13.4s, %%v4.s[2]                  #! 0xaaaabe371a80 = 0xaaaabe371a80;
(* and	v3.16b, v16.16b, v1.16b                     #! PC = 0xaaaabe371a84 *)
and %v3@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371a88 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v4.s[0]                   #! PC = 0xaaaabe371a8c *)
smlal	%%v16.2d, %%v14.2s, %%v4.s[0]                   #! 0xaaaabe371a8c = 0xaaaabe371a8c;
(* smlal2	v16.2d, v14.4s, v4.s[2]                  #! PC = 0xaaaabe371a90 *)
smlal2	%%v16.2d, %%v14.4s, %%v4.s[2]                  #! 0xaaaabe371a90 = 0xaaaabe371a90;
(* smlal	v16.2d, v13.2s, v4.s[1]                   #! PC = 0xaaaabe371a94 *)
smlal	%%v16.2d, %%v13.2s, %%v4.s[1]                   #! 0xaaaabe371a94 = 0xaaaabe371a94;
(* smlal2	v16.2d, v13.4s, v4.s[3]                  #! PC = 0xaaaabe371a98 *)
smlal2	%%v16.2d, %%v13.4s, %%v4.s[3]                  #! 0xaaaabe371a98 = 0xaaaabe371a98;
(* and	v17.16b, v16.16b, v1.16b                    #! PC = 0xaaaabe371a9c *)
and %v17@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371aa0 *)
split %v16 %dc %v16 30;
(* shl	v17.2d, v17.2d, #32                         #! PC = 0xaaaabe371aa4 *)
shls %dc %v17 %v17 [32, 32];
(* orr	v3.16b, v3.16b, v17.16b                     #! PC = 0xaaaabe371aa8 *)
or %v3@uint64[2] %v3 %v17;
(* smlal	v16.2d, v14.2s, v4.s[1]                   #! PC = 0xaaaabe371aac *)
smlal	%%v16.2d, %%v14.2s, %%v4.s[1]                   #! 0xaaaabe371aac = 0xaaaabe371aac;
(* smlal2	v16.2d, v14.4s, v4.s[3]                  #! PC = 0xaaaabe371ab0 *)
smlal2	%%v16.2d, %%v14.4s, %%v4.s[3]                  #! 0xaaaabe371ab0 = 0xaaaabe371ab0;
(* smlal	v16.2d, v13.2s, v5.s[0]                   #! PC = 0xaaaabe371ab4 *)
smlal	%%v16.2d, %%v13.2s, %%v5.s[0]                   #! 0xaaaabe371ab4 = 0xaaaabe371ab4;
(* smlal2	v16.2d, v13.4s, v5.s[2]                  #! PC = 0xaaaabe371ab8 *)
smlal2	%%v16.2d, %%v13.4s, %%v5.s[2]                  #! 0xaaaabe371ab8 = 0xaaaabe371ab8;
(* and	v4.16b, v16.16b, v1.16b                     #! PC = 0xaaaabe371abc *)
and %v4@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371ac0 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v5.s[0]                   #! PC = 0xaaaabe371ac4 *)
smlal	%%v16.2d, %%v14.2s, %%v5.s[0]                   #! 0xaaaabe371ac4 = 0xaaaabe371ac4;
(* smlal2	v16.2d, v14.4s, v5.s[2]                  #! PC = 0xaaaabe371ac8 *)
smlal2	%%v16.2d, %%v14.4s, %%v5.s[2]                  #! 0xaaaabe371ac8 = 0xaaaabe371ac8;
(* smlal	v16.2d, v13.2s, v5.s[1]                   #! PC = 0xaaaabe371acc *)
smlal	%%v16.2d, %%v13.2s, %%v5.s[1]                   #! 0xaaaabe371acc = 0xaaaabe371acc;
(* smlal2	v16.2d, v13.4s, v5.s[3]                  #! PC = 0xaaaabe371ad0 *)
smlal2	%%v16.2d, %%v13.4s, %%v5.s[3]                  #! 0xaaaabe371ad0 = 0xaaaabe371ad0;
(* and	v17.16b, v16.16b, v1.16b                    #! PC = 0xaaaabe371ad4 *)
and %v17@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371ad8 *)
split %v16 %dc %v16 30;
(* shl	v17.2d, v17.2d, #32                         #! PC = 0xaaaabe371adc *)
shls %dc %v17 %v17 [32, 32];
(* orr	v4.16b, v4.16b, v17.16b                     #! PC = 0xaaaabe371ae0 *)
or %v4@uint64[2] %v4 %v17;
(* smlal	v16.2d, v14.2s, v5.s[1]                   #! PC = 0xaaaabe371ae4 *)
smlal	%%v16.2d, %%v14.2s, %%v5.s[1]                   #! 0xaaaabe371ae4 = 0xaaaabe371ae4;
(* smlal2	v16.2d, v14.4s, v5.s[3]                  #! PC = 0xaaaabe371ae8 *)
smlal2	%%v16.2d, %%v14.4s, %%v5.s[3]                  #! 0xaaaabe371ae8 = 0xaaaabe371ae8;
(* smlal	v16.2d, v13.2s, v6.s[0]                   #! PC = 0xaaaabe371aec *)
smlal	%%v16.2d, %%v13.2s, %%v6.s[0]                   #! 0xaaaabe371aec = 0xaaaabe371aec;
(* smlal2	v16.2d, v13.4s, v6.s[2]                  #! PC = 0xaaaabe371af0 *)
smlal2	%%v16.2d, %%v13.4s, %%v6.s[2]                  #! 0xaaaabe371af0 = 0xaaaabe371af0;
(* and	v5.16b, v16.16b, v1.16b                     #! PC = 0xaaaabe371af4 *)
and %v5@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371af8 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v6.s[0]                   #! PC = 0xaaaabe371afc *)
smlal	%%v16.2d, %%v14.2s, %%v6.s[0]                   #! 0xaaaabe371afc = 0xaaaabe371afc;
(* smlal2	v16.2d, v14.4s, v6.s[2]                  #! PC = 0xaaaabe371b00 *)
smlal2	%%v16.2d, %%v14.4s, %%v6.s[2]                  #! 0xaaaabe371b00 = 0xaaaabe371b00;
(* smlal	v16.2d, v13.2s, v6.s[1]                   #! PC = 0xaaaabe371b04 *)
smlal	%%v16.2d, %%v13.2s, %%v6.s[1]                   #! 0xaaaabe371b04 = 0xaaaabe371b04;
(* smlal2	v16.2d, v13.4s, v6.s[3]                  #! PC = 0xaaaabe371b08 *)
smlal2	%%v16.2d, %%v13.4s, %%v6.s[3]                  #! 0xaaaabe371b08 = 0xaaaabe371b08;
(* and	v17.16b, v16.16b, v1.16b                    #! PC = 0xaaaabe371b0c *)
and %v17@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371b10 *)
split %v16 %dc %v16 30;
(* shl	v17.2d, v17.2d, #32                         #! PC = 0xaaaabe371b14 *)
shls %dc %v17 %v17 [32, 32];
(* orr	v5.16b, v5.16b, v17.16b                     #! PC = 0xaaaabe371b18 *)
or %v5@uint64[2] %v5 %v17;
(* smlal	v16.2d, v14.2s, v6.s[1]                   #! PC = 0xaaaabe371b1c *)
smlal	%%v16.2d, %%v14.2s, %%v6.s[1]                   #! 0xaaaabe371b1c = 0xaaaabe371b1c;
(* smlal2	v16.2d, v14.4s, v6.s[3]                  #! PC = 0xaaaabe371b20 *)
smlal2	%%v16.2d, %%v14.4s, %%v6.s[3]                  #! 0xaaaabe371b20 = 0xaaaabe371b20;
(* smlal	v16.2d, v13.2s, v7.s[0]                   #! PC = 0xaaaabe371b24 *)
smlal	%%v16.2d, %%v13.2s, %%v7.s[0]                   #! 0xaaaabe371b24 = 0xaaaabe371b24;
(* smlal2	v16.2d, v13.4s, v7.s[2]                  #! PC = 0xaaaabe371b28 *)
smlal2	%%v16.2d, %%v13.4s, %%v7.s[2]                  #! 0xaaaabe371b28 = 0xaaaabe371b28;
(* and	v6.16b, v16.16b, v1.16b                     #! PC = 0xaaaabe371b2c *)
and %v6@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371b30 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v7.s[0]                   #! PC = 0xaaaabe371b34 *)
smlal	%%v16.2d, %%v14.2s, %%v7.s[0]                   #! 0xaaaabe371b34 = 0xaaaabe371b34;
(* smlal2	v16.2d, v14.4s, v7.s[2]                  #! PC = 0xaaaabe371b38 *)
smlal2	%%v16.2d, %%v14.4s, %%v7.s[2]                  #! 0xaaaabe371b38 = 0xaaaabe371b38;
(* and	v17.16b, v16.16b, v1.16b                    #! PC = 0xaaaabe371b3c *)
and %v17@uint64[2] %v16 %v1;
(* sshr	v7.2d, v16.2d, #30                         #! PC = 0xaaaabe371b40 *)
split %v7 %dc %v16 30;
(* shl	v17.2d, v17.2d, #32                         #! PC = 0xaaaabe371b44 *)
shls %dc %v17 %v17 [32, 32];
(* orr	v6.16b, v6.16b, v17.16b                     #! PC = 0xaaaabe371b48 *)
or %v6@uint64[2] %v6 %v17;
(* and	x7, x1, #0xfffff                            #! PC = 0xaaaabe371b4c *)
and x7@uint64 x1 0xfffff@uint64;
(* and	x8, x2, #0xfffff                            #! PC = 0xaaaabe371b50 *)
and x8@uint64 x2 0xfffff@uint64;
(* orr	x7, x7, #0xfffffe0000000000                 #! PC = 0xaaaabe371b54 *)
or x7@uint64 x7 0xfffffe0000000000@uint64;
(* orr	x8, x8, #0xc000000000000000                 #! PC = 0xaaaabe371b58 *)
or x8@uint64 x8 0xc000000000000000@uint64;
(* tst	x8, #0x1                                    #! PC = 0xaaaabe371b5c *)
spl dc x8_lo x8 1;
and ne@bit x8_lo 1@bit;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371b60 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371b64 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371b68 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371b6c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371b70 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371b74 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371b78 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371b7c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371b80 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371b84 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371b88 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371b8c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371b90 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371b94 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371b98 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371b9c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371ba0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371ba4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371ba8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371bac *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371bb0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371bb4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371bb8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371bbc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371bc0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371bc4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371bc8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371bcc *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371bd0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371bd4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371bd8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371bdc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371be0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371be4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371be8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371bec *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371bf0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371bf4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371bf8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371bfc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c00 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c04 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c08 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c0c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371c10 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371c14 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371c18 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371c1c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371c20 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c24 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c28 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c2c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c30 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371c34 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371c38 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371c3c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371c40 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371c44 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c48 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c4c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c50 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c54 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371c58 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371c5c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371c60 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371c64 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371c68 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c6c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c70 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c74 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c78 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371c7c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371c80 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371c84 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371c88 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371c8c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c90 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c94 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c98 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c9c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371ca0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371ca4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371ca8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371cac *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371cb0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371cb4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371cb8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371cbc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371cc0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371cc4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371cc8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371ccc *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371cd0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371cd4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371cd8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371cdc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371ce0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371ce4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371ce8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371cec *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371cf0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371cf4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371cf8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371cfc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d00 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d04 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d08 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d0c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371d10 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371d14 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371d18 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371d1c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371d20 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d24 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d28 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d2c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d30 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371d34 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371d38 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371d3c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371d40 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371d44 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d48 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d4c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d50 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d54 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371d58 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371d5c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371d60 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371d64 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371d68 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d6c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d70 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d74 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d78 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371d7c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371d80 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371d84 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371d88 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371d8c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d90 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d94 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d98 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d9c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371da0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371da4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371da8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371dac *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371db0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371db4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371db8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371dbc *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371dc0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371dc4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371dc8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371dcc *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371dd0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371dd4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371dd8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371ddc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371de0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371de4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371de8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371dec *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371df0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371df4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371df8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371dfc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371e00 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371e04 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371e08 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371e0c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371e10 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371e14 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371e18 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371e1c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371e20 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371e24 *)
add x3 x3 0x2@sint64;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371e28 *)
ssplit x8 dcL x8 1;
(* add	x12, x7, x6                                 #! PC = 0xaaaabe371e2c *)
add x12 x7 x6;
(* asr	x12, x12, #42                               #! PC = 0xaaaabe371e30 *)
ssplit x12 dcL x12 42;
(* add	x11, x7, #0x100, lsl #12                    #! PC = 0xaaaabe371e34 *)
add x11 x7 0x100@sint64, lsl;
(* lsl	x11, x11, #22                               #! PC = 0xaaaabe371e38 *)
split dcH x11 x11 (64-22); shl x11 x11 22;
(* asr	x11, x11, #43                               #! PC = 0xaaaabe371e3c *)
ssplit x11 dcL x11 43;
(* add	x14, x8, x6                                 #! PC = 0xaaaabe371e40 *)
add x14 x8 x6;
(* asr	x14, x14, #42                               #! PC = 0xaaaabe371e44 *)
ssplit x14 dcL x14 42;
(* add	x13, x8, #0x100, lsl #12                    #! PC = 0xaaaabe371e48 *)
add x13 x8 0x100@sint64, lsl;
(* lsl	x13, x13, #22                               #! PC = 0xaaaabe371e4c *)
split dcH x13 x13 (64-22); shl x13 x13 22;
(* asr	x13, x13, #43                               #! PC = 0xaaaabe371e50 *)
ssplit x13 dcL x13 43;
(* mul	x9, x11, x1                                 #! PC = 0xaaaabe371e54 *)
mull dcH x9 x11 x1;
(* madd	x9, x12, x2, x9                            #! PC = 0xaaaabe371e58 *)
mull dcH mul_tmp x12 x2;
adds dc x9 mul_tmp x9;
(* asr	x9, x9, #20                                 #! PC = 0xaaaabe371e5c *)
ssplit x9 dcL x9 20;
(* mul	x10, x13, x1                                #! PC = 0xaaaabe371e60 *)
mull dcH x10 x13 x1;
(* madd	x10, x14, x2, x10                          #! PC = 0xaaaabe371e64 *)
mull dcH mul_tmp x14 x2;
adds dc x10 mul_tmp x10;
(* asr	x2, x10, #20                                #! PC = 0xaaaabe371e68 *)
ssplit x2 dcL x10 20;
(* mov	x1, x9                                      #! PC = 0xaaaabe371e6c *)
mov x1 x9;
(* mov	w4, v3.s[0]                                 #! PC = 0xaaaabe371e70 *)
mov w4 v3.s[0];
(* mov	w27, v3.s[1]                                #! PC = 0xaaaabe371e74 *)
mov w27 v3.s[1];
(* add	x4, x4, x27, lsl #30                        #! PC = 0xaaaabe371e78 *)
add x4 x4 x27, lsl;
(* mov	w27, v4.s[0]                                #! PC = 0xaaaabe371e7c *)
mov w27 v4.s[0];
(* add	x4, x4, x27, lsl #60                        #! PC = 0xaaaabe371e80 *)
add x4 x4 x27, lsl;
(* add	x21, xzr, x27, lsr #4                       #! PC = 0xaaaabe371e84 *)
add	%%x21, xzr, %%x27, lsr #4                       #! 0xaaaabe371e84 = 0xaaaabe371e84;
(* mov	w27, v4.s[1]                                #! PC = 0xaaaabe371e88 *)
mov w27 v4.s[1];
(* add	x21, x21, x27, lsl #26                      #! PC = 0xaaaabe371e8c *)
add x21 x21 x27, lsl;
(* mov	w5, v3.s[2]                                 #! PC = 0xaaaabe371e90 *)
mov w5 v3.s[2];
(* mov	w27, v3.s[3]                                #! PC = 0xaaaabe371e94 *)
mov w27 v3.s[3];
(* add	x5, x5, x27, lsl #30                        #! PC = 0xaaaabe371e98 *)
add x5 x5 x27, lsl;
(* mov	w27, v4.s[2]                                #! PC = 0xaaaabe371e9c *)
mov w27 v4.s[2];
(* add	x5, x5, x27, lsl #60                        #! PC = 0xaaaabe371ea0 *)
add x5 x5 x27, lsl;
(* add	x22, xzr, x27, lsr #4                       #! PC = 0xaaaabe371ea4 *)
add	%%x22, xzr, %%x27, lsr #4                       #! 0xaaaabe371ea4 = 0xaaaabe371ea4;
(* mov	w27, v4.s[3]                                #! PC = 0xaaaabe371ea8 *)
mov w27 v4.s[3];
(* add	x22, x22, x27, lsl #26                      #! PC = 0xaaaabe371eac *)
add x22 x22 x27, lsl;
(* and	x7, x1, #0xfffff                            #! PC = 0xaaaabe371eb0 *)
and x7@uint64 x1 0xfffff@uint64;
(* and	x8, x2, #0xfffff                            #! PC = 0xaaaabe371eb4 *)
and x8@uint64 x2 0xfffff@uint64;
(* orr	x7, x7, #0xfffffe0000000000                 #! PC = 0xaaaabe371eb8 *)
or x7@uint64 x7 0xfffffe0000000000@uint64;
(* orr	x8, x8, #0xc000000000000000                 #! PC = 0xaaaabe371ebc *)
or x8@uint64 x8 0xc000000000000000@uint64;
(* tst	x8, #0x1                                    #! PC = 0xaaaabe371ec0 *)
spl dc x8_lo x8 1;
and ne@bit x8_lo 1@bit;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371ec4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371ec8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371ecc *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371ed0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371ed4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371ed8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371edc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371ee0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371ee4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371ee8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371eec *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371ef0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371ef4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371ef8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371efc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f00 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f04 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f08 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f0c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371f10 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371f14 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371f18 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371f1c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371f20 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f24 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f28 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f2c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f30 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371f34 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371f38 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371f3c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371f40 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371f44 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f48 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f4c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f50 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f54 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371f58 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371f5c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371f60 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371f64 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371f68 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f6c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f70 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f74 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f78 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371f7c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371f80 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371f84 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371f88 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371f8c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f90 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f94 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f98 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f9c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371fa0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371fa4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371fa8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371fac *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371fb0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371fb4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371fb8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371fbc *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371fc0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371fc4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371fc8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371fcc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371fd0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371fd4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371fd8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371fdc *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371fe0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371fe4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371fe8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371fec *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371ff0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371ff4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371ff8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371ffc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372000 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372004 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372008 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37200c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372010 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372014 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372018 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37201c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372020 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372024 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372028 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37202c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372030 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372034 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372038 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37203c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372040 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372044 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372048 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37204c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372050 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372054 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372058 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37205c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372060 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372064 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372068 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37206c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372070 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372074 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372078 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37207c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372080 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372084 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372088 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37208c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372090 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372094 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372098 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37209c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3720a0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3720a4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3720a8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3720ac *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3720b0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3720b4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3720b8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3720bc *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3720c0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3720c4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3720c8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3720cc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3720d0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3720d4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3720d8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3720dc *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3720e0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3720e4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3720e8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3720ec *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3720f0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3720f4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3720f8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3720fc *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372100 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372104 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372108 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37210c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372110 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372114 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372118 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37211c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372120 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372124 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372128 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37212c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372130 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372134 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372138 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37213c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372140 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372144 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372148 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37214c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372150 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372154 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372158 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37215c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372160 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372164 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372168 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37216c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372170 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372174 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372178 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37217c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372180 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372184 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372188 *)
add x3 x3 0x2@sint64;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37218c *)
ssplit x8 dcL x8 1;
(* add	x16, x7, x6                                 #! PC = 0xaaaabe372190 *)
add x16 x7 x6;
(* asr	x16, x16, #42                               #! PC = 0xaaaabe372194 *)
ssplit x16 dcL x16 42;
(* add	x15, x7, #0x100, lsl #12                    #! PC = 0xaaaabe372198 *)
add x15 x7 0x100@sint64, lsl;
(* lsl	x15, x15, #22                               #! PC = 0xaaaabe37219c *)
split dcH x15 x15 (64-22); shl x15 x15 22;
(* asr	x15, x15, #43                               #! PC = 0xaaaabe3721a0 *)
ssplit x15 dcL x15 43;
(* add	x20, x8, x6                                 #! PC = 0xaaaabe3721a4 *)
add x20 x8 x6;
(* asr	x20, x20, #42                               #! PC = 0xaaaabe3721a8 *)
ssplit x20 dcL x20 42;
(* add	x17, x8, #0x100, lsl #12                    #! PC = 0xaaaabe3721ac *)
add x17 x8 0x100@sint64, lsl;
(* lsl	x17, x17, #22                               #! PC = 0xaaaabe3721b0 *)
split dcH x17 x17 (64-22); shl x17 x17 22;
(* asr	x17, x17, #43                               #! PC = 0xaaaabe3721b4 *)
ssplit x17 dcL x17 43;
(* mul	x9, x15, x1                                 #! PC = 0xaaaabe3721b8 *)
mull dcH x9 x15 x1;
(* madd	x9, x16, x2, x9                            #! PC = 0xaaaabe3721bc *)
mull dcH mul_tmp x16 x2;
adds dc x9 mul_tmp x9;
(* asr	x9, x9, #20                                 #! PC = 0xaaaabe3721c0 *)
ssplit x9 dcL x9 20;
(* mul	x10, x17, x1                                #! PC = 0xaaaabe3721c4 *)
mull dcH x10 x17 x1;
(* madd	x10, x20, x2, x10                          #! PC = 0xaaaabe3721c8 *)
mull dcH mul_tmp x20 x2;
adds dc x10 mul_tmp x10;
(* asr	x2, x10, #20                                #! PC = 0xaaaabe3721cc *)
ssplit x2 dcL x10 20;
(* mov	x1, x9                                      #! PC = 0xaaaabe3721d0 *)
mov x1 x9;
(* mul	x9, x15, x11                                #! PC = 0xaaaabe3721d4 *)
mull dcH x9 x15 x11;
(* madd	x10, x16, x13, x9                          #! PC = 0xaaaabe3721d8 *)
mull dcH mul_tmp x16 x13;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x11                                #! PC = 0xaaaabe3721dc *)
mull dcH x9 x17 x11;
(* madd	x13, x20, x13, x9                          #! PC = 0xaaaabe3721e0 *)
mull dcH mul_tmp x20 x13;
adds dc x13 mul_tmp x9;
(* mov	x11, x10                                    #! PC = 0xaaaabe3721e4 *)
mov x11 x10;
(* mul	x9, x15, x12                                #! PC = 0xaaaabe3721e8 *)
mull dcH x9 x15 x12;
(* madd	x10, x16, x14, x9                          #! PC = 0xaaaabe3721ec *)
mull dcH mul_tmp x16 x14;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x12                                #! PC = 0xaaaabe3721f0 *)
mull dcH x9 x17 x12;
(* madd	x14, x20, x14, x9                          #! PC = 0xaaaabe3721f4 *)
mull dcH mul_tmp x20 x14;
adds dc x14 mul_tmp x9;
(* mov	x12, x10                                    #! PC = 0xaaaabe3721f8 *)
mov x12 x10;
(* mov	x9, #0x13                  	// #19          #! PC = 0xaaaabe3721fc *)
mov x9 0x13@uint64;
(* dup	v16.2d, x9                                  #! PC = 0xaaaabe372200 *)
mov %v16 [x9,x9];
(* smull	v17.2d, v13.2s, v8.s[0]                   #! PC = 0xaaaabe372204 *)
smull	%%v17.2d, %%v13.2s, %%v8.s[0]                   #! 0xaaaabe372204 = 0xaaaabe372204;
(* smlal2	v17.2d, v13.4s, v8.s[2]                  #! PC = 0xaaaabe372208 *)
smlal2	%%v17.2d, %%v13.4s, %%v8.s[2]                  #! 0xaaaabe372208 = 0xaaaabe372208;
(* mul	v19.4s, v17.4s, v15.4s                      #! PC = 0xaaaabe37220c *)
mul %v19 %v17 %v15;
(* and	v19.16b, v19.16b, v1.16b                    #! PC = 0xaaaabe372210 *)
and %v19@uint64[2] %v19 %v1;
(* uzp1	v19.4s, v19.4s, v19.4s                     #! PC = 0xaaaabe372214 *)
mov %v19 [%v19[0], %v19[2], %v19[0], %v19[2]];
(* smlsl	v17.2d, v19.2s, v16.s[0]                  #! PC = 0xaaaabe372218 *)
smlsl	%%v17.2d, %%v19.2s, %%v16.s[0]                  #! 0xaaaabe372218 = 0xaaaabe372218;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe37221c *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v8.s[0]                   #! PC = 0xaaaabe372220 *)
smlal	%%v17.2d, %%v14.2s, %%v8.s[0]                   #! 0xaaaabe372220 = 0xaaaabe372220;
(* smlal2	v17.2d, v14.4s, v8.s[2]                  #! PC = 0xaaaabe372224 *)
smlal2	%%v17.2d, %%v14.4s, %%v8.s[2]                  #! 0xaaaabe372224 = 0xaaaabe372224;
(* smlal	v17.2d, v13.2s, v8.s[1]                   #! PC = 0xaaaabe372228 *)
smlal	%%v17.2d, %%v13.2s, %%v8.s[1]                   #! 0xaaaabe372228 = 0xaaaabe372228;
(* smlal2	v17.2d, v13.4s, v8.s[3]                  #! PC = 0xaaaabe37222c *)
smlal2	%%v17.2d, %%v13.4s, %%v8.s[3]                  #! 0xaaaabe37222c = 0xaaaabe37222c;
(* mul	v20.4s, v17.4s, v15.4s                      #! PC = 0xaaaabe372230 *)
mul %v20 %v17 %v15;
(* and	v20.16b, v20.16b, v1.16b                    #! PC = 0xaaaabe372234 *)
and %v20@uint64[2] %v20 %v1;
(* uzp1	v20.4s, v20.4s, v20.4s                     #! PC = 0xaaaabe372238 *)
mov %v20 [%v20[0], %v20[2], %v20[0], %v20[2]];
(* smlsl	v17.2d, v20.2s, v16.s[0]                  #! PC = 0xaaaabe37223c *)
smlsl	%%v17.2d, %%v20.2s, %%v16.s[0]                  #! 0xaaaabe37223c = 0xaaaabe37223c;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe372240 *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v8.s[1]                   #! PC = 0xaaaabe372244 *)
smlal	%%v17.2d, %%v14.2s, %%v8.s[1]                   #! 0xaaaabe372244 = 0xaaaabe372244;
(* smlal2	v17.2d, v14.4s, v8.s[3]                  #! PC = 0xaaaabe372248 *)
smlal2	%%v17.2d, %%v14.4s, %%v8.s[3]                  #! 0xaaaabe372248 = 0xaaaabe372248;
(* smlal	v17.2d, v13.2s, v9.s[0]                   #! PC = 0xaaaabe37224c *)
smlal	%%v17.2d, %%v13.2s, %%v9.s[0]                   #! 0xaaaabe37224c = 0xaaaabe37224c;
(* smlal2	v17.2d, v13.4s, v9.s[2]                  #! PC = 0xaaaabe372250 *)
smlal2	%%v17.2d, %%v13.4s, %%v9.s[2]                  #! 0xaaaabe372250 = 0xaaaabe372250;
(* and	v8.16b, v17.16b, v1.16b                     #! PC = 0xaaaabe372254 *)
and %v8@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe372258 *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v9.s[0]                   #! PC = 0xaaaabe37225c *)
smlal	%%v17.2d, %%v14.2s, %%v9.s[0]                   #! 0xaaaabe37225c = 0xaaaabe37225c;
(* smlal2	v17.2d, v14.4s, v9.s[2]                  #! PC = 0xaaaabe372260 *)
smlal2	%%v17.2d, %%v14.4s, %%v9.s[2]                  #! 0xaaaabe372260 = 0xaaaabe372260;
(* smlal	v17.2d, v13.2s, v9.s[1]                   #! PC = 0xaaaabe372264 *)
smlal	%%v17.2d, %%v13.2s, %%v9.s[1]                   #! 0xaaaabe372264 = 0xaaaabe372264;
(* smlal2	v17.2d, v13.4s, v9.s[3]                  #! PC = 0xaaaabe372268 *)
smlal2	%%v17.2d, %%v13.4s, %%v9.s[3]                  #! 0xaaaabe372268 = 0xaaaabe372268;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe37226c *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe372270 *)
split %v17 %dc %v17 30;
(* sli	v8.2d, v18.2d, #32                          #! PC = 0xaaaabe372274 *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v8 %v8 32; or %v8@uint64[2] %slih %v8;
(* smlal	v17.2d, v14.2s, v9.s[1]                   #! PC = 0xaaaabe372278 *)
smlal	%%v17.2d, %%v14.2s, %%v9.s[1]                   #! 0xaaaabe372278 = 0xaaaabe372278;
(* smlal2	v17.2d, v14.4s, v9.s[3]                  #! PC = 0xaaaabe37227c *)
smlal2	%%v17.2d, %%v14.4s, %%v9.s[3]                  #! 0xaaaabe37227c = 0xaaaabe37227c;
(* smlal	v17.2d, v13.2s, v10.s[0]                  #! PC = 0xaaaabe372280 *)
smlal	%%v17.2d, %%v13.2s, %%v10.s[0]                  #! 0xaaaabe372280 = 0xaaaabe372280;
(* smlal2	v17.2d, v13.4s, v10.s[2]                 #! PC = 0xaaaabe372284 *)
smlal2	%%v17.2d, %%v13.4s, %%v10.s[2]                 #! 0xaaaabe372284 = 0xaaaabe372284;
(* and	v9.16b, v17.16b, v1.16b                     #! PC = 0xaaaabe372288 *)
and %v9@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe37228c *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v10.s[0]                  #! PC = 0xaaaabe372290 *)
smlal	%%v17.2d, %%v14.2s, %%v10.s[0]                  #! 0xaaaabe372290 = 0xaaaabe372290;
(* smlal2	v17.2d, v14.4s, v10.s[2]                 #! PC = 0xaaaabe372294 *)
smlal2	%%v17.2d, %%v14.4s, %%v10.s[2]                 #! 0xaaaabe372294 = 0xaaaabe372294;
(* smlal	v17.2d, v13.2s, v10.s[1]                  #! PC = 0xaaaabe372298 *)
smlal	%%v17.2d, %%v13.2s, %%v10.s[1]                  #! 0xaaaabe372298 = 0xaaaabe372298;
(* smlal2	v17.2d, v13.4s, v10.s[3]                 #! PC = 0xaaaabe37229c *)
smlal2	%%v17.2d, %%v13.4s, %%v10.s[3]                 #! 0xaaaabe37229c = 0xaaaabe37229c;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe3722a0 *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3722a4 *)
split %v17 %dc %v17 30;
(* sli	v9.2d, v18.2d, #32                          #! PC = 0xaaaabe3722a8 *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v9 %v9 32; or %v9@uint64[2] %slih %v9;
(* smlal	v17.2d, v14.2s, v10.s[1]                  #! PC = 0xaaaabe3722ac *)
smlal	%%v17.2d, %%v14.2s, %%v10.s[1]                  #! 0xaaaabe3722ac = 0xaaaabe3722ac;
(* smlal2	v17.2d, v14.4s, v10.s[3]                 #! PC = 0xaaaabe3722b0 *)
smlal2	%%v17.2d, %%v14.4s, %%v10.s[3]                 #! 0xaaaabe3722b0 = 0xaaaabe3722b0;
(* smlal	v17.2d, v13.2s, v11.s[0]                  #! PC = 0xaaaabe3722b4 *)
smlal	%%v17.2d, %%v13.2s, %%v11.s[0]                  #! 0xaaaabe3722b4 = 0xaaaabe3722b4;
(* smlal2	v17.2d, v13.4s, v11.s[2]                 #! PC = 0xaaaabe3722b8 *)
smlal2	%%v17.2d, %%v13.4s, %%v11.s[2]                 #! 0xaaaabe3722b8 = 0xaaaabe3722b8;
(* and	v10.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe3722bc *)
and %v10@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3722c0 *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v11.s[0]                  #! PC = 0xaaaabe3722c4 *)
smlal	%%v17.2d, %%v14.2s, %%v11.s[0]                  #! 0xaaaabe3722c4 = 0xaaaabe3722c4;
(* smlal2	v17.2d, v14.4s, v11.s[2]                 #! PC = 0xaaaabe3722c8 *)
smlal2	%%v17.2d, %%v14.4s, %%v11.s[2]                 #! 0xaaaabe3722c8 = 0xaaaabe3722c8;
(* smlal	v17.2d, v13.2s, v11.s[1]                  #! PC = 0xaaaabe3722cc *)
smlal	%%v17.2d, %%v13.2s, %%v11.s[1]                  #! 0xaaaabe3722cc = 0xaaaabe3722cc;
(* smlal2	v17.2d, v13.4s, v11.s[3]                 #! PC = 0xaaaabe3722d0 *)
smlal2	%%v17.2d, %%v13.4s, %%v11.s[3]                 #! 0xaaaabe3722d0 = 0xaaaabe3722d0;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe3722d4 *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3722d8 *)
split %v17 %dc %v17 30;
(* sli	v10.2d, v18.2d, #32                         #! PC = 0xaaaabe3722dc *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v10 %v10 32; or %v10@uint64[2] %slih %v10;
(* smlal	v17.2d, v14.2s, v11.s[1]                  #! PC = 0xaaaabe3722e0 *)
smlal	%%v17.2d, %%v14.2s, %%v11.s[1]                  #! 0xaaaabe3722e0 = 0xaaaabe3722e0;
(* smlal2	v17.2d, v14.4s, v11.s[3]                 #! PC = 0xaaaabe3722e4 *)
smlal2	%%v17.2d, %%v14.4s, %%v11.s[3]                 #! 0xaaaabe3722e4 = 0xaaaabe3722e4;
(* smlal	v17.2d, v13.2s, v12.s[0]                  #! PC = 0xaaaabe3722e8 *)
smlal	%%v17.2d, %%v13.2s, %%v12.s[0]                  #! 0xaaaabe3722e8 = 0xaaaabe3722e8;
(* smlal2	v17.2d, v13.4s, v12.s[2]                 #! PC = 0xaaaabe3722ec *)
smlal2	%%v17.2d, %%v13.4s, %%v12.s[2]                 #! 0xaaaabe3722ec = 0xaaaabe3722ec;
(* ushll	v19.2d, v19.2s, #15                       #! PC = 0xaaaabe3722f0 *)
ushll	%%v19.2d, %%v19.2s, #15                       #! 0xaaaabe3722f0 = 0xaaaabe3722f0;
(* add	v17.2d, v17.2d, v19.2d                      #! PC = 0xaaaabe3722f4 *)
add	%%v17.2d, %%v17.2d, %%v19.2d                      #! 0xaaaabe3722f4 = 0xaaaabe3722f4;
(* and	v11.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe3722f8 *)
and %v11@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3722fc *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v12.s[0]                  #! PC = 0xaaaabe372300 *)
smlal	%%v17.2d, %%v14.2s, %%v12.s[0]                  #! 0xaaaabe372300 = 0xaaaabe372300;
(* smlal2	v17.2d, v14.4s, v12.s[2]                 #! PC = 0xaaaabe372304 *)
smlal2	%%v17.2d, %%v14.4s, %%v12.s[2]                 #! 0xaaaabe372304 = 0xaaaabe372304;
(* ushll	v20.2d, v20.2s, #15                       #! PC = 0xaaaabe372308 *)
ushll	%%v20.2d, %%v20.2s, #15                       #! 0xaaaabe372308 = 0xaaaabe372308;
(* add	v17.2d, v17.2d, v20.2d                      #! PC = 0xaaaabe37230c *)
add	%%v17.2d, %%v17.2d, %%v20.2d                      #! 0xaaaabe37230c = 0xaaaabe37230c;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe372310 *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v12.2d, v17.2d, #30                        #! PC = 0xaaaabe372314 *)
split %v12 %dc %v17 30;
(* sli	v11.2d, v18.2d, #32                         #! PC = 0xaaaabe372318 *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v11 %v11 32; or %v11@uint64[2] %slih %v11;
(* sshr	v18.2d, v12.2d, #15                        #! PC = 0xaaaabe37231c *)
split %v18 %dc %v12 15;
(* shl	v17.2d, v18.2d, #15                         #! PC = 0xaaaabe372320 *)
shls %dc %v17 %v18 [15, 15];
(* sub	v12.2d, v12.2d, v17.2d                      #! PC = 0xaaaabe372324 *)
sub	%%v12.2d, %%v12.2d, %%v17.2d                      #! 0xaaaabe372324 = 0xaaaabe372324;
(* mla	v8.4s, v18.4s, v16.4s                       #! PC = 0xaaaabe372328 *)
mull %dc %mla %v18 %v16; add %v8 %v8 %mla;
(* and	x7, x1, #0xfffff                            #! PC = 0xaaaabe37232c *)
and x7@uint64 x1 0xfffff@uint64;
(* and	x8, x2, #0xfffff                            #! PC = 0xaaaabe372330 *)
and x8@uint64 x2 0xfffff@uint64;
(* orr	x7, x7, #0xfffffe0000000000                 #! PC = 0xaaaabe372334 *)
or x7@uint64 x7 0xfffffe0000000000@uint64;
(* orr	x8, x8, #0xc000000000000000                 #! PC = 0xaaaabe372338 *)
or x8@uint64 x8 0xc000000000000000@uint64;
(* tst	x8, #0x1                                    #! PC = 0xaaaabe37233c *)
spl dc x8_lo x8 1;
and ne@bit x8_lo 1@bit;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372340 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372344 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372348 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37234c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372350 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372354 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372358 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37235c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372360 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372364 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372368 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37236c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372370 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372374 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372378 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37237c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372380 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372384 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372388 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37238c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372390 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372394 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372398 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37239c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3723a0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3723a4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3723a8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3723ac *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3723b0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3723b4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3723b8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3723bc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3723c0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3723c4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3723c8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3723cc *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3723d0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3723d4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3723d8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3723dc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3723e0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3723e4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3723e8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3723ec *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3723f0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3723f4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3723f8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3723fc *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372400 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372404 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372408 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37240c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372410 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372414 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372418 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37241c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372420 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372424 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372428 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37242c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372430 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372434 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372438 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37243c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372440 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372444 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372448 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37244c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372450 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372454 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372458 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37245c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372460 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372464 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372468 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37246c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372470 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372474 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372478 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37247c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372480 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372484 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372488 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37248c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372490 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372494 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372498 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37249c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3724a0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3724a4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3724a8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3724ac *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3724b0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3724b4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3724b8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3724bc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3724c0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3724c4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3724c8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3724cc *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3724d0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3724d4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3724d8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3724dc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3724e0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3724e4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3724e8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3724ec *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3724f0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3724f4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3724f8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3724fc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372500 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372504 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372508 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37250c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372510 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372514 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372518 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37251c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372520 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372524 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372528 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37252c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372530 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372534 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372538 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37253c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372540 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372544 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372548 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37254c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372550 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372554 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372558 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37255c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372560 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372564 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372568 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37256c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372570 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372574 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372578 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37257c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372580 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372584 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372588 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37258c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372590 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372594 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372598 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37259c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3725a0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3725a4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3725a8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3725ac *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3725b0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3725b4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3725b8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3725bc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3725c0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3725c4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3725c8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3725cc *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3725d0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3725d4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3725d8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3725dc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3725e0 *)
add x3 x3 0x2@sint64;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3725e4 *)
ssplit x8 dcL x8 1;
(* add	x16, x7, x6                                 #! PC = 0xaaaabe3725e8 *)
add x16 x7 x6;
(* asr	x16, x16, #42                               #! PC = 0xaaaabe3725ec *)
ssplit x16 dcL x16 42;
(* add	x15, x7, #0x100, lsl #12                    #! PC = 0xaaaabe3725f0 *)
add x15 x7 0x100@sint64, lsl;
(* lsl	x15, x15, #22                               #! PC = 0xaaaabe3725f4 *)
split dcH x15 x15 (64-22); shl x15 x15 22;
(* asr	x15, x15, #43                               #! PC = 0xaaaabe3725f8 *)
ssplit x15 dcL x15 43;
(* add	x20, x8, x6                                 #! PC = 0xaaaabe3725fc *)
add x20 x8 x6;
(* asr	x20, x20, #42                               #! PC = 0xaaaabe372600 *)
ssplit x20 dcL x20 42;
(* add	x17, x8, #0x100, lsl #12                    #! PC = 0xaaaabe372604 *)
add x17 x8 0x100@sint64, lsl;
(* lsl	x17, x17, #22                               #! PC = 0xaaaabe372608 *)
split dcH x17 x17 (64-22); shl x17 x17 22;
(* asr	x17, x17, #43                               #! PC = 0xaaaabe37260c *)
ssplit x17 dcL x17 43;
(* mul	x9, x15, x11                                #! PC = 0xaaaabe372610 *)
mull dcH x9 x15 x11;
(* madd	x10, x16, x13, x9                          #! PC = 0xaaaabe372614 *)
mull dcH mul_tmp x16 x13;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x11                                #! PC = 0xaaaabe372618 *)
mull dcH x9 x17 x11;
(* madd	x13, x20, x13, x9                          #! PC = 0xaaaabe37261c *)
mull dcH mul_tmp x20 x13;
adds dc x13 mul_tmp x9;
(* mov	x11, x10                                    #! PC = 0xaaaabe372620 *)
mov x11 x10;
(* mul	x9, x15, x12                                #! PC = 0xaaaabe372624 *)
mull dcH x9 x15 x12;
(* madd	x10, x16, x14, x9                          #! PC = 0xaaaabe372628 *)
mull dcH mul_tmp x16 x14;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x12                                #! PC = 0xaaaabe37262c *)
mull dcH x9 x17 x12;
(* madd	x14, x20, x14, x9                          #! PC = 0xaaaabe372630 *)
mull dcH mul_tmp x20 x14;
adds dc x14 mul_tmp x9;
(* mov	x12, x10                                    #! PC = 0xaaaabe372634 *)
mov x12 x10;
(* subs	x19, x19, #0x1                             #! PC = 0xaaaabe372638 *)
subc carry x19 x19 0x1@uint64;
(* #cbnz	x19, 0xaaaabe371960 <Lbig_loop>           #! PC = 0xaaaabe37263c *)
#cbnz	%%x19, 0xaaaabe371960 <Lbig_loop>           #! 0xaaaabe37263c = 0xaaaabe37263c;
(* mov	v16.d[0], x11                               #! PC = 0xaaaabe371960 *)
mov %v16 [x11, %v16[1]];
(* mov	v16.d[1], x13                               #! PC = 0xaaaabe371964 *)
mov %v16 [%v16[0], x13];
(* mov	v17.d[0], x12                               #! PC = 0xaaaabe371968 *)
mov %v17 [x12, %v17[1]];
(* mov	v17.d[1], x14                               #! PC = 0xaaaabe37196c *)
mov %v17 [%v17[0], x14];
(* uzp1	v13.4s, v16.4s, v17.4s                     #! PC = 0xaaaabe371970 *)
mov %v13 [%v16[0], %v16[2], %v17[0], %v17[2]];
(* and	v13.16b, v13.16b, v2.16b                    #! PC = 0xaaaabe371974 *)
and %v13@uint64[2] %v13 %v2;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371978 *)
split %v16 %dc %v16 30;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe37197c *)
split %v17 %dc %v17 30;
(* uzp1	v14.4s, v16.4s, v17.4s                     #! PC = 0xaaaabe371980 *)
mov %v14 [%v16[0], %v16[2], %v17[0], %v17[2]];
(* cmp	x11, xzr                                    #! PC = 0xaaaabe371984 *)
subc zero dc 0@uint64 x11;
(* csetm	x23, mi	// mi = first                     #! PC = 0xaaaabe371988 *)
csetm	%%x23, mi	// mi = first                     #! 0xaaaabe371988 = 0xaaaabe371988;
(* cneg	x11, x11, mi	// mi = first                 #! PC = 0xaaaabe37198c *)
cneg	%%x11, %%x11, mi	// mi = first                 #! 0xaaaabe37198c = 0xaaaabe37198c;
(* cmp	x12, xzr                                    #! PC = 0xaaaabe371990 *)
subc zero dc 0@uint64 x12;
(* csetm	x24, mi	// mi = first                     #! PC = 0xaaaabe371994 *)
csetm	%%x24, mi	// mi = first                     #! 0xaaaabe371994 = 0xaaaabe371994;
(* cneg	x12, x12, mi	// mi = first                 #! PC = 0xaaaabe371998 *)
cneg	%%x12, %%x12, mi	// mi = first                 #! 0xaaaabe371998 = 0xaaaabe371998;
(* cmp	x13, xzr                                    #! PC = 0xaaaabe37199c *)
subc zero dc 0@uint64 x13;
(* csetm	x25, mi	// mi = first                     #! PC = 0xaaaabe3719a0 *)
csetm	%%x25, mi	// mi = first                     #! 0xaaaabe3719a0 = 0xaaaabe3719a0;
(* cneg	x13, x13, mi	// mi = first                 #! PC = 0xaaaabe3719a4 *)
cneg	%%x13, %%x13, mi	// mi = first                 #! 0xaaaabe3719a4 = 0xaaaabe3719a4;
(* cmp	x14, xzr                                    #! PC = 0xaaaabe3719a8 *)
subc zero dc 0@uint64 x14;
(* csetm	x26, mi	// mi = first                     #! PC = 0xaaaabe3719ac *)
csetm	%%x26, mi	// mi = first                     #! 0xaaaabe3719ac = 0xaaaabe3719ac;
(* cneg	x14, x14, mi	// mi = first                 #! PC = 0xaaaabe3719b0 *)
cneg	%%x14, %%x14, mi	// mi = first                 #! 0xaaaabe3719b0 = 0xaaaabe3719b0;
(* and	x27, x11, x23                               #! PC = 0xaaaabe3719b4 *)
and x27@uint64 x11 x23;
(* and	x28, x12, x24                               #! PC = 0xaaaabe3719b8 *)
and x28@uint64 x12 x24;
(* add	x15, x27, x28                               #! PC = 0xaaaabe3719bc *)
add x15 x27 x28;
(* eor	x27, x4, x23                                #! PC = 0xaaaabe3719c0 *)
xor x27@uint64 x4 x23;
(* mul	x9, x27, x11                                #! PC = 0xaaaabe3719c4 *)
mull dcH x9 x27 x11;
(* umulh	x10, x27, x11                             #! PC = 0xaaaabe3719c8 *)
mull x10 dcL x27 x11;
(* adds	x15, x9, x15                               #! PC = 0xaaaabe3719cc *)
adds carry x15 x9 x15;
(* adc	x16, x10, xzr                               #! PC = 0xaaaabe3719d0 *)
adc x16 x10 0@uint64 carry;
(* eor	x27, x21, x23                               #! PC = 0xaaaabe3719d4 *)
xor x27@uint64 x21 x23;
(* mul	x9, x27, x11                                #! PC = 0xaaaabe3719d8 *)
mull dcH x9 x27 x11;
(* add	x16, x16, x9                                #! PC = 0xaaaabe3719dc *)
add x16 x16 x9;
(* eor	x27, x5, x24                                #! PC = 0xaaaabe3719e0 *)
xor x27@uint64 x5 x24;
(* mul	x9, x27, x12                                #! PC = 0xaaaabe3719e4 *)
mull dcH x9 x27 x12;
(* umulh	x10, x27, x12                             #! PC = 0xaaaabe3719e8 *)
mull x10 dcL x27 x12;
(* adds	x15, x9, x15                               #! PC = 0xaaaabe3719ec *)
adds carry x15 x9 x15;
(* adc	x16, x10, x16                               #! PC = 0xaaaabe3719f0 *)
adc x16 x10 x16 carry;
(* eor	x27, x22, x24                               #! PC = 0xaaaabe3719f4 *)
xor x27@uint64 x22 x24;
(* mul	x9, x27, x12                                #! PC = 0xaaaabe3719f8 *)
mull dcH x9 x27 x12;
(* add	x16, x16, x9                                #! PC = 0xaaaabe3719fc *)
add x16 x16 x9;
(* extr	x1, x16, x15, #60                          #! PC = 0xaaaabe371a00 *)
spl dc extr_H x16 60; spl extr_L dc x15 60; join x1 extr_H extr_L;
(* and	x27, x13, x25                               #! PC = 0xaaaabe371a04 *)
and x27@uint64 x13 x25;
(* and	x28, x14, x26                               #! PC = 0xaaaabe371a08 *)
and x28@uint64 x14 x26;
(* add	x17, x27, x28                               #! PC = 0xaaaabe371a0c *)
add x17 x27 x28;
(* eor	x27, x4, x25                                #! PC = 0xaaaabe371a10 *)
xor x27@uint64 x4 x25;
(* mul	x9, x27, x13                                #! PC = 0xaaaabe371a14 *)
mull dcH x9 x27 x13;
(* umulh	x10, x27, x13                             #! PC = 0xaaaabe371a18 *)
mull x10 dcL x27 x13;
(* adds	x17, x9, x17                               #! PC = 0xaaaabe371a1c *)
adds carry x17 x9 x17;
(* adc	x20, x10, xzr                               #! PC = 0xaaaabe371a20 *)
adc x20 x10 0@uint64 carry;
(* eor	x27, x21, x25                               #! PC = 0xaaaabe371a24 *)
xor x27@uint64 x21 x25;
(* mul	x9, x27, x13                                #! PC = 0xaaaabe371a28 *)
mull dcH x9 x27 x13;
(* add	x20, x20, x9                                #! PC = 0xaaaabe371a2c *)
add x20 x20 x9;
(* eor	x27, x5, x26                                #! PC = 0xaaaabe371a30 *)
xor x27@uint64 x5 x26;
(* mul	x9, x27, x14                                #! PC = 0xaaaabe371a34 *)
mull dcH x9 x27 x14;
(* umulh	x10, x27, x14                             #! PC = 0xaaaabe371a38 *)
mull x10 dcL x27 x14;
(* adds	x17, x9, x17                               #! PC = 0xaaaabe371a3c *)
adds carry x17 x9 x17;
(* adc	x20, x10, x20                               #! PC = 0xaaaabe371a40 *)
adc x20 x10 x20 carry;
(* eor	x27, x22, x26                               #! PC = 0xaaaabe371a44 *)
xor x27@uint64 x22 x26;
(* mul	x9, x27, x14                                #! PC = 0xaaaabe371a48 *)
mull dcH x9 x27 x14;
(* add	x20, x20, x9                                #! PC = 0xaaaabe371a4c *)
add x20 x20 x9;
(* extr	x2, x20, x17, #60                          #! PC = 0xaaaabe371a50 *)
spl dc extr_H x20 60; spl extr_L dc x17 60; join x2 extr_H extr_L;
(* smull	v16.2d, v13.2s, v3.s[0]                   #! PC = 0xaaaabe371a54 *)
smull	%%v16.2d, %%v13.2s, %%v3.s[0]                   #! 0xaaaabe371a54 = 0xaaaabe371a54;
(* smlal2	v16.2d, v13.4s, v3.s[2]                  #! PC = 0xaaaabe371a58 *)
smlal2	%%v16.2d, %%v13.4s, %%v3.s[2]                  #! 0xaaaabe371a58 = 0xaaaabe371a58;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371a5c *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v3.s[0]                   #! PC = 0xaaaabe371a60 *)
smlal	%%v16.2d, %%v14.2s, %%v3.s[0]                   #! 0xaaaabe371a60 = 0xaaaabe371a60;
(* smlal2	v16.2d, v14.4s, v3.s[2]                  #! PC = 0xaaaabe371a64 *)
smlal2	%%v16.2d, %%v14.4s, %%v3.s[2]                  #! 0xaaaabe371a64 = 0xaaaabe371a64;
(* smlal	v16.2d, v13.2s, v3.s[1]                   #! PC = 0xaaaabe371a68 *)
smlal	%%v16.2d, %%v13.2s, %%v3.s[1]                   #! 0xaaaabe371a68 = 0xaaaabe371a68;
(* smlal2	v16.2d, v13.4s, v3.s[3]                  #! PC = 0xaaaabe371a6c *)
smlal2	%%v16.2d, %%v13.4s, %%v3.s[3]                  #! 0xaaaabe371a6c = 0xaaaabe371a6c;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371a70 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v3.s[1]                   #! PC = 0xaaaabe371a74 *)
smlal	%%v16.2d, %%v14.2s, %%v3.s[1]                   #! 0xaaaabe371a74 = 0xaaaabe371a74;
(* smlal2	v16.2d, v14.4s, v3.s[3]                  #! PC = 0xaaaabe371a78 *)
smlal2	%%v16.2d, %%v14.4s, %%v3.s[3]                  #! 0xaaaabe371a78 = 0xaaaabe371a78;
(* smlal	v16.2d, v13.2s, v4.s[0]                   #! PC = 0xaaaabe371a7c *)
smlal	%%v16.2d, %%v13.2s, %%v4.s[0]                   #! 0xaaaabe371a7c = 0xaaaabe371a7c;
(* smlal2	v16.2d, v13.4s, v4.s[2]                  #! PC = 0xaaaabe371a80 *)
smlal2	%%v16.2d, %%v13.4s, %%v4.s[2]                  #! 0xaaaabe371a80 = 0xaaaabe371a80;
(* and	v3.16b, v16.16b, v1.16b                     #! PC = 0xaaaabe371a84 *)
and %v3@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371a88 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v4.s[0]                   #! PC = 0xaaaabe371a8c *)
smlal	%%v16.2d, %%v14.2s, %%v4.s[0]                   #! 0xaaaabe371a8c = 0xaaaabe371a8c;
(* smlal2	v16.2d, v14.4s, v4.s[2]                  #! PC = 0xaaaabe371a90 *)
smlal2	%%v16.2d, %%v14.4s, %%v4.s[2]                  #! 0xaaaabe371a90 = 0xaaaabe371a90;
(* smlal	v16.2d, v13.2s, v4.s[1]                   #! PC = 0xaaaabe371a94 *)
smlal	%%v16.2d, %%v13.2s, %%v4.s[1]                   #! 0xaaaabe371a94 = 0xaaaabe371a94;
(* smlal2	v16.2d, v13.4s, v4.s[3]                  #! PC = 0xaaaabe371a98 *)
smlal2	%%v16.2d, %%v13.4s, %%v4.s[3]                  #! 0xaaaabe371a98 = 0xaaaabe371a98;
(* and	v17.16b, v16.16b, v1.16b                    #! PC = 0xaaaabe371a9c *)
and %v17@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371aa0 *)
split %v16 %dc %v16 30;
(* shl	v17.2d, v17.2d, #32                         #! PC = 0xaaaabe371aa4 *)
shls %dc %v17 %v17 [32, 32];
(* orr	v3.16b, v3.16b, v17.16b                     #! PC = 0xaaaabe371aa8 *)
or %v3@uint64[2] %v3 %v17;
(* smlal	v16.2d, v14.2s, v4.s[1]                   #! PC = 0xaaaabe371aac *)
smlal	%%v16.2d, %%v14.2s, %%v4.s[1]                   #! 0xaaaabe371aac = 0xaaaabe371aac;
(* smlal2	v16.2d, v14.4s, v4.s[3]                  #! PC = 0xaaaabe371ab0 *)
smlal2	%%v16.2d, %%v14.4s, %%v4.s[3]                  #! 0xaaaabe371ab0 = 0xaaaabe371ab0;
(* smlal	v16.2d, v13.2s, v5.s[0]                   #! PC = 0xaaaabe371ab4 *)
smlal	%%v16.2d, %%v13.2s, %%v5.s[0]                   #! 0xaaaabe371ab4 = 0xaaaabe371ab4;
(* smlal2	v16.2d, v13.4s, v5.s[2]                  #! PC = 0xaaaabe371ab8 *)
smlal2	%%v16.2d, %%v13.4s, %%v5.s[2]                  #! 0xaaaabe371ab8 = 0xaaaabe371ab8;
(* and	v4.16b, v16.16b, v1.16b                     #! PC = 0xaaaabe371abc *)
and %v4@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371ac0 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v5.s[0]                   #! PC = 0xaaaabe371ac4 *)
smlal	%%v16.2d, %%v14.2s, %%v5.s[0]                   #! 0xaaaabe371ac4 = 0xaaaabe371ac4;
(* smlal2	v16.2d, v14.4s, v5.s[2]                  #! PC = 0xaaaabe371ac8 *)
smlal2	%%v16.2d, %%v14.4s, %%v5.s[2]                  #! 0xaaaabe371ac8 = 0xaaaabe371ac8;
(* smlal	v16.2d, v13.2s, v5.s[1]                   #! PC = 0xaaaabe371acc *)
smlal	%%v16.2d, %%v13.2s, %%v5.s[1]                   #! 0xaaaabe371acc = 0xaaaabe371acc;
(* smlal2	v16.2d, v13.4s, v5.s[3]                  #! PC = 0xaaaabe371ad0 *)
smlal2	%%v16.2d, %%v13.4s, %%v5.s[3]                  #! 0xaaaabe371ad0 = 0xaaaabe371ad0;
(* and	v17.16b, v16.16b, v1.16b                    #! PC = 0xaaaabe371ad4 *)
and %v17@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371ad8 *)
split %v16 %dc %v16 30;
(* shl	v17.2d, v17.2d, #32                         #! PC = 0xaaaabe371adc *)
shls %dc %v17 %v17 [32, 32];
(* orr	v4.16b, v4.16b, v17.16b                     #! PC = 0xaaaabe371ae0 *)
or %v4@uint64[2] %v4 %v17;
(* smlal	v16.2d, v14.2s, v5.s[1]                   #! PC = 0xaaaabe371ae4 *)
smlal	%%v16.2d, %%v14.2s, %%v5.s[1]                   #! 0xaaaabe371ae4 = 0xaaaabe371ae4;
(* smlal2	v16.2d, v14.4s, v5.s[3]                  #! PC = 0xaaaabe371ae8 *)
smlal2	%%v16.2d, %%v14.4s, %%v5.s[3]                  #! 0xaaaabe371ae8 = 0xaaaabe371ae8;
(* smlal	v16.2d, v13.2s, v6.s[0]                   #! PC = 0xaaaabe371aec *)
smlal	%%v16.2d, %%v13.2s, %%v6.s[0]                   #! 0xaaaabe371aec = 0xaaaabe371aec;
(* smlal2	v16.2d, v13.4s, v6.s[2]                  #! PC = 0xaaaabe371af0 *)
smlal2	%%v16.2d, %%v13.4s, %%v6.s[2]                  #! 0xaaaabe371af0 = 0xaaaabe371af0;
(* and	v5.16b, v16.16b, v1.16b                     #! PC = 0xaaaabe371af4 *)
and %v5@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371af8 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v6.s[0]                   #! PC = 0xaaaabe371afc *)
smlal	%%v16.2d, %%v14.2s, %%v6.s[0]                   #! 0xaaaabe371afc = 0xaaaabe371afc;
(* smlal2	v16.2d, v14.4s, v6.s[2]                  #! PC = 0xaaaabe371b00 *)
smlal2	%%v16.2d, %%v14.4s, %%v6.s[2]                  #! 0xaaaabe371b00 = 0xaaaabe371b00;
(* smlal	v16.2d, v13.2s, v6.s[1]                   #! PC = 0xaaaabe371b04 *)
smlal	%%v16.2d, %%v13.2s, %%v6.s[1]                   #! 0xaaaabe371b04 = 0xaaaabe371b04;
(* smlal2	v16.2d, v13.4s, v6.s[3]                  #! PC = 0xaaaabe371b08 *)
smlal2	%%v16.2d, %%v13.4s, %%v6.s[3]                  #! 0xaaaabe371b08 = 0xaaaabe371b08;
(* and	v17.16b, v16.16b, v1.16b                    #! PC = 0xaaaabe371b0c *)
and %v17@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371b10 *)
split %v16 %dc %v16 30;
(* shl	v17.2d, v17.2d, #32                         #! PC = 0xaaaabe371b14 *)
shls %dc %v17 %v17 [32, 32];
(* orr	v5.16b, v5.16b, v17.16b                     #! PC = 0xaaaabe371b18 *)
or %v5@uint64[2] %v5 %v17;
(* smlal	v16.2d, v14.2s, v6.s[1]                   #! PC = 0xaaaabe371b1c *)
smlal	%%v16.2d, %%v14.2s, %%v6.s[1]                   #! 0xaaaabe371b1c = 0xaaaabe371b1c;
(* smlal2	v16.2d, v14.4s, v6.s[3]                  #! PC = 0xaaaabe371b20 *)
smlal2	%%v16.2d, %%v14.4s, %%v6.s[3]                  #! 0xaaaabe371b20 = 0xaaaabe371b20;
(* smlal	v16.2d, v13.2s, v7.s[0]                   #! PC = 0xaaaabe371b24 *)
smlal	%%v16.2d, %%v13.2s, %%v7.s[0]                   #! 0xaaaabe371b24 = 0xaaaabe371b24;
(* smlal2	v16.2d, v13.4s, v7.s[2]                  #! PC = 0xaaaabe371b28 *)
smlal2	%%v16.2d, %%v13.4s, %%v7.s[2]                  #! 0xaaaabe371b28 = 0xaaaabe371b28;
(* and	v6.16b, v16.16b, v1.16b                     #! PC = 0xaaaabe371b2c *)
and %v6@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371b30 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v7.s[0]                   #! PC = 0xaaaabe371b34 *)
smlal	%%v16.2d, %%v14.2s, %%v7.s[0]                   #! 0xaaaabe371b34 = 0xaaaabe371b34;
(* smlal2	v16.2d, v14.4s, v7.s[2]                  #! PC = 0xaaaabe371b38 *)
smlal2	%%v16.2d, %%v14.4s, %%v7.s[2]                  #! 0xaaaabe371b38 = 0xaaaabe371b38;
(* and	v17.16b, v16.16b, v1.16b                    #! PC = 0xaaaabe371b3c *)
and %v17@uint64[2] %v16 %v1;
(* sshr	v7.2d, v16.2d, #30                         #! PC = 0xaaaabe371b40 *)
split %v7 %dc %v16 30;
(* shl	v17.2d, v17.2d, #32                         #! PC = 0xaaaabe371b44 *)
shls %dc %v17 %v17 [32, 32];
(* orr	v6.16b, v6.16b, v17.16b                     #! PC = 0xaaaabe371b48 *)
or %v6@uint64[2] %v6 %v17;
(* and	x7, x1, #0xfffff                            #! PC = 0xaaaabe371b4c *)
and x7@uint64 x1 0xfffff@uint64;
(* and	x8, x2, #0xfffff                            #! PC = 0xaaaabe371b50 *)
and x8@uint64 x2 0xfffff@uint64;
(* orr	x7, x7, #0xfffffe0000000000                 #! PC = 0xaaaabe371b54 *)
or x7@uint64 x7 0xfffffe0000000000@uint64;
(* orr	x8, x8, #0xc000000000000000                 #! PC = 0xaaaabe371b58 *)
or x8@uint64 x8 0xc000000000000000@uint64;
(* tst	x8, #0x1                                    #! PC = 0xaaaabe371b5c *)
spl dc x8_lo x8 1;
and ne@bit x8_lo 1@bit;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371b60 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371b64 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371b68 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371b6c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371b70 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371b74 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371b78 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371b7c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371b80 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371b84 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371b88 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371b8c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371b90 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371b94 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371b98 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371b9c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371ba0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371ba4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371ba8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371bac *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371bb0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371bb4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371bb8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371bbc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371bc0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371bc4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371bc8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371bcc *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371bd0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371bd4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371bd8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371bdc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371be0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371be4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371be8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371bec *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371bf0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371bf4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371bf8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371bfc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c00 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c04 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c08 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c0c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371c10 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371c14 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371c18 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371c1c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371c20 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c24 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c28 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c2c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c30 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371c34 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371c38 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371c3c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371c40 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371c44 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c48 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c4c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c50 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c54 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371c58 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371c5c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371c60 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371c64 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371c68 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c6c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c70 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c74 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c78 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371c7c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371c80 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371c84 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371c88 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371c8c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c90 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c94 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c98 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c9c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371ca0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371ca4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371ca8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371cac *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371cb0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371cb4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371cb8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371cbc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371cc0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371cc4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371cc8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371ccc *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371cd0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371cd4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371cd8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371cdc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371ce0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371ce4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371ce8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371cec *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371cf0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371cf4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371cf8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371cfc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d00 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d04 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d08 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d0c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371d10 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371d14 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371d18 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371d1c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371d20 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d24 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d28 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d2c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d30 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371d34 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371d38 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371d3c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371d40 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371d44 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d48 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d4c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d50 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d54 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371d58 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371d5c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371d60 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371d64 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371d68 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d6c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d70 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d74 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d78 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371d7c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371d80 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371d84 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371d88 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371d8c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d90 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d94 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d98 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d9c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371da0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371da4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371da8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371dac *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371db0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371db4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371db8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371dbc *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371dc0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371dc4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371dc8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371dcc *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371dd0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371dd4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371dd8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371ddc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371de0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371de4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371de8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371dec *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371df0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371df4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371df8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371dfc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371e00 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371e04 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371e08 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371e0c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371e10 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371e14 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371e18 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371e1c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371e20 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371e24 *)
add x3 x3 0x2@sint64;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371e28 *)
ssplit x8 dcL x8 1;
(* add	x12, x7, x6                                 #! PC = 0xaaaabe371e2c *)
add x12 x7 x6;
(* asr	x12, x12, #42                               #! PC = 0xaaaabe371e30 *)
ssplit x12 dcL x12 42;
(* add	x11, x7, #0x100, lsl #12                    #! PC = 0xaaaabe371e34 *)
add x11 x7 0x100@sint64, lsl;
(* lsl	x11, x11, #22                               #! PC = 0xaaaabe371e38 *)
split dcH x11 x11 (64-22); shl x11 x11 22;
(* asr	x11, x11, #43                               #! PC = 0xaaaabe371e3c *)
ssplit x11 dcL x11 43;
(* add	x14, x8, x6                                 #! PC = 0xaaaabe371e40 *)
add x14 x8 x6;
(* asr	x14, x14, #42                               #! PC = 0xaaaabe371e44 *)
ssplit x14 dcL x14 42;
(* add	x13, x8, #0x100, lsl #12                    #! PC = 0xaaaabe371e48 *)
add x13 x8 0x100@sint64, lsl;
(* lsl	x13, x13, #22                               #! PC = 0xaaaabe371e4c *)
split dcH x13 x13 (64-22); shl x13 x13 22;
(* asr	x13, x13, #43                               #! PC = 0xaaaabe371e50 *)
ssplit x13 dcL x13 43;
(* mul	x9, x11, x1                                 #! PC = 0xaaaabe371e54 *)
mull dcH x9 x11 x1;
(* madd	x9, x12, x2, x9                            #! PC = 0xaaaabe371e58 *)
mull dcH mul_tmp x12 x2;
adds dc x9 mul_tmp x9;
(* asr	x9, x9, #20                                 #! PC = 0xaaaabe371e5c *)
ssplit x9 dcL x9 20;
(* mul	x10, x13, x1                                #! PC = 0xaaaabe371e60 *)
mull dcH x10 x13 x1;
(* madd	x10, x14, x2, x10                          #! PC = 0xaaaabe371e64 *)
mull dcH mul_tmp x14 x2;
adds dc x10 mul_tmp x10;
(* asr	x2, x10, #20                                #! PC = 0xaaaabe371e68 *)
ssplit x2 dcL x10 20;
(* mov	x1, x9                                      #! PC = 0xaaaabe371e6c *)
mov x1 x9;
(* mov	w4, v3.s[0]                                 #! PC = 0xaaaabe371e70 *)
mov w4 v3.s[0];
(* mov	w27, v3.s[1]                                #! PC = 0xaaaabe371e74 *)
mov w27 v3.s[1];
(* add	x4, x4, x27, lsl #30                        #! PC = 0xaaaabe371e78 *)
add x4 x4 x27, lsl;
(* mov	w27, v4.s[0]                                #! PC = 0xaaaabe371e7c *)
mov w27 v4.s[0];
(* add	x4, x4, x27, lsl #60                        #! PC = 0xaaaabe371e80 *)
add x4 x4 x27, lsl;
(* add	x21, xzr, x27, lsr #4                       #! PC = 0xaaaabe371e84 *)
add	%%x21, xzr, %%x27, lsr #4                       #! 0xaaaabe371e84 = 0xaaaabe371e84;
(* mov	w27, v4.s[1]                                #! PC = 0xaaaabe371e88 *)
mov w27 v4.s[1];
(* add	x21, x21, x27, lsl #26                      #! PC = 0xaaaabe371e8c *)
add x21 x21 x27, lsl;
(* mov	w5, v3.s[2]                                 #! PC = 0xaaaabe371e90 *)
mov w5 v3.s[2];
(* mov	w27, v3.s[3]                                #! PC = 0xaaaabe371e94 *)
mov w27 v3.s[3];
(* add	x5, x5, x27, lsl #30                        #! PC = 0xaaaabe371e98 *)
add x5 x5 x27, lsl;
(* mov	w27, v4.s[2]                                #! PC = 0xaaaabe371e9c *)
mov w27 v4.s[2];
(* add	x5, x5, x27, lsl #60                        #! PC = 0xaaaabe371ea0 *)
add x5 x5 x27, lsl;
(* add	x22, xzr, x27, lsr #4                       #! PC = 0xaaaabe371ea4 *)
add	%%x22, xzr, %%x27, lsr #4                       #! 0xaaaabe371ea4 = 0xaaaabe371ea4;
(* mov	w27, v4.s[3]                                #! PC = 0xaaaabe371ea8 *)
mov w27 v4.s[3];
(* add	x22, x22, x27, lsl #26                      #! PC = 0xaaaabe371eac *)
add x22 x22 x27, lsl;
(* and	x7, x1, #0xfffff                            #! PC = 0xaaaabe371eb0 *)
and x7@uint64 x1 0xfffff@uint64;
(* and	x8, x2, #0xfffff                            #! PC = 0xaaaabe371eb4 *)
and x8@uint64 x2 0xfffff@uint64;
(* orr	x7, x7, #0xfffffe0000000000                 #! PC = 0xaaaabe371eb8 *)
or x7@uint64 x7 0xfffffe0000000000@uint64;
(* orr	x8, x8, #0xc000000000000000                 #! PC = 0xaaaabe371ebc *)
or x8@uint64 x8 0xc000000000000000@uint64;
(* tst	x8, #0x1                                    #! PC = 0xaaaabe371ec0 *)
spl dc x8_lo x8 1;
and ne@bit x8_lo 1@bit;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371ec4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371ec8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371ecc *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371ed0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371ed4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371ed8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371edc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371ee0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371ee4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371ee8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371eec *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371ef0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371ef4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371ef8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371efc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f00 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f04 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f08 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f0c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371f10 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371f14 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371f18 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371f1c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371f20 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f24 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f28 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f2c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f30 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371f34 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371f38 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371f3c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371f40 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371f44 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f48 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f4c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f50 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f54 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371f58 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371f5c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371f60 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371f64 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371f68 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f6c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f70 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f74 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f78 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371f7c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371f80 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371f84 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371f88 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371f8c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f90 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f94 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f98 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f9c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371fa0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371fa4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371fa8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371fac *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371fb0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371fb4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371fb8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371fbc *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371fc0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371fc4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371fc8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371fcc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371fd0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371fd4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371fd8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371fdc *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371fe0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371fe4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371fe8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371fec *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371ff0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371ff4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371ff8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371ffc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372000 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372004 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372008 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37200c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372010 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372014 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372018 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37201c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372020 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372024 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372028 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37202c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372030 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372034 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372038 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37203c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372040 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372044 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372048 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37204c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372050 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372054 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372058 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37205c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372060 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372064 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372068 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37206c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372070 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372074 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372078 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37207c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372080 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372084 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372088 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37208c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372090 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372094 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372098 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37209c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3720a0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3720a4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3720a8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3720ac *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3720b0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3720b4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3720b8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3720bc *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3720c0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3720c4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3720c8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3720cc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3720d0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3720d4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3720d8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3720dc *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3720e0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3720e4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3720e8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3720ec *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3720f0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3720f4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3720f8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3720fc *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372100 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372104 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372108 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37210c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372110 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372114 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372118 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37211c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372120 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372124 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372128 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37212c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372130 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372134 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372138 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37213c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372140 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372144 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372148 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37214c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372150 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372154 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372158 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37215c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372160 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372164 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372168 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37216c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372170 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372174 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372178 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37217c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372180 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372184 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372188 *)
add x3 x3 0x2@sint64;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37218c *)
ssplit x8 dcL x8 1;
(* add	x16, x7, x6                                 #! PC = 0xaaaabe372190 *)
add x16 x7 x6;
(* asr	x16, x16, #42                               #! PC = 0xaaaabe372194 *)
ssplit x16 dcL x16 42;
(* add	x15, x7, #0x100, lsl #12                    #! PC = 0xaaaabe372198 *)
add x15 x7 0x100@sint64, lsl;
(* lsl	x15, x15, #22                               #! PC = 0xaaaabe37219c *)
split dcH x15 x15 (64-22); shl x15 x15 22;
(* asr	x15, x15, #43                               #! PC = 0xaaaabe3721a0 *)
ssplit x15 dcL x15 43;
(* add	x20, x8, x6                                 #! PC = 0xaaaabe3721a4 *)
add x20 x8 x6;
(* asr	x20, x20, #42                               #! PC = 0xaaaabe3721a8 *)
ssplit x20 dcL x20 42;
(* add	x17, x8, #0x100, lsl #12                    #! PC = 0xaaaabe3721ac *)
add x17 x8 0x100@sint64, lsl;
(* lsl	x17, x17, #22                               #! PC = 0xaaaabe3721b0 *)
split dcH x17 x17 (64-22); shl x17 x17 22;
(* asr	x17, x17, #43                               #! PC = 0xaaaabe3721b4 *)
ssplit x17 dcL x17 43;
(* mul	x9, x15, x1                                 #! PC = 0xaaaabe3721b8 *)
mull dcH x9 x15 x1;
(* madd	x9, x16, x2, x9                            #! PC = 0xaaaabe3721bc *)
mull dcH mul_tmp x16 x2;
adds dc x9 mul_tmp x9;
(* asr	x9, x9, #20                                 #! PC = 0xaaaabe3721c0 *)
ssplit x9 dcL x9 20;
(* mul	x10, x17, x1                                #! PC = 0xaaaabe3721c4 *)
mull dcH x10 x17 x1;
(* madd	x10, x20, x2, x10                          #! PC = 0xaaaabe3721c8 *)
mull dcH mul_tmp x20 x2;
adds dc x10 mul_tmp x10;
(* asr	x2, x10, #20                                #! PC = 0xaaaabe3721cc *)
ssplit x2 dcL x10 20;
(* mov	x1, x9                                      #! PC = 0xaaaabe3721d0 *)
mov x1 x9;
(* mul	x9, x15, x11                                #! PC = 0xaaaabe3721d4 *)
mull dcH x9 x15 x11;
(* madd	x10, x16, x13, x9                          #! PC = 0xaaaabe3721d8 *)
mull dcH mul_tmp x16 x13;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x11                                #! PC = 0xaaaabe3721dc *)
mull dcH x9 x17 x11;
(* madd	x13, x20, x13, x9                          #! PC = 0xaaaabe3721e0 *)
mull dcH mul_tmp x20 x13;
adds dc x13 mul_tmp x9;
(* mov	x11, x10                                    #! PC = 0xaaaabe3721e4 *)
mov x11 x10;
(* mul	x9, x15, x12                                #! PC = 0xaaaabe3721e8 *)
mull dcH x9 x15 x12;
(* madd	x10, x16, x14, x9                          #! PC = 0xaaaabe3721ec *)
mull dcH mul_tmp x16 x14;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x12                                #! PC = 0xaaaabe3721f0 *)
mull dcH x9 x17 x12;
(* madd	x14, x20, x14, x9                          #! PC = 0xaaaabe3721f4 *)
mull dcH mul_tmp x20 x14;
adds dc x14 mul_tmp x9;
(* mov	x12, x10                                    #! PC = 0xaaaabe3721f8 *)
mov x12 x10;
(* mov	x9, #0x13                  	// #19          #! PC = 0xaaaabe3721fc *)
mov x9 0x13@uint64;
(* dup	v16.2d, x9                                  #! PC = 0xaaaabe372200 *)
mov %v16 [x9,x9];
(* smull	v17.2d, v13.2s, v8.s[0]                   #! PC = 0xaaaabe372204 *)
smull	%%v17.2d, %%v13.2s, %%v8.s[0]                   #! 0xaaaabe372204 = 0xaaaabe372204;
(* smlal2	v17.2d, v13.4s, v8.s[2]                  #! PC = 0xaaaabe372208 *)
smlal2	%%v17.2d, %%v13.4s, %%v8.s[2]                  #! 0xaaaabe372208 = 0xaaaabe372208;
(* mul	v19.4s, v17.4s, v15.4s                      #! PC = 0xaaaabe37220c *)
mul %v19 %v17 %v15;
(* and	v19.16b, v19.16b, v1.16b                    #! PC = 0xaaaabe372210 *)
and %v19@uint64[2] %v19 %v1;
(* uzp1	v19.4s, v19.4s, v19.4s                     #! PC = 0xaaaabe372214 *)
mov %v19 [%v19[0], %v19[2], %v19[0], %v19[2]];
(* smlsl	v17.2d, v19.2s, v16.s[0]                  #! PC = 0xaaaabe372218 *)
smlsl	%%v17.2d, %%v19.2s, %%v16.s[0]                  #! 0xaaaabe372218 = 0xaaaabe372218;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe37221c *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v8.s[0]                   #! PC = 0xaaaabe372220 *)
smlal	%%v17.2d, %%v14.2s, %%v8.s[0]                   #! 0xaaaabe372220 = 0xaaaabe372220;
(* smlal2	v17.2d, v14.4s, v8.s[2]                  #! PC = 0xaaaabe372224 *)
smlal2	%%v17.2d, %%v14.4s, %%v8.s[2]                  #! 0xaaaabe372224 = 0xaaaabe372224;
(* smlal	v17.2d, v13.2s, v8.s[1]                   #! PC = 0xaaaabe372228 *)
smlal	%%v17.2d, %%v13.2s, %%v8.s[1]                   #! 0xaaaabe372228 = 0xaaaabe372228;
(* smlal2	v17.2d, v13.4s, v8.s[3]                  #! PC = 0xaaaabe37222c *)
smlal2	%%v17.2d, %%v13.4s, %%v8.s[3]                  #! 0xaaaabe37222c = 0xaaaabe37222c;
(* mul	v20.4s, v17.4s, v15.4s                      #! PC = 0xaaaabe372230 *)
mul %v20 %v17 %v15;
(* and	v20.16b, v20.16b, v1.16b                    #! PC = 0xaaaabe372234 *)
and %v20@uint64[2] %v20 %v1;
(* uzp1	v20.4s, v20.4s, v20.4s                     #! PC = 0xaaaabe372238 *)
mov %v20 [%v20[0], %v20[2], %v20[0], %v20[2]];
(* smlsl	v17.2d, v20.2s, v16.s[0]                  #! PC = 0xaaaabe37223c *)
smlsl	%%v17.2d, %%v20.2s, %%v16.s[0]                  #! 0xaaaabe37223c = 0xaaaabe37223c;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe372240 *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v8.s[1]                   #! PC = 0xaaaabe372244 *)
smlal	%%v17.2d, %%v14.2s, %%v8.s[1]                   #! 0xaaaabe372244 = 0xaaaabe372244;
(* smlal2	v17.2d, v14.4s, v8.s[3]                  #! PC = 0xaaaabe372248 *)
smlal2	%%v17.2d, %%v14.4s, %%v8.s[3]                  #! 0xaaaabe372248 = 0xaaaabe372248;
(* smlal	v17.2d, v13.2s, v9.s[0]                   #! PC = 0xaaaabe37224c *)
smlal	%%v17.2d, %%v13.2s, %%v9.s[0]                   #! 0xaaaabe37224c = 0xaaaabe37224c;
(* smlal2	v17.2d, v13.4s, v9.s[2]                  #! PC = 0xaaaabe372250 *)
smlal2	%%v17.2d, %%v13.4s, %%v9.s[2]                  #! 0xaaaabe372250 = 0xaaaabe372250;
(* and	v8.16b, v17.16b, v1.16b                     #! PC = 0xaaaabe372254 *)
and %v8@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe372258 *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v9.s[0]                   #! PC = 0xaaaabe37225c *)
smlal	%%v17.2d, %%v14.2s, %%v9.s[0]                   #! 0xaaaabe37225c = 0xaaaabe37225c;
(* smlal2	v17.2d, v14.4s, v9.s[2]                  #! PC = 0xaaaabe372260 *)
smlal2	%%v17.2d, %%v14.4s, %%v9.s[2]                  #! 0xaaaabe372260 = 0xaaaabe372260;
(* smlal	v17.2d, v13.2s, v9.s[1]                   #! PC = 0xaaaabe372264 *)
smlal	%%v17.2d, %%v13.2s, %%v9.s[1]                   #! 0xaaaabe372264 = 0xaaaabe372264;
(* smlal2	v17.2d, v13.4s, v9.s[3]                  #! PC = 0xaaaabe372268 *)
smlal2	%%v17.2d, %%v13.4s, %%v9.s[3]                  #! 0xaaaabe372268 = 0xaaaabe372268;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe37226c *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe372270 *)
split %v17 %dc %v17 30;
(* sli	v8.2d, v18.2d, #32                          #! PC = 0xaaaabe372274 *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v8 %v8 32; or %v8@uint64[2] %slih %v8;
(* smlal	v17.2d, v14.2s, v9.s[1]                   #! PC = 0xaaaabe372278 *)
smlal	%%v17.2d, %%v14.2s, %%v9.s[1]                   #! 0xaaaabe372278 = 0xaaaabe372278;
(* smlal2	v17.2d, v14.4s, v9.s[3]                  #! PC = 0xaaaabe37227c *)
smlal2	%%v17.2d, %%v14.4s, %%v9.s[3]                  #! 0xaaaabe37227c = 0xaaaabe37227c;
(* smlal	v17.2d, v13.2s, v10.s[0]                  #! PC = 0xaaaabe372280 *)
smlal	%%v17.2d, %%v13.2s, %%v10.s[0]                  #! 0xaaaabe372280 = 0xaaaabe372280;
(* smlal2	v17.2d, v13.4s, v10.s[2]                 #! PC = 0xaaaabe372284 *)
smlal2	%%v17.2d, %%v13.4s, %%v10.s[2]                 #! 0xaaaabe372284 = 0xaaaabe372284;
(* and	v9.16b, v17.16b, v1.16b                     #! PC = 0xaaaabe372288 *)
and %v9@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe37228c *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v10.s[0]                  #! PC = 0xaaaabe372290 *)
smlal	%%v17.2d, %%v14.2s, %%v10.s[0]                  #! 0xaaaabe372290 = 0xaaaabe372290;
(* smlal2	v17.2d, v14.4s, v10.s[2]                 #! PC = 0xaaaabe372294 *)
smlal2	%%v17.2d, %%v14.4s, %%v10.s[2]                 #! 0xaaaabe372294 = 0xaaaabe372294;
(* smlal	v17.2d, v13.2s, v10.s[1]                  #! PC = 0xaaaabe372298 *)
smlal	%%v17.2d, %%v13.2s, %%v10.s[1]                  #! 0xaaaabe372298 = 0xaaaabe372298;
(* smlal2	v17.2d, v13.4s, v10.s[3]                 #! PC = 0xaaaabe37229c *)
smlal2	%%v17.2d, %%v13.4s, %%v10.s[3]                 #! 0xaaaabe37229c = 0xaaaabe37229c;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe3722a0 *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3722a4 *)
split %v17 %dc %v17 30;
(* sli	v9.2d, v18.2d, #32                          #! PC = 0xaaaabe3722a8 *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v9 %v9 32; or %v9@uint64[2] %slih %v9;
(* smlal	v17.2d, v14.2s, v10.s[1]                  #! PC = 0xaaaabe3722ac *)
smlal	%%v17.2d, %%v14.2s, %%v10.s[1]                  #! 0xaaaabe3722ac = 0xaaaabe3722ac;
(* smlal2	v17.2d, v14.4s, v10.s[3]                 #! PC = 0xaaaabe3722b0 *)
smlal2	%%v17.2d, %%v14.4s, %%v10.s[3]                 #! 0xaaaabe3722b0 = 0xaaaabe3722b0;
(* smlal	v17.2d, v13.2s, v11.s[0]                  #! PC = 0xaaaabe3722b4 *)
smlal	%%v17.2d, %%v13.2s, %%v11.s[0]                  #! 0xaaaabe3722b4 = 0xaaaabe3722b4;
(* smlal2	v17.2d, v13.4s, v11.s[2]                 #! PC = 0xaaaabe3722b8 *)
smlal2	%%v17.2d, %%v13.4s, %%v11.s[2]                 #! 0xaaaabe3722b8 = 0xaaaabe3722b8;
(* and	v10.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe3722bc *)
and %v10@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3722c0 *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v11.s[0]                  #! PC = 0xaaaabe3722c4 *)
smlal	%%v17.2d, %%v14.2s, %%v11.s[0]                  #! 0xaaaabe3722c4 = 0xaaaabe3722c4;
(* smlal2	v17.2d, v14.4s, v11.s[2]                 #! PC = 0xaaaabe3722c8 *)
smlal2	%%v17.2d, %%v14.4s, %%v11.s[2]                 #! 0xaaaabe3722c8 = 0xaaaabe3722c8;
(* smlal	v17.2d, v13.2s, v11.s[1]                  #! PC = 0xaaaabe3722cc *)
smlal	%%v17.2d, %%v13.2s, %%v11.s[1]                  #! 0xaaaabe3722cc = 0xaaaabe3722cc;
(* smlal2	v17.2d, v13.4s, v11.s[3]                 #! PC = 0xaaaabe3722d0 *)
smlal2	%%v17.2d, %%v13.4s, %%v11.s[3]                 #! 0xaaaabe3722d0 = 0xaaaabe3722d0;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe3722d4 *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3722d8 *)
split %v17 %dc %v17 30;
(* sli	v10.2d, v18.2d, #32                         #! PC = 0xaaaabe3722dc *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v10 %v10 32; or %v10@uint64[2] %slih %v10;
(* smlal	v17.2d, v14.2s, v11.s[1]                  #! PC = 0xaaaabe3722e0 *)
smlal	%%v17.2d, %%v14.2s, %%v11.s[1]                  #! 0xaaaabe3722e0 = 0xaaaabe3722e0;
(* smlal2	v17.2d, v14.4s, v11.s[3]                 #! PC = 0xaaaabe3722e4 *)
smlal2	%%v17.2d, %%v14.4s, %%v11.s[3]                 #! 0xaaaabe3722e4 = 0xaaaabe3722e4;
(* smlal	v17.2d, v13.2s, v12.s[0]                  #! PC = 0xaaaabe3722e8 *)
smlal	%%v17.2d, %%v13.2s, %%v12.s[0]                  #! 0xaaaabe3722e8 = 0xaaaabe3722e8;
(* smlal2	v17.2d, v13.4s, v12.s[2]                 #! PC = 0xaaaabe3722ec *)
smlal2	%%v17.2d, %%v13.4s, %%v12.s[2]                 #! 0xaaaabe3722ec = 0xaaaabe3722ec;
(* ushll	v19.2d, v19.2s, #15                       #! PC = 0xaaaabe3722f0 *)
ushll	%%v19.2d, %%v19.2s, #15                       #! 0xaaaabe3722f0 = 0xaaaabe3722f0;
(* add	v17.2d, v17.2d, v19.2d                      #! PC = 0xaaaabe3722f4 *)
add	%%v17.2d, %%v17.2d, %%v19.2d                      #! 0xaaaabe3722f4 = 0xaaaabe3722f4;
(* and	v11.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe3722f8 *)
and %v11@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3722fc *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v12.s[0]                  #! PC = 0xaaaabe372300 *)
smlal	%%v17.2d, %%v14.2s, %%v12.s[0]                  #! 0xaaaabe372300 = 0xaaaabe372300;
(* smlal2	v17.2d, v14.4s, v12.s[2]                 #! PC = 0xaaaabe372304 *)
smlal2	%%v17.2d, %%v14.4s, %%v12.s[2]                 #! 0xaaaabe372304 = 0xaaaabe372304;
(* ushll	v20.2d, v20.2s, #15                       #! PC = 0xaaaabe372308 *)
ushll	%%v20.2d, %%v20.2s, #15                       #! 0xaaaabe372308 = 0xaaaabe372308;
(* add	v17.2d, v17.2d, v20.2d                      #! PC = 0xaaaabe37230c *)
add	%%v17.2d, %%v17.2d, %%v20.2d                      #! 0xaaaabe37230c = 0xaaaabe37230c;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe372310 *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v12.2d, v17.2d, #30                        #! PC = 0xaaaabe372314 *)
split %v12 %dc %v17 30;
(* sli	v11.2d, v18.2d, #32                         #! PC = 0xaaaabe372318 *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v11 %v11 32; or %v11@uint64[2] %slih %v11;
(* sshr	v18.2d, v12.2d, #15                        #! PC = 0xaaaabe37231c *)
split %v18 %dc %v12 15;
(* shl	v17.2d, v18.2d, #15                         #! PC = 0xaaaabe372320 *)
shls %dc %v17 %v18 [15, 15];
(* sub	v12.2d, v12.2d, v17.2d                      #! PC = 0xaaaabe372324 *)
sub	%%v12.2d, %%v12.2d, %%v17.2d                      #! 0xaaaabe372324 = 0xaaaabe372324;
(* mla	v8.4s, v18.4s, v16.4s                       #! PC = 0xaaaabe372328 *)
mull %dc %mla %v18 %v16; add %v8 %v8 %mla;
(* and	x7, x1, #0xfffff                            #! PC = 0xaaaabe37232c *)
and x7@uint64 x1 0xfffff@uint64;
(* and	x8, x2, #0xfffff                            #! PC = 0xaaaabe372330 *)
and x8@uint64 x2 0xfffff@uint64;
(* orr	x7, x7, #0xfffffe0000000000                 #! PC = 0xaaaabe372334 *)
or x7@uint64 x7 0xfffffe0000000000@uint64;
(* orr	x8, x8, #0xc000000000000000                 #! PC = 0xaaaabe372338 *)
or x8@uint64 x8 0xc000000000000000@uint64;
(* tst	x8, #0x1                                    #! PC = 0xaaaabe37233c *)
spl dc x8_lo x8 1;
and ne@bit x8_lo 1@bit;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372340 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372344 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372348 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37234c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372350 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372354 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372358 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37235c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372360 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372364 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372368 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37236c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372370 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372374 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372378 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37237c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372380 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372384 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372388 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37238c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372390 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372394 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372398 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37239c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3723a0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3723a4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3723a8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3723ac *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3723b0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3723b4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3723b8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3723bc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3723c0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3723c4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3723c8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3723cc *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3723d0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3723d4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3723d8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3723dc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3723e0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3723e4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3723e8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3723ec *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3723f0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3723f4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3723f8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3723fc *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372400 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372404 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372408 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37240c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372410 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372414 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372418 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37241c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372420 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372424 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372428 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37242c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372430 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372434 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372438 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37243c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372440 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372444 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372448 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37244c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372450 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372454 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372458 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37245c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372460 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372464 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372468 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37246c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372470 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372474 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372478 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37247c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372480 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372484 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372488 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37248c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372490 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372494 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372498 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37249c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3724a0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3724a4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3724a8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3724ac *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3724b0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3724b4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3724b8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3724bc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3724c0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3724c4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3724c8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3724cc *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3724d0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3724d4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3724d8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3724dc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3724e0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3724e4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3724e8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3724ec *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3724f0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3724f4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3724f8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3724fc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372500 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372504 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372508 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37250c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372510 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372514 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372518 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37251c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372520 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372524 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372528 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37252c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372530 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372534 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372538 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37253c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372540 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372544 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372548 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37254c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372550 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372554 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372558 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37255c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372560 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372564 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372568 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37256c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372570 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372574 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372578 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37257c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372580 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372584 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372588 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37258c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372590 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372594 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372598 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37259c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3725a0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3725a4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3725a8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3725ac *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3725b0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3725b4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3725b8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3725bc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3725c0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3725c4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3725c8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3725cc *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3725d0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3725d4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3725d8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3725dc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3725e0 *)
add x3 x3 0x2@sint64;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3725e4 *)
ssplit x8 dcL x8 1;
(* add	x16, x7, x6                                 #! PC = 0xaaaabe3725e8 *)
add x16 x7 x6;
(* asr	x16, x16, #42                               #! PC = 0xaaaabe3725ec *)
ssplit x16 dcL x16 42;
(* add	x15, x7, #0x100, lsl #12                    #! PC = 0xaaaabe3725f0 *)
add x15 x7 0x100@sint64, lsl;
(* lsl	x15, x15, #22                               #! PC = 0xaaaabe3725f4 *)
split dcH x15 x15 (64-22); shl x15 x15 22;
(* asr	x15, x15, #43                               #! PC = 0xaaaabe3725f8 *)
ssplit x15 dcL x15 43;
(* add	x20, x8, x6                                 #! PC = 0xaaaabe3725fc *)
add x20 x8 x6;
(* asr	x20, x20, #42                               #! PC = 0xaaaabe372600 *)
ssplit x20 dcL x20 42;
(* add	x17, x8, #0x100, lsl #12                    #! PC = 0xaaaabe372604 *)
add x17 x8 0x100@sint64, lsl;
(* lsl	x17, x17, #22                               #! PC = 0xaaaabe372608 *)
split dcH x17 x17 (64-22); shl x17 x17 22;
(* asr	x17, x17, #43                               #! PC = 0xaaaabe37260c *)
ssplit x17 dcL x17 43;
(* mul	x9, x15, x11                                #! PC = 0xaaaabe372610 *)
mull dcH x9 x15 x11;
(* madd	x10, x16, x13, x9                          #! PC = 0xaaaabe372614 *)
mull dcH mul_tmp x16 x13;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x11                                #! PC = 0xaaaabe372618 *)
mull dcH x9 x17 x11;
(* madd	x13, x20, x13, x9                          #! PC = 0xaaaabe37261c *)
mull dcH mul_tmp x20 x13;
adds dc x13 mul_tmp x9;
(* mov	x11, x10                                    #! PC = 0xaaaabe372620 *)
mov x11 x10;
(* mul	x9, x15, x12                                #! PC = 0xaaaabe372624 *)
mull dcH x9 x15 x12;
(* madd	x10, x16, x14, x9                          #! PC = 0xaaaabe372628 *)
mull dcH mul_tmp x16 x14;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x12                                #! PC = 0xaaaabe37262c *)
mull dcH x9 x17 x12;
(* madd	x14, x20, x14, x9                          #! PC = 0xaaaabe372630 *)
mull dcH mul_tmp x20 x14;
adds dc x14 mul_tmp x9;
(* mov	x12, x10                                    #! PC = 0xaaaabe372634 *)
mov x12 x10;
(* subs	x19, x19, #0x1                             #! PC = 0xaaaabe372638 *)
subc carry x19 x19 0x1@uint64;
(* #cbnz	x19, 0xaaaabe371960 <Lbig_loop>           #! PC = 0xaaaabe37263c *)
#cbnz	%%x19, 0xaaaabe371960 <Lbig_loop>           #! 0xaaaabe37263c = 0xaaaabe37263c;
(* mov	v16.d[0], x11                               #! PC = 0xaaaabe371960 *)
mov %v16 [x11, %v16[1]];
(* mov	v16.d[1], x13                               #! PC = 0xaaaabe371964 *)
mov %v16 [%v16[0], x13];
(* mov	v17.d[0], x12                               #! PC = 0xaaaabe371968 *)
mov %v17 [x12, %v17[1]];
(* mov	v17.d[1], x14                               #! PC = 0xaaaabe37196c *)
mov %v17 [%v17[0], x14];
(* uzp1	v13.4s, v16.4s, v17.4s                     #! PC = 0xaaaabe371970 *)
mov %v13 [%v16[0], %v16[2], %v17[0], %v17[2]];
(* and	v13.16b, v13.16b, v2.16b                    #! PC = 0xaaaabe371974 *)
and %v13@uint64[2] %v13 %v2;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371978 *)
split %v16 %dc %v16 30;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe37197c *)
split %v17 %dc %v17 30;
(* uzp1	v14.4s, v16.4s, v17.4s                     #! PC = 0xaaaabe371980 *)
mov %v14 [%v16[0], %v16[2], %v17[0], %v17[2]];
(* cmp	x11, xzr                                    #! PC = 0xaaaabe371984 *)
subc zero dc 0@uint64 x11;
(* csetm	x23, mi	// mi = first                     #! PC = 0xaaaabe371988 *)
csetm	%%x23, mi	// mi = first                     #! 0xaaaabe371988 = 0xaaaabe371988;
(* cneg	x11, x11, mi	// mi = first                 #! PC = 0xaaaabe37198c *)
cneg	%%x11, %%x11, mi	// mi = first                 #! 0xaaaabe37198c = 0xaaaabe37198c;
(* cmp	x12, xzr                                    #! PC = 0xaaaabe371990 *)
subc zero dc 0@uint64 x12;
(* csetm	x24, mi	// mi = first                     #! PC = 0xaaaabe371994 *)
csetm	%%x24, mi	// mi = first                     #! 0xaaaabe371994 = 0xaaaabe371994;
(* cneg	x12, x12, mi	// mi = first                 #! PC = 0xaaaabe371998 *)
cneg	%%x12, %%x12, mi	// mi = first                 #! 0xaaaabe371998 = 0xaaaabe371998;
(* cmp	x13, xzr                                    #! PC = 0xaaaabe37199c *)
subc zero dc 0@uint64 x13;
(* csetm	x25, mi	// mi = first                     #! PC = 0xaaaabe3719a0 *)
csetm	%%x25, mi	// mi = first                     #! 0xaaaabe3719a0 = 0xaaaabe3719a0;
(* cneg	x13, x13, mi	// mi = first                 #! PC = 0xaaaabe3719a4 *)
cneg	%%x13, %%x13, mi	// mi = first                 #! 0xaaaabe3719a4 = 0xaaaabe3719a4;
(* cmp	x14, xzr                                    #! PC = 0xaaaabe3719a8 *)
subc zero dc 0@uint64 x14;
(* csetm	x26, mi	// mi = first                     #! PC = 0xaaaabe3719ac *)
csetm	%%x26, mi	// mi = first                     #! 0xaaaabe3719ac = 0xaaaabe3719ac;
(* cneg	x14, x14, mi	// mi = first                 #! PC = 0xaaaabe3719b0 *)
cneg	%%x14, %%x14, mi	// mi = first                 #! 0xaaaabe3719b0 = 0xaaaabe3719b0;
(* and	x27, x11, x23                               #! PC = 0xaaaabe3719b4 *)
and x27@uint64 x11 x23;
(* and	x28, x12, x24                               #! PC = 0xaaaabe3719b8 *)
and x28@uint64 x12 x24;
(* add	x15, x27, x28                               #! PC = 0xaaaabe3719bc *)
add x15 x27 x28;
(* eor	x27, x4, x23                                #! PC = 0xaaaabe3719c0 *)
xor x27@uint64 x4 x23;
(* mul	x9, x27, x11                                #! PC = 0xaaaabe3719c4 *)
mull dcH x9 x27 x11;
(* umulh	x10, x27, x11                             #! PC = 0xaaaabe3719c8 *)
mull x10 dcL x27 x11;
(* adds	x15, x9, x15                               #! PC = 0xaaaabe3719cc *)
adds carry x15 x9 x15;
(* adc	x16, x10, xzr                               #! PC = 0xaaaabe3719d0 *)
adc x16 x10 0@uint64 carry;
(* eor	x27, x21, x23                               #! PC = 0xaaaabe3719d4 *)
xor x27@uint64 x21 x23;
(* mul	x9, x27, x11                                #! PC = 0xaaaabe3719d8 *)
mull dcH x9 x27 x11;
(* add	x16, x16, x9                                #! PC = 0xaaaabe3719dc *)
add x16 x16 x9;
(* eor	x27, x5, x24                                #! PC = 0xaaaabe3719e0 *)
xor x27@uint64 x5 x24;
(* mul	x9, x27, x12                                #! PC = 0xaaaabe3719e4 *)
mull dcH x9 x27 x12;
(* umulh	x10, x27, x12                             #! PC = 0xaaaabe3719e8 *)
mull x10 dcL x27 x12;
(* adds	x15, x9, x15                               #! PC = 0xaaaabe3719ec *)
adds carry x15 x9 x15;
(* adc	x16, x10, x16                               #! PC = 0xaaaabe3719f0 *)
adc x16 x10 x16 carry;
(* eor	x27, x22, x24                               #! PC = 0xaaaabe3719f4 *)
xor x27@uint64 x22 x24;
(* mul	x9, x27, x12                                #! PC = 0xaaaabe3719f8 *)
mull dcH x9 x27 x12;
(* add	x16, x16, x9                                #! PC = 0xaaaabe3719fc *)
add x16 x16 x9;
(* extr	x1, x16, x15, #60                          #! PC = 0xaaaabe371a00 *)
spl dc extr_H x16 60; spl extr_L dc x15 60; join x1 extr_H extr_L;
(* and	x27, x13, x25                               #! PC = 0xaaaabe371a04 *)
and x27@uint64 x13 x25;
(* and	x28, x14, x26                               #! PC = 0xaaaabe371a08 *)
and x28@uint64 x14 x26;
(* add	x17, x27, x28                               #! PC = 0xaaaabe371a0c *)
add x17 x27 x28;
(* eor	x27, x4, x25                                #! PC = 0xaaaabe371a10 *)
xor x27@uint64 x4 x25;
(* mul	x9, x27, x13                                #! PC = 0xaaaabe371a14 *)
mull dcH x9 x27 x13;
(* umulh	x10, x27, x13                             #! PC = 0xaaaabe371a18 *)
mull x10 dcL x27 x13;
(* adds	x17, x9, x17                               #! PC = 0xaaaabe371a1c *)
adds carry x17 x9 x17;
(* adc	x20, x10, xzr                               #! PC = 0xaaaabe371a20 *)
adc x20 x10 0@uint64 carry;
(* eor	x27, x21, x25                               #! PC = 0xaaaabe371a24 *)
xor x27@uint64 x21 x25;
(* mul	x9, x27, x13                                #! PC = 0xaaaabe371a28 *)
mull dcH x9 x27 x13;
(* add	x20, x20, x9                                #! PC = 0xaaaabe371a2c *)
add x20 x20 x9;
(* eor	x27, x5, x26                                #! PC = 0xaaaabe371a30 *)
xor x27@uint64 x5 x26;
(* mul	x9, x27, x14                                #! PC = 0xaaaabe371a34 *)
mull dcH x9 x27 x14;
(* umulh	x10, x27, x14                             #! PC = 0xaaaabe371a38 *)
mull x10 dcL x27 x14;
(* adds	x17, x9, x17                               #! PC = 0xaaaabe371a3c *)
adds carry x17 x9 x17;
(* adc	x20, x10, x20                               #! PC = 0xaaaabe371a40 *)
adc x20 x10 x20 carry;
(* eor	x27, x22, x26                               #! PC = 0xaaaabe371a44 *)
xor x27@uint64 x22 x26;
(* mul	x9, x27, x14                                #! PC = 0xaaaabe371a48 *)
mull dcH x9 x27 x14;
(* add	x20, x20, x9                                #! PC = 0xaaaabe371a4c *)
add x20 x20 x9;
(* extr	x2, x20, x17, #60                          #! PC = 0xaaaabe371a50 *)
spl dc extr_H x20 60; spl extr_L dc x17 60; join x2 extr_H extr_L;
(* smull	v16.2d, v13.2s, v3.s[0]                   #! PC = 0xaaaabe371a54 *)
smull	%%v16.2d, %%v13.2s, %%v3.s[0]                   #! 0xaaaabe371a54 = 0xaaaabe371a54;
(* smlal2	v16.2d, v13.4s, v3.s[2]                  #! PC = 0xaaaabe371a58 *)
smlal2	%%v16.2d, %%v13.4s, %%v3.s[2]                  #! 0xaaaabe371a58 = 0xaaaabe371a58;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371a5c *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v3.s[0]                   #! PC = 0xaaaabe371a60 *)
smlal	%%v16.2d, %%v14.2s, %%v3.s[0]                   #! 0xaaaabe371a60 = 0xaaaabe371a60;
(* smlal2	v16.2d, v14.4s, v3.s[2]                  #! PC = 0xaaaabe371a64 *)
smlal2	%%v16.2d, %%v14.4s, %%v3.s[2]                  #! 0xaaaabe371a64 = 0xaaaabe371a64;
(* smlal	v16.2d, v13.2s, v3.s[1]                   #! PC = 0xaaaabe371a68 *)
smlal	%%v16.2d, %%v13.2s, %%v3.s[1]                   #! 0xaaaabe371a68 = 0xaaaabe371a68;
(* smlal2	v16.2d, v13.4s, v3.s[3]                  #! PC = 0xaaaabe371a6c *)
smlal2	%%v16.2d, %%v13.4s, %%v3.s[3]                  #! 0xaaaabe371a6c = 0xaaaabe371a6c;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371a70 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v3.s[1]                   #! PC = 0xaaaabe371a74 *)
smlal	%%v16.2d, %%v14.2s, %%v3.s[1]                   #! 0xaaaabe371a74 = 0xaaaabe371a74;
(* smlal2	v16.2d, v14.4s, v3.s[3]                  #! PC = 0xaaaabe371a78 *)
smlal2	%%v16.2d, %%v14.4s, %%v3.s[3]                  #! 0xaaaabe371a78 = 0xaaaabe371a78;
(* smlal	v16.2d, v13.2s, v4.s[0]                   #! PC = 0xaaaabe371a7c *)
smlal	%%v16.2d, %%v13.2s, %%v4.s[0]                   #! 0xaaaabe371a7c = 0xaaaabe371a7c;
(* smlal2	v16.2d, v13.4s, v4.s[2]                  #! PC = 0xaaaabe371a80 *)
smlal2	%%v16.2d, %%v13.4s, %%v4.s[2]                  #! 0xaaaabe371a80 = 0xaaaabe371a80;
(* and	v3.16b, v16.16b, v1.16b                     #! PC = 0xaaaabe371a84 *)
and %v3@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371a88 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v4.s[0]                   #! PC = 0xaaaabe371a8c *)
smlal	%%v16.2d, %%v14.2s, %%v4.s[0]                   #! 0xaaaabe371a8c = 0xaaaabe371a8c;
(* smlal2	v16.2d, v14.4s, v4.s[2]                  #! PC = 0xaaaabe371a90 *)
smlal2	%%v16.2d, %%v14.4s, %%v4.s[2]                  #! 0xaaaabe371a90 = 0xaaaabe371a90;
(* smlal	v16.2d, v13.2s, v4.s[1]                   #! PC = 0xaaaabe371a94 *)
smlal	%%v16.2d, %%v13.2s, %%v4.s[1]                   #! 0xaaaabe371a94 = 0xaaaabe371a94;
(* smlal2	v16.2d, v13.4s, v4.s[3]                  #! PC = 0xaaaabe371a98 *)
smlal2	%%v16.2d, %%v13.4s, %%v4.s[3]                  #! 0xaaaabe371a98 = 0xaaaabe371a98;
(* and	v17.16b, v16.16b, v1.16b                    #! PC = 0xaaaabe371a9c *)
and %v17@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371aa0 *)
split %v16 %dc %v16 30;
(* shl	v17.2d, v17.2d, #32                         #! PC = 0xaaaabe371aa4 *)
shls %dc %v17 %v17 [32, 32];
(* orr	v3.16b, v3.16b, v17.16b                     #! PC = 0xaaaabe371aa8 *)
or %v3@uint64[2] %v3 %v17;
(* smlal	v16.2d, v14.2s, v4.s[1]                   #! PC = 0xaaaabe371aac *)
smlal	%%v16.2d, %%v14.2s, %%v4.s[1]                   #! 0xaaaabe371aac = 0xaaaabe371aac;
(* smlal2	v16.2d, v14.4s, v4.s[3]                  #! PC = 0xaaaabe371ab0 *)
smlal2	%%v16.2d, %%v14.4s, %%v4.s[3]                  #! 0xaaaabe371ab0 = 0xaaaabe371ab0;
(* smlal	v16.2d, v13.2s, v5.s[0]                   #! PC = 0xaaaabe371ab4 *)
smlal	%%v16.2d, %%v13.2s, %%v5.s[0]                   #! 0xaaaabe371ab4 = 0xaaaabe371ab4;
(* smlal2	v16.2d, v13.4s, v5.s[2]                  #! PC = 0xaaaabe371ab8 *)
smlal2	%%v16.2d, %%v13.4s, %%v5.s[2]                  #! 0xaaaabe371ab8 = 0xaaaabe371ab8;
(* and	v4.16b, v16.16b, v1.16b                     #! PC = 0xaaaabe371abc *)
and %v4@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371ac0 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v5.s[0]                   #! PC = 0xaaaabe371ac4 *)
smlal	%%v16.2d, %%v14.2s, %%v5.s[0]                   #! 0xaaaabe371ac4 = 0xaaaabe371ac4;
(* smlal2	v16.2d, v14.4s, v5.s[2]                  #! PC = 0xaaaabe371ac8 *)
smlal2	%%v16.2d, %%v14.4s, %%v5.s[2]                  #! 0xaaaabe371ac8 = 0xaaaabe371ac8;
(* smlal	v16.2d, v13.2s, v5.s[1]                   #! PC = 0xaaaabe371acc *)
smlal	%%v16.2d, %%v13.2s, %%v5.s[1]                   #! 0xaaaabe371acc = 0xaaaabe371acc;
(* smlal2	v16.2d, v13.4s, v5.s[3]                  #! PC = 0xaaaabe371ad0 *)
smlal2	%%v16.2d, %%v13.4s, %%v5.s[3]                  #! 0xaaaabe371ad0 = 0xaaaabe371ad0;
(* and	v17.16b, v16.16b, v1.16b                    #! PC = 0xaaaabe371ad4 *)
and %v17@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371ad8 *)
split %v16 %dc %v16 30;
(* shl	v17.2d, v17.2d, #32                         #! PC = 0xaaaabe371adc *)
shls %dc %v17 %v17 [32, 32];
(* orr	v4.16b, v4.16b, v17.16b                     #! PC = 0xaaaabe371ae0 *)
or %v4@uint64[2] %v4 %v17;
(* smlal	v16.2d, v14.2s, v5.s[1]                   #! PC = 0xaaaabe371ae4 *)
smlal	%%v16.2d, %%v14.2s, %%v5.s[1]                   #! 0xaaaabe371ae4 = 0xaaaabe371ae4;
(* smlal2	v16.2d, v14.4s, v5.s[3]                  #! PC = 0xaaaabe371ae8 *)
smlal2	%%v16.2d, %%v14.4s, %%v5.s[3]                  #! 0xaaaabe371ae8 = 0xaaaabe371ae8;
(* smlal	v16.2d, v13.2s, v6.s[0]                   #! PC = 0xaaaabe371aec *)
smlal	%%v16.2d, %%v13.2s, %%v6.s[0]                   #! 0xaaaabe371aec = 0xaaaabe371aec;
(* smlal2	v16.2d, v13.4s, v6.s[2]                  #! PC = 0xaaaabe371af0 *)
smlal2	%%v16.2d, %%v13.4s, %%v6.s[2]                  #! 0xaaaabe371af0 = 0xaaaabe371af0;
(* and	v5.16b, v16.16b, v1.16b                     #! PC = 0xaaaabe371af4 *)
and %v5@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371af8 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v6.s[0]                   #! PC = 0xaaaabe371afc *)
smlal	%%v16.2d, %%v14.2s, %%v6.s[0]                   #! 0xaaaabe371afc = 0xaaaabe371afc;
(* smlal2	v16.2d, v14.4s, v6.s[2]                  #! PC = 0xaaaabe371b00 *)
smlal2	%%v16.2d, %%v14.4s, %%v6.s[2]                  #! 0xaaaabe371b00 = 0xaaaabe371b00;
(* smlal	v16.2d, v13.2s, v6.s[1]                   #! PC = 0xaaaabe371b04 *)
smlal	%%v16.2d, %%v13.2s, %%v6.s[1]                   #! 0xaaaabe371b04 = 0xaaaabe371b04;
(* smlal2	v16.2d, v13.4s, v6.s[3]                  #! PC = 0xaaaabe371b08 *)
smlal2	%%v16.2d, %%v13.4s, %%v6.s[3]                  #! 0xaaaabe371b08 = 0xaaaabe371b08;
(* and	v17.16b, v16.16b, v1.16b                    #! PC = 0xaaaabe371b0c *)
and %v17@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371b10 *)
split %v16 %dc %v16 30;
(* shl	v17.2d, v17.2d, #32                         #! PC = 0xaaaabe371b14 *)
shls %dc %v17 %v17 [32, 32];
(* orr	v5.16b, v5.16b, v17.16b                     #! PC = 0xaaaabe371b18 *)
or %v5@uint64[2] %v5 %v17;
(* smlal	v16.2d, v14.2s, v6.s[1]                   #! PC = 0xaaaabe371b1c *)
smlal	%%v16.2d, %%v14.2s, %%v6.s[1]                   #! 0xaaaabe371b1c = 0xaaaabe371b1c;
(* smlal2	v16.2d, v14.4s, v6.s[3]                  #! PC = 0xaaaabe371b20 *)
smlal2	%%v16.2d, %%v14.4s, %%v6.s[3]                  #! 0xaaaabe371b20 = 0xaaaabe371b20;
(* smlal	v16.2d, v13.2s, v7.s[0]                   #! PC = 0xaaaabe371b24 *)
smlal	%%v16.2d, %%v13.2s, %%v7.s[0]                   #! 0xaaaabe371b24 = 0xaaaabe371b24;
(* smlal2	v16.2d, v13.4s, v7.s[2]                  #! PC = 0xaaaabe371b28 *)
smlal2	%%v16.2d, %%v13.4s, %%v7.s[2]                  #! 0xaaaabe371b28 = 0xaaaabe371b28;
(* and	v6.16b, v16.16b, v1.16b                     #! PC = 0xaaaabe371b2c *)
and %v6@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371b30 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v7.s[0]                   #! PC = 0xaaaabe371b34 *)
smlal	%%v16.2d, %%v14.2s, %%v7.s[0]                   #! 0xaaaabe371b34 = 0xaaaabe371b34;
(* smlal2	v16.2d, v14.4s, v7.s[2]                  #! PC = 0xaaaabe371b38 *)
smlal2	%%v16.2d, %%v14.4s, %%v7.s[2]                  #! 0xaaaabe371b38 = 0xaaaabe371b38;
(* and	v17.16b, v16.16b, v1.16b                    #! PC = 0xaaaabe371b3c *)
and %v17@uint64[2] %v16 %v1;
(* sshr	v7.2d, v16.2d, #30                         #! PC = 0xaaaabe371b40 *)
split %v7 %dc %v16 30;
(* shl	v17.2d, v17.2d, #32                         #! PC = 0xaaaabe371b44 *)
shls %dc %v17 %v17 [32, 32];
(* orr	v6.16b, v6.16b, v17.16b                     #! PC = 0xaaaabe371b48 *)
or %v6@uint64[2] %v6 %v17;
(* and	x7, x1, #0xfffff                            #! PC = 0xaaaabe371b4c *)
and x7@uint64 x1 0xfffff@uint64;
(* and	x8, x2, #0xfffff                            #! PC = 0xaaaabe371b50 *)
and x8@uint64 x2 0xfffff@uint64;
(* orr	x7, x7, #0xfffffe0000000000                 #! PC = 0xaaaabe371b54 *)
or x7@uint64 x7 0xfffffe0000000000@uint64;
(* orr	x8, x8, #0xc000000000000000                 #! PC = 0xaaaabe371b58 *)
or x8@uint64 x8 0xc000000000000000@uint64;
(* tst	x8, #0x1                                    #! PC = 0xaaaabe371b5c *)
spl dc x8_lo x8 1;
and ne@bit x8_lo 1@bit;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371b60 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371b64 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371b68 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371b6c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371b70 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371b74 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371b78 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371b7c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371b80 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371b84 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371b88 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371b8c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371b90 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371b94 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371b98 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371b9c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371ba0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371ba4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371ba8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371bac *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371bb0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371bb4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371bb8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371bbc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371bc0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371bc4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371bc8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371bcc *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371bd0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371bd4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371bd8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371bdc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371be0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371be4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371be8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371bec *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371bf0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371bf4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371bf8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371bfc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c00 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c04 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c08 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c0c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371c10 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371c14 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371c18 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371c1c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371c20 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c24 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c28 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c2c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c30 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371c34 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371c38 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371c3c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371c40 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371c44 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c48 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c4c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c50 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c54 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371c58 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371c5c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371c60 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371c64 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371c68 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c6c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c70 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c74 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c78 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371c7c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371c80 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371c84 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371c88 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371c8c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c90 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c94 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c98 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c9c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371ca0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371ca4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371ca8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371cac *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371cb0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371cb4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371cb8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371cbc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371cc0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371cc4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371cc8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371ccc *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371cd0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371cd4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371cd8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371cdc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371ce0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371ce4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371ce8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371cec *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371cf0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371cf4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371cf8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371cfc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d00 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d04 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d08 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d0c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371d10 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371d14 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371d18 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371d1c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371d20 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d24 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d28 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d2c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d30 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371d34 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371d38 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371d3c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371d40 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371d44 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d48 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d4c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d50 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d54 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371d58 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371d5c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371d60 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371d64 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371d68 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d6c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d70 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d74 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d78 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371d7c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371d80 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371d84 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371d88 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371d8c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d90 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d94 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d98 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d9c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371da0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371da4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371da8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371dac *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371db0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371db4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371db8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371dbc *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371dc0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371dc4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371dc8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371dcc *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371dd0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371dd4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371dd8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371ddc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371de0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371de4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371de8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371dec *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371df0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371df4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371df8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371dfc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371e00 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371e04 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371e08 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371e0c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371e10 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371e14 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371e18 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371e1c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371e20 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371e24 *)
add x3 x3 0x2@sint64;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371e28 *)
ssplit x8 dcL x8 1;
(* add	x12, x7, x6                                 #! PC = 0xaaaabe371e2c *)
add x12 x7 x6;
(* asr	x12, x12, #42                               #! PC = 0xaaaabe371e30 *)
ssplit x12 dcL x12 42;
(* add	x11, x7, #0x100, lsl #12                    #! PC = 0xaaaabe371e34 *)
add x11 x7 0x100@sint64, lsl;
(* lsl	x11, x11, #22                               #! PC = 0xaaaabe371e38 *)
split dcH x11 x11 (64-22); shl x11 x11 22;
(* asr	x11, x11, #43                               #! PC = 0xaaaabe371e3c *)
ssplit x11 dcL x11 43;
(* add	x14, x8, x6                                 #! PC = 0xaaaabe371e40 *)
add x14 x8 x6;
(* asr	x14, x14, #42                               #! PC = 0xaaaabe371e44 *)
ssplit x14 dcL x14 42;
(* add	x13, x8, #0x100, lsl #12                    #! PC = 0xaaaabe371e48 *)
add x13 x8 0x100@sint64, lsl;
(* lsl	x13, x13, #22                               #! PC = 0xaaaabe371e4c *)
split dcH x13 x13 (64-22); shl x13 x13 22;
(* asr	x13, x13, #43                               #! PC = 0xaaaabe371e50 *)
ssplit x13 dcL x13 43;
(* mul	x9, x11, x1                                 #! PC = 0xaaaabe371e54 *)
mull dcH x9 x11 x1;
(* madd	x9, x12, x2, x9                            #! PC = 0xaaaabe371e58 *)
mull dcH mul_tmp x12 x2;
adds dc x9 mul_tmp x9;
(* asr	x9, x9, #20                                 #! PC = 0xaaaabe371e5c *)
ssplit x9 dcL x9 20;
(* mul	x10, x13, x1                                #! PC = 0xaaaabe371e60 *)
mull dcH x10 x13 x1;
(* madd	x10, x14, x2, x10                          #! PC = 0xaaaabe371e64 *)
mull dcH mul_tmp x14 x2;
adds dc x10 mul_tmp x10;
(* asr	x2, x10, #20                                #! PC = 0xaaaabe371e68 *)
ssplit x2 dcL x10 20;
(* mov	x1, x9                                      #! PC = 0xaaaabe371e6c *)
mov x1 x9;
(* mov	w4, v3.s[0]                                 #! PC = 0xaaaabe371e70 *)
mov w4 v3.s[0];
(* mov	w27, v3.s[1]                                #! PC = 0xaaaabe371e74 *)
mov w27 v3.s[1];
(* add	x4, x4, x27, lsl #30                        #! PC = 0xaaaabe371e78 *)
add x4 x4 x27, lsl;
(* mov	w27, v4.s[0]                                #! PC = 0xaaaabe371e7c *)
mov w27 v4.s[0];
(* add	x4, x4, x27, lsl #60                        #! PC = 0xaaaabe371e80 *)
add x4 x4 x27, lsl;
(* add	x21, xzr, x27, lsr #4                       #! PC = 0xaaaabe371e84 *)
add	%%x21, xzr, %%x27, lsr #4                       #! 0xaaaabe371e84 = 0xaaaabe371e84;
(* mov	w27, v4.s[1]                                #! PC = 0xaaaabe371e88 *)
mov w27 v4.s[1];
(* add	x21, x21, x27, lsl #26                      #! PC = 0xaaaabe371e8c *)
add x21 x21 x27, lsl;
(* mov	w5, v3.s[2]                                 #! PC = 0xaaaabe371e90 *)
mov w5 v3.s[2];
(* mov	w27, v3.s[3]                                #! PC = 0xaaaabe371e94 *)
mov w27 v3.s[3];
(* add	x5, x5, x27, lsl #30                        #! PC = 0xaaaabe371e98 *)
add x5 x5 x27, lsl;
(* mov	w27, v4.s[2]                                #! PC = 0xaaaabe371e9c *)
mov w27 v4.s[2];
(* add	x5, x5, x27, lsl #60                        #! PC = 0xaaaabe371ea0 *)
add x5 x5 x27, lsl;
(* add	x22, xzr, x27, lsr #4                       #! PC = 0xaaaabe371ea4 *)
add	%%x22, xzr, %%x27, lsr #4                       #! 0xaaaabe371ea4 = 0xaaaabe371ea4;
(* mov	w27, v4.s[3]                                #! PC = 0xaaaabe371ea8 *)
mov w27 v4.s[3];
(* add	x22, x22, x27, lsl #26                      #! PC = 0xaaaabe371eac *)
add x22 x22 x27, lsl;
(* and	x7, x1, #0xfffff                            #! PC = 0xaaaabe371eb0 *)
and x7@uint64 x1 0xfffff@uint64;
(* and	x8, x2, #0xfffff                            #! PC = 0xaaaabe371eb4 *)
and x8@uint64 x2 0xfffff@uint64;
(* orr	x7, x7, #0xfffffe0000000000                 #! PC = 0xaaaabe371eb8 *)
or x7@uint64 x7 0xfffffe0000000000@uint64;
(* orr	x8, x8, #0xc000000000000000                 #! PC = 0xaaaabe371ebc *)
or x8@uint64 x8 0xc000000000000000@uint64;
(* tst	x8, #0x1                                    #! PC = 0xaaaabe371ec0 *)
spl dc x8_lo x8 1;
and ne@bit x8_lo 1@bit;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371ec4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371ec8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371ecc *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371ed0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371ed4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371ed8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371edc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371ee0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371ee4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371ee8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371eec *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371ef0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371ef4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371ef8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371efc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f00 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f04 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f08 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f0c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371f10 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371f14 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371f18 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371f1c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371f20 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f24 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f28 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f2c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f30 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371f34 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371f38 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371f3c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371f40 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371f44 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f48 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f4c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f50 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f54 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371f58 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371f5c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371f60 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371f64 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371f68 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f6c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f70 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f74 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f78 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371f7c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371f80 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371f84 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371f88 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371f8c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f90 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f94 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f98 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f9c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371fa0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371fa4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371fa8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371fac *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371fb0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371fb4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371fb8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371fbc *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371fc0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371fc4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371fc8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371fcc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371fd0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371fd4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371fd8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371fdc *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371fe0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371fe4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371fe8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371fec *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371ff0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371ff4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371ff8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371ffc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372000 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372004 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372008 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37200c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372010 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372014 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372018 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37201c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372020 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372024 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372028 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37202c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372030 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372034 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372038 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37203c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372040 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372044 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372048 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37204c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372050 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372054 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372058 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37205c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372060 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372064 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372068 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37206c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372070 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372074 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372078 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37207c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372080 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372084 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372088 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37208c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372090 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372094 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372098 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37209c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3720a0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3720a4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3720a8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3720ac *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3720b0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3720b4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3720b8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3720bc *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3720c0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3720c4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3720c8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3720cc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3720d0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3720d4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3720d8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3720dc *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3720e0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3720e4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3720e8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3720ec *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3720f0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3720f4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3720f8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3720fc *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372100 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372104 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372108 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37210c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372110 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372114 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372118 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37211c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372120 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372124 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372128 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37212c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372130 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372134 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372138 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37213c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372140 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372144 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372148 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37214c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372150 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372154 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372158 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37215c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372160 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372164 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372168 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37216c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372170 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372174 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372178 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37217c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372180 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372184 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372188 *)
add x3 x3 0x2@sint64;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37218c *)
ssplit x8 dcL x8 1;
(* add	x16, x7, x6                                 #! PC = 0xaaaabe372190 *)
add x16 x7 x6;
(* asr	x16, x16, #42                               #! PC = 0xaaaabe372194 *)
ssplit x16 dcL x16 42;
(* add	x15, x7, #0x100, lsl #12                    #! PC = 0xaaaabe372198 *)
add x15 x7 0x100@sint64, lsl;
(* lsl	x15, x15, #22                               #! PC = 0xaaaabe37219c *)
split dcH x15 x15 (64-22); shl x15 x15 22;
(* asr	x15, x15, #43                               #! PC = 0xaaaabe3721a0 *)
ssplit x15 dcL x15 43;
(* add	x20, x8, x6                                 #! PC = 0xaaaabe3721a4 *)
add x20 x8 x6;
(* asr	x20, x20, #42                               #! PC = 0xaaaabe3721a8 *)
ssplit x20 dcL x20 42;
(* add	x17, x8, #0x100, lsl #12                    #! PC = 0xaaaabe3721ac *)
add x17 x8 0x100@sint64, lsl;
(* lsl	x17, x17, #22                               #! PC = 0xaaaabe3721b0 *)
split dcH x17 x17 (64-22); shl x17 x17 22;
(* asr	x17, x17, #43                               #! PC = 0xaaaabe3721b4 *)
ssplit x17 dcL x17 43;
(* mul	x9, x15, x1                                 #! PC = 0xaaaabe3721b8 *)
mull dcH x9 x15 x1;
(* madd	x9, x16, x2, x9                            #! PC = 0xaaaabe3721bc *)
mull dcH mul_tmp x16 x2;
adds dc x9 mul_tmp x9;
(* asr	x9, x9, #20                                 #! PC = 0xaaaabe3721c0 *)
ssplit x9 dcL x9 20;
(* mul	x10, x17, x1                                #! PC = 0xaaaabe3721c4 *)
mull dcH x10 x17 x1;
(* madd	x10, x20, x2, x10                          #! PC = 0xaaaabe3721c8 *)
mull dcH mul_tmp x20 x2;
adds dc x10 mul_tmp x10;
(* asr	x2, x10, #20                                #! PC = 0xaaaabe3721cc *)
ssplit x2 dcL x10 20;
(* mov	x1, x9                                      #! PC = 0xaaaabe3721d0 *)
mov x1 x9;
(* mul	x9, x15, x11                                #! PC = 0xaaaabe3721d4 *)
mull dcH x9 x15 x11;
(* madd	x10, x16, x13, x9                          #! PC = 0xaaaabe3721d8 *)
mull dcH mul_tmp x16 x13;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x11                                #! PC = 0xaaaabe3721dc *)
mull dcH x9 x17 x11;
(* madd	x13, x20, x13, x9                          #! PC = 0xaaaabe3721e0 *)
mull dcH mul_tmp x20 x13;
adds dc x13 mul_tmp x9;
(* mov	x11, x10                                    #! PC = 0xaaaabe3721e4 *)
mov x11 x10;
(* mul	x9, x15, x12                                #! PC = 0xaaaabe3721e8 *)
mull dcH x9 x15 x12;
(* madd	x10, x16, x14, x9                          #! PC = 0xaaaabe3721ec *)
mull dcH mul_tmp x16 x14;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x12                                #! PC = 0xaaaabe3721f0 *)
mull dcH x9 x17 x12;
(* madd	x14, x20, x14, x9                          #! PC = 0xaaaabe3721f4 *)
mull dcH mul_tmp x20 x14;
adds dc x14 mul_tmp x9;
(* mov	x12, x10                                    #! PC = 0xaaaabe3721f8 *)
mov x12 x10;
(* mov	x9, #0x13                  	// #19          #! PC = 0xaaaabe3721fc *)
mov x9 0x13@uint64;
(* dup	v16.2d, x9                                  #! PC = 0xaaaabe372200 *)
mov %v16 [x9,x9];
(* smull	v17.2d, v13.2s, v8.s[0]                   #! PC = 0xaaaabe372204 *)
smull	%%v17.2d, %%v13.2s, %%v8.s[0]                   #! 0xaaaabe372204 = 0xaaaabe372204;
(* smlal2	v17.2d, v13.4s, v8.s[2]                  #! PC = 0xaaaabe372208 *)
smlal2	%%v17.2d, %%v13.4s, %%v8.s[2]                  #! 0xaaaabe372208 = 0xaaaabe372208;
(* mul	v19.4s, v17.4s, v15.4s                      #! PC = 0xaaaabe37220c *)
mul %v19 %v17 %v15;
(* and	v19.16b, v19.16b, v1.16b                    #! PC = 0xaaaabe372210 *)
and %v19@uint64[2] %v19 %v1;
(* uzp1	v19.4s, v19.4s, v19.4s                     #! PC = 0xaaaabe372214 *)
mov %v19 [%v19[0], %v19[2], %v19[0], %v19[2]];
(* smlsl	v17.2d, v19.2s, v16.s[0]                  #! PC = 0xaaaabe372218 *)
smlsl	%%v17.2d, %%v19.2s, %%v16.s[0]                  #! 0xaaaabe372218 = 0xaaaabe372218;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe37221c *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v8.s[0]                   #! PC = 0xaaaabe372220 *)
smlal	%%v17.2d, %%v14.2s, %%v8.s[0]                   #! 0xaaaabe372220 = 0xaaaabe372220;
(* smlal2	v17.2d, v14.4s, v8.s[2]                  #! PC = 0xaaaabe372224 *)
smlal2	%%v17.2d, %%v14.4s, %%v8.s[2]                  #! 0xaaaabe372224 = 0xaaaabe372224;
(* smlal	v17.2d, v13.2s, v8.s[1]                   #! PC = 0xaaaabe372228 *)
smlal	%%v17.2d, %%v13.2s, %%v8.s[1]                   #! 0xaaaabe372228 = 0xaaaabe372228;
(* smlal2	v17.2d, v13.4s, v8.s[3]                  #! PC = 0xaaaabe37222c *)
smlal2	%%v17.2d, %%v13.4s, %%v8.s[3]                  #! 0xaaaabe37222c = 0xaaaabe37222c;
(* mul	v20.4s, v17.4s, v15.4s                      #! PC = 0xaaaabe372230 *)
mul %v20 %v17 %v15;
(* and	v20.16b, v20.16b, v1.16b                    #! PC = 0xaaaabe372234 *)
and %v20@uint64[2] %v20 %v1;
(* uzp1	v20.4s, v20.4s, v20.4s                     #! PC = 0xaaaabe372238 *)
mov %v20 [%v20[0], %v20[2], %v20[0], %v20[2]];
(* smlsl	v17.2d, v20.2s, v16.s[0]                  #! PC = 0xaaaabe37223c *)
smlsl	%%v17.2d, %%v20.2s, %%v16.s[0]                  #! 0xaaaabe37223c = 0xaaaabe37223c;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe372240 *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v8.s[1]                   #! PC = 0xaaaabe372244 *)
smlal	%%v17.2d, %%v14.2s, %%v8.s[1]                   #! 0xaaaabe372244 = 0xaaaabe372244;
(* smlal2	v17.2d, v14.4s, v8.s[3]                  #! PC = 0xaaaabe372248 *)
smlal2	%%v17.2d, %%v14.4s, %%v8.s[3]                  #! 0xaaaabe372248 = 0xaaaabe372248;
(* smlal	v17.2d, v13.2s, v9.s[0]                   #! PC = 0xaaaabe37224c *)
smlal	%%v17.2d, %%v13.2s, %%v9.s[0]                   #! 0xaaaabe37224c = 0xaaaabe37224c;
(* smlal2	v17.2d, v13.4s, v9.s[2]                  #! PC = 0xaaaabe372250 *)
smlal2	%%v17.2d, %%v13.4s, %%v9.s[2]                  #! 0xaaaabe372250 = 0xaaaabe372250;
(* and	v8.16b, v17.16b, v1.16b                     #! PC = 0xaaaabe372254 *)
and %v8@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe372258 *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v9.s[0]                   #! PC = 0xaaaabe37225c *)
smlal	%%v17.2d, %%v14.2s, %%v9.s[0]                   #! 0xaaaabe37225c = 0xaaaabe37225c;
(* smlal2	v17.2d, v14.4s, v9.s[2]                  #! PC = 0xaaaabe372260 *)
smlal2	%%v17.2d, %%v14.4s, %%v9.s[2]                  #! 0xaaaabe372260 = 0xaaaabe372260;
(* smlal	v17.2d, v13.2s, v9.s[1]                   #! PC = 0xaaaabe372264 *)
smlal	%%v17.2d, %%v13.2s, %%v9.s[1]                   #! 0xaaaabe372264 = 0xaaaabe372264;
(* smlal2	v17.2d, v13.4s, v9.s[3]                  #! PC = 0xaaaabe372268 *)
smlal2	%%v17.2d, %%v13.4s, %%v9.s[3]                  #! 0xaaaabe372268 = 0xaaaabe372268;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe37226c *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe372270 *)
split %v17 %dc %v17 30;
(* sli	v8.2d, v18.2d, #32                          #! PC = 0xaaaabe372274 *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v8 %v8 32; or %v8@uint64[2] %slih %v8;
(* smlal	v17.2d, v14.2s, v9.s[1]                   #! PC = 0xaaaabe372278 *)
smlal	%%v17.2d, %%v14.2s, %%v9.s[1]                   #! 0xaaaabe372278 = 0xaaaabe372278;
(* smlal2	v17.2d, v14.4s, v9.s[3]                  #! PC = 0xaaaabe37227c *)
smlal2	%%v17.2d, %%v14.4s, %%v9.s[3]                  #! 0xaaaabe37227c = 0xaaaabe37227c;
(* smlal	v17.2d, v13.2s, v10.s[0]                  #! PC = 0xaaaabe372280 *)
smlal	%%v17.2d, %%v13.2s, %%v10.s[0]                  #! 0xaaaabe372280 = 0xaaaabe372280;
(* smlal2	v17.2d, v13.4s, v10.s[2]                 #! PC = 0xaaaabe372284 *)
smlal2	%%v17.2d, %%v13.4s, %%v10.s[2]                 #! 0xaaaabe372284 = 0xaaaabe372284;
(* and	v9.16b, v17.16b, v1.16b                     #! PC = 0xaaaabe372288 *)
and %v9@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe37228c *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v10.s[0]                  #! PC = 0xaaaabe372290 *)
smlal	%%v17.2d, %%v14.2s, %%v10.s[0]                  #! 0xaaaabe372290 = 0xaaaabe372290;
(* smlal2	v17.2d, v14.4s, v10.s[2]                 #! PC = 0xaaaabe372294 *)
smlal2	%%v17.2d, %%v14.4s, %%v10.s[2]                 #! 0xaaaabe372294 = 0xaaaabe372294;
(* smlal	v17.2d, v13.2s, v10.s[1]                  #! PC = 0xaaaabe372298 *)
smlal	%%v17.2d, %%v13.2s, %%v10.s[1]                  #! 0xaaaabe372298 = 0xaaaabe372298;
(* smlal2	v17.2d, v13.4s, v10.s[3]                 #! PC = 0xaaaabe37229c *)
smlal2	%%v17.2d, %%v13.4s, %%v10.s[3]                 #! 0xaaaabe37229c = 0xaaaabe37229c;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe3722a0 *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3722a4 *)
split %v17 %dc %v17 30;
(* sli	v9.2d, v18.2d, #32                          #! PC = 0xaaaabe3722a8 *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v9 %v9 32; or %v9@uint64[2] %slih %v9;
(* smlal	v17.2d, v14.2s, v10.s[1]                  #! PC = 0xaaaabe3722ac *)
smlal	%%v17.2d, %%v14.2s, %%v10.s[1]                  #! 0xaaaabe3722ac = 0xaaaabe3722ac;
(* smlal2	v17.2d, v14.4s, v10.s[3]                 #! PC = 0xaaaabe3722b0 *)
smlal2	%%v17.2d, %%v14.4s, %%v10.s[3]                 #! 0xaaaabe3722b0 = 0xaaaabe3722b0;
(* smlal	v17.2d, v13.2s, v11.s[0]                  #! PC = 0xaaaabe3722b4 *)
smlal	%%v17.2d, %%v13.2s, %%v11.s[0]                  #! 0xaaaabe3722b4 = 0xaaaabe3722b4;
(* smlal2	v17.2d, v13.4s, v11.s[2]                 #! PC = 0xaaaabe3722b8 *)
smlal2	%%v17.2d, %%v13.4s, %%v11.s[2]                 #! 0xaaaabe3722b8 = 0xaaaabe3722b8;
(* and	v10.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe3722bc *)
and %v10@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3722c0 *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v11.s[0]                  #! PC = 0xaaaabe3722c4 *)
smlal	%%v17.2d, %%v14.2s, %%v11.s[0]                  #! 0xaaaabe3722c4 = 0xaaaabe3722c4;
(* smlal2	v17.2d, v14.4s, v11.s[2]                 #! PC = 0xaaaabe3722c8 *)
smlal2	%%v17.2d, %%v14.4s, %%v11.s[2]                 #! 0xaaaabe3722c8 = 0xaaaabe3722c8;
(* smlal	v17.2d, v13.2s, v11.s[1]                  #! PC = 0xaaaabe3722cc *)
smlal	%%v17.2d, %%v13.2s, %%v11.s[1]                  #! 0xaaaabe3722cc = 0xaaaabe3722cc;
(* smlal2	v17.2d, v13.4s, v11.s[3]                 #! PC = 0xaaaabe3722d0 *)
smlal2	%%v17.2d, %%v13.4s, %%v11.s[3]                 #! 0xaaaabe3722d0 = 0xaaaabe3722d0;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe3722d4 *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3722d8 *)
split %v17 %dc %v17 30;
(* sli	v10.2d, v18.2d, #32                         #! PC = 0xaaaabe3722dc *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v10 %v10 32; or %v10@uint64[2] %slih %v10;
(* smlal	v17.2d, v14.2s, v11.s[1]                  #! PC = 0xaaaabe3722e0 *)
smlal	%%v17.2d, %%v14.2s, %%v11.s[1]                  #! 0xaaaabe3722e0 = 0xaaaabe3722e0;
(* smlal2	v17.2d, v14.4s, v11.s[3]                 #! PC = 0xaaaabe3722e4 *)
smlal2	%%v17.2d, %%v14.4s, %%v11.s[3]                 #! 0xaaaabe3722e4 = 0xaaaabe3722e4;
(* smlal	v17.2d, v13.2s, v12.s[0]                  #! PC = 0xaaaabe3722e8 *)
smlal	%%v17.2d, %%v13.2s, %%v12.s[0]                  #! 0xaaaabe3722e8 = 0xaaaabe3722e8;
(* smlal2	v17.2d, v13.4s, v12.s[2]                 #! PC = 0xaaaabe3722ec *)
smlal2	%%v17.2d, %%v13.4s, %%v12.s[2]                 #! 0xaaaabe3722ec = 0xaaaabe3722ec;
(* ushll	v19.2d, v19.2s, #15                       #! PC = 0xaaaabe3722f0 *)
ushll	%%v19.2d, %%v19.2s, #15                       #! 0xaaaabe3722f0 = 0xaaaabe3722f0;
(* add	v17.2d, v17.2d, v19.2d                      #! PC = 0xaaaabe3722f4 *)
add	%%v17.2d, %%v17.2d, %%v19.2d                      #! 0xaaaabe3722f4 = 0xaaaabe3722f4;
(* and	v11.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe3722f8 *)
and %v11@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3722fc *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v12.s[0]                  #! PC = 0xaaaabe372300 *)
smlal	%%v17.2d, %%v14.2s, %%v12.s[0]                  #! 0xaaaabe372300 = 0xaaaabe372300;
(* smlal2	v17.2d, v14.4s, v12.s[2]                 #! PC = 0xaaaabe372304 *)
smlal2	%%v17.2d, %%v14.4s, %%v12.s[2]                 #! 0xaaaabe372304 = 0xaaaabe372304;
(* ushll	v20.2d, v20.2s, #15                       #! PC = 0xaaaabe372308 *)
ushll	%%v20.2d, %%v20.2s, #15                       #! 0xaaaabe372308 = 0xaaaabe372308;
(* add	v17.2d, v17.2d, v20.2d                      #! PC = 0xaaaabe37230c *)
add	%%v17.2d, %%v17.2d, %%v20.2d                      #! 0xaaaabe37230c = 0xaaaabe37230c;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe372310 *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v12.2d, v17.2d, #30                        #! PC = 0xaaaabe372314 *)
split %v12 %dc %v17 30;
(* sli	v11.2d, v18.2d, #32                         #! PC = 0xaaaabe372318 *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v11 %v11 32; or %v11@uint64[2] %slih %v11;
(* sshr	v18.2d, v12.2d, #15                        #! PC = 0xaaaabe37231c *)
split %v18 %dc %v12 15;
(* shl	v17.2d, v18.2d, #15                         #! PC = 0xaaaabe372320 *)
shls %dc %v17 %v18 [15, 15];
(* sub	v12.2d, v12.2d, v17.2d                      #! PC = 0xaaaabe372324 *)
sub	%%v12.2d, %%v12.2d, %%v17.2d                      #! 0xaaaabe372324 = 0xaaaabe372324;
(* mla	v8.4s, v18.4s, v16.4s                       #! PC = 0xaaaabe372328 *)
mull %dc %mla %v18 %v16; add %v8 %v8 %mla;
(* and	x7, x1, #0xfffff                            #! PC = 0xaaaabe37232c *)
and x7@uint64 x1 0xfffff@uint64;
(* and	x8, x2, #0xfffff                            #! PC = 0xaaaabe372330 *)
and x8@uint64 x2 0xfffff@uint64;
(* orr	x7, x7, #0xfffffe0000000000                 #! PC = 0xaaaabe372334 *)
or x7@uint64 x7 0xfffffe0000000000@uint64;
(* orr	x8, x8, #0xc000000000000000                 #! PC = 0xaaaabe372338 *)
or x8@uint64 x8 0xc000000000000000@uint64;
(* tst	x8, #0x1                                    #! PC = 0xaaaabe37233c *)
spl dc x8_lo x8 1;
and ne@bit x8_lo 1@bit;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372340 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372344 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372348 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37234c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372350 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372354 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372358 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37235c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372360 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372364 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372368 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37236c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372370 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372374 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372378 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37237c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372380 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372384 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372388 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37238c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372390 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372394 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372398 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37239c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3723a0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3723a4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3723a8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3723ac *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3723b0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3723b4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3723b8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3723bc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3723c0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3723c4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3723c8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3723cc *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3723d0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3723d4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3723d8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3723dc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3723e0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3723e4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3723e8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3723ec *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3723f0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3723f4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3723f8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3723fc *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372400 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372404 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372408 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37240c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372410 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372414 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372418 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37241c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372420 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372424 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372428 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37242c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372430 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372434 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372438 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37243c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372440 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372444 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372448 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37244c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372450 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372454 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372458 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37245c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372460 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372464 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372468 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37246c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372470 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372474 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372478 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37247c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372480 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372484 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372488 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37248c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372490 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372494 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372498 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37249c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3724a0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3724a4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3724a8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3724ac *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3724b0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3724b4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3724b8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3724bc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3724c0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3724c4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3724c8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3724cc *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3724d0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3724d4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3724d8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3724dc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3724e0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3724e4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3724e8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3724ec *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3724f0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3724f4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3724f8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3724fc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372500 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372504 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372508 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37250c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372510 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372514 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372518 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37251c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372520 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372524 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372528 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37252c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372530 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372534 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372538 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37253c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372540 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372544 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372548 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37254c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372550 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372554 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372558 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37255c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372560 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372564 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372568 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37256c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372570 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372574 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372578 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37257c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372580 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372584 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372588 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37258c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372590 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372594 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372598 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37259c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3725a0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3725a4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3725a8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3725ac *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3725b0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3725b4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3725b8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3725bc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3725c0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3725c4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3725c8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3725cc *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3725d0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3725d4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3725d8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3725dc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3725e0 *)
add x3 x3 0x2@sint64;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3725e4 *)
ssplit x8 dcL x8 1;
(* add	x16, x7, x6                                 #! PC = 0xaaaabe3725e8 *)
add x16 x7 x6;
(* asr	x16, x16, #42                               #! PC = 0xaaaabe3725ec *)
ssplit x16 dcL x16 42;
(* add	x15, x7, #0x100, lsl #12                    #! PC = 0xaaaabe3725f0 *)
add x15 x7 0x100@sint64, lsl;
(* lsl	x15, x15, #22                               #! PC = 0xaaaabe3725f4 *)
split dcH x15 x15 (64-22); shl x15 x15 22;
(* asr	x15, x15, #43                               #! PC = 0xaaaabe3725f8 *)
ssplit x15 dcL x15 43;
(* add	x20, x8, x6                                 #! PC = 0xaaaabe3725fc *)
add x20 x8 x6;
(* asr	x20, x20, #42                               #! PC = 0xaaaabe372600 *)
ssplit x20 dcL x20 42;
(* add	x17, x8, #0x100, lsl #12                    #! PC = 0xaaaabe372604 *)
add x17 x8 0x100@sint64, lsl;
(* lsl	x17, x17, #22                               #! PC = 0xaaaabe372608 *)
split dcH x17 x17 (64-22); shl x17 x17 22;
(* asr	x17, x17, #43                               #! PC = 0xaaaabe37260c *)
ssplit x17 dcL x17 43;
(* mul	x9, x15, x11                                #! PC = 0xaaaabe372610 *)
mull dcH x9 x15 x11;
(* madd	x10, x16, x13, x9                          #! PC = 0xaaaabe372614 *)
mull dcH mul_tmp x16 x13;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x11                                #! PC = 0xaaaabe372618 *)
mull dcH x9 x17 x11;
(* madd	x13, x20, x13, x9                          #! PC = 0xaaaabe37261c *)
mull dcH mul_tmp x20 x13;
adds dc x13 mul_tmp x9;
(* mov	x11, x10                                    #! PC = 0xaaaabe372620 *)
mov x11 x10;
(* mul	x9, x15, x12                                #! PC = 0xaaaabe372624 *)
mull dcH x9 x15 x12;
(* madd	x10, x16, x14, x9                          #! PC = 0xaaaabe372628 *)
mull dcH mul_tmp x16 x14;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x12                                #! PC = 0xaaaabe37262c *)
mull dcH x9 x17 x12;
(* madd	x14, x20, x14, x9                          #! PC = 0xaaaabe372630 *)
mull dcH mul_tmp x20 x14;
adds dc x14 mul_tmp x9;
(* mov	x12, x10                                    #! PC = 0xaaaabe372634 *)
mov x12 x10;
(* subs	x19, x19, #0x1                             #! PC = 0xaaaabe372638 *)
subc carry x19 x19 0x1@uint64;
(* #cbnz	x19, 0xaaaabe371960 <Lbig_loop>           #! PC = 0xaaaabe37263c *)
#cbnz	%%x19, 0xaaaabe371960 <Lbig_loop>           #! 0xaaaabe37263c = 0xaaaabe37263c;
(* mov	v16.d[0], x11                               #! PC = 0xaaaabe371960 *)
mov %v16 [x11, %v16[1]];
(* mov	v16.d[1], x13                               #! PC = 0xaaaabe371964 *)
mov %v16 [%v16[0], x13];
(* mov	v17.d[0], x12                               #! PC = 0xaaaabe371968 *)
mov %v17 [x12, %v17[1]];
(* mov	v17.d[1], x14                               #! PC = 0xaaaabe37196c *)
mov %v17 [%v17[0], x14];
(* uzp1	v13.4s, v16.4s, v17.4s                     #! PC = 0xaaaabe371970 *)
mov %v13 [%v16[0], %v16[2], %v17[0], %v17[2]];
(* and	v13.16b, v13.16b, v2.16b                    #! PC = 0xaaaabe371974 *)
and %v13@uint64[2] %v13 %v2;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371978 *)
split %v16 %dc %v16 30;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe37197c *)
split %v17 %dc %v17 30;
(* uzp1	v14.4s, v16.4s, v17.4s                     #! PC = 0xaaaabe371980 *)
mov %v14 [%v16[0], %v16[2], %v17[0], %v17[2]];
(* cmp	x11, xzr                                    #! PC = 0xaaaabe371984 *)
subc zero dc 0@uint64 x11;
(* csetm	x23, mi	// mi = first                     #! PC = 0xaaaabe371988 *)
csetm	%%x23, mi	// mi = first                     #! 0xaaaabe371988 = 0xaaaabe371988;
(* cneg	x11, x11, mi	// mi = first                 #! PC = 0xaaaabe37198c *)
cneg	%%x11, %%x11, mi	// mi = first                 #! 0xaaaabe37198c = 0xaaaabe37198c;
(* cmp	x12, xzr                                    #! PC = 0xaaaabe371990 *)
subc zero dc 0@uint64 x12;
(* csetm	x24, mi	// mi = first                     #! PC = 0xaaaabe371994 *)
csetm	%%x24, mi	// mi = first                     #! 0xaaaabe371994 = 0xaaaabe371994;
(* cneg	x12, x12, mi	// mi = first                 #! PC = 0xaaaabe371998 *)
cneg	%%x12, %%x12, mi	// mi = first                 #! 0xaaaabe371998 = 0xaaaabe371998;
(* cmp	x13, xzr                                    #! PC = 0xaaaabe37199c *)
subc zero dc 0@uint64 x13;
(* csetm	x25, mi	// mi = first                     #! PC = 0xaaaabe3719a0 *)
csetm	%%x25, mi	// mi = first                     #! 0xaaaabe3719a0 = 0xaaaabe3719a0;
(* cneg	x13, x13, mi	// mi = first                 #! PC = 0xaaaabe3719a4 *)
cneg	%%x13, %%x13, mi	// mi = first                 #! 0xaaaabe3719a4 = 0xaaaabe3719a4;
(* cmp	x14, xzr                                    #! PC = 0xaaaabe3719a8 *)
subc zero dc 0@uint64 x14;
(* csetm	x26, mi	// mi = first                     #! PC = 0xaaaabe3719ac *)
csetm	%%x26, mi	// mi = first                     #! 0xaaaabe3719ac = 0xaaaabe3719ac;
(* cneg	x14, x14, mi	// mi = first                 #! PC = 0xaaaabe3719b0 *)
cneg	%%x14, %%x14, mi	// mi = first                 #! 0xaaaabe3719b0 = 0xaaaabe3719b0;
(* and	x27, x11, x23                               #! PC = 0xaaaabe3719b4 *)
and x27@uint64 x11 x23;
(* and	x28, x12, x24                               #! PC = 0xaaaabe3719b8 *)
and x28@uint64 x12 x24;
(* add	x15, x27, x28                               #! PC = 0xaaaabe3719bc *)
add x15 x27 x28;
(* eor	x27, x4, x23                                #! PC = 0xaaaabe3719c0 *)
xor x27@uint64 x4 x23;
(* mul	x9, x27, x11                                #! PC = 0xaaaabe3719c4 *)
mull dcH x9 x27 x11;
(* umulh	x10, x27, x11                             #! PC = 0xaaaabe3719c8 *)
mull x10 dcL x27 x11;
(* adds	x15, x9, x15                               #! PC = 0xaaaabe3719cc *)
adds carry x15 x9 x15;
(* adc	x16, x10, xzr                               #! PC = 0xaaaabe3719d0 *)
adc x16 x10 0@uint64 carry;
(* eor	x27, x21, x23                               #! PC = 0xaaaabe3719d4 *)
xor x27@uint64 x21 x23;
(* mul	x9, x27, x11                                #! PC = 0xaaaabe3719d8 *)
mull dcH x9 x27 x11;
(* add	x16, x16, x9                                #! PC = 0xaaaabe3719dc *)
add x16 x16 x9;
(* eor	x27, x5, x24                                #! PC = 0xaaaabe3719e0 *)
xor x27@uint64 x5 x24;
(* mul	x9, x27, x12                                #! PC = 0xaaaabe3719e4 *)
mull dcH x9 x27 x12;
(* umulh	x10, x27, x12                             #! PC = 0xaaaabe3719e8 *)
mull x10 dcL x27 x12;
(* adds	x15, x9, x15                               #! PC = 0xaaaabe3719ec *)
adds carry x15 x9 x15;
(* adc	x16, x10, x16                               #! PC = 0xaaaabe3719f0 *)
adc x16 x10 x16 carry;
(* eor	x27, x22, x24                               #! PC = 0xaaaabe3719f4 *)
xor x27@uint64 x22 x24;
(* mul	x9, x27, x12                                #! PC = 0xaaaabe3719f8 *)
mull dcH x9 x27 x12;
(* add	x16, x16, x9                                #! PC = 0xaaaabe3719fc *)
add x16 x16 x9;
(* extr	x1, x16, x15, #60                          #! PC = 0xaaaabe371a00 *)
spl dc extr_H x16 60; spl extr_L dc x15 60; join x1 extr_H extr_L;
(* and	x27, x13, x25                               #! PC = 0xaaaabe371a04 *)
and x27@uint64 x13 x25;
(* and	x28, x14, x26                               #! PC = 0xaaaabe371a08 *)
and x28@uint64 x14 x26;
(* add	x17, x27, x28                               #! PC = 0xaaaabe371a0c *)
add x17 x27 x28;
(* eor	x27, x4, x25                                #! PC = 0xaaaabe371a10 *)
xor x27@uint64 x4 x25;
(* mul	x9, x27, x13                                #! PC = 0xaaaabe371a14 *)
mull dcH x9 x27 x13;
(* umulh	x10, x27, x13                             #! PC = 0xaaaabe371a18 *)
mull x10 dcL x27 x13;
(* adds	x17, x9, x17                               #! PC = 0xaaaabe371a1c *)
adds carry x17 x9 x17;
(* adc	x20, x10, xzr                               #! PC = 0xaaaabe371a20 *)
adc x20 x10 0@uint64 carry;
(* eor	x27, x21, x25                               #! PC = 0xaaaabe371a24 *)
xor x27@uint64 x21 x25;
(* mul	x9, x27, x13                                #! PC = 0xaaaabe371a28 *)
mull dcH x9 x27 x13;
(* add	x20, x20, x9                                #! PC = 0xaaaabe371a2c *)
add x20 x20 x9;
(* eor	x27, x5, x26                                #! PC = 0xaaaabe371a30 *)
xor x27@uint64 x5 x26;
(* mul	x9, x27, x14                                #! PC = 0xaaaabe371a34 *)
mull dcH x9 x27 x14;
(* umulh	x10, x27, x14                             #! PC = 0xaaaabe371a38 *)
mull x10 dcL x27 x14;
(* adds	x17, x9, x17                               #! PC = 0xaaaabe371a3c *)
adds carry x17 x9 x17;
(* adc	x20, x10, x20                               #! PC = 0xaaaabe371a40 *)
adc x20 x10 x20 carry;
(* eor	x27, x22, x26                               #! PC = 0xaaaabe371a44 *)
xor x27@uint64 x22 x26;
(* mul	x9, x27, x14                                #! PC = 0xaaaabe371a48 *)
mull dcH x9 x27 x14;
(* add	x20, x20, x9                                #! PC = 0xaaaabe371a4c *)
add x20 x20 x9;
(* extr	x2, x20, x17, #60                          #! PC = 0xaaaabe371a50 *)
spl dc extr_H x20 60; spl extr_L dc x17 60; join x2 extr_H extr_L;
(* smull	v16.2d, v13.2s, v3.s[0]                   #! PC = 0xaaaabe371a54 *)
smull	%%v16.2d, %%v13.2s, %%v3.s[0]                   #! 0xaaaabe371a54 = 0xaaaabe371a54;
(* smlal2	v16.2d, v13.4s, v3.s[2]                  #! PC = 0xaaaabe371a58 *)
smlal2	%%v16.2d, %%v13.4s, %%v3.s[2]                  #! 0xaaaabe371a58 = 0xaaaabe371a58;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371a5c *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v3.s[0]                   #! PC = 0xaaaabe371a60 *)
smlal	%%v16.2d, %%v14.2s, %%v3.s[0]                   #! 0xaaaabe371a60 = 0xaaaabe371a60;
(* smlal2	v16.2d, v14.4s, v3.s[2]                  #! PC = 0xaaaabe371a64 *)
smlal2	%%v16.2d, %%v14.4s, %%v3.s[2]                  #! 0xaaaabe371a64 = 0xaaaabe371a64;
(* smlal	v16.2d, v13.2s, v3.s[1]                   #! PC = 0xaaaabe371a68 *)
smlal	%%v16.2d, %%v13.2s, %%v3.s[1]                   #! 0xaaaabe371a68 = 0xaaaabe371a68;
(* smlal2	v16.2d, v13.4s, v3.s[3]                  #! PC = 0xaaaabe371a6c *)
smlal2	%%v16.2d, %%v13.4s, %%v3.s[3]                  #! 0xaaaabe371a6c = 0xaaaabe371a6c;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371a70 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v3.s[1]                   #! PC = 0xaaaabe371a74 *)
smlal	%%v16.2d, %%v14.2s, %%v3.s[1]                   #! 0xaaaabe371a74 = 0xaaaabe371a74;
(* smlal2	v16.2d, v14.4s, v3.s[3]                  #! PC = 0xaaaabe371a78 *)
smlal2	%%v16.2d, %%v14.4s, %%v3.s[3]                  #! 0xaaaabe371a78 = 0xaaaabe371a78;
(* smlal	v16.2d, v13.2s, v4.s[0]                   #! PC = 0xaaaabe371a7c *)
smlal	%%v16.2d, %%v13.2s, %%v4.s[0]                   #! 0xaaaabe371a7c = 0xaaaabe371a7c;
(* smlal2	v16.2d, v13.4s, v4.s[2]                  #! PC = 0xaaaabe371a80 *)
smlal2	%%v16.2d, %%v13.4s, %%v4.s[2]                  #! 0xaaaabe371a80 = 0xaaaabe371a80;
(* and	v3.16b, v16.16b, v1.16b                     #! PC = 0xaaaabe371a84 *)
and %v3@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371a88 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v4.s[0]                   #! PC = 0xaaaabe371a8c *)
smlal	%%v16.2d, %%v14.2s, %%v4.s[0]                   #! 0xaaaabe371a8c = 0xaaaabe371a8c;
(* smlal2	v16.2d, v14.4s, v4.s[2]                  #! PC = 0xaaaabe371a90 *)
smlal2	%%v16.2d, %%v14.4s, %%v4.s[2]                  #! 0xaaaabe371a90 = 0xaaaabe371a90;
(* smlal	v16.2d, v13.2s, v4.s[1]                   #! PC = 0xaaaabe371a94 *)
smlal	%%v16.2d, %%v13.2s, %%v4.s[1]                   #! 0xaaaabe371a94 = 0xaaaabe371a94;
(* smlal2	v16.2d, v13.4s, v4.s[3]                  #! PC = 0xaaaabe371a98 *)
smlal2	%%v16.2d, %%v13.4s, %%v4.s[3]                  #! 0xaaaabe371a98 = 0xaaaabe371a98;
(* and	v17.16b, v16.16b, v1.16b                    #! PC = 0xaaaabe371a9c *)
and %v17@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371aa0 *)
split %v16 %dc %v16 30;
(* shl	v17.2d, v17.2d, #32                         #! PC = 0xaaaabe371aa4 *)
shls %dc %v17 %v17 [32, 32];
(* orr	v3.16b, v3.16b, v17.16b                     #! PC = 0xaaaabe371aa8 *)
or %v3@uint64[2] %v3 %v17;
(* smlal	v16.2d, v14.2s, v4.s[1]                   #! PC = 0xaaaabe371aac *)
smlal	%%v16.2d, %%v14.2s, %%v4.s[1]                   #! 0xaaaabe371aac = 0xaaaabe371aac;
(* smlal2	v16.2d, v14.4s, v4.s[3]                  #! PC = 0xaaaabe371ab0 *)
smlal2	%%v16.2d, %%v14.4s, %%v4.s[3]                  #! 0xaaaabe371ab0 = 0xaaaabe371ab0;
(* smlal	v16.2d, v13.2s, v5.s[0]                   #! PC = 0xaaaabe371ab4 *)
smlal	%%v16.2d, %%v13.2s, %%v5.s[0]                   #! 0xaaaabe371ab4 = 0xaaaabe371ab4;
(* smlal2	v16.2d, v13.4s, v5.s[2]                  #! PC = 0xaaaabe371ab8 *)
smlal2	%%v16.2d, %%v13.4s, %%v5.s[2]                  #! 0xaaaabe371ab8 = 0xaaaabe371ab8;
(* and	v4.16b, v16.16b, v1.16b                     #! PC = 0xaaaabe371abc *)
and %v4@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371ac0 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v5.s[0]                   #! PC = 0xaaaabe371ac4 *)
smlal	%%v16.2d, %%v14.2s, %%v5.s[0]                   #! 0xaaaabe371ac4 = 0xaaaabe371ac4;
(* smlal2	v16.2d, v14.4s, v5.s[2]                  #! PC = 0xaaaabe371ac8 *)
smlal2	%%v16.2d, %%v14.4s, %%v5.s[2]                  #! 0xaaaabe371ac8 = 0xaaaabe371ac8;
(* smlal	v16.2d, v13.2s, v5.s[1]                   #! PC = 0xaaaabe371acc *)
smlal	%%v16.2d, %%v13.2s, %%v5.s[1]                   #! 0xaaaabe371acc = 0xaaaabe371acc;
(* smlal2	v16.2d, v13.4s, v5.s[3]                  #! PC = 0xaaaabe371ad0 *)
smlal2	%%v16.2d, %%v13.4s, %%v5.s[3]                  #! 0xaaaabe371ad0 = 0xaaaabe371ad0;
(* and	v17.16b, v16.16b, v1.16b                    #! PC = 0xaaaabe371ad4 *)
and %v17@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371ad8 *)
split %v16 %dc %v16 30;
(* shl	v17.2d, v17.2d, #32                         #! PC = 0xaaaabe371adc *)
shls %dc %v17 %v17 [32, 32];
(* orr	v4.16b, v4.16b, v17.16b                     #! PC = 0xaaaabe371ae0 *)
or %v4@uint64[2] %v4 %v17;
(* smlal	v16.2d, v14.2s, v5.s[1]                   #! PC = 0xaaaabe371ae4 *)
smlal	%%v16.2d, %%v14.2s, %%v5.s[1]                   #! 0xaaaabe371ae4 = 0xaaaabe371ae4;
(* smlal2	v16.2d, v14.4s, v5.s[3]                  #! PC = 0xaaaabe371ae8 *)
smlal2	%%v16.2d, %%v14.4s, %%v5.s[3]                  #! 0xaaaabe371ae8 = 0xaaaabe371ae8;
(* smlal	v16.2d, v13.2s, v6.s[0]                   #! PC = 0xaaaabe371aec *)
smlal	%%v16.2d, %%v13.2s, %%v6.s[0]                   #! 0xaaaabe371aec = 0xaaaabe371aec;
(* smlal2	v16.2d, v13.4s, v6.s[2]                  #! PC = 0xaaaabe371af0 *)
smlal2	%%v16.2d, %%v13.4s, %%v6.s[2]                  #! 0xaaaabe371af0 = 0xaaaabe371af0;
(* and	v5.16b, v16.16b, v1.16b                     #! PC = 0xaaaabe371af4 *)
and %v5@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371af8 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v6.s[0]                   #! PC = 0xaaaabe371afc *)
smlal	%%v16.2d, %%v14.2s, %%v6.s[0]                   #! 0xaaaabe371afc = 0xaaaabe371afc;
(* smlal2	v16.2d, v14.4s, v6.s[2]                  #! PC = 0xaaaabe371b00 *)
smlal2	%%v16.2d, %%v14.4s, %%v6.s[2]                  #! 0xaaaabe371b00 = 0xaaaabe371b00;
(* smlal	v16.2d, v13.2s, v6.s[1]                   #! PC = 0xaaaabe371b04 *)
smlal	%%v16.2d, %%v13.2s, %%v6.s[1]                   #! 0xaaaabe371b04 = 0xaaaabe371b04;
(* smlal2	v16.2d, v13.4s, v6.s[3]                  #! PC = 0xaaaabe371b08 *)
smlal2	%%v16.2d, %%v13.4s, %%v6.s[3]                  #! 0xaaaabe371b08 = 0xaaaabe371b08;
(* and	v17.16b, v16.16b, v1.16b                    #! PC = 0xaaaabe371b0c *)
and %v17@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371b10 *)
split %v16 %dc %v16 30;
(* shl	v17.2d, v17.2d, #32                         #! PC = 0xaaaabe371b14 *)
shls %dc %v17 %v17 [32, 32];
(* orr	v5.16b, v5.16b, v17.16b                     #! PC = 0xaaaabe371b18 *)
or %v5@uint64[2] %v5 %v17;
(* smlal	v16.2d, v14.2s, v6.s[1]                   #! PC = 0xaaaabe371b1c *)
smlal	%%v16.2d, %%v14.2s, %%v6.s[1]                   #! 0xaaaabe371b1c = 0xaaaabe371b1c;
(* smlal2	v16.2d, v14.4s, v6.s[3]                  #! PC = 0xaaaabe371b20 *)
smlal2	%%v16.2d, %%v14.4s, %%v6.s[3]                  #! 0xaaaabe371b20 = 0xaaaabe371b20;
(* smlal	v16.2d, v13.2s, v7.s[0]                   #! PC = 0xaaaabe371b24 *)
smlal	%%v16.2d, %%v13.2s, %%v7.s[0]                   #! 0xaaaabe371b24 = 0xaaaabe371b24;
(* smlal2	v16.2d, v13.4s, v7.s[2]                  #! PC = 0xaaaabe371b28 *)
smlal2	%%v16.2d, %%v13.4s, %%v7.s[2]                  #! 0xaaaabe371b28 = 0xaaaabe371b28;
(* and	v6.16b, v16.16b, v1.16b                     #! PC = 0xaaaabe371b2c *)
and %v6@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371b30 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v7.s[0]                   #! PC = 0xaaaabe371b34 *)
smlal	%%v16.2d, %%v14.2s, %%v7.s[0]                   #! 0xaaaabe371b34 = 0xaaaabe371b34;
(* smlal2	v16.2d, v14.4s, v7.s[2]                  #! PC = 0xaaaabe371b38 *)
smlal2	%%v16.2d, %%v14.4s, %%v7.s[2]                  #! 0xaaaabe371b38 = 0xaaaabe371b38;
(* and	v17.16b, v16.16b, v1.16b                    #! PC = 0xaaaabe371b3c *)
and %v17@uint64[2] %v16 %v1;
(* sshr	v7.2d, v16.2d, #30                         #! PC = 0xaaaabe371b40 *)
split %v7 %dc %v16 30;
(* shl	v17.2d, v17.2d, #32                         #! PC = 0xaaaabe371b44 *)
shls %dc %v17 %v17 [32, 32];
(* orr	v6.16b, v6.16b, v17.16b                     #! PC = 0xaaaabe371b48 *)
or %v6@uint64[2] %v6 %v17;
(* and	x7, x1, #0xfffff                            #! PC = 0xaaaabe371b4c *)
and x7@uint64 x1 0xfffff@uint64;
(* and	x8, x2, #0xfffff                            #! PC = 0xaaaabe371b50 *)
and x8@uint64 x2 0xfffff@uint64;
(* orr	x7, x7, #0xfffffe0000000000                 #! PC = 0xaaaabe371b54 *)
or x7@uint64 x7 0xfffffe0000000000@uint64;
(* orr	x8, x8, #0xc000000000000000                 #! PC = 0xaaaabe371b58 *)
or x8@uint64 x8 0xc000000000000000@uint64;
(* tst	x8, #0x1                                    #! PC = 0xaaaabe371b5c *)
spl dc x8_lo x8 1;
and ne@bit x8_lo 1@bit;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371b60 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371b64 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371b68 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371b6c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371b70 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371b74 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371b78 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371b7c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371b80 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371b84 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371b88 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371b8c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371b90 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371b94 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371b98 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371b9c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371ba0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371ba4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371ba8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371bac *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371bb0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371bb4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371bb8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371bbc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371bc0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371bc4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371bc8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371bcc *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371bd0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371bd4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371bd8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371bdc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371be0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371be4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371be8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371bec *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371bf0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371bf4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371bf8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371bfc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c00 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c04 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c08 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c0c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371c10 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371c14 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371c18 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371c1c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371c20 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c24 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c28 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c2c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c30 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371c34 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371c38 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371c3c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371c40 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371c44 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c48 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c4c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c50 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c54 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371c58 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371c5c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371c60 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371c64 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371c68 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c6c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c70 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c74 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c78 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371c7c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371c80 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371c84 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371c88 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371c8c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c90 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c94 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c98 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c9c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371ca0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371ca4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371ca8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371cac *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371cb0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371cb4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371cb8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371cbc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371cc0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371cc4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371cc8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371ccc *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371cd0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371cd4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371cd8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371cdc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371ce0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371ce4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371ce8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371cec *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371cf0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371cf4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371cf8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371cfc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d00 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d04 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d08 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d0c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371d10 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371d14 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371d18 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371d1c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371d20 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d24 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d28 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d2c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d30 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371d34 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371d38 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371d3c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371d40 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371d44 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d48 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d4c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d50 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d54 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371d58 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371d5c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371d60 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371d64 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371d68 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d6c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d70 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d74 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d78 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371d7c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371d80 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371d84 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371d88 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371d8c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d90 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d94 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d98 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d9c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371da0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371da4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371da8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371dac *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371db0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371db4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371db8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371dbc *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371dc0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371dc4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371dc8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371dcc *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371dd0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371dd4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371dd8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371ddc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371de0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371de4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371de8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371dec *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371df0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371df4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371df8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371dfc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371e00 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371e04 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371e08 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371e0c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371e10 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371e14 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371e18 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371e1c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371e20 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371e24 *)
add x3 x3 0x2@sint64;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371e28 *)
ssplit x8 dcL x8 1;
(* add	x12, x7, x6                                 #! PC = 0xaaaabe371e2c *)
add x12 x7 x6;
(* asr	x12, x12, #42                               #! PC = 0xaaaabe371e30 *)
ssplit x12 dcL x12 42;
(* add	x11, x7, #0x100, lsl #12                    #! PC = 0xaaaabe371e34 *)
add x11 x7 0x100@sint64, lsl;
(* lsl	x11, x11, #22                               #! PC = 0xaaaabe371e38 *)
split dcH x11 x11 (64-22); shl x11 x11 22;
(* asr	x11, x11, #43                               #! PC = 0xaaaabe371e3c *)
ssplit x11 dcL x11 43;
(* add	x14, x8, x6                                 #! PC = 0xaaaabe371e40 *)
add x14 x8 x6;
(* asr	x14, x14, #42                               #! PC = 0xaaaabe371e44 *)
ssplit x14 dcL x14 42;
(* add	x13, x8, #0x100, lsl #12                    #! PC = 0xaaaabe371e48 *)
add x13 x8 0x100@sint64, lsl;
(* lsl	x13, x13, #22                               #! PC = 0xaaaabe371e4c *)
split dcH x13 x13 (64-22); shl x13 x13 22;
(* asr	x13, x13, #43                               #! PC = 0xaaaabe371e50 *)
ssplit x13 dcL x13 43;
(* mul	x9, x11, x1                                 #! PC = 0xaaaabe371e54 *)
mull dcH x9 x11 x1;
(* madd	x9, x12, x2, x9                            #! PC = 0xaaaabe371e58 *)
mull dcH mul_tmp x12 x2;
adds dc x9 mul_tmp x9;
(* asr	x9, x9, #20                                 #! PC = 0xaaaabe371e5c *)
ssplit x9 dcL x9 20;
(* mul	x10, x13, x1                                #! PC = 0xaaaabe371e60 *)
mull dcH x10 x13 x1;
(* madd	x10, x14, x2, x10                          #! PC = 0xaaaabe371e64 *)
mull dcH mul_tmp x14 x2;
adds dc x10 mul_tmp x10;
(* asr	x2, x10, #20                                #! PC = 0xaaaabe371e68 *)
ssplit x2 dcL x10 20;
(* mov	x1, x9                                      #! PC = 0xaaaabe371e6c *)
mov x1 x9;
(* mov	w4, v3.s[0]                                 #! PC = 0xaaaabe371e70 *)
mov w4 v3.s[0];
(* mov	w27, v3.s[1]                                #! PC = 0xaaaabe371e74 *)
mov w27 v3.s[1];
(* add	x4, x4, x27, lsl #30                        #! PC = 0xaaaabe371e78 *)
add x4 x4 x27, lsl;
(* mov	w27, v4.s[0]                                #! PC = 0xaaaabe371e7c *)
mov w27 v4.s[0];
(* add	x4, x4, x27, lsl #60                        #! PC = 0xaaaabe371e80 *)
add x4 x4 x27, lsl;
(* add	x21, xzr, x27, lsr #4                       #! PC = 0xaaaabe371e84 *)
add	%%x21, xzr, %%x27, lsr #4                       #! 0xaaaabe371e84 = 0xaaaabe371e84;
(* mov	w27, v4.s[1]                                #! PC = 0xaaaabe371e88 *)
mov w27 v4.s[1];
(* add	x21, x21, x27, lsl #26                      #! PC = 0xaaaabe371e8c *)
add x21 x21 x27, lsl;
(* mov	w5, v3.s[2]                                 #! PC = 0xaaaabe371e90 *)
mov w5 v3.s[2];
(* mov	w27, v3.s[3]                                #! PC = 0xaaaabe371e94 *)
mov w27 v3.s[3];
(* add	x5, x5, x27, lsl #30                        #! PC = 0xaaaabe371e98 *)
add x5 x5 x27, lsl;
(* mov	w27, v4.s[2]                                #! PC = 0xaaaabe371e9c *)
mov w27 v4.s[2];
(* add	x5, x5, x27, lsl #60                        #! PC = 0xaaaabe371ea0 *)
add x5 x5 x27, lsl;
(* add	x22, xzr, x27, lsr #4                       #! PC = 0xaaaabe371ea4 *)
add	%%x22, xzr, %%x27, lsr #4                       #! 0xaaaabe371ea4 = 0xaaaabe371ea4;
(* mov	w27, v4.s[3]                                #! PC = 0xaaaabe371ea8 *)
mov w27 v4.s[3];
(* add	x22, x22, x27, lsl #26                      #! PC = 0xaaaabe371eac *)
add x22 x22 x27, lsl;
(* and	x7, x1, #0xfffff                            #! PC = 0xaaaabe371eb0 *)
and x7@uint64 x1 0xfffff@uint64;
(* and	x8, x2, #0xfffff                            #! PC = 0xaaaabe371eb4 *)
and x8@uint64 x2 0xfffff@uint64;
(* orr	x7, x7, #0xfffffe0000000000                 #! PC = 0xaaaabe371eb8 *)
or x7@uint64 x7 0xfffffe0000000000@uint64;
(* orr	x8, x8, #0xc000000000000000                 #! PC = 0xaaaabe371ebc *)
or x8@uint64 x8 0xc000000000000000@uint64;
(* tst	x8, #0x1                                    #! PC = 0xaaaabe371ec0 *)
spl dc x8_lo x8 1;
and ne@bit x8_lo 1@bit;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371ec4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371ec8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371ecc *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371ed0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371ed4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371ed8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371edc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371ee0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371ee4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371ee8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371eec *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371ef0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371ef4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371ef8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371efc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f00 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f04 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f08 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f0c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371f10 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371f14 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371f18 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371f1c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371f20 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f24 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f28 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f2c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f30 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371f34 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371f38 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371f3c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371f40 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371f44 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f48 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f4c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f50 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f54 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371f58 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371f5c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371f60 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371f64 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371f68 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f6c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f70 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f74 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f78 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371f7c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371f80 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371f84 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371f88 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371f8c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f90 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f94 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f98 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f9c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371fa0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371fa4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371fa8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371fac *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371fb0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371fb4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371fb8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371fbc *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371fc0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371fc4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371fc8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371fcc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371fd0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371fd4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371fd8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371fdc *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371fe0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371fe4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371fe8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371fec *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371ff0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371ff4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371ff8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371ffc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372000 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372004 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372008 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37200c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372010 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372014 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372018 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37201c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372020 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372024 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372028 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37202c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372030 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372034 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372038 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37203c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372040 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372044 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372048 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37204c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372050 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372054 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372058 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37205c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372060 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372064 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372068 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37206c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372070 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372074 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372078 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37207c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372080 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372084 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372088 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37208c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372090 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372094 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372098 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37209c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3720a0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3720a4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3720a8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3720ac *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3720b0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3720b4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3720b8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3720bc *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3720c0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3720c4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3720c8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3720cc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3720d0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3720d4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3720d8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3720dc *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3720e0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3720e4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3720e8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3720ec *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3720f0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3720f4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3720f8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3720fc *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372100 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372104 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372108 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37210c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372110 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372114 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372118 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37211c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372120 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372124 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372128 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37212c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372130 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372134 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372138 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37213c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372140 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372144 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372148 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37214c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372150 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372154 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372158 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37215c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372160 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372164 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372168 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37216c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372170 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372174 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372178 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37217c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372180 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372184 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372188 *)
add x3 x3 0x2@sint64;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37218c *)
ssplit x8 dcL x8 1;
(* add	x16, x7, x6                                 #! PC = 0xaaaabe372190 *)
add x16 x7 x6;
(* asr	x16, x16, #42                               #! PC = 0xaaaabe372194 *)
ssplit x16 dcL x16 42;
(* add	x15, x7, #0x100, lsl #12                    #! PC = 0xaaaabe372198 *)
add x15 x7 0x100@sint64, lsl;
(* lsl	x15, x15, #22                               #! PC = 0xaaaabe37219c *)
split dcH x15 x15 (64-22); shl x15 x15 22;
(* asr	x15, x15, #43                               #! PC = 0xaaaabe3721a0 *)
ssplit x15 dcL x15 43;
(* add	x20, x8, x6                                 #! PC = 0xaaaabe3721a4 *)
add x20 x8 x6;
(* asr	x20, x20, #42                               #! PC = 0xaaaabe3721a8 *)
ssplit x20 dcL x20 42;
(* add	x17, x8, #0x100, lsl #12                    #! PC = 0xaaaabe3721ac *)
add x17 x8 0x100@sint64, lsl;
(* lsl	x17, x17, #22                               #! PC = 0xaaaabe3721b0 *)
split dcH x17 x17 (64-22); shl x17 x17 22;
(* asr	x17, x17, #43                               #! PC = 0xaaaabe3721b4 *)
ssplit x17 dcL x17 43;
(* mul	x9, x15, x1                                 #! PC = 0xaaaabe3721b8 *)
mull dcH x9 x15 x1;
(* madd	x9, x16, x2, x9                            #! PC = 0xaaaabe3721bc *)
mull dcH mul_tmp x16 x2;
adds dc x9 mul_tmp x9;
(* asr	x9, x9, #20                                 #! PC = 0xaaaabe3721c0 *)
ssplit x9 dcL x9 20;
(* mul	x10, x17, x1                                #! PC = 0xaaaabe3721c4 *)
mull dcH x10 x17 x1;
(* madd	x10, x20, x2, x10                          #! PC = 0xaaaabe3721c8 *)
mull dcH mul_tmp x20 x2;
adds dc x10 mul_tmp x10;
(* asr	x2, x10, #20                                #! PC = 0xaaaabe3721cc *)
ssplit x2 dcL x10 20;
(* mov	x1, x9                                      #! PC = 0xaaaabe3721d0 *)
mov x1 x9;
(* mul	x9, x15, x11                                #! PC = 0xaaaabe3721d4 *)
mull dcH x9 x15 x11;
(* madd	x10, x16, x13, x9                          #! PC = 0xaaaabe3721d8 *)
mull dcH mul_tmp x16 x13;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x11                                #! PC = 0xaaaabe3721dc *)
mull dcH x9 x17 x11;
(* madd	x13, x20, x13, x9                          #! PC = 0xaaaabe3721e0 *)
mull dcH mul_tmp x20 x13;
adds dc x13 mul_tmp x9;
(* mov	x11, x10                                    #! PC = 0xaaaabe3721e4 *)
mov x11 x10;
(* mul	x9, x15, x12                                #! PC = 0xaaaabe3721e8 *)
mull dcH x9 x15 x12;
(* madd	x10, x16, x14, x9                          #! PC = 0xaaaabe3721ec *)
mull dcH mul_tmp x16 x14;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x12                                #! PC = 0xaaaabe3721f0 *)
mull dcH x9 x17 x12;
(* madd	x14, x20, x14, x9                          #! PC = 0xaaaabe3721f4 *)
mull dcH mul_tmp x20 x14;
adds dc x14 mul_tmp x9;
(* mov	x12, x10                                    #! PC = 0xaaaabe3721f8 *)
mov x12 x10;
(* mov	x9, #0x13                  	// #19          #! PC = 0xaaaabe3721fc *)
mov x9 0x13@uint64;
(* dup	v16.2d, x9                                  #! PC = 0xaaaabe372200 *)
mov %v16 [x9,x9];
(* smull	v17.2d, v13.2s, v8.s[0]                   #! PC = 0xaaaabe372204 *)
smull	%%v17.2d, %%v13.2s, %%v8.s[0]                   #! 0xaaaabe372204 = 0xaaaabe372204;
(* smlal2	v17.2d, v13.4s, v8.s[2]                  #! PC = 0xaaaabe372208 *)
smlal2	%%v17.2d, %%v13.4s, %%v8.s[2]                  #! 0xaaaabe372208 = 0xaaaabe372208;
(* mul	v19.4s, v17.4s, v15.4s                      #! PC = 0xaaaabe37220c *)
mul %v19 %v17 %v15;
(* and	v19.16b, v19.16b, v1.16b                    #! PC = 0xaaaabe372210 *)
and %v19@uint64[2] %v19 %v1;
(* uzp1	v19.4s, v19.4s, v19.4s                     #! PC = 0xaaaabe372214 *)
mov %v19 [%v19[0], %v19[2], %v19[0], %v19[2]];
(* smlsl	v17.2d, v19.2s, v16.s[0]                  #! PC = 0xaaaabe372218 *)
smlsl	%%v17.2d, %%v19.2s, %%v16.s[0]                  #! 0xaaaabe372218 = 0xaaaabe372218;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe37221c *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v8.s[0]                   #! PC = 0xaaaabe372220 *)
smlal	%%v17.2d, %%v14.2s, %%v8.s[0]                   #! 0xaaaabe372220 = 0xaaaabe372220;
(* smlal2	v17.2d, v14.4s, v8.s[2]                  #! PC = 0xaaaabe372224 *)
smlal2	%%v17.2d, %%v14.4s, %%v8.s[2]                  #! 0xaaaabe372224 = 0xaaaabe372224;
(* smlal	v17.2d, v13.2s, v8.s[1]                   #! PC = 0xaaaabe372228 *)
smlal	%%v17.2d, %%v13.2s, %%v8.s[1]                   #! 0xaaaabe372228 = 0xaaaabe372228;
(* smlal2	v17.2d, v13.4s, v8.s[3]                  #! PC = 0xaaaabe37222c *)
smlal2	%%v17.2d, %%v13.4s, %%v8.s[3]                  #! 0xaaaabe37222c = 0xaaaabe37222c;
(* mul	v20.4s, v17.4s, v15.4s                      #! PC = 0xaaaabe372230 *)
mul %v20 %v17 %v15;
(* and	v20.16b, v20.16b, v1.16b                    #! PC = 0xaaaabe372234 *)
and %v20@uint64[2] %v20 %v1;
(* uzp1	v20.4s, v20.4s, v20.4s                     #! PC = 0xaaaabe372238 *)
mov %v20 [%v20[0], %v20[2], %v20[0], %v20[2]];
(* smlsl	v17.2d, v20.2s, v16.s[0]                  #! PC = 0xaaaabe37223c *)
smlsl	%%v17.2d, %%v20.2s, %%v16.s[0]                  #! 0xaaaabe37223c = 0xaaaabe37223c;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe372240 *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v8.s[1]                   #! PC = 0xaaaabe372244 *)
smlal	%%v17.2d, %%v14.2s, %%v8.s[1]                   #! 0xaaaabe372244 = 0xaaaabe372244;
(* smlal2	v17.2d, v14.4s, v8.s[3]                  #! PC = 0xaaaabe372248 *)
smlal2	%%v17.2d, %%v14.4s, %%v8.s[3]                  #! 0xaaaabe372248 = 0xaaaabe372248;
(* smlal	v17.2d, v13.2s, v9.s[0]                   #! PC = 0xaaaabe37224c *)
smlal	%%v17.2d, %%v13.2s, %%v9.s[0]                   #! 0xaaaabe37224c = 0xaaaabe37224c;
(* smlal2	v17.2d, v13.4s, v9.s[2]                  #! PC = 0xaaaabe372250 *)
smlal2	%%v17.2d, %%v13.4s, %%v9.s[2]                  #! 0xaaaabe372250 = 0xaaaabe372250;
(* and	v8.16b, v17.16b, v1.16b                     #! PC = 0xaaaabe372254 *)
and %v8@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe372258 *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v9.s[0]                   #! PC = 0xaaaabe37225c *)
smlal	%%v17.2d, %%v14.2s, %%v9.s[0]                   #! 0xaaaabe37225c = 0xaaaabe37225c;
(* smlal2	v17.2d, v14.4s, v9.s[2]                  #! PC = 0xaaaabe372260 *)
smlal2	%%v17.2d, %%v14.4s, %%v9.s[2]                  #! 0xaaaabe372260 = 0xaaaabe372260;
(* smlal	v17.2d, v13.2s, v9.s[1]                   #! PC = 0xaaaabe372264 *)
smlal	%%v17.2d, %%v13.2s, %%v9.s[1]                   #! 0xaaaabe372264 = 0xaaaabe372264;
(* smlal2	v17.2d, v13.4s, v9.s[3]                  #! PC = 0xaaaabe372268 *)
smlal2	%%v17.2d, %%v13.4s, %%v9.s[3]                  #! 0xaaaabe372268 = 0xaaaabe372268;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe37226c *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe372270 *)
split %v17 %dc %v17 30;
(* sli	v8.2d, v18.2d, #32                          #! PC = 0xaaaabe372274 *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v8 %v8 32; or %v8@uint64[2] %slih %v8;
(* smlal	v17.2d, v14.2s, v9.s[1]                   #! PC = 0xaaaabe372278 *)
smlal	%%v17.2d, %%v14.2s, %%v9.s[1]                   #! 0xaaaabe372278 = 0xaaaabe372278;
(* smlal2	v17.2d, v14.4s, v9.s[3]                  #! PC = 0xaaaabe37227c *)
smlal2	%%v17.2d, %%v14.4s, %%v9.s[3]                  #! 0xaaaabe37227c = 0xaaaabe37227c;
(* smlal	v17.2d, v13.2s, v10.s[0]                  #! PC = 0xaaaabe372280 *)
smlal	%%v17.2d, %%v13.2s, %%v10.s[0]                  #! 0xaaaabe372280 = 0xaaaabe372280;
(* smlal2	v17.2d, v13.4s, v10.s[2]                 #! PC = 0xaaaabe372284 *)
smlal2	%%v17.2d, %%v13.4s, %%v10.s[2]                 #! 0xaaaabe372284 = 0xaaaabe372284;
(* and	v9.16b, v17.16b, v1.16b                     #! PC = 0xaaaabe372288 *)
and %v9@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe37228c *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v10.s[0]                  #! PC = 0xaaaabe372290 *)
smlal	%%v17.2d, %%v14.2s, %%v10.s[0]                  #! 0xaaaabe372290 = 0xaaaabe372290;
(* smlal2	v17.2d, v14.4s, v10.s[2]                 #! PC = 0xaaaabe372294 *)
smlal2	%%v17.2d, %%v14.4s, %%v10.s[2]                 #! 0xaaaabe372294 = 0xaaaabe372294;
(* smlal	v17.2d, v13.2s, v10.s[1]                  #! PC = 0xaaaabe372298 *)
smlal	%%v17.2d, %%v13.2s, %%v10.s[1]                  #! 0xaaaabe372298 = 0xaaaabe372298;
(* smlal2	v17.2d, v13.4s, v10.s[3]                 #! PC = 0xaaaabe37229c *)
smlal2	%%v17.2d, %%v13.4s, %%v10.s[3]                 #! 0xaaaabe37229c = 0xaaaabe37229c;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe3722a0 *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3722a4 *)
split %v17 %dc %v17 30;
(* sli	v9.2d, v18.2d, #32                          #! PC = 0xaaaabe3722a8 *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v9 %v9 32; or %v9@uint64[2] %slih %v9;
(* smlal	v17.2d, v14.2s, v10.s[1]                  #! PC = 0xaaaabe3722ac *)
smlal	%%v17.2d, %%v14.2s, %%v10.s[1]                  #! 0xaaaabe3722ac = 0xaaaabe3722ac;
(* smlal2	v17.2d, v14.4s, v10.s[3]                 #! PC = 0xaaaabe3722b0 *)
smlal2	%%v17.2d, %%v14.4s, %%v10.s[3]                 #! 0xaaaabe3722b0 = 0xaaaabe3722b0;
(* smlal	v17.2d, v13.2s, v11.s[0]                  #! PC = 0xaaaabe3722b4 *)
smlal	%%v17.2d, %%v13.2s, %%v11.s[0]                  #! 0xaaaabe3722b4 = 0xaaaabe3722b4;
(* smlal2	v17.2d, v13.4s, v11.s[2]                 #! PC = 0xaaaabe3722b8 *)
smlal2	%%v17.2d, %%v13.4s, %%v11.s[2]                 #! 0xaaaabe3722b8 = 0xaaaabe3722b8;
(* and	v10.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe3722bc *)
and %v10@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3722c0 *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v11.s[0]                  #! PC = 0xaaaabe3722c4 *)
smlal	%%v17.2d, %%v14.2s, %%v11.s[0]                  #! 0xaaaabe3722c4 = 0xaaaabe3722c4;
(* smlal2	v17.2d, v14.4s, v11.s[2]                 #! PC = 0xaaaabe3722c8 *)
smlal2	%%v17.2d, %%v14.4s, %%v11.s[2]                 #! 0xaaaabe3722c8 = 0xaaaabe3722c8;
(* smlal	v17.2d, v13.2s, v11.s[1]                  #! PC = 0xaaaabe3722cc *)
smlal	%%v17.2d, %%v13.2s, %%v11.s[1]                  #! 0xaaaabe3722cc = 0xaaaabe3722cc;
(* smlal2	v17.2d, v13.4s, v11.s[3]                 #! PC = 0xaaaabe3722d0 *)
smlal2	%%v17.2d, %%v13.4s, %%v11.s[3]                 #! 0xaaaabe3722d0 = 0xaaaabe3722d0;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe3722d4 *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3722d8 *)
split %v17 %dc %v17 30;
(* sli	v10.2d, v18.2d, #32                         #! PC = 0xaaaabe3722dc *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v10 %v10 32; or %v10@uint64[2] %slih %v10;
(* smlal	v17.2d, v14.2s, v11.s[1]                  #! PC = 0xaaaabe3722e0 *)
smlal	%%v17.2d, %%v14.2s, %%v11.s[1]                  #! 0xaaaabe3722e0 = 0xaaaabe3722e0;
(* smlal2	v17.2d, v14.4s, v11.s[3]                 #! PC = 0xaaaabe3722e4 *)
smlal2	%%v17.2d, %%v14.4s, %%v11.s[3]                 #! 0xaaaabe3722e4 = 0xaaaabe3722e4;
(* smlal	v17.2d, v13.2s, v12.s[0]                  #! PC = 0xaaaabe3722e8 *)
smlal	%%v17.2d, %%v13.2s, %%v12.s[0]                  #! 0xaaaabe3722e8 = 0xaaaabe3722e8;
(* smlal2	v17.2d, v13.4s, v12.s[2]                 #! PC = 0xaaaabe3722ec *)
smlal2	%%v17.2d, %%v13.4s, %%v12.s[2]                 #! 0xaaaabe3722ec = 0xaaaabe3722ec;
(* ushll	v19.2d, v19.2s, #15                       #! PC = 0xaaaabe3722f0 *)
ushll	%%v19.2d, %%v19.2s, #15                       #! 0xaaaabe3722f0 = 0xaaaabe3722f0;
(* add	v17.2d, v17.2d, v19.2d                      #! PC = 0xaaaabe3722f4 *)
add	%%v17.2d, %%v17.2d, %%v19.2d                      #! 0xaaaabe3722f4 = 0xaaaabe3722f4;
(* and	v11.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe3722f8 *)
and %v11@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3722fc *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v12.s[0]                  #! PC = 0xaaaabe372300 *)
smlal	%%v17.2d, %%v14.2s, %%v12.s[0]                  #! 0xaaaabe372300 = 0xaaaabe372300;
(* smlal2	v17.2d, v14.4s, v12.s[2]                 #! PC = 0xaaaabe372304 *)
smlal2	%%v17.2d, %%v14.4s, %%v12.s[2]                 #! 0xaaaabe372304 = 0xaaaabe372304;
(* ushll	v20.2d, v20.2s, #15                       #! PC = 0xaaaabe372308 *)
ushll	%%v20.2d, %%v20.2s, #15                       #! 0xaaaabe372308 = 0xaaaabe372308;
(* add	v17.2d, v17.2d, v20.2d                      #! PC = 0xaaaabe37230c *)
add	%%v17.2d, %%v17.2d, %%v20.2d                      #! 0xaaaabe37230c = 0xaaaabe37230c;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe372310 *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v12.2d, v17.2d, #30                        #! PC = 0xaaaabe372314 *)
split %v12 %dc %v17 30;
(* sli	v11.2d, v18.2d, #32                         #! PC = 0xaaaabe372318 *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v11 %v11 32; or %v11@uint64[2] %slih %v11;
(* sshr	v18.2d, v12.2d, #15                        #! PC = 0xaaaabe37231c *)
split %v18 %dc %v12 15;
(* shl	v17.2d, v18.2d, #15                         #! PC = 0xaaaabe372320 *)
shls %dc %v17 %v18 [15, 15];
(* sub	v12.2d, v12.2d, v17.2d                      #! PC = 0xaaaabe372324 *)
sub	%%v12.2d, %%v12.2d, %%v17.2d                      #! 0xaaaabe372324 = 0xaaaabe372324;
(* mla	v8.4s, v18.4s, v16.4s                       #! PC = 0xaaaabe372328 *)
mull %dc %mla %v18 %v16; add %v8 %v8 %mla;
(* and	x7, x1, #0xfffff                            #! PC = 0xaaaabe37232c *)
and x7@uint64 x1 0xfffff@uint64;
(* and	x8, x2, #0xfffff                            #! PC = 0xaaaabe372330 *)
and x8@uint64 x2 0xfffff@uint64;
(* orr	x7, x7, #0xfffffe0000000000                 #! PC = 0xaaaabe372334 *)
or x7@uint64 x7 0xfffffe0000000000@uint64;
(* orr	x8, x8, #0xc000000000000000                 #! PC = 0xaaaabe372338 *)
or x8@uint64 x8 0xc000000000000000@uint64;
(* tst	x8, #0x1                                    #! PC = 0xaaaabe37233c *)
spl dc x8_lo x8 1;
and ne@bit x8_lo 1@bit;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372340 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372344 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372348 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37234c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372350 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372354 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372358 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37235c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372360 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372364 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372368 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37236c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372370 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372374 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372378 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37237c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372380 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372384 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372388 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37238c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372390 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372394 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372398 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37239c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3723a0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3723a4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3723a8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3723ac *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3723b0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3723b4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3723b8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3723bc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3723c0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3723c4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3723c8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3723cc *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3723d0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3723d4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3723d8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3723dc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3723e0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3723e4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3723e8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3723ec *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3723f0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3723f4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3723f8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3723fc *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372400 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372404 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372408 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37240c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372410 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372414 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372418 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37241c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372420 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372424 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372428 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37242c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372430 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372434 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372438 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37243c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372440 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372444 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372448 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37244c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372450 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372454 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372458 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37245c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372460 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372464 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372468 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37246c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372470 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372474 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372478 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37247c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372480 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372484 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372488 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37248c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372490 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372494 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372498 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37249c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3724a0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3724a4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3724a8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3724ac *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3724b0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3724b4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3724b8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3724bc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3724c0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3724c4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3724c8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3724cc *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3724d0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3724d4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3724d8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3724dc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3724e0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3724e4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3724e8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3724ec *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3724f0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3724f4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3724f8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3724fc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372500 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372504 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372508 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37250c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372510 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372514 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372518 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37251c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372520 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372524 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372528 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37252c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372530 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372534 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372538 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37253c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372540 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372544 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372548 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37254c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372550 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372554 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372558 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37255c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372560 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372564 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372568 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37256c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372570 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372574 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372578 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37257c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372580 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372584 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372588 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37258c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372590 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372594 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372598 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37259c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3725a0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3725a4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3725a8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3725ac *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3725b0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3725b4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3725b8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3725bc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3725c0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3725c4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3725c8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3725cc *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3725d0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3725d4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3725d8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3725dc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3725e0 *)
add x3 x3 0x2@sint64;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3725e4 *)
ssplit x8 dcL x8 1;
(* add	x16, x7, x6                                 #! PC = 0xaaaabe3725e8 *)
add x16 x7 x6;
(* asr	x16, x16, #42                               #! PC = 0xaaaabe3725ec *)
ssplit x16 dcL x16 42;
(* add	x15, x7, #0x100, lsl #12                    #! PC = 0xaaaabe3725f0 *)
add x15 x7 0x100@sint64, lsl;
(* lsl	x15, x15, #22                               #! PC = 0xaaaabe3725f4 *)
split dcH x15 x15 (64-22); shl x15 x15 22;
(* asr	x15, x15, #43                               #! PC = 0xaaaabe3725f8 *)
ssplit x15 dcL x15 43;
(* add	x20, x8, x6                                 #! PC = 0xaaaabe3725fc *)
add x20 x8 x6;
(* asr	x20, x20, #42                               #! PC = 0xaaaabe372600 *)
ssplit x20 dcL x20 42;
(* add	x17, x8, #0x100, lsl #12                    #! PC = 0xaaaabe372604 *)
add x17 x8 0x100@sint64, lsl;
(* lsl	x17, x17, #22                               #! PC = 0xaaaabe372608 *)
split dcH x17 x17 (64-22); shl x17 x17 22;
(* asr	x17, x17, #43                               #! PC = 0xaaaabe37260c *)
ssplit x17 dcL x17 43;
(* mul	x9, x15, x11                                #! PC = 0xaaaabe372610 *)
mull dcH x9 x15 x11;
(* madd	x10, x16, x13, x9                          #! PC = 0xaaaabe372614 *)
mull dcH mul_tmp x16 x13;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x11                                #! PC = 0xaaaabe372618 *)
mull dcH x9 x17 x11;
(* madd	x13, x20, x13, x9                          #! PC = 0xaaaabe37261c *)
mull dcH mul_tmp x20 x13;
adds dc x13 mul_tmp x9;
(* mov	x11, x10                                    #! PC = 0xaaaabe372620 *)
mov x11 x10;
(* mul	x9, x15, x12                                #! PC = 0xaaaabe372624 *)
mull dcH x9 x15 x12;
(* madd	x10, x16, x14, x9                          #! PC = 0xaaaabe372628 *)
mull dcH mul_tmp x16 x14;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x12                                #! PC = 0xaaaabe37262c *)
mull dcH x9 x17 x12;
(* madd	x14, x20, x14, x9                          #! PC = 0xaaaabe372630 *)
mull dcH mul_tmp x20 x14;
adds dc x14 mul_tmp x9;
(* mov	x12, x10                                    #! PC = 0xaaaabe372634 *)
mov x12 x10;
(* subs	x19, x19, #0x1                             #! PC = 0xaaaabe372638 *)
subc carry x19 x19 0x1@uint64;
(* #cbnz	x19, 0xaaaabe371960 <Lbig_loop>           #! PC = 0xaaaabe37263c *)
#cbnz	%%x19, 0xaaaabe371960 <Lbig_loop>           #! 0xaaaabe37263c = 0xaaaabe37263c;
(* mov	v16.d[0], x11                               #! PC = 0xaaaabe371960 *)
mov %v16 [x11, %v16[1]];
(* mov	v16.d[1], x13                               #! PC = 0xaaaabe371964 *)
mov %v16 [%v16[0], x13];
(* mov	v17.d[0], x12                               #! PC = 0xaaaabe371968 *)
mov %v17 [x12, %v17[1]];
(* mov	v17.d[1], x14                               #! PC = 0xaaaabe37196c *)
mov %v17 [%v17[0], x14];
(* uzp1	v13.4s, v16.4s, v17.4s                     #! PC = 0xaaaabe371970 *)
mov %v13 [%v16[0], %v16[2], %v17[0], %v17[2]];
(* and	v13.16b, v13.16b, v2.16b                    #! PC = 0xaaaabe371974 *)
and %v13@uint64[2] %v13 %v2;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371978 *)
split %v16 %dc %v16 30;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe37197c *)
split %v17 %dc %v17 30;
(* uzp1	v14.4s, v16.4s, v17.4s                     #! PC = 0xaaaabe371980 *)
mov %v14 [%v16[0], %v16[2], %v17[0], %v17[2]];
(* cmp	x11, xzr                                    #! PC = 0xaaaabe371984 *)
subc zero dc 0@uint64 x11;
(* csetm	x23, mi	// mi = first                     #! PC = 0xaaaabe371988 *)
csetm	%%x23, mi	// mi = first                     #! 0xaaaabe371988 = 0xaaaabe371988;
(* cneg	x11, x11, mi	// mi = first                 #! PC = 0xaaaabe37198c *)
cneg	%%x11, %%x11, mi	// mi = first                 #! 0xaaaabe37198c = 0xaaaabe37198c;
(* cmp	x12, xzr                                    #! PC = 0xaaaabe371990 *)
subc zero dc 0@uint64 x12;
(* csetm	x24, mi	// mi = first                     #! PC = 0xaaaabe371994 *)
csetm	%%x24, mi	// mi = first                     #! 0xaaaabe371994 = 0xaaaabe371994;
(* cneg	x12, x12, mi	// mi = first                 #! PC = 0xaaaabe371998 *)
cneg	%%x12, %%x12, mi	// mi = first                 #! 0xaaaabe371998 = 0xaaaabe371998;
(* cmp	x13, xzr                                    #! PC = 0xaaaabe37199c *)
subc zero dc 0@uint64 x13;
(* csetm	x25, mi	// mi = first                     #! PC = 0xaaaabe3719a0 *)
csetm	%%x25, mi	// mi = first                     #! 0xaaaabe3719a0 = 0xaaaabe3719a0;
(* cneg	x13, x13, mi	// mi = first                 #! PC = 0xaaaabe3719a4 *)
cneg	%%x13, %%x13, mi	// mi = first                 #! 0xaaaabe3719a4 = 0xaaaabe3719a4;
(* cmp	x14, xzr                                    #! PC = 0xaaaabe3719a8 *)
subc zero dc 0@uint64 x14;
(* csetm	x26, mi	// mi = first                     #! PC = 0xaaaabe3719ac *)
csetm	%%x26, mi	// mi = first                     #! 0xaaaabe3719ac = 0xaaaabe3719ac;
(* cneg	x14, x14, mi	// mi = first                 #! PC = 0xaaaabe3719b0 *)
cneg	%%x14, %%x14, mi	// mi = first                 #! 0xaaaabe3719b0 = 0xaaaabe3719b0;
(* and	x27, x11, x23                               #! PC = 0xaaaabe3719b4 *)
and x27@uint64 x11 x23;
(* and	x28, x12, x24                               #! PC = 0xaaaabe3719b8 *)
and x28@uint64 x12 x24;
(* add	x15, x27, x28                               #! PC = 0xaaaabe3719bc *)
add x15 x27 x28;
(* eor	x27, x4, x23                                #! PC = 0xaaaabe3719c0 *)
xor x27@uint64 x4 x23;
(* mul	x9, x27, x11                                #! PC = 0xaaaabe3719c4 *)
mull dcH x9 x27 x11;
(* umulh	x10, x27, x11                             #! PC = 0xaaaabe3719c8 *)
mull x10 dcL x27 x11;
(* adds	x15, x9, x15                               #! PC = 0xaaaabe3719cc *)
adds carry x15 x9 x15;
(* adc	x16, x10, xzr                               #! PC = 0xaaaabe3719d0 *)
adc x16 x10 0@uint64 carry;
(* eor	x27, x21, x23                               #! PC = 0xaaaabe3719d4 *)
xor x27@uint64 x21 x23;
(* mul	x9, x27, x11                                #! PC = 0xaaaabe3719d8 *)
mull dcH x9 x27 x11;
(* add	x16, x16, x9                                #! PC = 0xaaaabe3719dc *)
add x16 x16 x9;
(* eor	x27, x5, x24                                #! PC = 0xaaaabe3719e0 *)
xor x27@uint64 x5 x24;
(* mul	x9, x27, x12                                #! PC = 0xaaaabe3719e4 *)
mull dcH x9 x27 x12;
(* umulh	x10, x27, x12                             #! PC = 0xaaaabe3719e8 *)
mull x10 dcL x27 x12;
(* adds	x15, x9, x15                               #! PC = 0xaaaabe3719ec *)
adds carry x15 x9 x15;
(* adc	x16, x10, x16                               #! PC = 0xaaaabe3719f0 *)
adc x16 x10 x16 carry;
(* eor	x27, x22, x24                               #! PC = 0xaaaabe3719f4 *)
xor x27@uint64 x22 x24;
(* mul	x9, x27, x12                                #! PC = 0xaaaabe3719f8 *)
mull dcH x9 x27 x12;
(* add	x16, x16, x9                                #! PC = 0xaaaabe3719fc *)
add x16 x16 x9;
(* extr	x1, x16, x15, #60                          #! PC = 0xaaaabe371a00 *)
spl dc extr_H x16 60; spl extr_L dc x15 60; join x1 extr_H extr_L;
(* and	x27, x13, x25                               #! PC = 0xaaaabe371a04 *)
and x27@uint64 x13 x25;
(* and	x28, x14, x26                               #! PC = 0xaaaabe371a08 *)
and x28@uint64 x14 x26;
(* add	x17, x27, x28                               #! PC = 0xaaaabe371a0c *)
add x17 x27 x28;
(* eor	x27, x4, x25                                #! PC = 0xaaaabe371a10 *)
xor x27@uint64 x4 x25;
(* mul	x9, x27, x13                                #! PC = 0xaaaabe371a14 *)
mull dcH x9 x27 x13;
(* umulh	x10, x27, x13                             #! PC = 0xaaaabe371a18 *)
mull x10 dcL x27 x13;
(* adds	x17, x9, x17                               #! PC = 0xaaaabe371a1c *)
adds carry x17 x9 x17;
(* adc	x20, x10, xzr                               #! PC = 0xaaaabe371a20 *)
adc x20 x10 0@uint64 carry;
(* eor	x27, x21, x25                               #! PC = 0xaaaabe371a24 *)
xor x27@uint64 x21 x25;
(* mul	x9, x27, x13                                #! PC = 0xaaaabe371a28 *)
mull dcH x9 x27 x13;
(* add	x20, x20, x9                                #! PC = 0xaaaabe371a2c *)
add x20 x20 x9;
(* eor	x27, x5, x26                                #! PC = 0xaaaabe371a30 *)
xor x27@uint64 x5 x26;
(* mul	x9, x27, x14                                #! PC = 0xaaaabe371a34 *)
mull dcH x9 x27 x14;
(* umulh	x10, x27, x14                             #! PC = 0xaaaabe371a38 *)
mull x10 dcL x27 x14;
(* adds	x17, x9, x17                               #! PC = 0xaaaabe371a3c *)
adds carry x17 x9 x17;
(* adc	x20, x10, x20                               #! PC = 0xaaaabe371a40 *)
adc x20 x10 x20 carry;
(* eor	x27, x22, x26                               #! PC = 0xaaaabe371a44 *)
xor x27@uint64 x22 x26;
(* mul	x9, x27, x14                                #! PC = 0xaaaabe371a48 *)
mull dcH x9 x27 x14;
(* add	x20, x20, x9                                #! PC = 0xaaaabe371a4c *)
add x20 x20 x9;
(* extr	x2, x20, x17, #60                          #! PC = 0xaaaabe371a50 *)
spl dc extr_H x20 60; spl extr_L dc x17 60; join x2 extr_H extr_L;
(* smull	v16.2d, v13.2s, v3.s[0]                   #! PC = 0xaaaabe371a54 *)
smull	%%v16.2d, %%v13.2s, %%v3.s[0]                   #! 0xaaaabe371a54 = 0xaaaabe371a54;
(* smlal2	v16.2d, v13.4s, v3.s[2]                  #! PC = 0xaaaabe371a58 *)
smlal2	%%v16.2d, %%v13.4s, %%v3.s[2]                  #! 0xaaaabe371a58 = 0xaaaabe371a58;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371a5c *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v3.s[0]                   #! PC = 0xaaaabe371a60 *)
smlal	%%v16.2d, %%v14.2s, %%v3.s[0]                   #! 0xaaaabe371a60 = 0xaaaabe371a60;
(* smlal2	v16.2d, v14.4s, v3.s[2]                  #! PC = 0xaaaabe371a64 *)
smlal2	%%v16.2d, %%v14.4s, %%v3.s[2]                  #! 0xaaaabe371a64 = 0xaaaabe371a64;
(* smlal	v16.2d, v13.2s, v3.s[1]                   #! PC = 0xaaaabe371a68 *)
smlal	%%v16.2d, %%v13.2s, %%v3.s[1]                   #! 0xaaaabe371a68 = 0xaaaabe371a68;
(* smlal2	v16.2d, v13.4s, v3.s[3]                  #! PC = 0xaaaabe371a6c *)
smlal2	%%v16.2d, %%v13.4s, %%v3.s[3]                  #! 0xaaaabe371a6c = 0xaaaabe371a6c;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371a70 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v3.s[1]                   #! PC = 0xaaaabe371a74 *)
smlal	%%v16.2d, %%v14.2s, %%v3.s[1]                   #! 0xaaaabe371a74 = 0xaaaabe371a74;
(* smlal2	v16.2d, v14.4s, v3.s[3]                  #! PC = 0xaaaabe371a78 *)
smlal2	%%v16.2d, %%v14.4s, %%v3.s[3]                  #! 0xaaaabe371a78 = 0xaaaabe371a78;
(* smlal	v16.2d, v13.2s, v4.s[0]                   #! PC = 0xaaaabe371a7c *)
smlal	%%v16.2d, %%v13.2s, %%v4.s[0]                   #! 0xaaaabe371a7c = 0xaaaabe371a7c;
(* smlal2	v16.2d, v13.4s, v4.s[2]                  #! PC = 0xaaaabe371a80 *)
smlal2	%%v16.2d, %%v13.4s, %%v4.s[2]                  #! 0xaaaabe371a80 = 0xaaaabe371a80;
(* and	v3.16b, v16.16b, v1.16b                     #! PC = 0xaaaabe371a84 *)
and %v3@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371a88 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v4.s[0]                   #! PC = 0xaaaabe371a8c *)
smlal	%%v16.2d, %%v14.2s, %%v4.s[0]                   #! 0xaaaabe371a8c = 0xaaaabe371a8c;
(* smlal2	v16.2d, v14.4s, v4.s[2]                  #! PC = 0xaaaabe371a90 *)
smlal2	%%v16.2d, %%v14.4s, %%v4.s[2]                  #! 0xaaaabe371a90 = 0xaaaabe371a90;
(* smlal	v16.2d, v13.2s, v4.s[1]                   #! PC = 0xaaaabe371a94 *)
smlal	%%v16.2d, %%v13.2s, %%v4.s[1]                   #! 0xaaaabe371a94 = 0xaaaabe371a94;
(* smlal2	v16.2d, v13.4s, v4.s[3]                  #! PC = 0xaaaabe371a98 *)
smlal2	%%v16.2d, %%v13.4s, %%v4.s[3]                  #! 0xaaaabe371a98 = 0xaaaabe371a98;
(* and	v17.16b, v16.16b, v1.16b                    #! PC = 0xaaaabe371a9c *)
and %v17@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371aa0 *)
split %v16 %dc %v16 30;
(* shl	v17.2d, v17.2d, #32                         #! PC = 0xaaaabe371aa4 *)
shls %dc %v17 %v17 [32, 32];
(* orr	v3.16b, v3.16b, v17.16b                     #! PC = 0xaaaabe371aa8 *)
or %v3@uint64[2] %v3 %v17;
(* smlal	v16.2d, v14.2s, v4.s[1]                   #! PC = 0xaaaabe371aac *)
smlal	%%v16.2d, %%v14.2s, %%v4.s[1]                   #! 0xaaaabe371aac = 0xaaaabe371aac;
(* smlal2	v16.2d, v14.4s, v4.s[3]                  #! PC = 0xaaaabe371ab0 *)
smlal2	%%v16.2d, %%v14.4s, %%v4.s[3]                  #! 0xaaaabe371ab0 = 0xaaaabe371ab0;
(* smlal	v16.2d, v13.2s, v5.s[0]                   #! PC = 0xaaaabe371ab4 *)
smlal	%%v16.2d, %%v13.2s, %%v5.s[0]                   #! 0xaaaabe371ab4 = 0xaaaabe371ab4;
(* smlal2	v16.2d, v13.4s, v5.s[2]                  #! PC = 0xaaaabe371ab8 *)
smlal2	%%v16.2d, %%v13.4s, %%v5.s[2]                  #! 0xaaaabe371ab8 = 0xaaaabe371ab8;
(* and	v4.16b, v16.16b, v1.16b                     #! PC = 0xaaaabe371abc *)
and %v4@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371ac0 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v5.s[0]                   #! PC = 0xaaaabe371ac4 *)
smlal	%%v16.2d, %%v14.2s, %%v5.s[0]                   #! 0xaaaabe371ac4 = 0xaaaabe371ac4;
(* smlal2	v16.2d, v14.4s, v5.s[2]                  #! PC = 0xaaaabe371ac8 *)
smlal2	%%v16.2d, %%v14.4s, %%v5.s[2]                  #! 0xaaaabe371ac8 = 0xaaaabe371ac8;
(* smlal	v16.2d, v13.2s, v5.s[1]                   #! PC = 0xaaaabe371acc *)
smlal	%%v16.2d, %%v13.2s, %%v5.s[1]                   #! 0xaaaabe371acc = 0xaaaabe371acc;
(* smlal2	v16.2d, v13.4s, v5.s[3]                  #! PC = 0xaaaabe371ad0 *)
smlal2	%%v16.2d, %%v13.4s, %%v5.s[3]                  #! 0xaaaabe371ad0 = 0xaaaabe371ad0;
(* and	v17.16b, v16.16b, v1.16b                    #! PC = 0xaaaabe371ad4 *)
and %v17@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371ad8 *)
split %v16 %dc %v16 30;
(* shl	v17.2d, v17.2d, #32                         #! PC = 0xaaaabe371adc *)
shls %dc %v17 %v17 [32, 32];
(* orr	v4.16b, v4.16b, v17.16b                     #! PC = 0xaaaabe371ae0 *)
or %v4@uint64[2] %v4 %v17;
(* smlal	v16.2d, v14.2s, v5.s[1]                   #! PC = 0xaaaabe371ae4 *)
smlal	%%v16.2d, %%v14.2s, %%v5.s[1]                   #! 0xaaaabe371ae4 = 0xaaaabe371ae4;
(* smlal2	v16.2d, v14.4s, v5.s[3]                  #! PC = 0xaaaabe371ae8 *)
smlal2	%%v16.2d, %%v14.4s, %%v5.s[3]                  #! 0xaaaabe371ae8 = 0xaaaabe371ae8;
(* smlal	v16.2d, v13.2s, v6.s[0]                   #! PC = 0xaaaabe371aec *)
smlal	%%v16.2d, %%v13.2s, %%v6.s[0]                   #! 0xaaaabe371aec = 0xaaaabe371aec;
(* smlal2	v16.2d, v13.4s, v6.s[2]                  #! PC = 0xaaaabe371af0 *)
smlal2	%%v16.2d, %%v13.4s, %%v6.s[2]                  #! 0xaaaabe371af0 = 0xaaaabe371af0;
(* and	v5.16b, v16.16b, v1.16b                     #! PC = 0xaaaabe371af4 *)
and %v5@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371af8 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v6.s[0]                   #! PC = 0xaaaabe371afc *)
smlal	%%v16.2d, %%v14.2s, %%v6.s[0]                   #! 0xaaaabe371afc = 0xaaaabe371afc;
(* smlal2	v16.2d, v14.4s, v6.s[2]                  #! PC = 0xaaaabe371b00 *)
smlal2	%%v16.2d, %%v14.4s, %%v6.s[2]                  #! 0xaaaabe371b00 = 0xaaaabe371b00;
(* smlal	v16.2d, v13.2s, v6.s[1]                   #! PC = 0xaaaabe371b04 *)
smlal	%%v16.2d, %%v13.2s, %%v6.s[1]                   #! 0xaaaabe371b04 = 0xaaaabe371b04;
(* smlal2	v16.2d, v13.4s, v6.s[3]                  #! PC = 0xaaaabe371b08 *)
smlal2	%%v16.2d, %%v13.4s, %%v6.s[3]                  #! 0xaaaabe371b08 = 0xaaaabe371b08;
(* and	v17.16b, v16.16b, v1.16b                    #! PC = 0xaaaabe371b0c *)
and %v17@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371b10 *)
split %v16 %dc %v16 30;
(* shl	v17.2d, v17.2d, #32                         #! PC = 0xaaaabe371b14 *)
shls %dc %v17 %v17 [32, 32];
(* orr	v5.16b, v5.16b, v17.16b                     #! PC = 0xaaaabe371b18 *)
or %v5@uint64[2] %v5 %v17;
(* smlal	v16.2d, v14.2s, v6.s[1]                   #! PC = 0xaaaabe371b1c *)
smlal	%%v16.2d, %%v14.2s, %%v6.s[1]                   #! 0xaaaabe371b1c = 0xaaaabe371b1c;
(* smlal2	v16.2d, v14.4s, v6.s[3]                  #! PC = 0xaaaabe371b20 *)
smlal2	%%v16.2d, %%v14.4s, %%v6.s[3]                  #! 0xaaaabe371b20 = 0xaaaabe371b20;
(* smlal	v16.2d, v13.2s, v7.s[0]                   #! PC = 0xaaaabe371b24 *)
smlal	%%v16.2d, %%v13.2s, %%v7.s[0]                   #! 0xaaaabe371b24 = 0xaaaabe371b24;
(* smlal2	v16.2d, v13.4s, v7.s[2]                  #! PC = 0xaaaabe371b28 *)
smlal2	%%v16.2d, %%v13.4s, %%v7.s[2]                  #! 0xaaaabe371b28 = 0xaaaabe371b28;
(* and	v6.16b, v16.16b, v1.16b                     #! PC = 0xaaaabe371b2c *)
and %v6@uint64[2] %v16 %v1;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe371b30 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v7.s[0]                   #! PC = 0xaaaabe371b34 *)
smlal	%%v16.2d, %%v14.2s, %%v7.s[0]                   #! 0xaaaabe371b34 = 0xaaaabe371b34;
(* smlal2	v16.2d, v14.4s, v7.s[2]                  #! PC = 0xaaaabe371b38 *)
smlal2	%%v16.2d, %%v14.4s, %%v7.s[2]                  #! 0xaaaabe371b38 = 0xaaaabe371b38;
(* and	v17.16b, v16.16b, v1.16b                    #! PC = 0xaaaabe371b3c *)
and %v17@uint64[2] %v16 %v1;
(* sshr	v7.2d, v16.2d, #30                         #! PC = 0xaaaabe371b40 *)
split %v7 %dc %v16 30;
(* shl	v17.2d, v17.2d, #32                         #! PC = 0xaaaabe371b44 *)
shls %dc %v17 %v17 [32, 32];
(* orr	v6.16b, v6.16b, v17.16b                     #! PC = 0xaaaabe371b48 *)
or %v6@uint64[2] %v6 %v17;
(* and	x7, x1, #0xfffff                            #! PC = 0xaaaabe371b4c *)
and x7@uint64 x1 0xfffff@uint64;
(* and	x8, x2, #0xfffff                            #! PC = 0xaaaabe371b50 *)
and x8@uint64 x2 0xfffff@uint64;
(* orr	x7, x7, #0xfffffe0000000000                 #! PC = 0xaaaabe371b54 *)
or x7@uint64 x7 0xfffffe0000000000@uint64;
(* orr	x8, x8, #0xc000000000000000                 #! PC = 0xaaaabe371b58 *)
or x8@uint64 x8 0xc000000000000000@uint64;
(* tst	x8, #0x1                                    #! PC = 0xaaaabe371b5c *)
spl dc x8_lo x8 1;
and ne@bit x8_lo 1@bit;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371b60 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371b64 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371b68 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371b6c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371b70 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371b74 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371b78 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371b7c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371b80 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371b84 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371b88 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371b8c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371b90 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371b94 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371b98 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371b9c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371ba0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371ba4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371ba8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371bac *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371bb0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371bb4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371bb8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371bbc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371bc0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371bc4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371bc8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371bcc *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371bd0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371bd4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371bd8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371bdc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371be0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371be4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371be8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371bec *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371bf0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371bf4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371bf8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371bfc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c00 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c04 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c08 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c0c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371c10 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371c14 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371c18 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371c1c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371c20 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c24 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c28 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c2c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c30 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371c34 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371c38 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371c3c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371c40 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371c44 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c48 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c4c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c50 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c54 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371c58 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371c5c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371c60 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371c64 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371c68 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c6c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c70 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c74 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c78 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371c7c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371c80 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371c84 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371c88 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371c8c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371c90 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371c94 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371c98 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371c9c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371ca0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371ca4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371ca8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371cac *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371cb0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371cb4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371cb8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371cbc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371cc0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371cc4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371cc8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371ccc *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371cd0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371cd4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371cd8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371cdc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371ce0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371ce4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371ce8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371cec *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371cf0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371cf4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371cf8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371cfc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d00 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d04 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d08 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d0c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371d10 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371d14 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371d18 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371d1c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371d20 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d24 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d28 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d2c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d30 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371d34 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371d38 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371d3c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371d40 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371d44 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d48 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d4c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d50 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d54 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371d58 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371d5c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371d60 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371d64 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371d68 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d6c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d70 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d74 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d78 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371d7c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371d80 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371d84 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371d88 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371d8c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371d90 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371d94 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371d98 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371d9c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371da0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371da4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371da8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371dac *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371db0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371db4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371db8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371dbc *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371dc0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371dc4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371dc8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371dcc *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371dd0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371dd4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371dd8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371ddc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371de0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371de4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371de8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371dec *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371df0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371df4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371df8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371dfc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371e00 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371e04 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371e08 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371e0c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371e10 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371e14 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371e18 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371e1c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371e20 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371e24 *)
add x3 x3 0x2@sint64;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371e28 *)
ssplit x8 dcL x8 1;
(* add	x12, x7, x6                                 #! PC = 0xaaaabe371e2c *)
add x12 x7 x6;
(* asr	x12, x12, #42                               #! PC = 0xaaaabe371e30 *)
ssplit x12 dcL x12 42;
(* add	x11, x7, #0x100, lsl #12                    #! PC = 0xaaaabe371e34 *)
add x11 x7 0x100@sint64, lsl;
(* lsl	x11, x11, #22                               #! PC = 0xaaaabe371e38 *)
split dcH x11 x11 (64-22); shl x11 x11 22;
(* asr	x11, x11, #43                               #! PC = 0xaaaabe371e3c *)
ssplit x11 dcL x11 43;
(* add	x14, x8, x6                                 #! PC = 0xaaaabe371e40 *)
add x14 x8 x6;
(* asr	x14, x14, #42                               #! PC = 0xaaaabe371e44 *)
ssplit x14 dcL x14 42;
(* add	x13, x8, #0x100, lsl #12                    #! PC = 0xaaaabe371e48 *)
add x13 x8 0x100@sint64, lsl;
(* lsl	x13, x13, #22                               #! PC = 0xaaaabe371e4c *)
split dcH x13 x13 (64-22); shl x13 x13 22;
(* asr	x13, x13, #43                               #! PC = 0xaaaabe371e50 *)
ssplit x13 dcL x13 43;
(* mul	x9, x11, x1                                 #! PC = 0xaaaabe371e54 *)
mull dcH x9 x11 x1;
(* madd	x9, x12, x2, x9                            #! PC = 0xaaaabe371e58 *)
mull dcH mul_tmp x12 x2;
adds dc x9 mul_tmp x9;
(* asr	x9, x9, #20                                 #! PC = 0xaaaabe371e5c *)
ssplit x9 dcL x9 20;
(* mul	x10, x13, x1                                #! PC = 0xaaaabe371e60 *)
mull dcH x10 x13 x1;
(* madd	x10, x14, x2, x10                          #! PC = 0xaaaabe371e64 *)
mull dcH mul_tmp x14 x2;
adds dc x10 mul_tmp x10;
(* asr	x2, x10, #20                                #! PC = 0xaaaabe371e68 *)
ssplit x2 dcL x10 20;
(* mov	x1, x9                                      #! PC = 0xaaaabe371e6c *)
mov x1 x9;
(* mov	w4, v3.s[0]                                 #! PC = 0xaaaabe371e70 *)
mov w4 v3.s[0];
(* mov	w27, v3.s[1]                                #! PC = 0xaaaabe371e74 *)
mov w27 v3.s[1];
(* add	x4, x4, x27, lsl #30                        #! PC = 0xaaaabe371e78 *)
add x4 x4 x27, lsl;
(* mov	w27, v4.s[0]                                #! PC = 0xaaaabe371e7c *)
mov w27 v4.s[0];
(* add	x4, x4, x27, lsl #60                        #! PC = 0xaaaabe371e80 *)
add x4 x4 x27, lsl;
(* add	x21, xzr, x27, lsr #4                       #! PC = 0xaaaabe371e84 *)
add	%%x21, xzr, %%x27, lsr #4                       #! 0xaaaabe371e84 = 0xaaaabe371e84;
(* mov	w27, v4.s[1]                                #! PC = 0xaaaabe371e88 *)
mov w27 v4.s[1];
(* add	x21, x21, x27, lsl #26                      #! PC = 0xaaaabe371e8c *)
add x21 x21 x27, lsl;
(* mov	w5, v3.s[2]                                 #! PC = 0xaaaabe371e90 *)
mov w5 v3.s[2];
(* mov	w27, v3.s[3]                                #! PC = 0xaaaabe371e94 *)
mov w27 v3.s[3];
(* add	x5, x5, x27, lsl #30                        #! PC = 0xaaaabe371e98 *)
add x5 x5 x27, lsl;
(* mov	w27, v4.s[2]                                #! PC = 0xaaaabe371e9c *)
mov w27 v4.s[2];
(* add	x5, x5, x27, lsl #60                        #! PC = 0xaaaabe371ea0 *)
add x5 x5 x27, lsl;
(* add	x22, xzr, x27, lsr #4                       #! PC = 0xaaaabe371ea4 *)
add	%%x22, xzr, %%x27, lsr #4                       #! 0xaaaabe371ea4 = 0xaaaabe371ea4;
(* mov	w27, v4.s[3]                                #! PC = 0xaaaabe371ea8 *)
mov w27 v4.s[3];
(* add	x22, x22, x27, lsl #26                      #! PC = 0xaaaabe371eac *)
add x22 x22 x27, lsl;
(* and	x7, x1, #0xfffff                            #! PC = 0xaaaabe371eb0 *)
and x7@uint64 x1 0xfffff@uint64;
(* and	x8, x2, #0xfffff                            #! PC = 0xaaaabe371eb4 *)
and x8@uint64 x2 0xfffff@uint64;
(* orr	x7, x7, #0xfffffe0000000000                 #! PC = 0xaaaabe371eb8 *)
or x7@uint64 x7 0xfffffe0000000000@uint64;
(* orr	x8, x8, #0xc000000000000000                 #! PC = 0xaaaabe371ebc *)
or x8@uint64 x8 0xc000000000000000@uint64;
(* tst	x8, #0x1                                    #! PC = 0xaaaabe371ec0 *)
spl dc x8_lo x8 1;
and ne@bit x8_lo 1@bit;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371ec4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371ec8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371ecc *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371ed0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371ed4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371ed8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371edc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371ee0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371ee4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371ee8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371eec *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371ef0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371ef4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371ef8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371efc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f00 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f04 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f08 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f0c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371f10 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371f14 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371f18 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371f1c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371f20 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f24 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f28 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f2c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f30 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371f34 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371f38 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371f3c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371f40 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371f44 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f48 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f4c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f50 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f54 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371f58 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371f5c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371f60 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371f64 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371f68 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f6c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f70 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f74 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f78 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371f7c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371f80 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371f84 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371f88 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371f8c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371f90 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371f94 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371f98 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371f9c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371fa0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371fa4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371fa8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371fac *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371fb0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371fb4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371fb8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371fbc *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371fc0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371fc4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371fc8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371fcc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371fd0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371fd4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371fd8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe371fdc *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe371fe0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe371fe4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe371fe8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe371fec *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe371ff0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe371ff4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe371ff8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe371ffc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372000 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372004 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372008 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37200c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372010 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372014 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372018 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37201c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372020 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372024 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372028 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37202c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372030 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372034 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372038 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37203c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372040 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372044 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372048 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37204c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372050 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372054 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372058 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37205c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372060 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372064 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372068 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37206c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372070 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372074 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372078 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37207c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372080 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372084 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372088 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37208c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372090 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372094 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372098 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37209c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3720a0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3720a4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3720a8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3720ac *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3720b0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3720b4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3720b8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3720bc *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3720c0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3720c4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3720c8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3720cc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3720d0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3720d4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3720d8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3720dc *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3720e0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3720e4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3720e8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3720ec *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3720f0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3720f4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3720f8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3720fc *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372100 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372104 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372108 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37210c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372110 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372114 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372118 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37211c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372120 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372124 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372128 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37212c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372130 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372134 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372138 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37213c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372140 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372144 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372148 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37214c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372150 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372154 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372158 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37215c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372160 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372164 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372168 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37216c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372170 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372174 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372178 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37217c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372180 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372184 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372188 *)
add x3 x3 0x2@sint64;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37218c *)
ssplit x8 dcL x8 1;
(* add	x16, x7, x6                                 #! PC = 0xaaaabe372190 *)
add x16 x7 x6;
(* asr	x16, x16, #42                               #! PC = 0xaaaabe372194 *)
ssplit x16 dcL x16 42;
(* add	x15, x7, #0x100, lsl #12                    #! PC = 0xaaaabe372198 *)
add x15 x7 0x100@sint64, lsl;
(* lsl	x15, x15, #22                               #! PC = 0xaaaabe37219c *)
split dcH x15 x15 (64-22); shl x15 x15 22;
(* asr	x15, x15, #43                               #! PC = 0xaaaabe3721a0 *)
ssplit x15 dcL x15 43;
(* add	x20, x8, x6                                 #! PC = 0xaaaabe3721a4 *)
add x20 x8 x6;
(* asr	x20, x20, #42                               #! PC = 0xaaaabe3721a8 *)
ssplit x20 dcL x20 42;
(* add	x17, x8, #0x100, lsl #12                    #! PC = 0xaaaabe3721ac *)
add x17 x8 0x100@sint64, lsl;
(* lsl	x17, x17, #22                               #! PC = 0xaaaabe3721b0 *)
split dcH x17 x17 (64-22); shl x17 x17 22;
(* asr	x17, x17, #43                               #! PC = 0xaaaabe3721b4 *)
ssplit x17 dcL x17 43;
(* mul	x9, x15, x1                                 #! PC = 0xaaaabe3721b8 *)
mull dcH x9 x15 x1;
(* madd	x9, x16, x2, x9                            #! PC = 0xaaaabe3721bc *)
mull dcH mul_tmp x16 x2;
adds dc x9 mul_tmp x9;
(* asr	x9, x9, #20                                 #! PC = 0xaaaabe3721c0 *)
ssplit x9 dcL x9 20;
(* mul	x10, x17, x1                                #! PC = 0xaaaabe3721c4 *)
mull dcH x10 x17 x1;
(* madd	x10, x20, x2, x10                          #! PC = 0xaaaabe3721c8 *)
mull dcH mul_tmp x20 x2;
adds dc x10 mul_tmp x10;
(* asr	x2, x10, #20                                #! PC = 0xaaaabe3721cc *)
ssplit x2 dcL x10 20;
(* mov	x1, x9                                      #! PC = 0xaaaabe3721d0 *)
mov x1 x9;
(* mul	x9, x15, x11                                #! PC = 0xaaaabe3721d4 *)
mull dcH x9 x15 x11;
(* madd	x10, x16, x13, x9                          #! PC = 0xaaaabe3721d8 *)
mull dcH mul_tmp x16 x13;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x11                                #! PC = 0xaaaabe3721dc *)
mull dcH x9 x17 x11;
(* madd	x13, x20, x13, x9                          #! PC = 0xaaaabe3721e0 *)
mull dcH mul_tmp x20 x13;
adds dc x13 mul_tmp x9;
(* mov	x11, x10                                    #! PC = 0xaaaabe3721e4 *)
mov x11 x10;
(* mul	x9, x15, x12                                #! PC = 0xaaaabe3721e8 *)
mull dcH x9 x15 x12;
(* madd	x10, x16, x14, x9                          #! PC = 0xaaaabe3721ec *)
mull dcH mul_tmp x16 x14;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x12                                #! PC = 0xaaaabe3721f0 *)
mull dcH x9 x17 x12;
(* madd	x14, x20, x14, x9                          #! PC = 0xaaaabe3721f4 *)
mull dcH mul_tmp x20 x14;
adds dc x14 mul_tmp x9;
(* mov	x12, x10                                    #! PC = 0xaaaabe3721f8 *)
mov x12 x10;
(* mov	x9, #0x13                  	// #19          #! PC = 0xaaaabe3721fc *)
mov x9 0x13@uint64;
(* dup	v16.2d, x9                                  #! PC = 0xaaaabe372200 *)
mov %v16 [x9,x9];
(* smull	v17.2d, v13.2s, v8.s[0]                   #! PC = 0xaaaabe372204 *)
smull	%%v17.2d, %%v13.2s, %%v8.s[0]                   #! 0xaaaabe372204 = 0xaaaabe372204;
(* smlal2	v17.2d, v13.4s, v8.s[2]                  #! PC = 0xaaaabe372208 *)
smlal2	%%v17.2d, %%v13.4s, %%v8.s[2]                  #! 0xaaaabe372208 = 0xaaaabe372208;
(* mul	v19.4s, v17.4s, v15.4s                      #! PC = 0xaaaabe37220c *)
mul %v19 %v17 %v15;
(* and	v19.16b, v19.16b, v1.16b                    #! PC = 0xaaaabe372210 *)
and %v19@uint64[2] %v19 %v1;
(* uzp1	v19.4s, v19.4s, v19.4s                     #! PC = 0xaaaabe372214 *)
mov %v19 [%v19[0], %v19[2], %v19[0], %v19[2]];
(* smlsl	v17.2d, v19.2s, v16.s[0]                  #! PC = 0xaaaabe372218 *)
smlsl	%%v17.2d, %%v19.2s, %%v16.s[0]                  #! 0xaaaabe372218 = 0xaaaabe372218;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe37221c *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v8.s[0]                   #! PC = 0xaaaabe372220 *)
smlal	%%v17.2d, %%v14.2s, %%v8.s[0]                   #! 0xaaaabe372220 = 0xaaaabe372220;
(* smlal2	v17.2d, v14.4s, v8.s[2]                  #! PC = 0xaaaabe372224 *)
smlal2	%%v17.2d, %%v14.4s, %%v8.s[2]                  #! 0xaaaabe372224 = 0xaaaabe372224;
(* smlal	v17.2d, v13.2s, v8.s[1]                   #! PC = 0xaaaabe372228 *)
smlal	%%v17.2d, %%v13.2s, %%v8.s[1]                   #! 0xaaaabe372228 = 0xaaaabe372228;
(* smlal2	v17.2d, v13.4s, v8.s[3]                  #! PC = 0xaaaabe37222c *)
smlal2	%%v17.2d, %%v13.4s, %%v8.s[3]                  #! 0xaaaabe37222c = 0xaaaabe37222c;
(* mul	v20.4s, v17.4s, v15.4s                      #! PC = 0xaaaabe372230 *)
mul %v20 %v17 %v15;
(* and	v20.16b, v20.16b, v1.16b                    #! PC = 0xaaaabe372234 *)
and %v20@uint64[2] %v20 %v1;
(* uzp1	v20.4s, v20.4s, v20.4s                     #! PC = 0xaaaabe372238 *)
mov %v20 [%v20[0], %v20[2], %v20[0], %v20[2]];
(* smlsl	v17.2d, v20.2s, v16.s[0]                  #! PC = 0xaaaabe37223c *)
smlsl	%%v17.2d, %%v20.2s, %%v16.s[0]                  #! 0xaaaabe37223c = 0xaaaabe37223c;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe372240 *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v8.s[1]                   #! PC = 0xaaaabe372244 *)
smlal	%%v17.2d, %%v14.2s, %%v8.s[1]                   #! 0xaaaabe372244 = 0xaaaabe372244;
(* smlal2	v17.2d, v14.4s, v8.s[3]                  #! PC = 0xaaaabe372248 *)
smlal2	%%v17.2d, %%v14.4s, %%v8.s[3]                  #! 0xaaaabe372248 = 0xaaaabe372248;
(* smlal	v17.2d, v13.2s, v9.s[0]                   #! PC = 0xaaaabe37224c *)
smlal	%%v17.2d, %%v13.2s, %%v9.s[0]                   #! 0xaaaabe37224c = 0xaaaabe37224c;
(* smlal2	v17.2d, v13.4s, v9.s[2]                  #! PC = 0xaaaabe372250 *)
smlal2	%%v17.2d, %%v13.4s, %%v9.s[2]                  #! 0xaaaabe372250 = 0xaaaabe372250;
(* and	v8.16b, v17.16b, v1.16b                     #! PC = 0xaaaabe372254 *)
and %v8@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe372258 *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v9.s[0]                   #! PC = 0xaaaabe37225c *)
smlal	%%v17.2d, %%v14.2s, %%v9.s[0]                   #! 0xaaaabe37225c = 0xaaaabe37225c;
(* smlal2	v17.2d, v14.4s, v9.s[2]                  #! PC = 0xaaaabe372260 *)
smlal2	%%v17.2d, %%v14.4s, %%v9.s[2]                  #! 0xaaaabe372260 = 0xaaaabe372260;
(* smlal	v17.2d, v13.2s, v9.s[1]                   #! PC = 0xaaaabe372264 *)
smlal	%%v17.2d, %%v13.2s, %%v9.s[1]                   #! 0xaaaabe372264 = 0xaaaabe372264;
(* smlal2	v17.2d, v13.4s, v9.s[3]                  #! PC = 0xaaaabe372268 *)
smlal2	%%v17.2d, %%v13.4s, %%v9.s[3]                  #! 0xaaaabe372268 = 0xaaaabe372268;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe37226c *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe372270 *)
split %v17 %dc %v17 30;
(* sli	v8.2d, v18.2d, #32                          #! PC = 0xaaaabe372274 *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v8 %v8 32; or %v8@uint64[2] %slih %v8;
(* smlal	v17.2d, v14.2s, v9.s[1]                   #! PC = 0xaaaabe372278 *)
smlal	%%v17.2d, %%v14.2s, %%v9.s[1]                   #! 0xaaaabe372278 = 0xaaaabe372278;
(* smlal2	v17.2d, v14.4s, v9.s[3]                  #! PC = 0xaaaabe37227c *)
smlal2	%%v17.2d, %%v14.4s, %%v9.s[3]                  #! 0xaaaabe37227c = 0xaaaabe37227c;
(* smlal	v17.2d, v13.2s, v10.s[0]                  #! PC = 0xaaaabe372280 *)
smlal	%%v17.2d, %%v13.2s, %%v10.s[0]                  #! 0xaaaabe372280 = 0xaaaabe372280;
(* smlal2	v17.2d, v13.4s, v10.s[2]                 #! PC = 0xaaaabe372284 *)
smlal2	%%v17.2d, %%v13.4s, %%v10.s[2]                 #! 0xaaaabe372284 = 0xaaaabe372284;
(* and	v9.16b, v17.16b, v1.16b                     #! PC = 0xaaaabe372288 *)
and %v9@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe37228c *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v10.s[0]                  #! PC = 0xaaaabe372290 *)
smlal	%%v17.2d, %%v14.2s, %%v10.s[0]                  #! 0xaaaabe372290 = 0xaaaabe372290;
(* smlal2	v17.2d, v14.4s, v10.s[2]                 #! PC = 0xaaaabe372294 *)
smlal2	%%v17.2d, %%v14.4s, %%v10.s[2]                 #! 0xaaaabe372294 = 0xaaaabe372294;
(* smlal	v17.2d, v13.2s, v10.s[1]                  #! PC = 0xaaaabe372298 *)
smlal	%%v17.2d, %%v13.2s, %%v10.s[1]                  #! 0xaaaabe372298 = 0xaaaabe372298;
(* smlal2	v17.2d, v13.4s, v10.s[3]                 #! PC = 0xaaaabe37229c *)
smlal2	%%v17.2d, %%v13.4s, %%v10.s[3]                 #! 0xaaaabe37229c = 0xaaaabe37229c;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe3722a0 *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3722a4 *)
split %v17 %dc %v17 30;
(* sli	v9.2d, v18.2d, #32                          #! PC = 0xaaaabe3722a8 *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v9 %v9 32; or %v9@uint64[2] %slih %v9;
(* smlal	v17.2d, v14.2s, v10.s[1]                  #! PC = 0xaaaabe3722ac *)
smlal	%%v17.2d, %%v14.2s, %%v10.s[1]                  #! 0xaaaabe3722ac = 0xaaaabe3722ac;
(* smlal2	v17.2d, v14.4s, v10.s[3]                 #! PC = 0xaaaabe3722b0 *)
smlal2	%%v17.2d, %%v14.4s, %%v10.s[3]                 #! 0xaaaabe3722b0 = 0xaaaabe3722b0;
(* smlal	v17.2d, v13.2s, v11.s[0]                  #! PC = 0xaaaabe3722b4 *)
smlal	%%v17.2d, %%v13.2s, %%v11.s[0]                  #! 0xaaaabe3722b4 = 0xaaaabe3722b4;
(* smlal2	v17.2d, v13.4s, v11.s[2]                 #! PC = 0xaaaabe3722b8 *)
smlal2	%%v17.2d, %%v13.4s, %%v11.s[2]                 #! 0xaaaabe3722b8 = 0xaaaabe3722b8;
(* and	v10.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe3722bc *)
and %v10@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3722c0 *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v11.s[0]                  #! PC = 0xaaaabe3722c4 *)
smlal	%%v17.2d, %%v14.2s, %%v11.s[0]                  #! 0xaaaabe3722c4 = 0xaaaabe3722c4;
(* smlal2	v17.2d, v14.4s, v11.s[2]                 #! PC = 0xaaaabe3722c8 *)
smlal2	%%v17.2d, %%v14.4s, %%v11.s[2]                 #! 0xaaaabe3722c8 = 0xaaaabe3722c8;
(* smlal	v17.2d, v13.2s, v11.s[1]                  #! PC = 0xaaaabe3722cc *)
smlal	%%v17.2d, %%v13.2s, %%v11.s[1]                  #! 0xaaaabe3722cc = 0xaaaabe3722cc;
(* smlal2	v17.2d, v13.4s, v11.s[3]                 #! PC = 0xaaaabe3722d0 *)
smlal2	%%v17.2d, %%v13.4s, %%v11.s[3]                 #! 0xaaaabe3722d0 = 0xaaaabe3722d0;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe3722d4 *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3722d8 *)
split %v17 %dc %v17 30;
(* sli	v10.2d, v18.2d, #32                         #! PC = 0xaaaabe3722dc *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v10 %v10 32; or %v10@uint64[2] %slih %v10;
(* smlal	v17.2d, v14.2s, v11.s[1]                  #! PC = 0xaaaabe3722e0 *)
smlal	%%v17.2d, %%v14.2s, %%v11.s[1]                  #! 0xaaaabe3722e0 = 0xaaaabe3722e0;
(* smlal2	v17.2d, v14.4s, v11.s[3]                 #! PC = 0xaaaabe3722e4 *)
smlal2	%%v17.2d, %%v14.4s, %%v11.s[3]                 #! 0xaaaabe3722e4 = 0xaaaabe3722e4;
(* smlal	v17.2d, v13.2s, v12.s[0]                  #! PC = 0xaaaabe3722e8 *)
smlal	%%v17.2d, %%v13.2s, %%v12.s[0]                  #! 0xaaaabe3722e8 = 0xaaaabe3722e8;
(* smlal2	v17.2d, v13.4s, v12.s[2]                 #! PC = 0xaaaabe3722ec *)
smlal2	%%v17.2d, %%v13.4s, %%v12.s[2]                 #! 0xaaaabe3722ec = 0xaaaabe3722ec;
(* ushll	v19.2d, v19.2s, #15                       #! PC = 0xaaaabe3722f0 *)
ushll	%%v19.2d, %%v19.2s, #15                       #! 0xaaaabe3722f0 = 0xaaaabe3722f0;
(* add	v17.2d, v17.2d, v19.2d                      #! PC = 0xaaaabe3722f4 *)
add	%%v17.2d, %%v17.2d, %%v19.2d                      #! 0xaaaabe3722f4 = 0xaaaabe3722f4;
(* and	v11.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe3722f8 *)
and %v11@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3722fc *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v12.s[0]                  #! PC = 0xaaaabe372300 *)
smlal	%%v17.2d, %%v14.2s, %%v12.s[0]                  #! 0xaaaabe372300 = 0xaaaabe372300;
(* smlal2	v17.2d, v14.4s, v12.s[2]                 #! PC = 0xaaaabe372304 *)
smlal2	%%v17.2d, %%v14.4s, %%v12.s[2]                 #! 0xaaaabe372304 = 0xaaaabe372304;
(* ushll	v20.2d, v20.2s, #15                       #! PC = 0xaaaabe372308 *)
ushll	%%v20.2d, %%v20.2s, #15                       #! 0xaaaabe372308 = 0xaaaabe372308;
(* add	v17.2d, v17.2d, v20.2d                      #! PC = 0xaaaabe37230c *)
add	%%v17.2d, %%v17.2d, %%v20.2d                      #! 0xaaaabe37230c = 0xaaaabe37230c;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe372310 *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v12.2d, v17.2d, #30                        #! PC = 0xaaaabe372314 *)
split %v12 %dc %v17 30;
(* sli	v11.2d, v18.2d, #32                         #! PC = 0xaaaabe372318 *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v11 %v11 32; or %v11@uint64[2] %slih %v11;
(* sshr	v18.2d, v12.2d, #15                        #! PC = 0xaaaabe37231c *)
split %v18 %dc %v12 15;
(* shl	v17.2d, v18.2d, #15                         #! PC = 0xaaaabe372320 *)
shls %dc %v17 %v18 [15, 15];
(* sub	v12.2d, v12.2d, v17.2d                      #! PC = 0xaaaabe372324 *)
sub	%%v12.2d, %%v12.2d, %%v17.2d                      #! 0xaaaabe372324 = 0xaaaabe372324;
(* mla	v8.4s, v18.4s, v16.4s                       #! PC = 0xaaaabe372328 *)
mull %dc %mla %v18 %v16; add %v8 %v8 %mla;
(* and	x7, x1, #0xfffff                            #! PC = 0xaaaabe37232c *)
and x7@uint64 x1 0xfffff@uint64;
(* and	x8, x2, #0xfffff                            #! PC = 0xaaaabe372330 *)
and x8@uint64 x2 0xfffff@uint64;
(* orr	x7, x7, #0xfffffe0000000000                 #! PC = 0xaaaabe372334 *)
or x7@uint64 x7 0xfffffe0000000000@uint64;
(* orr	x8, x8, #0xc000000000000000                 #! PC = 0xaaaabe372338 *)
or x8@uint64 x8 0xc000000000000000@uint64;
(* tst	x8, #0x1                                    #! PC = 0xaaaabe37233c *)
spl dc x8_lo x8 1;
and ne@bit x8_lo 1@bit;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372340 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372344 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372348 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37234c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372350 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372354 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372358 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37235c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372360 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372364 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372368 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37236c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372370 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372374 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372378 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37237c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372380 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372384 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372388 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37238c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372390 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372394 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372398 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37239c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3723a0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3723a4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3723a8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3723ac *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3723b0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3723b4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3723b8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3723bc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3723c0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3723c4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3723c8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3723cc *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3723d0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3723d4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3723d8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3723dc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3723e0 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3723e4 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3723e8 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3723ec *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3723f0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3723f4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3723f8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3723fc *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372400 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372404 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372408 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37240c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372410 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372414 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372418 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37241c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372420 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372424 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372428 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37242c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372430 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372434 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372438 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37243c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372440 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372444 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372448 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37244c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372450 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372454 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372458 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37245c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372460 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372464 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372468 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37246c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372470 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372474 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372478 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37247c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372480 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372484 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372488 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37248c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372490 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372494 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372498 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37249c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3724a0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3724a4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3724a8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3724ac *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3724b0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3724b4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3724b8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3724bc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3724c0 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3724c4 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3724c8 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3724cc *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3724d0 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3724d4 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3724d8 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3724dc *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3724e0 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3724e4 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3724e8 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3724ec *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3724f0 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3724f4 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3724f8 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3724fc *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372500 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372504 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372508 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37250c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372510 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372514 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372518 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe37251c *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372520 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372524 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372528 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe37252c *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372530 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372534 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372538 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe37253c *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372540 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372544 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372548 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe37254c *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372550 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372554 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe372558 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe37255c *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372560 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372564 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe372568 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe37256c *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372570 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372574 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe372578 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe37257c *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe372580 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe372584 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe372588 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe37258c *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe372590 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe372594 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe372598 *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe37259c *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3725a0 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3725a4 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3725a8 *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3725ac *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3725b0 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3725b4 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3725b8 *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3725bc *)
add x3 x3 0x2@sint64;
(* tst	x8, #0x2                                    #! PC = 0xaaaabe3725c0 *)
spl dc x8_lo x8 2;
spl x8_target dc x8_lo 1;
and ne@bit x8_target 1@bit;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3725c4 *)
ssplit x8 dcL x8 1;
(* csel	x10, x7, xzr, ne	// ne = any               #! PC = 0xaaaabe3725c8 *)
cmov x10 ne x7 0@sint64;
(* ccmp	x3, xzr, #0x8, ne	// ne = any              #! PC = 0xaaaabe3725cc *)
spl ge dc x3 63;
not ge@bit ge;
cmov ge ne ge 0@bit;	// ne = any;
(* cneg	x3, x3, ge	// ge = tcont                   #! PC = 0xaaaabe3725d0 *)
subs dc x3_neg 0@sint64 x3;
cmov x3 ge x3_neg x3;	// ge = tcont;;
(* cneg	x10, x10, ge	// ge = tcont                 #! PC = 0xaaaabe3725d4 *)
subs dc x10_neg 0@sint64 x10;
cmov x10 ge x10_neg x10;	// ge = tcont;;
(* csel	x7, x8, x7, ge	// ge = tcont               #! PC = 0xaaaabe3725d8 *)
cmov x7 ge x8 x7;
(* add	x8, x8, x10                                 #! PC = 0xaaaabe3725dc *)
add x8 x8 x10;
(* add	x3, x3, #0x2                                #! PC = 0xaaaabe3725e0 *)
add x3 x3 0x2@sint64;
(* asr	x8, x8, #1                                  #! PC = 0xaaaabe3725e4 *)
ssplit x8 dcL x8 1;
(* add	x16, x7, x6                                 #! PC = 0xaaaabe3725e8 *)
add x16 x7 x6;
(* asr	x16, x16, #42                               #! PC = 0xaaaabe3725ec *)
ssplit x16 dcL x16 42;
(* add	x15, x7, #0x100, lsl #12                    #! PC = 0xaaaabe3725f0 *)
add x15 x7 0x100@sint64, lsl;
(* lsl	x15, x15, #22                               #! PC = 0xaaaabe3725f4 *)
split dcH x15 x15 (64-22); shl x15 x15 22;
(* asr	x15, x15, #43                               #! PC = 0xaaaabe3725f8 *)
ssplit x15 dcL x15 43;
(* add	x20, x8, x6                                 #! PC = 0xaaaabe3725fc *)
add x20 x8 x6;
(* asr	x20, x20, #42                               #! PC = 0xaaaabe372600 *)
ssplit x20 dcL x20 42;
(* add	x17, x8, #0x100, lsl #12                    #! PC = 0xaaaabe372604 *)
add x17 x8 0x100@sint64, lsl;
(* lsl	x17, x17, #22                               #! PC = 0xaaaabe372608 *)
split dcH x17 x17 (64-22); shl x17 x17 22;
(* asr	x17, x17, #43                               #! PC = 0xaaaabe37260c *)
ssplit x17 dcL x17 43;
(* mul	x9, x15, x11                                #! PC = 0xaaaabe372610 *)
mull dcH x9 x15 x11;
(* madd	x10, x16, x13, x9                          #! PC = 0xaaaabe372614 *)
mull dcH mul_tmp x16 x13;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x11                                #! PC = 0xaaaabe372618 *)
mull dcH x9 x17 x11;
(* madd	x13, x20, x13, x9                          #! PC = 0xaaaabe37261c *)
mull dcH mul_tmp x20 x13;
adds dc x13 mul_tmp x9;
(* mov	x11, x10                                    #! PC = 0xaaaabe372620 *)
mov x11 x10;
(* mul	x9, x15, x12                                #! PC = 0xaaaabe372624 *)
mull dcH x9 x15 x12;
(* madd	x10, x16, x14, x9                          #! PC = 0xaaaabe372628 *)
mull dcH mul_tmp x16 x14;
adds dc x10 mul_tmp x9;
(* mul	x9, x17, x12                                #! PC = 0xaaaabe37262c *)
mull dcH x9 x17 x12;
(* madd	x14, x20, x14, x9                          #! PC = 0xaaaabe372630 *)
mull dcH mul_tmp x20 x14;
adds dc x14 mul_tmp x9;
(* mov	x12, x10                                    #! PC = 0xaaaabe372634 *)
mov x12 x10;
(* subs	x19, x19, #0x1                             #! PC = 0xaaaabe372638 *)
subc carry x19 x19 0x1@uint64;
(* #cbnz	x19, 0xaaaabe371960 <Lbig_loop>           #! PC = 0xaaaabe37263c *)
#cbnz	%%x19, 0xaaaabe371960 <Lbig_loop>           #! 0xaaaabe37263c = 0xaaaabe37263c;
(* mov	v16.d[0], x11                               #! PC = 0xaaaabe372640 *)
mov %v16 [x11, %v16[1]];
(* mov	v16.d[1], x13                               #! PC = 0xaaaabe372644 *)
mov %v16 [%v16[0], x13];
(* mov	v17.d[0], x12                               #! PC = 0xaaaabe372648 *)
mov %v17 [x12, %v17[1]];
(* mov	v17.d[1], x14                               #! PC = 0xaaaabe37264c *)
mov %v17 [%v17[0], x14];
(* uzp1	v13.4s, v16.4s, v17.4s                     #! PC = 0xaaaabe372650 *)
mov %v13 [%v16[0], %v16[2], %v17[0], %v17[2]];
(* and	v13.16b, v13.16b, v2.16b                    #! PC = 0xaaaabe372654 *)
and %v13@uint64[2] %v13 %v2;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe372658 *)
split %v16 %dc %v16 30;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe37265c *)
split %v17 %dc %v17 30;
(* uzp1	v14.4s, v16.4s, v17.4s                     #! PC = 0xaaaabe372660 *)
mov %v14 [%v16[0], %v16[2], %v17[0], %v17[2]];
(* smull	v16.2d, v13.2s, v3.s[0]                   #! PC = 0xaaaabe372664 *)
smull	%%v16.2d, %%v13.2s, %%v3.s[0]                   #! 0xaaaabe372664 = 0xaaaabe372664;
(* smlal2	v16.2d, v13.4s, v3.s[2]                  #! PC = 0xaaaabe372668 *)
smlal2	%%v16.2d, %%v13.4s, %%v3.s[2]                  #! 0xaaaabe372668 = 0xaaaabe372668;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe37266c *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v3.s[0]                   #! PC = 0xaaaabe372670 *)
smlal	%%v16.2d, %%v14.2s, %%v3.s[0]                   #! 0xaaaabe372670 = 0xaaaabe372670;
(* smlal2	v16.2d, v14.4s, v3.s[2]                  #! PC = 0xaaaabe372674 *)
smlal2	%%v16.2d, %%v14.4s, %%v3.s[2]                  #! 0xaaaabe372674 = 0xaaaabe372674;
(* smlal	v16.2d, v13.2s, v3.s[1]                   #! PC = 0xaaaabe372678 *)
smlal	%%v16.2d, %%v13.2s, %%v3.s[1]                   #! 0xaaaabe372678 = 0xaaaabe372678;
(* smlal2	v16.2d, v13.4s, v3.s[3]                  #! PC = 0xaaaabe37267c *)
smlal2	%%v16.2d, %%v13.4s, %%v3.s[3]                  #! 0xaaaabe37267c = 0xaaaabe37267c;
(* sshr	v16.2d, v16.2d, #30                        #! PC = 0xaaaabe372680 *)
split %v16 %dc %v16 30;
(* smlal	v16.2d, v14.2s, v3.s[1]                   #! PC = 0xaaaabe372684 *)
smlal	%%v16.2d, %%v14.2s, %%v3.s[1]                   #! 0xaaaabe372684 = 0xaaaabe372684;
(* smlal2	v16.2d, v14.4s, v3.s[3]                  #! PC = 0xaaaabe372688 *)
smlal2	%%v16.2d, %%v14.4s, %%v3.s[3]                  #! 0xaaaabe372688 = 0xaaaabe372688;
(* smlal	v16.2d, v13.2s, v4.s[0]                   #! PC = 0xaaaabe37268c *)
smlal	%%v16.2d, %%v13.2s, %%v4.s[0]                   #! 0xaaaabe37268c = 0xaaaabe37268c;
(* smlal2	v16.2d, v13.4s, v4.s[2]                  #! PC = 0xaaaabe372690 *)
smlal2	%%v16.2d, %%v13.4s, %%v4.s[2]                  #! 0xaaaabe372690 = 0xaaaabe372690;
(* and	v3.16b, v16.16b, v1.16b                     #! PC = 0xaaaabe372694 *)
and %v3@uint64[2] %v16 %v1;
(* mov	x9, #0x13                  	// #19          #! PC = 0xaaaabe372698 *)
mov x9 0x13@uint64;
(* dup	v16.2d, x9                                  #! PC = 0xaaaabe37269c *)
mov %v16 [x9,x9];
(* smull	v17.2d, v13.2s, v8.s[0]                   #! PC = 0xaaaabe3726a0 *)
smull	%%v17.2d, %%v13.2s, %%v8.s[0]                   #! 0xaaaabe3726a0 = 0xaaaabe3726a0;
(* smlal2	v17.2d, v13.4s, v8.s[2]                  #! PC = 0xaaaabe3726a4 *)
smlal2	%%v17.2d, %%v13.4s, %%v8.s[2]                  #! 0xaaaabe3726a4 = 0xaaaabe3726a4;
(* mul	v19.4s, v17.4s, v15.4s                      #! PC = 0xaaaabe3726a8 *)
mul %v19 %v17 %v15;
(* and	v19.16b, v19.16b, v1.16b                    #! PC = 0xaaaabe3726ac *)
and %v19@uint64[2] %v19 %v1;
(* uzp1	v19.4s, v19.4s, v19.4s                     #! PC = 0xaaaabe3726b0 *)
mov %v19 [%v19[0], %v19[2], %v19[0], %v19[2]];
(* smlsl	v17.2d, v19.2s, v16.s[0]                  #! PC = 0xaaaabe3726b4 *)
smlsl	%%v17.2d, %%v19.2s, %%v16.s[0]                  #! 0xaaaabe3726b4 = 0xaaaabe3726b4;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3726b8 *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v8.s[0]                   #! PC = 0xaaaabe3726bc *)
smlal	%%v17.2d, %%v14.2s, %%v8.s[0]                   #! 0xaaaabe3726bc = 0xaaaabe3726bc;
(* smlal2	v17.2d, v14.4s, v8.s[2]                  #! PC = 0xaaaabe3726c0 *)
smlal2	%%v17.2d, %%v14.4s, %%v8.s[2]                  #! 0xaaaabe3726c0 = 0xaaaabe3726c0;
(* smlal	v17.2d, v13.2s, v8.s[1]                   #! PC = 0xaaaabe3726c4 *)
smlal	%%v17.2d, %%v13.2s, %%v8.s[1]                   #! 0xaaaabe3726c4 = 0xaaaabe3726c4;
(* smlal2	v17.2d, v13.4s, v8.s[3]                  #! PC = 0xaaaabe3726c8 *)
smlal2	%%v17.2d, %%v13.4s, %%v8.s[3]                  #! 0xaaaabe3726c8 = 0xaaaabe3726c8;
(* mul	v20.4s, v17.4s, v15.4s                      #! PC = 0xaaaabe3726cc *)
mul %v20 %v17 %v15;
(* and	v20.16b, v20.16b, v1.16b                    #! PC = 0xaaaabe3726d0 *)
and %v20@uint64[2] %v20 %v1;
(* uzp1	v20.4s, v20.4s, v20.4s                     #! PC = 0xaaaabe3726d4 *)
mov %v20 [%v20[0], %v20[2], %v20[0], %v20[2]];
(* smlsl	v17.2d, v20.2s, v16.s[0]                  #! PC = 0xaaaabe3726d8 *)
smlsl	%%v17.2d, %%v20.2s, %%v16.s[0]                  #! 0xaaaabe3726d8 = 0xaaaabe3726d8;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3726dc *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v8.s[1]                   #! PC = 0xaaaabe3726e0 *)
smlal	%%v17.2d, %%v14.2s, %%v8.s[1]                   #! 0xaaaabe3726e0 = 0xaaaabe3726e0;
(* smlal2	v17.2d, v14.4s, v8.s[3]                  #! PC = 0xaaaabe3726e4 *)
smlal2	%%v17.2d, %%v14.4s, %%v8.s[3]                  #! 0xaaaabe3726e4 = 0xaaaabe3726e4;
(* smlal	v17.2d, v13.2s, v9.s[0]                   #! PC = 0xaaaabe3726e8 *)
smlal	%%v17.2d, %%v13.2s, %%v9.s[0]                   #! 0xaaaabe3726e8 = 0xaaaabe3726e8;
(* smlal2	v17.2d, v13.4s, v9.s[2]                  #! PC = 0xaaaabe3726ec *)
smlal2	%%v17.2d, %%v13.4s, %%v9.s[2]                  #! 0xaaaabe3726ec = 0xaaaabe3726ec;
(* and	v8.16b, v17.16b, v1.16b                     #! PC = 0xaaaabe3726f0 *)
and %v8@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe3726f4 *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v9.s[0]                   #! PC = 0xaaaabe3726f8 *)
smlal	%%v17.2d, %%v14.2s, %%v9.s[0]                   #! 0xaaaabe3726f8 = 0xaaaabe3726f8;
(* smlal2	v17.2d, v14.4s, v9.s[2]                  #! PC = 0xaaaabe3726fc *)
smlal2	%%v17.2d, %%v14.4s, %%v9.s[2]                  #! 0xaaaabe3726fc = 0xaaaabe3726fc;
(* smlal	v17.2d, v13.2s, v9.s[1]                   #! PC = 0xaaaabe372700 *)
smlal	%%v17.2d, %%v13.2s, %%v9.s[1]                   #! 0xaaaabe372700 = 0xaaaabe372700;
(* smlal2	v17.2d, v13.4s, v9.s[3]                  #! PC = 0xaaaabe372704 *)
smlal2	%%v17.2d, %%v13.4s, %%v9.s[3]                  #! 0xaaaabe372704 = 0xaaaabe372704;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe372708 *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe37270c *)
split %v17 %dc %v17 30;
(* sli	v8.2d, v18.2d, #32                          #! PC = 0xaaaabe372710 *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v8 %v8 32; or %v8@uint64[2] %slih %v8;
(* smlal	v17.2d, v14.2s, v9.s[1]                   #! PC = 0xaaaabe372714 *)
smlal	%%v17.2d, %%v14.2s, %%v9.s[1]                   #! 0xaaaabe372714 = 0xaaaabe372714;
(* smlal2	v17.2d, v14.4s, v9.s[3]                  #! PC = 0xaaaabe372718 *)
smlal2	%%v17.2d, %%v14.4s, %%v9.s[3]                  #! 0xaaaabe372718 = 0xaaaabe372718;
(* smlal	v17.2d, v13.2s, v10.s[0]                  #! PC = 0xaaaabe37271c *)
smlal	%%v17.2d, %%v13.2s, %%v10.s[0]                  #! 0xaaaabe37271c = 0xaaaabe37271c;
(* smlal2	v17.2d, v13.4s, v10.s[2]                 #! PC = 0xaaaabe372720 *)
smlal2	%%v17.2d, %%v13.4s, %%v10.s[2]                 #! 0xaaaabe372720 = 0xaaaabe372720;
(* and	v9.16b, v17.16b, v1.16b                     #! PC = 0xaaaabe372724 *)
and %v9@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe372728 *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v10.s[0]                  #! PC = 0xaaaabe37272c *)
smlal	%%v17.2d, %%v14.2s, %%v10.s[0]                  #! 0xaaaabe37272c = 0xaaaabe37272c;
(* smlal2	v17.2d, v14.4s, v10.s[2]                 #! PC = 0xaaaabe372730 *)
smlal2	%%v17.2d, %%v14.4s, %%v10.s[2]                 #! 0xaaaabe372730 = 0xaaaabe372730;
(* smlal	v17.2d, v13.2s, v10.s[1]                  #! PC = 0xaaaabe372734 *)
smlal	%%v17.2d, %%v13.2s, %%v10.s[1]                  #! 0xaaaabe372734 = 0xaaaabe372734;
(* smlal2	v17.2d, v13.4s, v10.s[3]                 #! PC = 0xaaaabe372738 *)
smlal2	%%v17.2d, %%v13.4s, %%v10.s[3]                 #! 0xaaaabe372738 = 0xaaaabe372738;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe37273c *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe372740 *)
split %v17 %dc %v17 30;
(* sli	v9.2d, v18.2d, #32                          #! PC = 0xaaaabe372744 *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v9 %v9 32; or %v9@uint64[2] %slih %v9;
(* smlal	v17.2d, v14.2s, v10.s[1]                  #! PC = 0xaaaabe372748 *)
smlal	%%v17.2d, %%v14.2s, %%v10.s[1]                  #! 0xaaaabe372748 = 0xaaaabe372748;
(* smlal2	v17.2d, v14.4s, v10.s[3]                 #! PC = 0xaaaabe37274c *)
smlal2	%%v17.2d, %%v14.4s, %%v10.s[3]                 #! 0xaaaabe37274c = 0xaaaabe37274c;
(* smlal	v17.2d, v13.2s, v11.s[0]                  #! PC = 0xaaaabe372750 *)
smlal	%%v17.2d, %%v13.2s, %%v11.s[0]                  #! 0xaaaabe372750 = 0xaaaabe372750;
(* smlal2	v17.2d, v13.4s, v11.s[2]                 #! PC = 0xaaaabe372754 *)
smlal2	%%v17.2d, %%v13.4s, %%v11.s[2]                 #! 0xaaaabe372754 = 0xaaaabe372754;
(* and	v10.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe372758 *)
and %v10@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe37275c *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v11.s[0]                  #! PC = 0xaaaabe372760 *)
smlal	%%v17.2d, %%v14.2s, %%v11.s[0]                  #! 0xaaaabe372760 = 0xaaaabe372760;
(* smlal2	v17.2d, v14.4s, v11.s[2]                 #! PC = 0xaaaabe372764 *)
smlal2	%%v17.2d, %%v14.4s, %%v11.s[2]                 #! 0xaaaabe372764 = 0xaaaabe372764;
(* smlal	v17.2d, v13.2s, v11.s[1]                  #! PC = 0xaaaabe372768 *)
smlal	%%v17.2d, %%v13.2s, %%v11.s[1]                  #! 0xaaaabe372768 = 0xaaaabe372768;
(* smlal2	v17.2d, v13.4s, v11.s[3]                 #! PC = 0xaaaabe37276c *)
smlal2	%%v17.2d, %%v13.4s, %%v11.s[3]                 #! 0xaaaabe37276c = 0xaaaabe37276c;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe372770 *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe372774 *)
split %v17 %dc %v17 30;
(* sli	v10.2d, v18.2d, #32                         #! PC = 0xaaaabe372778 *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v10 %v10 32; or %v10@uint64[2] %slih %v10;
(* smlal	v17.2d, v14.2s, v11.s[1]                  #! PC = 0xaaaabe37277c *)
smlal	%%v17.2d, %%v14.2s, %%v11.s[1]                  #! 0xaaaabe37277c = 0xaaaabe37277c;
(* smlal2	v17.2d, v14.4s, v11.s[3]                 #! PC = 0xaaaabe372780 *)
smlal2	%%v17.2d, %%v14.4s, %%v11.s[3]                 #! 0xaaaabe372780 = 0xaaaabe372780;
(* smlal	v17.2d, v13.2s, v12.s[0]                  #! PC = 0xaaaabe372784 *)
smlal	%%v17.2d, %%v13.2s, %%v12.s[0]                  #! 0xaaaabe372784 = 0xaaaabe372784;
(* smlal2	v17.2d, v13.4s, v12.s[2]                 #! PC = 0xaaaabe372788 *)
smlal2	%%v17.2d, %%v13.4s, %%v12.s[2]                 #! 0xaaaabe372788 = 0xaaaabe372788;
(* ushll	v19.2d, v19.2s, #15                       #! PC = 0xaaaabe37278c *)
ushll	%%v19.2d, %%v19.2s, #15                       #! 0xaaaabe37278c = 0xaaaabe37278c;
(* add	v17.2d, v17.2d, v19.2d                      #! PC = 0xaaaabe372790 *)
add	%%v17.2d, %%v17.2d, %%v19.2d                      #! 0xaaaabe372790 = 0xaaaabe372790;
(* and	v11.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe372794 *)
and %v11@uint64[2] %v17 %v1;
(* sshr	v17.2d, v17.2d, #30                        #! PC = 0xaaaabe372798 *)
split %v17 %dc %v17 30;
(* smlal	v17.2d, v14.2s, v12.s[0]                  #! PC = 0xaaaabe37279c *)
smlal	%%v17.2d, %%v14.2s, %%v12.s[0]                  #! 0xaaaabe37279c = 0xaaaabe37279c;
(* smlal2	v17.2d, v14.4s, v12.s[2]                 #! PC = 0xaaaabe3727a0 *)
smlal2	%%v17.2d, %%v14.4s, %%v12.s[2]                 #! 0xaaaabe3727a0 = 0xaaaabe3727a0;
(* ushll	v20.2d, v20.2s, #15                       #! PC = 0xaaaabe3727a4 *)
ushll	%%v20.2d, %%v20.2s, #15                       #! 0xaaaabe3727a4 = 0xaaaabe3727a4;
(* add	v17.2d, v17.2d, v20.2d                      #! PC = 0xaaaabe3727a8 *)
add	%%v17.2d, %%v17.2d, %%v20.2d                      #! 0xaaaabe3727a8 = 0xaaaabe3727a8;
(* and	v18.16b, v17.16b, v1.16b                    #! PC = 0xaaaabe3727ac *)
and %v18@uint64[2] %v17 %v1;
(* sshr	v12.2d, v17.2d, #30                        #! PC = 0xaaaabe3727b0 *)
split %v12 %dc %v17 30;
(* sli	v11.2d, v18.2d, #32                         #! PC = 0xaaaabe3727b4 *)
split %dc %slil %v18 (64-32); shl %slih %v18 [32@uint64, 32@uint64];
split %dc %v11 %v11 32; or %v11@uint64[2] %slih %v11;
(* sshr	v18.2d, v12.2d, #15                        #! PC = 0xaaaabe3727b8 *)
split %v18 %dc %v12 15;
(* shl	v17.2d, v18.2d, #15                         #! PC = 0xaaaabe3727bc *)
shls %dc %v17 %v18 [15, 15];
(* sub	v12.2d, v12.2d, v17.2d                      #! PC = 0xaaaabe3727c0 *)
sub	%%v12.2d, %%v12.2d, %%v17.2d                      #! 0xaaaabe3727c0 = 0xaaaabe3727c0;
(* mla	v8.4s, v18.4s, v16.4s                       #! PC = 0xaaaabe3727c4 *)
mull %dc %mla %v18 %v16; add %v8 %v8 %mla;
(* dup	v17.4s, v1.s[0]                             #! PC = 0xaaaabe3727c8 *)
dup	%%v17.4s, %%v1.s[0]                             #! 0xaaaabe3727c8 = 0xaaaabe3727c8;
(* mvn	v17.16b, v17.16b                            #! PC = 0xaaaabe3727cc *)
mvn	%%v17.16b, %%v17.16b                            #! 0xaaaabe3727cc = 0xaaaabe3727cc;
(* sshr	v18.4s, v8.4s, #30                         #! PC = 0xaaaabe3727d0 *)
split %v18 %dc %v8 30;
(* shl	v18.2d, v18.2d, #32                         #! PC = 0xaaaabe3727d4 *)
shls %dc %v18 %v18 [32, 32];
(* add	v8.4s, v8.4s, v18.4s                        #! PC = 0xaaaabe3727d8 *)
add %v8 %v8 %v18;
(* sshr	v18.2d, v8.2d, #30                         #! PC = 0xaaaabe3727dc *)
split %v18 %dc %v8 30;
(* ushr	v18.2d, v18.2d, #32                        #! PC = 0xaaaabe3727e0 *)
shrs %v18 %dc %v18 [32, 32];
(* add	v9.4s, v9.4s, v18.4s                        #! PC = 0xaaaabe3727e4 *)
add %v9 %v9 %v18;
(* bic	v8.16b, v8.16b, v17.16b                     #! PC = 0xaaaabe3727e8 *)
bic	%%v8.16b, %%v8.16b, %%v17.16b                     #! 0xaaaabe3727e8 = 0xaaaabe3727e8;
(* sshr	v18.4s, v9.4s, #30                         #! PC = 0xaaaabe3727ec *)
split %v18 %dc %v9 30;
(* shl	v18.2d, v18.2d, #32                         #! PC = 0xaaaabe3727f0 *)
shls %dc %v18 %v18 [32, 32];
(* add	v9.4s, v9.4s, v18.4s                        #! PC = 0xaaaabe3727f4 *)
add %v9 %v9 %v18;
(* sshr	v18.2d, v9.2d, #30                         #! PC = 0xaaaabe3727f8 *)
split %v18 %dc %v9 30;
(* ushr	v18.2d, v18.2d, #32                        #! PC = 0xaaaabe3727fc *)
shrs %v18 %dc %v18 [32, 32];
(* add	v10.4s, v10.4s, v18.4s                      #! PC = 0xaaaabe372800 *)
add %v10 %v10 %v18;
(* bic	v9.16b, v9.16b, v17.16b                     #! PC = 0xaaaabe372804 *)
bic	%%v9.16b, %%v9.16b, %%v17.16b                     #! 0xaaaabe372804 = 0xaaaabe372804;
(* sshr	v18.4s, v10.4s, #30                        #! PC = 0xaaaabe372808 *)
split %v18 %dc %v10 30;
(* shl	v18.2d, v18.2d, #32                         #! PC = 0xaaaabe37280c *)
shls %dc %v18 %v18 [32, 32];
(* add	v10.4s, v10.4s, v18.4s                      #! PC = 0xaaaabe372810 *)
add %v10 %v10 %v18;
(* sshr	v18.2d, v10.2d, #30                        #! PC = 0xaaaabe372814 *)
split %v18 %dc %v10 30;
(* ushr	v18.2d, v18.2d, #32                        #! PC = 0xaaaabe372818 *)
shrs %v18 %dc %v18 [32, 32];
(* add	v11.4s, v11.4s, v18.4s                      #! PC = 0xaaaabe37281c *)
add %v11 %v11 %v18;
(* bic	v10.16b, v10.16b, v17.16b                   #! PC = 0xaaaabe372820 *)
bic	%%v10.16b, %%v10.16b, %%v17.16b                   #! 0xaaaabe372820 = 0xaaaabe372820;
(* sshr	v18.4s, v11.4s, #30                        #! PC = 0xaaaabe372824 *)
split %v18 %dc %v11 30;
(* shl	v18.2d, v18.2d, #32                         #! PC = 0xaaaabe372828 *)
shls %dc %v18 %v18 [32, 32];
(* add	v11.4s, v11.4s, v18.4s                      #! PC = 0xaaaabe37282c *)
add %v11 %v11 %v18;
(* sshr	v18.2d, v11.2d, #30                        #! PC = 0xaaaabe372830 *)
split %v18 %dc %v11 30;
(* ushr	v18.2d, v18.2d, #32                        #! PC = 0xaaaabe372834 *)
shrs %v18 %dc %v18 [32, 32];
(* add	v12.4s, v12.4s, v18.4s                      #! PC = 0xaaaabe372838 *)
add %v12 %v12 %v18;
(* bic	v11.16b, v11.16b, v17.16b                   #! PC = 0xaaaabe37283c *)
bic	%%v11.16b, %%v11.16b, %%v17.16b                   #! 0xaaaabe37283c = 0xaaaabe37283c;
(* smov	x9, v8.s[0]                                #! PC = 0xaaaabe372840 *)
smov	%%x9, %%v8.s[0]                                #! 0xaaaabe372840 = 0xaaaabe372840;
(* smov	x10, v8.s[1]                               #! PC = 0xaaaabe372844 *)
smov	%%x10, %%v8.s[1]                               #! 0xaaaabe372844 = 0xaaaabe372844;
(* smov	x11, v9.s[0]                               #! PC = 0xaaaabe372848 *)
smov	%%x11, %%v9.s[0]                               #! 0xaaaabe372848 = 0xaaaabe372848;
(* smov	x12, v9.s[1]                               #! PC = 0xaaaabe37284c *)
smov	%%x12, %%v9.s[1]                               #! 0xaaaabe37284c = 0xaaaabe37284c;
(* smov	x13, v10.s[0]                              #! PC = 0xaaaabe372850 *)
smov	%%x13, %%v10.s[0]                              #! 0xaaaabe372850 = 0xaaaabe372850;
(* smov	x14, v10.s[1]                              #! PC = 0xaaaabe372854 *)
smov	%%x14, %%v10.s[1]                              #! 0xaaaabe372854 = 0xaaaabe372854;
(* smov	x15, v11.s[0]                              #! PC = 0xaaaabe372858 *)
smov	%%x15, %%v11.s[0]                              #! 0xaaaabe372858 = 0xaaaabe372858;
(* smov	x16, v11.s[1]                              #! PC = 0xaaaabe37285c *)
smov	%%x16, %%v11.s[1]                              #! 0xaaaabe37285c = 0xaaaabe37285c;
(* smov	x17, v12.s[0]                              #! PC = 0xaaaabe372860 *)
smov	%%x17, %%v12.s[0]                              #! 0xaaaabe372860 = 0xaaaabe372860;
(* add	x9, x9, x10, lsl #30                        #! PC = 0xaaaabe372864 *)
add x9 x9 x10, lsl;
(* add	x9, x9, x11, lsl #60                        #! PC = 0xaaaabe372868 *)
add x9 x9 x11, lsl;
(* lsr	x10, x11, #4                                #! PC = 0xaaaabe37286c *)
split x10 dcL x11 4;
(* add	x10, x10, x12, lsl #26                      #! PC = 0xaaaabe372870 *)
add x10 x10 x12, lsl;
(* add	x10, x10, x13, lsl #56                      #! PC = 0xaaaabe372874 *)
add x10 x10 x13, lsl;
(* lsr	x11, x13, #8                                #! PC = 0xaaaabe372878 *)
split x11 dcL x13 8;
(* add	x11, x11, x14, lsl #22                      #! PC = 0xaaaabe37287c *)
add x11 x11 x14, lsl;
(* add	x11, x11, x15, lsl #52                      #! PC = 0xaaaabe372880 *)
add x11 x11 x15, lsl;
(* lsr	x12, x15, #12                               #! PC = 0xaaaabe372884 *)
split x12 dcL x15 12;
(* add	x12, x12, x16, lsl #18                      #! PC = 0xaaaabe372888 *)
add x12 x12 x16, lsl;
(* add	x12, x12, x17, lsl #48                      #! PC = 0xaaaabe37288c *)
add x12 x12 x17, lsl;
(* smov	x19, v3.s[0]                               #! PC = 0xaaaabe372890 *)
smov	%%x19, %%v3.s[0]                               #! 0xaaaabe372890 = 0xaaaabe372890;
(* lsl	x19, x19, #34                               #! PC = 0xaaaabe372894 *)
split dcH x19 x19 (64-34); shl x19 x19 34;
(* asr	x19, x19, #63                               #! PC = 0xaaaabe372898 *)
ssplit x19 dcL x19 63;
(* eor	x9, x9, x19                                 #! PC = 0xaaaabe37289c *)
xor x9@uint64 x9 x19;
(* eor	x10, x10, x19                               #! PC = 0xaaaabe3728a0 *)
xor x10@uint64 x10 x19;
(* eor	x11, x11, x19                               #! PC = 0xaaaabe3728a4 *)
xor x11@uint64 x11 x19;
(* eor	x12, x12, x19                               #! PC = 0xaaaabe3728a8 *)
xor x12@uint64 x12 x19;
(* neg	x19, x19                                    #! PC = 0xaaaabe3728ac *)
neg	%%x19, %%x19                                    #! 0xaaaabe3728ac = 0xaaaabe3728ac;
(* adds	x9, x9, x19                                #! PC = 0xaaaabe3728b0 *)
adds carry x9 x9 x19;
(* adcs	x10, x10, xzr                              #! PC = 0xaaaabe3728b4 *)
adcs carry x10 x10 0@uint64 carry;
(* adcs	x11, x11, xzr                              #! PC = 0xaaaabe3728b8 *)
adcs carry x11 x11 0@uint64 carry;
(* adcs	x12, x12, xzr                              #! PC = 0xaaaabe3728bc *)
adcs carry x12 x12 0@uint64 carry;
(* cmn	x12, #0x0                                   #! PC = 0xaaaabe3728c0 *)
cmn	%%x12, #0x0                                   #! 0xaaaabe3728c0 = 0xaaaabe3728c0;
(* mov	x13, #0xffffffffffffffed    	// #-19        #! PC = 0xaaaabe3728c4 *)
mov x13 0xffffffffffffffed@uint64;
(* csel	x13, x13, xzr, mi	// mi = first            #! PC = 0xaaaabe3728c8 *)
csel	%%x13, %%x13, xzr, mi	// mi = first            #! 0xaaaabe3728c8 = 0xaaaabe3728c8;
(* adds	x9, x9, x13                                #! PC = 0xaaaabe3728cc *)
adds carry x9 x9 x13;
(* asr	x13, x13, #5                                #! PC = 0xaaaabe3728d0 *)
ssplit x13 dcL x13 5;
(* adcs	x10, x10, x13                              #! PC = 0xaaaabe3728d4 *)
adcs carry x10 x10 x13 carry;
(* adcs	x11, x11, x13                              #! PC = 0xaaaabe3728d8 *)
adcs carry x11 x11 x13 carry;
(* lsr	x13, x13, #1                                #! PC = 0xaaaabe3728dc *)
split x13 dcL x13 1;
(* adcs	x12, x12, x13                              #! PC = 0xaaaabe3728e0 *)
adcs carry x12 x12 x13 carry;
(* stp	x9, x10, [x0]                               #! EA = L0xffffc68e1828; PC = 0xaaaabe3728e4 *)
mov L0xffffc68e1828 x9; mov L0xffffc68e1830 x10;
(* stp	x11, x12, [x0, #16]                         #! EA = L0xffffc68e1838; PC = 0xaaaabe3728e8 *)
mov L0xffffc68e1838 x11; mov L0xffffc68e1840 x12;
(* ldp	q14, q15, [sp], #32                         #! EA = L0xffffc68e16e0; Value = 0x0000000000000000; PC = 0xaaaabe3728ec *)
mov %v14 [L0xffffc68e16e0, L0xffffc68e16e8];
mov %v15 [L0xffffc68e16f0, L0xffffc68e16f8];
(* ldp	q12, q13, [sp], #32                         #! EA = L0xffffc68e1700; Value = 0x0000000000000000; PC = 0xaaaabe3728f0 *)
mov %v12 [L0xffffc68e1700, L0xffffc68e1708];
mov %v13 [L0xffffc68e1710, L0xffffc68e1718];
(* ldp	q10, q11, [sp], #32                         #! EA = L0xffffc68e1720; Value = 0x0000000000000000; PC = 0xaaaabe3728f4 *)
mov %v10 [L0xffffc68e1720, L0xffffc68e1728];
mov %v11 [L0xffffc68e1730, L0xffffc68e1738];
(* ldp	q8, q9, [sp], #32                           #! EA = L0xffffc68e1740; Value = 0x0000000000000000; PC = 0xaaaabe3728f8 *)
mov %v8 [L0xffffc68e1740, L0xffffc68e1748];
mov %v9 [L0xffffc68e1750, L0xffffc68e1758];
(* ldp	x27, x28, [sp], #16                         #! EA = L0xffffc68e1760; Value = 0x0000aaaabe38fd10; PC = 0xaaaabe3728fc *)
mov x27 L0xffffc68e1760; mov x28 L0xffffc68e1768;
(* ldp	x25, x26, [sp], #16                         #! EA = L0xffffc68e1770; Value = 0x0000aaaabe3729d8; PC = 0xaaaabe372900 *)
mov x25 L0xffffc68e1770; mov x26 L0xffffc68e1778;
(* ldp	x23, x24, [sp], #16                         #! EA = L0xffffc68e1780; Value = 0x0000ffffc68e17d8; PC = 0xaaaabe372904 *)
mov x23 L0xffffc68e1780; mov x24 L0xffffc68e1788;
(* ldp	x21, x22, [sp], #16                         #! EA = L0xffffc68e1790; Value = 0x0000ffffc68e17c8; PC = 0xaaaabe372908 *)
mov x21 L0xffffc68e1790; mov x22 L0xffffc68e1798;
(* ldp	x19, x20, [sp], #16                         #! EA = L0xffffc68e17a0; Value = 0x0000ffffc68e1828; PC = 0xaaaabe37290c *)
mov x19 L0xffffc68e17a0; mov x20 L0xffffc68e17a8;
(* ldp	x29, x30, [sp], #16                         #! EA = L0xffffc68e17b0; Value = 0x0000ffffc68e1850; PC = 0xaaaabe372910 *)
mov x29 L0xffffc68e17b0; mov x30 L0xffffc68e17b8;
(* #! <- SP = 0xffffc68e17c0 *)
#! 0xffffc68e17c0 = 0xffffc68e17c0;
(* #ret                                            #! PC = 0xaaaabe372914 *)
#ret                                            #! 0xaaaabe372914 = 0xaaaabe372914;

