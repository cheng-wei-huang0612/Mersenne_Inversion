proc main(uint64 op_x0_0, uint64 op_x1_0, uint64 op_x2_0, uint64 op_x3_0) =
{ true && true }
split x2_2 dcL_1 18446744073709551615@uint64 1;
shrs v1_uint64_0_1 dc_1 18446744073709551615@uint64 34;
shrs v1_uint64_1_1 dc_2 18446744073709551615@uint64 34;
assert true && v1_uint64_0_1 = 1073741823@64, v1_uint64_1_1 = 1073741823@64;
split dc_3 v3_uint64_0_2 18446744073709551597@uint64 30;
split dc_4 v3_uint64_1_2 op_x0_0 30;
shrs v12_uint64_0_1 dc_5 18446744073709551597@uint64 30;
shrs v12_uint64_1_1 dc_6 op_x0_0 30;
assert true && v1_uint64_0_1 = 1073741823@64, v1_uint64_1_1 = 1073741823@64;
split dc_7 v12_uint64_0_2 v12_uint64_0_1 30;
split dc_8 v12_uint64_1_2 v12_uint64_1_1 30;
cast v3_sint32_0_1@int32 v3_uint64_0_2;
cast v3_sint32_2_1@int32 v3_uint64_1_2;
cast v3_sint32_1_1@int32 v12_uint64_0_2;
cast v3_sint32_3_1@int32 v12_uint64_1_2;
assert true && 0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32;
shrs v4_uint64_0_2 dc_9 18446744073709551597@uint64 60;
shrs v4_uint64_1_2 dc_10 op_x0_0 60;
shls dc_11 v12_uint64_0_3 18446744073709551615@uint64 4;
shls dc_12 v12_uint64_1_3 op_x1_0 4;
split dc_13 v12_uint64_0_4 v12_uint64_0_3 30;
split dc_14 v12_uint64_1_4 v12_uint64_1_3 30;
or v4_uint64_0_3@uint64 v4_uint64_0_2 v12_uint64_0_4;
or v4_uint64_1_3@uint64 v4_uint64_1_2 v12_uint64_1_4;
shrs v12_uint64_0_5 dc_15 18446744073709551615@uint64 26;
shrs v12_uint64_1_5 dc_16 op_x1_0 26;
split dc_17 v12_uint64_0_6 v12_uint64_0_5 30;
split dc_18 v12_uint64_1_6 v12_uint64_1_5 30;
cast v4_sint32_0_1@int32 v4_uint64_0_3;
cast v4_sint32_2_1@int32 v4_uint64_1_3;
cast v4_sint32_1_1@int32 v12_uint64_0_6;
cast v4_sint32_3_1@int32 v12_uint64_1_6;
shrs v5_uint64_0_2 dc_19 18446744073709551615@uint64 56;
shrs v5_uint64_1_2 dc_20 op_x1_0 56;
shls dc_21 v12_uint64_0_7 18446744073709551615@uint64 8;
shls dc_22 v12_uint64_1_7 op_x2_0 8;
split dc_23 v12_uint64_0_8 v12_uint64_0_7 30;
split dc_24 v12_uint64_1_8 v12_uint64_1_7 30;
or v5_uint64_0_3@uint64 v5_uint64_0_2 v12_uint64_0_8;
or v5_uint64_1_3@uint64 v5_uint64_1_2 v12_uint64_1_8;
shrs v12_uint64_0_9 dc_25 18446744073709551615@uint64 22;
shrs v12_uint64_1_9 dc_26 op_x2_0 22;
split dc_27 v12_uint64_0_10 v12_uint64_0_9 30;
split dc_28 v12_uint64_1_10 v12_uint64_1_9 30;
cast v5_sint32_0_1@int32 v5_uint64_0_3;
cast v5_sint32_2_1@int32 v5_uint64_1_3;
cast v5_sint32_1_1@int32 v12_uint64_0_10;
cast v5_sint32_3_1@int32 v12_uint64_1_10;
shrs v6_uint64_0_2 dc_29 18446744073709551615@uint64 52;
shrs v6_uint64_1_2 dc_30 op_x2_0 52;
shls dc_31 v12_uint64_0_11 x2_2 12;
shls dc_32 v12_uint64_1_11 op_x3_0 12;
split dc_33 v12_uint64_0_12 v12_uint64_0_11 30;
split dc_34 v12_uint64_1_12 v12_uint64_1_11 30;
or v6_uint64_0_3@uint64 v6_uint64_0_2 v12_uint64_0_12;
or v6_uint64_1_3@uint64 v6_uint64_1_2 v12_uint64_1_12;
shrs v12_uint64_0_13 dc_35 x2_2 18;
shrs v12_uint64_1_13 dc_36 op_x3_0 18;
split dc_37 v12_uint64_0_14 v12_uint64_0_13 30;
split dc_38 v12_uint64_1_14 v12_uint64_1_13 30;
cast v6_sint32_0_1@int32 v6_uint64_0_3;
cast v6_sint32_2_1@int32 v6_uint64_1_3;
cast v6_sint32_1_1@int32 v12_uint64_0_14;
cast v6_sint32_3_1@int32 v12_uint64_1_14;
shrs v7_uint64_0_1 dc_39 x2_2 48;
shrs v7_uint64_1_1 dc_40 op_x3_0 48;
spl v7_sint32_1_1 v7_sint32_0_1 v7_uint64_0_1 32;
spl v7_sint32_3_1 v7_sint32_2_1 v7_uint64_1_1 32;
cast v8_sint32_2_2@int32 1@uint64;
spl v1_uint32_1_1 v1_uint32_0_1 v1_uint64_0_1 32;
spl v1_uint32_3_1 v1_uint32_2_1 v1_uint64_1_1 32;
add x6_2 2199023255552@int64 1048576@int64;
cast w7_1@int32 678152731@int64;
{ true && and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 32767@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext 18446744073709551597@64 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext op_x0_0 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64] }