===== Verifying program safety =====
=== Cut #0 ===
== Number of safety conditions to be verified: 21 ==
INPUT IN SMTLIB2 FORMAT:
; Verify: safety
; Track: default
; Cut: #0
; Round: 1
; Timeout: 300
; Safety condition: #2
; Instruction: vpc v3_sint32_2_2@int32 v3_sint32_2_1;
; Output file: /tmp/outputqfbv_fbad49.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (not (= ((_ extract 63 31) v3_sint32_2_1) #b000000000000000000000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_f3a43c.smt2
Execution time of boolector: 0.0023 seconds
OUTPUT FROM boolector:
unsat

INPUT IN SMTLIB2 FORMAT:
; Verify: safety
; Track: default
; Cut: #0
; Round: 1
; Timeout: 300
; Safety condition: #1
; Instruction: vpc v3_sint32_1_2@int32 v3_sint32_1_1;
; Output file: /tmp/outputqfbv_0d032a.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (not (= ((_ extract 63 31) v3_sint32_1_1) #b000000000000000000000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_f84690.smt2
Execution time of boolector: 0.0029 seconds
OUTPUT FROM boolector:
unsat

INPUT IN SMTLIB2 FORMAT:
; Verify: safety
; Track: default
; Cut: #0
; Round: 1
; Timeout: 300
; Safety condition: #0
; Instruction: vpc v3_sint32_0_2@int32 v3_sint32_0_1;
; Output file: /tmp/outputqfbv_094dc6.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (not (= ((_ extract 63 31) v3_sint32_0_1) #b000000000000000000000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_1eb3b8.smt2
Execution time of boolector: 0.0034 seconds
OUTPUT FROM boolector:
unsat

INPUT IN SMTLIB2 FORMAT:
; Verify: safety
; Track: default
; Cut: #0
; Round: 1
; Timeout: 300
; Safety condition: #3
; Instruction: vpc v3_sint32_3_2@int32 v3_sint32_3_1;
; Output file: /tmp/outputqfbv_9fc2c2.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (not (= ((_ extract 63 31) v3_sint32_3_1) #b000000000000000000000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_12fd2a.smt2
Execution time of boolector: 0.0022 seconds
OUTPUT FROM boolector:
unsat

INPUT IN SMTLIB2 FORMAT:
; Verify: safety
; Track: default
; Cut: #0
; Round: 1
; Timeout: 300
; Safety condition: #4
; Instruction: vpc v4_sint32_0_1@int32 v4_uint64_0_3;
; Output file: /tmp/outputqfbv_3e83c5.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (not (= ((_ extract 63 31) v4_uint64_0_3) #b000000000000000000000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_5e10a8.smt2
Execution time of boolector: 0.0014 seconds
OUTPUT FROM boolector:
unsat

INPUT IN SMTLIB2 FORMAT:
; Verify: safety
; Track: default
; Cut: #0
; Round: 1
; Timeout: 300
; Safety condition: #5
; Instruction: vpc v4_sint32_2_1@int32 v4_uint64_1_3;
; Output file: /tmp/outputqfbv_5f170b.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (not (= ((_ extract 63 31) v4_uint64_1_3) #b000000000000000000000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_d09f41.smt2
Execution time of boolector: 0.0015 seconds
OUTPUT FROM boolector:
unsat

INPUT IN SMTLIB2 FORMAT:
; Verify: safety
; Track: default
; Cut: #0
; Round: 1
; Timeout: 300
; Safety condition: #6
; Instruction: vpc v4_sint32_1_2@int32 v4_sint32_1_1;
; Output file: /tmp/outputqfbv_568355.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (not (= ((_ extract 63 31) v4_sint32_1_1) #b000000000000000000000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_28145e.smt2
Execution time of boolector: 0.0012 seconds
OUTPUT FROM boolector:
unsat

INPUT IN SMTLIB2 FORMAT:
; Verify: safety
; Track: default
; Cut: #0
; Round: 1
; Timeout: 300
; Safety condition: #7
; Instruction: vpc v4_sint32_3_2@int32 v4_sint32_3_1;
; Output file: /tmp/outputqfbv_c9186d.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (not (= ((_ extract 63 31) v4_sint32_3_1) #b000000000000000000000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_7bc714.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

INPUT IN SMTLIB2 FORMAT:
; Verify: safety
; Track: default
; Cut: #0
; Round: 1
; Timeout: 300
; Safety condition: #8
; Instruction: vpc v5_sint32_0_1@int32 v5_uint64_0_3;
; Output file: /tmp/outputqfbv_4974dc.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (not (= ((_ extract 63 31) v5_uint64_0_3) #b000000000000000000000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_202607.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

INPUT IN SMTLIB2 FORMAT:
; Verify: safety
; Track: default
; Cut: #0
; Round: 1
; Timeout: 300
; Safety condition: #9
; Instruction: vpc v5_sint32_2_1@int32 v5_uint64_1_3;
; Output file: /tmp/outputqfbv_052eaa.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (not (= ((_ extract 63 31) v5_uint64_1_3) #b000000000000000000000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_3659ab.smt2
Execution time of boolector: 0.0013 seconds
OUTPUT FROM boolector:
unsat

INPUT IN SMTLIB2 FORMAT:
; Verify: safety
; Track: default
; Cut: #0
; Round: 1
; Timeout: 300
; Safety condition: #10
; Instruction: vpc v5_sint32_1_2@int32 v5_sint32_1_1;
; Output file: /tmp/outputqfbv_418da5.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (not (= ((_ extract 63 31) v5_sint32_1_1) #b000000000000000000000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_9e45f2.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

INPUT IN SMTLIB2 FORMAT:
; Verify: safety
; Track: default
; Cut: #0
; Round: 1
; Timeout: 300
; Safety condition: #11
; Instruction: vpc v5_sint32_3_2@int32 v5_sint32_3_1;
; Output file: /tmp/outputqfbv_775349.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (not (= ((_ extract 63 31) v5_sint32_3_1) #b000000000000000000000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_b9a06f.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

INPUT IN SMTLIB2 FORMAT:
; Verify: safety
; Track: default
; Cut: #0
; Round: 1
; Timeout: 300
; Safety condition: #12
; Instruction: vpc v6_sint32_0_1@int32 v6_uint64_0_3;
; Output file: /tmp/outputqfbv_3d5261.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (not (= ((_ extract 63 31) v6_uint64_0_3) #b000000000000000000000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_466534.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

INPUT IN SMTLIB2 FORMAT:
; Verify: safety
; Track: default
; Cut: #0
; Round: 1
; Timeout: 300
; Safety condition: #13
; Instruction: vpc v6_sint32_2_1@int32 v6_uint64_1_3;
; Output file: /tmp/outputqfbv_830565.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (not (= ((_ extract 63 31) v6_uint64_1_3) #b000000000000000000000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_225777.smt2
Execution time of boolector: 0.0013 seconds
OUTPUT FROM boolector:
unsat

INPUT IN SMTLIB2 FORMAT:
; Verify: safety
; Track: default
; Cut: #0
; Round: 1
; Timeout: 300
; Safety condition: #14
; Instruction: vpc v6_sint32_1_2@int32 v6_sint32_1_1;
; Output file: /tmp/outputqfbv_1e5cac.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (not (= ((_ extract 63 31) v6_sint32_1_1) #b000000000000000000000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_5bb73a.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

INPUT IN SMTLIB2 FORMAT:
; Verify: safety
; Track: default
; Cut: #0
; Round: 1
; Timeout: 300
; Safety condition: #15
; Instruction: vpc v6_sint32_3_2@int32 v6_sint32_3_1;
; Output file: /tmp/outputqfbv_7e40dc.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (not (= ((_ extract 63 31) v6_sint32_3_1) #b000000000000000000000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_fae02f.smt2
Execution time of boolector: 0.0010 seconds
OUTPUT FROM boolector:
unsat

INPUT IN SMTLIB2 FORMAT:
; Verify: safety
; Track: default
; Cut: #0
; Round: 1
; Timeout: 300
; Safety condition: #16
; Instruction: vpc v7_sint32_0_1@int32 v7_uint64_0_1;
; Output file: /tmp/outputqfbv_94ebb4.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (not (= ((_ extract 63 31) v7_uint64_0_1) #b000000000000000000000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_cf2d94.smt2
Execution time of boolector: 0.0014 seconds
OUTPUT FROM boolector:
unsat

INPUT IN SMTLIB2 FORMAT:
; Verify: safety
; Track: default
; Cut: #0
; Round: 1
; Timeout: 300
; Safety condition: #17
; Instruction: vpc v7_sint32_2_1@int32 v7_uint64_1_1;
; Output file: /tmp/outputqfbv_0cb324.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (not (= ((_ extract 63 31) v7_uint64_1_1) #b000000000000000000000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_d833c8.smt2
Execution time of boolector: 0.0012 seconds
OUTPUT FROM boolector:
unsat

INPUT IN SMTLIB2 FORMAT:
; Verify: safety
; Track: default
; Cut: #0
; Round: 1
; Timeout: 300
; Safety condition: #18
; Instruction: vpc v8_sint32_2_3@int32 1@uint64;
; Output file: /tmp/outputqfbv_3ed9ae.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (not (= ((_ extract 63 31) #x0000000000000001) #b000000000000000000000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_6d8003.smt2
Execution time of boolector: 0.0009 seconds
OUTPUT FROM boolector:
unsat

INPUT IN SMTLIB2 FORMAT:
; Verify: safety
; Track: default
; Cut: #0
; Round: 1
; Timeout: 300
; Safety condition: #19
; Instruction: add x6_2 2199023255552@uint64 1048576@uint64;
; Output file: /tmp/outputqfbv_2ea03d.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (not (not (= ((_ extract 64 64) (bvadd ((_ zero_extend 1) #x0000020000000000) ((_ zero_extend 1) #x0000000000100000))) #b1))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_fdf13d.smt2
Execution time of boolector: 0.0009 seconds
OUTPUT FROM boolector:
unsat

INPUT IN SMTLIB2 FORMAT:
; Verify: safety
; Track: default
; Cut: #0
; Round: 1
; Timeout: 300
; Safety condition: #20
; Instruction: vpc w7_1@int32 678152731@uint64;
; Output file: /tmp/outputqfbv_91ea2f.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (= ((_ extract 63 31) #x00000000286BCA1B) #b000000000000000000000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_ec7ee5.smt2
Execution time of boolector: 0.0010 seconds
OUTPUT FROM boolector:
unsat

===== Verifying range specifications =====
=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: 0 <=s v3_sint32_0_2
; Output file: /tmp/outputqfbv_cc9d96.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 v3_sint32_0_2)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_60073a.smt2
Execution time of boolector: 0.0012 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: 0 <=s v3_sint32_1_2
; Output file: /tmp/outputqfbv_f2f6d5.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 v3_sint32_1_2)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_157726.smt2
Execution time of boolector: 0.0012 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: v3_sint32_0_2 <=s 1073741823
; Output file: /tmp/outputqfbv_a475d7.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle v3_sint32_0_2 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_eac120.smt2
Execution time of boolector: 0.0012 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: v3_sint32_1_2 <=s 1073741823
; Output file: /tmp/outputqfbv_83cb91.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle v3_sint32_1_2 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_21fa13.smt2
Execution time of boolector: 0.0012 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: 0 <=s v4_sint32_0_2
; Output file: /tmp/outputqfbv_76a73d.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 v4_sint32_0_2)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_a34614.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: v4_sint32_0_2 <=s 1073741823
; Output file: /tmp/outputqfbv_ef53a7.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle v4_sint32_0_2 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_8caa33.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: 0 <=s v4_sint32_1_2
; Output file: /tmp/outputqfbv_0e8d6a.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 v4_sint32_1_2)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_923729.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: v4_sint32_1_2 <=s 1073741823
; Output file: /tmp/outputqfbv_0bc5f4.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle v4_sint32_1_2 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_6ecd93.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: 0 <=s v5_sint32_0_2
; Output file: /tmp/outputqfbv_b791ab.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 v5_sint32_0_2)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_95b295.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: v5_sint32_0_2 <=s 1073741823
; Output file: /tmp/outputqfbv_32e408.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle v5_sint32_0_2 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_dab52f.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: 0 <=s v5_sint32_1_2
; Output file: /tmp/outputqfbv_825e9b.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 v5_sint32_1_2)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_6b7cbc.smt2
Execution time of boolector: 0.0010 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: v5_sint32_1_2 <=s 1073741823
; Output file: /tmp/outputqfbv_467859.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle v5_sint32_1_2 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_bc7906.smt2
Execution time of boolector: 0.0010 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: 0 <=s v6_sint32_0_2
; Output file: /tmp/outputqfbv_105750.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 v6_sint32_0_2)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_86f95c.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: v6_sint32_0_2 <=s 1073741823
; Output file: /tmp/outputqfbv_f127ab.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle v6_sint32_0_2 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_8e9304.smt2
Execution time of boolector: 0.0012 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: 0 <=s v6_sint32_1_2
; Output file: /tmp/outputqfbv_7b79ec.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 v6_sint32_1_2)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_69ed1b.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: v6_sint32_1_2 <=s 1073741823
; Output file: /tmp/outputqfbv_fa2a48.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle v6_sint32_1_2 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_d94b92.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: 0 <=s v7_sint32_0_1
; Output file: /tmp/outputqfbv_902859.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 v7_sint32_0_1)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_312324.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: v7_sint32_0_1 <=s 32767
; Output file: /tmp/outputqfbv_5b4c8f.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle v7_sint32_0_1 #x00007FFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_24138e.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: 0 <=s v3_sint32_2_2
; Output file: /tmp/outputqfbv_f5b9b6.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 v3_sint32_2_2)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_bda256.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: v3_sint32_2_2 <=s 1073741823
; Output file: /tmp/outputqfbv_c5765e.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle v3_sint32_2_2 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_bd09a4.smt2
Execution time of boolector: 0.0013 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: 0 <=s v3_sint32_3_2
; Output file: /tmp/outputqfbv_80f3ef.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 v3_sint32_3_2)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_4b12d6.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: v3_sint32_3_2 <=s 1073741823
; Output file: /tmp/outputqfbv_de7313.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle v3_sint32_3_2 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_31bf77.smt2
Execution time of boolector: 0.0013 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: 0 <=s v4_sint32_2_2
; Output file: /tmp/outputqfbv_2a3f72.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 v4_sint32_2_2)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_37b2b0.smt2
Execution time of boolector: 0.0012 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: v4_sint32_2_2 <=s 1073741823
; Output file: /tmp/outputqfbv_1b3d25.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle v4_sint32_2_2 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_b890ff.smt2
Execution time of boolector: 0.0012 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: 0 <=s v4_sint32_3_2
; Output file: /tmp/outputqfbv_fc2447.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 v4_sint32_3_2)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_f717a9.smt2
Execution time of boolector: 0.0012 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: v4_sint32_3_2 <=s 1073741823
; Output file: /tmp/outputqfbv_48191a.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle v4_sint32_3_2 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_953c3b.smt2
Execution time of boolector: 0.0013 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: 0 <=s v5_sint32_2_2
; Output file: /tmp/outputqfbv_c6d5af.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 v5_sint32_2_2)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_ae94cc.smt2
Execution time of boolector: 0.0012 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: v5_sint32_2_2 <=s 1073741823
; Output file: /tmp/outputqfbv_fec8b1.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle v5_sint32_2_2 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_e32105.smt2
Execution time of boolector: 0.0013 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: 0 <=s v5_sint32_3_2
; Output file: /tmp/outputqfbv_291f07.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 v5_sint32_3_2)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_6cecd3.smt2
Execution time of boolector: 0.0012 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: v5_sint32_3_2 <=s 1073741823
; Output file: /tmp/outputqfbv_7982ab.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle v5_sint32_3_2 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_d3d263.smt2
Execution time of boolector: 0.0013 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: 0 <=s v6_sint32_2_2
; Output file: /tmp/outputqfbv_d20c32.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 v6_sint32_2_2)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_9a2c5c.smt2
Execution time of boolector: 0.0013 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: v6_sint32_2_2 <=s 1073741823
; Output file: /tmp/outputqfbv_c0528f.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle v6_sint32_2_2 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_e68d08.smt2
Execution time of boolector: 0.0012 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: 0 <=s v6_sint32_3_2
; Output file: /tmp/outputqfbv_a19fb3.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 v6_sint32_3_2)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_e2fb26.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: v6_sint32_3_2 <=s 1073741823
; Output file: /tmp/outputqfbv_91dc93.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle v6_sint32_3_2 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_0a58ee.smt2
Execution time of boolector: 0.0013 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: 0 <=s v7_sint32_2_1
; Output file: /tmp/outputqfbv_283aca.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 v7_sint32_2_1)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_0ea8c2.smt2
Execution time of boolector: 0.0012 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: ((((((((v3_sint32_0_2@s224) + ((v3_sint32_1_2@s224) * 1073741824)) + ((v4_sint32_0_2@s224) * 1152921504606846976)) + ((v4_sint32_1_2@s224) * 1237940039285380274899124224)) + ((v5_sint32_0_2@s224) * 1329227995784915872903807060280344576)) + ((v5_sint32_1_2@s224) * 1427247692705959881058285969449495136382746624)) + ((v6_sint32_0_2@s224) * 1532495540865888858358347027150309183618739122183602176)) + ((v6_sint32_1_2@s224) * 1645504557321206042154969182557350504982735865633579863348609024)) + ((v7_sint32_0_1@s224) * 1766847064778384329583297500742918515827483896875618958121606201292619776) = (((18446744073709551597@e192) + ((18446744073709551615@e192) * 18446744073709551616)) + ((18446744073709551615@e192) * 340282366920938463463374607431768211456)) + ((9223372036854775807@e192) * 6277101735386680763835789423207666416102355444464034512896)
; Output file: /tmp/outputqfbv_6c3713.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (= (bvadd (bvadd (bvadd (bvadd (bvadd (bvadd (bvadd (bvadd ((_ sign_extend 224) v3_sint32_0_2) (bvmul ((_ sign_extend 224) v3_sint32_1_2) #x0000000000000000000000000000000000000000000000000000000040000000)) (bvmul ((_ sign_extend 224) v4_sint32_0_2) #x0000000000000000000000000000000000000000000000001000000000000000)) (bvmul ((_ sign_extend 224) v4_sint32_1_2) #x0000000000000000000000000000000000000000040000000000000000000000)) (bvmul ((_ sign_extend 224) v5_sint32_0_2) #x0000000000000000000000000000000001000000000000000000000000000000)) (bvmul ((_ sign_extend 224) v5_sint32_1_2) #x0000000000000000000000000040000000000000000000000000000000000000)) (bvmul ((_ sign_extend 224) v6_sint32_0_2) #x0000000000000000001000000000000000000000000000000000000000000000)) (bvmul ((_ sign_extend 224) v6_sint32_1_2) #x0000000000040000000000000000000000000000000000000000000000000000)) (bvmul ((_ sign_extend 224) v7_sint32_0_1) #x0001000000000000000000000000000000000000000000000000000000000000)) (bvadd (bvadd (bvadd ((_ zero_extend 192) #xFFFFFFFFFFFFFFED) (bvmul ((_ zero_extend 192) #xFFFFFFFFFFFFFFFF) #x0000000000000000000000000000000000000000000000010000000000000000)) (bvmul ((_ zero_extend 192) #xFFFFFFFFFFFFFFFF) #x0000000000000000000000000000000100000000000000000000000000000000)) (bvmul ((_ zero_extend 192) #x7FFFFFFFFFFFFFFF) #x0000000000000001000000000000000000000000000000000000000000000000)))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_a3a037.smt2
Execution time of boolector: 0.0013 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: v7_sint32_2_1 <=s 32767
; Output file: /tmp/outputqfbv_b94fca.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle v7_sint32_2_1 #x00007FFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_c734fd.smt2
Execution time of boolector: 0.0059 seconds
OUTPUT FROM boolector:
sat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: ((((((((0@s224) + ((0@s224) * 1073741824)) + ((0@s224) * 1152921504606846976)) + ((0@s224) * 1237940039285380274899124224)) + ((0@s224) * 1329227995784915872903807060280344576)) + ((0@s224) * 1427247692705959881058285969449495136382746624)) + ((0@s224) * 1532495540865888858358347027150309183618739122183602176)) + ((0@s224) * 1645504557321206042154969182557350504982735865633579863348609024)) + ((0@s224) * 1766847064778384329583297500742918515827483896875618958121606201292619776) = 0
; Output file: /tmp/outputqfbv_b7ff96.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (= (bvadd (bvadd (bvadd (bvadd (bvadd (bvadd (bvadd (bvadd ((_ sign_extend 224) #x00000000) (bvmul ((_ sign_extend 224) #x00000000) #x0000000000000000000000000000000000000000000000000000000040000000)) (bvmul ((_ sign_extend 224) #x00000000) #x0000000000000000000000000000000000000000000000001000000000000000)) (bvmul ((_ sign_extend 224) #x00000000) #x0000000000000000000000000000000000000000040000000000000000000000)) (bvmul ((_ sign_extend 224) #x00000000) #x0000000000000000000000000000000001000000000000000000000000000000)) (bvmul ((_ sign_extend 224) #x00000000) #x0000000000000000000000000040000000000000000000000000000000000000)) (bvmul ((_ sign_extend 224) #x00000000) #x0000000000000000001000000000000000000000000000000000000000000000)) (bvmul ((_ sign_extend 224) #x00000000) #x0000000000040000000000000000000000000000000000000000000000000000)) (bvmul ((_ sign_extend 224) #x00000000) #x0001000000000000000000000000000000000000000000000000000000000000)) #x0000000000000000000000000000000000000000000000000000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_658a70.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: ((((((((v8_sint32_2_3@s224) + ((0@s224) * 1073741824)) + ((0@s224) * 1152921504606846976)) + ((0@s224) * 1237940039285380274899124224)) + ((0@s224) * 1329227995784915872903807060280344576)) + ((0@s224) * 1427247692705959881058285969449495136382746624)) + ((0@s224) * 1532495540865888858358347027150309183618739122183602176)) + ((0@s224) * 1645504557321206042154969182557350504982735865633579863348609024)) + ((0@s224) * 1766847064778384329583297500742918515827483896875618958121606201292619776) = 1
; Output file: /tmp/outputqfbv_0591d7.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (= (bvadd (bvadd (bvadd (bvadd (bvadd (bvadd (bvadd (bvadd ((_ sign_extend 224) v8_sint32_2_3) (bvmul ((_ sign_extend 224) #x00000000) #x0000000000000000000000000000000000000000000000000000000040000000)) (bvmul ((_ sign_extend 224) #x00000000) #x0000000000000000000000000000000000000000000000001000000000000000)) (bvmul ((_ sign_extend 224) #x00000000) #x0000000000000000000000000000000000000000040000000000000000000000)) (bvmul ((_ sign_extend 224) #x00000000) #x0000000000000000000000000000000001000000000000000000000000000000)) (bvmul ((_ sign_extend 224) #x00000000) #x0000000000000000000000000040000000000000000000000000000000000000)) (bvmul ((_ sign_extend 224) #x00000000) #x0000000000000000001000000000000000000000000000000000000000000000)) (bvmul ((_ sign_extend 224) #x00000000) #x0000000000040000000000000000000000000000000000000000000000000000)) (bvmul ((_ sign_extend 224) #x00000000) #x0001000000000000000000000000000000000000000000000000000000000000)) #x0000000000000000000000000000000000000000000000000000000000000001)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_ed6d95.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_2, v3_sint32_0_2 <=s 1073741823@32, 0@32 <=s v3_sint32_1_2, v3_sint32_1_2 <=s 1073741823@32, 0@32 <=s v4_sint32_0_2, v4_sint32_0_2 <=s 1073741823@32, 0@32 <=s v4_sint32_1_2, v4_sint32_1_2 <=s 1073741823@32, 0@32 <=s v5_sint32_0_2, v5_sint32_0_2 <=s 1073741823@32, 0@32 <=s v5_sint32_1_2, v5_sint32_1_2 <=s 1073741823@32, 0@32 <=s v6_sint32_0_2, v6_sint32_0_2 <=s 1073741823@32, 0@32 <=s v6_sint32_1_2, v6_sint32_1_2 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_2, v3_sint32_2_2 <=s 1073741823@32, 0@32 <=s v3_sint32_3_2, v3_sint32_3_2 <=s 1073741823@32, 0@32 <=s v4_sint32_2_2, v4_sint32_2_2 <=s 1073741823@32, 0@32 <=s v4_sint32_3_2, v4_sint32_3_2 <=s 1073741823@32, 0@32 <=s v5_sint32_2_2, v5_sint32_2_2 <=s 1073741823@32, 0@32 <=s v5_sint32_3_2, v5_sint32_3_2 <=s 1073741823@32, 0@32 <=s v6_sint32_2_2, v6_sint32_2_2 <=s 1073741823@32, 0@32 <=s v6_sint32_3_2, v6_sint32_3_2 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 32767@32, add (add (add (add (add (add (add (add (sext v3_sint32_0_2 224) (mul (sext v3_sint32_1_2 224) 1073741824@256)) (mul (sext v4_sint32_0_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_1_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_0_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_1_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_0_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_1_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_0_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext 18446744073709551597@64 192) (mul (uext 18446744073709551615@64 192) 18446744073709551616@256)) (mul (uext 18446744073709551615@64 192) 340282366920938463463374607431768211456@256)) (mul (uext 9223372036854775807@64 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext v3_sint32_2_2 224) (mul (sext v3_sint32_3_2 224) 1073741824@256)) (mul (sext v4_sint32_2_2 224) 1152921504606846976@256)) (mul (sext v4_sint32_3_2 224) 1237940039285380274899124224@256)) (mul (sext v5_sint32_2_2 224) 1329227995784915872903807060280344576@256)) (mul (sext v5_sint32_3_2 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext v6_sint32_2_2 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext v6_sint32_3_2 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext v7_sint32_2_1 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = add (add (add (uext op_x0_0 192) (mul (uext op_x1_0 192) 18446744073709551616@256)) (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256)) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256), add (add (add (add (add (add (add (add (sext 0@32 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 0@256, add (add (add (add (add (add (add (add (sext v8_sint32_2_3 224) (mul (sext 0@32 224) 1073741824@256)) (mul (sext 0@32 224) 1152921504606846976@256)) (mul (sext 0@32 224) 1237940039285380274899124224@256)) (mul (sext 0@32 224) 1329227995784915872903807060280344576@256)) (mul (sext 0@32 224) 1427247692705959881058285969449495136382746624@256)) (mul (sext 0@32 224) 1532495540865888858358347027150309183618739122183602176@256)) (mul (sext 0@32 224) 1645504557321206042154969182557350504982735865633579863348609024@256)) (mul (sext 0@32 224) 1766847064778384329583297500742918515827483896875618958121606201292619776@256) = 1@256]
; Range condition: ((((((((v3_sint32_2_2@s224) + ((v3_sint32_3_2@s224) * 1073741824)) + ((v4_sint32_2_2@s224) * 1152921504606846976)) + ((v4_sint32_3_2@s224) * 1237940039285380274899124224)) + ((v5_sint32_2_2@s224) * 1329227995784915872903807060280344576)) + ((v5_sint32_3_2@s224) * 1427247692705959881058285969449495136382746624)) + ((v6_sint32_2_2@s224) * 1532495540865888858358347027150309183618739122183602176)) + ((v6_sint32_3_2@s224) * 1645504557321206042154969182557350504982735865633579863348609024)) + ((v7_sint32_2_1@s224) * 1766847064778384329583297500742918515827483896875618958121606201292619776) = (((op_x0_0@e192) + ((op_x1_0@e192) * 18446744073709551616)) + ((op_x2_0@e192) * 340282366920938463463374607431768211456)) + ((op_x3_0@e192) * 6277101735386680763835789423207666416102355444464034512896)
; Output file: /tmp/outputqfbv_a02ab8.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_3 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_2 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 64))
(declare-fun v6_sint32_2_2 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_2 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 64))
(declare-fun v6_sint32_0_2 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_2 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 64))
(declare-fun v5_sint32_2_2 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_2 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 64))
(declare-fun v5_sint32_0_2 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_2 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 64))
(declare-fun v4_sint32_2_2 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_2 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 64))
(declare-fun v4_sint32_0_2 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_2 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 64))
(declare-fun v3_sint32_2_2 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 64))
(declare-fun v3_sint32_1_2 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 64))
(declare-fun v3_sint32_0_2 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 48))
(declare-fun dc_47 () (_ BitVec 48))
(declare-fun dc_46 () (_ BitVec 64))
(declare-fun dc_45 () (_ BitVec 64))
(declare-fun dc_44 () (_ BitVec 64))
(declare-fun dc_43 () (_ BitVec 64))
(declare-fun dc_42 () (_ BitVec 18))
(declare-fun dc_41 () (_ BitVec 18))
(declare-fun dc_40 () (_ BitVec 64))
(declare-fun dc_39 () (_ BitVec 64))
(declare-fun dc_38 () (_ BitVec 12))
(declare-fun dc_37 () (_ BitVec 12))
(declare-fun dc_36 () (_ BitVec 52))
(declare-fun dc_35 () (_ BitVec 52))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 64))
(declare-fun dc_31 () (_ BitVec 64))
(declare-fun dc_30 () (_ BitVec 22))
(declare-fun dc_29 () (_ BitVec 22))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 8))
(declare-fun dc_25 () (_ BitVec 8))
(declare-fun dc_24 () (_ BitVec 56))
(declare-fun dc_23 () (_ BitVec 56))
(declare-fun dc_22 () (_ BitVec 64))
(declare-fun dc_21 () (_ BitVec 64))
(declare-fun dc_20 () (_ BitVec 64))
(declare-fun dc_19 () (_ BitVec 64))
(declare-fun dc_18 () (_ BitVec 26))
(declare-fun dc_17 () (_ BitVec 26))
(declare-fun dc_16 () (_ BitVec 64))
(declare-fun dc_15 () (_ BitVec 64))
(declare-fun dc_14 () (_ BitVec 4))
(declare-fun dc_13 () (_ BitVec 4))
(declare-fun dc_12 () (_ BitVec 60))
(declare-fun dc_11 () (_ BitVec 60))
(declare-fun dc_10 () (_ BitVec 64))
(declare-fun dc_9 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert (bvslt (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED))
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_sint32_0_1 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_sint32_2_1 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (and (= dc_9 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_2))) (= v3_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_2)))))
(assert (and (= dc_10 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_2))) (= v3_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_2)))))
(assert (= v3_sint32_0_2 ((_ extract 31 0) v3_sint32_0_1)))
(assert (= v3_sint32_1_2 ((_ extract 31 0) v3_sint32_1_1)))
(assert (= v3_sint32_2_2 ((_ extract 31 0) v3_sint32_2_1)))
(assert (= v3_sint32_3_2 ((_ extract 31 0) v3_sint32_3_1)))
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_11 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_12 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_13 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_14 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_15 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_16 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_17 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_18 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_19 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_20 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (and (= dc_21 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_6))) (= v4_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_6)))))
(assert (and (= dc_22 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_6))) (= v4_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_6)))))
(assert (= v4_sint32_0_2 v4_sint32_0_1))
(assert (= v4_sint32_1_2 ((_ extract 31 0) v4_sint32_1_1)))
(assert (= v4_sint32_2_2 v4_sint32_2_1))
(assert (= v4_sint32_3_2 ((_ extract 31 0) v4_sint32_3_1)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_23 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_24 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_25 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_26 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_29 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_30 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_31 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_32 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (and (= dc_33 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_10))) (= v5_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_10)))))
(assert (and (= dc_34 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_10))) (= v5_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_10)))))
(assert (= v5_sint32_0_2 v5_sint32_0_1))
(assert (= v5_sint32_1_2 ((_ extract 31 0) v5_sint32_1_1)))
(assert (= v5_sint32_2_2 v5_sint32_2_1))
(assert (= v5_sint32_3_2 ((_ extract 31 0) v5_sint32_3_1)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_35 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_36 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_37 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_38 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_39 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_40 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_41 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_42 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_43 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_44 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (and (= dc_45 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_0_14))) (= v6_sint32_1_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_0_14)))))
(assert (and (= dc_46 ((_ zero_extend 32) ((_ extract 63 32) v12_uint64_1_14))) (= v6_sint32_3_1 ((_ zero_extend 32) ((_ extract 31 0) v12_uint64_1_14)))))
(assert (= v6_sint32_0_2 v6_sint32_0_1))
(assert (= v6_sint32_1_2 ((_ extract 31 0) v6_sint32_1_1)))
(assert (= v6_sint32_2_2 v6_sint32_2_1))
(assert (= v6_sint32_3_2 ((_ extract 31 0) v6_sint32_3_1)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_47 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_48 ((_ extract 47 0) op_x3_0))))
(assert (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1)))
(assert (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1)))
(assert (= v8_sint32_2_3 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (= (bvadd (bvadd (bvadd (bvadd (bvadd (bvadd (bvadd (bvadd ((_ sign_extend 224) v3_sint32_2_2) (bvmul ((_ sign_extend 224) v3_sint32_3_2) #x0000000000000000000000000000000000000000000000000000000040000000)) (bvmul ((_ sign_extend 224) v4_sint32_2_2) #x0000000000000000000000000000000000000000000000001000000000000000)) (bvmul ((_ sign_extend 224) v4_sint32_3_2) #x0000000000000000000000000000000000000000040000000000000000000000)) (bvmul ((_ sign_extend 224) v5_sint32_2_2) #x0000000000000000000000000000000001000000000000000000000000000000)) (bvmul ((_ sign_extend 224) v5_sint32_3_2) #x0000000000000000000000000040000000000000000000000000000000000000)) (bvmul ((_ sign_extend 224) v6_sint32_2_2) #x0000000000000000001000000000000000000000000000000000000000000000)) (bvmul ((_ sign_extend 224) v6_sint32_3_2) #x0000000000040000000000000000000000000000000000000000000000000000)) (bvmul ((_ sign_extend 224) v7_sint32_2_1) #x0001000000000000000000000000000000000000000000000000000000000000)) (bvadd (bvadd (bvadd ((_ zero_extend 192) op_x0_0) (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000)) (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000)) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_cbe958.smt2
Execution time of boolector: 0.0162 seconds
OUTPUT FROM boolector:
unsat

