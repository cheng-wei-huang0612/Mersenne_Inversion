===== Verifying program safety =====
=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: safety
; Track: default
; Cut: #0
; Verify: safety (all in one query)
; Output file: /tmp/outputqfbv_5ee34c.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and true true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) #x0000020000000000) ((_ extract 63 63) #x0000000000100000)) (bvnot ((_ extract 63 63) (bvadd #x0000020000000000 #x0000000000100000)))) (bvand (bvand (bvnot ((_ extract 63 63) #x0000020000000000)) (bvnot ((_ extract 63 63) #x0000000000100000))) ((_ extract 63 63) (bvadd #x0000020000000000 #x0000000000100000)))) #b1))) true)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_876cf4.smt2
Execution time of boolector: 0.0012 seconds
OUTPUT FROM boolector:
unsat

Execution of safety task: 0.0061 seconds
=== Cut #1 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: safety
; Track: default
; Cut: #1
; Verify: safety (all in one query)
; Output file: /tmp/outputqfbv_c03660.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_2 () (_ BitVec 64))
(declare-fun x8_1 () (_ BitVec 64))
(declare-fun x7_3 () (_ BitVec 64))
(declare-fun x7_2 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun g_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_0_1 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (bvsle #x00000000 v3_sint32_0_1) (bvsle v3_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v3_sint32_1_1)) (bvsle v3_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_0_1)) (bvsle v4_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_1_1)) (bvsle v4_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_0_1)) (bvsle v5_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_1_1)) (bvsle v5_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_0_1)) (bvsle v6_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_1_1)) (bvsle v6_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v7_sint32_0_1)) (bvsle v7_sint32_0_1 #x00007FFF)) (bvsle #x00000000 v3_sint32_2_1)) (bvsle v3_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v3_sint32_3_1)) (bvsle v3_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_2_1)) (bvsle v4_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_3_1)) (bvsle v4_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_2_1)) (bvsle v5_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_3_1)) (bvsle v5_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_2_1)) (bvsle v6_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_3_1)) (bvsle v6_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v7_sint32_2_1)) (bvsle v7_sint32_2_1 #x0000FFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x0000FFFF)) (bvsle #x00000000 v8_sint32_2_2)) (bvsle v8_sint32_2_2 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x0000FFFF)) (= (bvadd (bvmul ((_ zero_extend 240) v3_sint32_0_1) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) v3_sint32_1_1) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_0_1) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_1_1) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_0_1) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_1_1) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_0_1) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_1_1) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) v7_sint32_0_1) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00007FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) (= (bvadd (bvmul ((_ zero_extend 240) v3_sint32_2_1) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) v3_sint32_3_1) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_2_1) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_3_1) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_2_1) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_3_1) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_2_1) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_3_1) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) v7_sint32_2_1) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) ((_ zero_extend 16) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000))))))) (= (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) #x00000000) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00000000000000000000000000000000000000000000000000000000000000000000)) (= (bvadd (bvmul ((_ zero_extend 240) v8_sint32_2_2) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) #x00000000) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00000000000000000000000000000000000000000000000000000000000000000001)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 192) x1_2)) ((_ zero_extend 1) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) ((_ zero_extend 1) #x0000000000000000000000000000000000000000000000001000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 192) x2_6)) ((_ zero_extend 1) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))))) ((_ zero_extend 1) #x0000000000000000000000000000000000000000000000001000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= #x0000000000000001 #x0000000000000001)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 128) (bvadd (bvmul ((_ zero_extend 64) #xFFFFFFFFFFFFFFED) #x00000000000000000000000000000001) (bvmul ((_ zero_extend 64) #xFFFFFFFFFFFFFFFF) #x00000000000000010000000000000000)))) ((_ zero_extend 1) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) ((_ zero_extend 1) #x0000000000000000000000000000000100000000000000000000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 128) (bvadd (bvmul ((_ zero_extend 64) op_x0_0) #x00000000000000000000000000000001) (bvmul ((_ zero_extend 64) op_x1_0) #x00000000000000010000000000000000)))) ((_ zero_extend 1) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))))) ((_ zero_extend 1) #x0000000000000000000000000000000100000000000000000000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= x6_2 #x0000020000100000)))
(assert (= x7_2 (bvand x1_2 #x00000000000FFFFF)))
(assert (= x8_1 (bvand x2_6 #x00000000000FFFFF)))
(assert (= x7_3 (bvor x7_2 #xFFFFFE0000000000)))
(assert (= x8_2 (bvor x8_1 #xC000000000000000)))
(assert (= f_0_low60_0_low20_0_1 (bvand x1_2 #x00000000000FFFFF)))
(assert (= g_0_low60_0_low20_0_1 (bvand x2_6 #x00000000000FFFFF)))
(assert (not (and (and (and (and (and (and true true) true) true) true) true) true)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_1b647d.smt2
Execution time of boolector: 0.0013 seconds
OUTPUT FROM boolector:
unsat

Execution of safety task: 0.0055 seconds
=== Cut #2 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: safety
; Track: default
; Cut: #2
; Verify: safety (all in one query)
; Output file: /tmp/outputqfbv_4aff15.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_19 () (_ BitVec 1))
(declare-fun x8_target_18 () (_ BitVec 1))
(declare-fun x8_target_17 () (_ BitVec 1))
(declare-fun x8_target_16 () (_ BitVec 1))
(declare-fun x8_target_15 () (_ BitVec 1))
(declare-fun x8_target_14 () (_ BitVec 1))
(declare-fun x8_target_13 () (_ BitVec 1))
(declare-fun x8_target_12 () (_ BitVec 1))
(declare-fun x8_target_11 () (_ BitVec 1))
(declare-fun x8_target_10 () (_ BitVec 1))
(declare-fun x8_target_9 () (_ BitVec 1))
(declare-fun x8_target_8 () (_ BitVec 1))
(declare-fun x8_target_7 () (_ BitVec 1))
(declare-fun x8_target_6 () (_ BitVec 1))
(declare-fun x8_target_5 () (_ BitVec 1))
(declare-fun x8_target_4 () (_ BitVec 1))
(declare-fun x8_target_3 () (_ BitVec 1))
(declare-fun x8_target_2 () (_ BitVec 1))
(declare-fun x8_target_1 () (_ BitVec 1))
(declare-fun x8_lo_20 () (_ BitVec 2))
(declare-fun x8_lo_19 () (_ BitVec 2))
(declare-fun x8_lo_18 () (_ BitVec 2))
(declare-fun x8_lo_17 () (_ BitVec 2))
(declare-fun x8_lo_16 () (_ BitVec 2))
(declare-fun x8_lo_15 () (_ BitVec 2))
(declare-fun x8_lo_14 () (_ BitVec 2))
(declare-fun x8_lo_13 () (_ BitVec 2))
(declare-fun x8_lo_12 () (_ BitVec 2))
(declare-fun x8_lo_11 () (_ BitVec 2))
(declare-fun x8_lo_10 () (_ BitVec 2))
(declare-fun x8_lo_9 () (_ BitVec 2))
(declare-fun x8_lo_8 () (_ BitVec 2))
(declare-fun x8_lo_7 () (_ BitVec 2))
(declare-fun x8_lo_6 () (_ BitVec 2))
(declare-fun x8_lo_5 () (_ BitVec 2))
(declare-fun x8_lo_4 () (_ BitVec 2))
(declare-fun x8_lo_3 () (_ BitVec 2))
(declare-fun x8_lo_2 () (_ BitVec 2))
(declare-fun x8_lo_1 () (_ BitVec 1))
(declare-fun x8_42 () (_ BitVec 64))
(declare-fun x8_41 () (_ BitVec 64))
(declare-fun x8_40 () (_ BitVec 64))
(declare-fun x8_39 () (_ BitVec 64))
(declare-fun x8_38 () (_ BitVec 64))
(declare-fun x8_37 () (_ BitVec 64))
(declare-fun x8_36 () (_ BitVec 64))
(declare-fun x8_35 () (_ BitVec 64))
(declare-fun x8_34 () (_ BitVec 64))
(declare-fun x8_33 () (_ BitVec 64))
(declare-fun x8_32 () (_ BitVec 64))
(declare-fun x8_31 () (_ BitVec 64))
(declare-fun x8_30 () (_ BitVec 64))
(declare-fun x8_29 () (_ BitVec 64))
(declare-fun x8_28 () (_ BitVec 64))
(declare-fun x8_27 () (_ BitVec 64))
(declare-fun x8_26 () (_ BitVec 64))
(declare-fun x8_25 () (_ BitVec 64))
(declare-fun x8_24 () (_ BitVec 64))
(declare-fun x8_23 () (_ BitVec 64))
(declare-fun x8_22 () (_ BitVec 64))
(declare-fun x8_21 () (_ BitVec 64))
(declare-fun x8_20 () (_ BitVec 64))
(declare-fun x8_19 () (_ BitVec 64))
(declare-fun x8_18 () (_ BitVec 64))
(declare-fun x8_17 () (_ BitVec 64))
(declare-fun x8_16 () (_ BitVec 64))
(declare-fun x8_15 () (_ BitVec 64))
(declare-fun x8_14 () (_ BitVec 64))
(declare-fun x8_13 () (_ BitVec 64))
(declare-fun x8_12 () (_ BitVec 64))
(declare-fun x8_11 () (_ BitVec 64))
(declare-fun x8_10 () (_ BitVec 64))
(declare-fun x8_9 () (_ BitVec 64))
(declare-fun x8_8 () (_ BitVec 64))
(declare-fun x8_7 () (_ BitVec 64))
(declare-fun x8_6 () (_ BitVec 64))
(declare-fun x8_5 () (_ BitVec 64))
(declare-fun x8_4 () (_ BitVec 64))
(declare-fun x8_3 () (_ BitVec 64))
(declare-fun x8_2 () (_ BitVec 64))
(declare-fun x7_23 () (_ BitVec 64))
(declare-fun x7_22 () (_ BitVec 64))
(declare-fun x7_21 () (_ BitVec 64))
(declare-fun x7_20 () (_ BitVec 64))
(declare-fun x7_19 () (_ BitVec 64))
(declare-fun x7_18 () (_ BitVec 64))
(declare-fun x7_17 () (_ BitVec 64))
(declare-fun x7_16 () (_ BitVec 64))
(declare-fun x7_15 () (_ BitVec 64))
(declare-fun x7_14 () (_ BitVec 64))
(declare-fun x7_13 () (_ BitVec 64))
(declare-fun x7_12 () (_ BitVec 64))
(declare-fun x7_11 () (_ BitVec 64))
(declare-fun x7_10 () (_ BitVec 64))
(declare-fun x7_9 () (_ BitVec 64))
(declare-fun x7_8 () (_ BitVec 64))
(declare-fun x7_7 () (_ BitVec 64))
(declare-fun x7_6 () (_ BitVec 64))
(declare-fun x7_5 () (_ BitVec 64))
(declare-fun x7_4 () (_ BitVec 64))
(declare-fun x7_3 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_20 () (_ BitVec 64))
(declare-fun x3_neg_19 () (_ BitVec 64))
(declare-fun x3_neg_18 () (_ BitVec 64))
(declare-fun x3_neg_17 () (_ BitVec 64))
(declare-fun x3_neg_16 () (_ BitVec 64))
(declare-fun x3_neg_15 () (_ BitVec 64))
(declare-fun x3_neg_14 () (_ BitVec 64))
(declare-fun x3_neg_13 () (_ BitVec 64))
(declare-fun x3_neg_12 () (_ BitVec 64))
(declare-fun x3_neg_11 () (_ BitVec 64))
(declare-fun x3_neg_10 () (_ BitVec 64))
(declare-fun x3_neg_9 () (_ BitVec 64))
(declare-fun x3_neg_8 () (_ BitVec 64))
(declare-fun x3_neg_7 () (_ BitVec 64))
(declare-fun x3_neg_6 () (_ BitVec 64))
(declare-fun x3_neg_5 () (_ BitVec 64))
(declare-fun x3_neg_4 () (_ BitVec 64))
(declare-fun x3_neg_3 () (_ BitVec 64))
(declare-fun x3_neg_2 () (_ BitVec 64))
(declare-fun x3_neg_1 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x3_40 () (_ BitVec 64))
(declare-fun x3_39 () (_ BitVec 64))
(declare-fun x3_38 () (_ BitVec 64))
(declare-fun x3_37 () (_ BitVec 64))
(declare-fun x3_36 () (_ BitVec 64))
(declare-fun x3_35 () (_ BitVec 64))
(declare-fun x3_34 () (_ BitVec 64))
(declare-fun x3_33 () (_ BitVec 64))
(declare-fun x3_32 () (_ BitVec 64))
(declare-fun x3_31 () (_ BitVec 64))
(declare-fun x3_30 () (_ BitVec 64))
(declare-fun x3_29 () (_ BitVec 64))
(declare-fun x3_28 () (_ BitVec 64))
(declare-fun x3_27 () (_ BitVec 64))
(declare-fun x3_26 () (_ BitVec 64))
(declare-fun x3_25 () (_ BitVec 64))
(declare-fun x3_24 () (_ BitVec 64))
(declare-fun x3_23 () (_ BitVec 64))
(declare-fun x3_22 () (_ BitVec 64))
(declare-fun x3_21 () (_ BitVec 64))
(declare-fun x3_20 () (_ BitVec 64))
(declare-fun x3_19 () (_ BitVec 64))
(declare-fun x3_18 () (_ BitVec 64))
(declare-fun x3_17 () (_ BitVec 64))
(declare-fun x3_16 () (_ BitVec 64))
(declare-fun x3_15 () (_ BitVec 64))
(declare-fun x3_14 () (_ BitVec 64))
(declare-fun x3_13 () (_ BitVec 64))
(declare-fun x3_12 () (_ BitVec 64))
(declare-fun x3_11 () (_ BitVec 64))
(declare-fun x3_10 () (_ BitVec 64))
(declare-fun x3_9 () (_ BitVec 64))
(declare-fun x3_8 () (_ BitVec 64))
(declare-fun x3_7 () (_ BitVec 64))
(declare-fun x3_6 () (_ BitVec 64))
(declare-fun x3_5 () (_ BitVec 64))
(declare-fun x3_4 () (_ BitVec 64))
(declare-fun x3_3 () (_ BitVec 64))
(declare-fun x3_2 () (_ BitVec 64))
(declare-fun x10_neg_20 () (_ BitVec 64))
(declare-fun x10_neg_19 () (_ BitVec 64))
(declare-fun x10_neg_18 () (_ BitVec 64))
(declare-fun x10_neg_17 () (_ BitVec 64))
(declare-fun x10_neg_16 () (_ BitVec 64))
(declare-fun x10_neg_15 () (_ BitVec 64))
(declare-fun x10_neg_14 () (_ BitVec 64))
(declare-fun x10_neg_13 () (_ BitVec 64))
(declare-fun x10_neg_12 () (_ BitVec 64))
(declare-fun x10_neg_11 () (_ BitVec 64))
(declare-fun x10_neg_10 () (_ BitVec 64))
(declare-fun x10_neg_9 () (_ BitVec 64))
(declare-fun x10_neg_8 () (_ BitVec 64))
(declare-fun x10_neg_7 () (_ BitVec 64))
(declare-fun x10_neg_6 () (_ BitVec 64))
(declare-fun x10_neg_5 () (_ BitVec 64))
(declare-fun x10_neg_4 () (_ BitVec 64))
(declare-fun x10_neg_3 () (_ BitVec 64))
(declare-fun x10_neg_2 () (_ BitVec 64))
(declare-fun x10_neg_1 () (_ BitVec 64))
(declare-fun x10_40 () (_ BitVec 64))
(declare-fun x10_39 () (_ BitVec 64))
(declare-fun x10_38 () (_ BitVec 64))
(declare-fun x10_37 () (_ BitVec 64))
(declare-fun x10_36 () (_ BitVec 64))
(declare-fun x10_35 () (_ BitVec 64))
(declare-fun x10_34 () (_ BitVec 64))
(declare-fun x10_33 () (_ BitVec 64))
(declare-fun x10_32 () (_ BitVec 64))
(declare-fun x10_31 () (_ BitVec 64))
(declare-fun x10_30 () (_ BitVec 64))
(declare-fun x10_29 () (_ BitVec 64))
(declare-fun x10_28 () (_ BitVec 64))
(declare-fun x10_27 () (_ BitVec 64))
(declare-fun x10_26 () (_ BitVec 64))
(declare-fun x10_25 () (_ BitVec 64))
(declare-fun x10_24 () (_ BitVec 64))
(declare-fun x10_23 () (_ BitVec 64))
(declare-fun x10_22 () (_ BitVec 64))
(declare-fun x10_21 () (_ BitVec 64))
(declare-fun x10_20 () (_ BitVec 64))
(declare-fun x10_19 () (_ BitVec 64))
(declare-fun x10_18 () (_ BitVec 64))
(declare-fun x10_17 () (_ BitVec 64))
(declare-fun x10_16 () (_ BitVec 64))
(declare-fun x10_15 () (_ BitVec 64))
(declare-fun x10_14 () (_ BitVec 64))
(declare-fun x10_13 () (_ BitVec 64))
(declare-fun x10_12 () (_ BitVec 64))
(declare-fun x10_11 () (_ BitVec 64))
(declare-fun x10_10 () (_ BitVec 64))
(declare-fun x10_9 () (_ BitVec 64))
(declare-fun x10_8 () (_ BitVec 64))
(declare-fun x10_7 () (_ BitVec 64))
(declare-fun x10_6 () (_ BitVec 64))
(declare-fun x10_5 () (_ BitVec 64))
(declare-fun x10_4 () (_ BitVec 64))
(declare-fun x10_3 () (_ BitVec 64))
(declare-fun x10_2 () (_ BitVec 64))
(declare-fun x10_1 () (_ BitVec 64))
(declare-fun v_0_20_2 () (_ BitVec 64))
(declare-fun u_0_20_2 () (_ BitVec 64))
(declare-fun s_0_20_2 () (_ BitVec 64))
(declare-fun r_0_20_2 () (_ BitVec 64))
(declare-fun ne_20 () (_ BitVec 1))
(declare-fun ne_19 () (_ BitVec 1))
(declare-fun ne_18 () (_ BitVec 1))
(declare-fun ne_17 () (_ BitVec 1))
(declare-fun ne_16 () (_ BitVec 1))
(declare-fun ne_15 () (_ BitVec 1))
(declare-fun ne_14 () (_ BitVec 1))
(declare-fun ne_13 () (_ BitVec 1))
(declare-fun ne_12 () (_ BitVec 1))
(declare-fun ne_11 () (_ BitVec 1))
(declare-fun ne_10 () (_ BitVec 1))
(declare-fun ne_9 () (_ BitVec 1))
(declare-fun ne_8 () (_ BitVec 1))
(declare-fun ne_7 () (_ BitVec 1))
(declare-fun ne_6 () (_ BitVec 1))
(declare-fun ne_5 () (_ BitVec 1))
(declare-fun ne_4 () (_ BitVec 1))
(declare-fun ne_3 () (_ BitVec 1))
(declare-fun ne_2 () (_ BitVec 1))
(declare-fun ne_1 () (_ BitVec 1))
(declare-fun ge_60 () (_ BitVec 1))
(declare-fun ge_59 () (_ BitVec 1))
(declare-fun ge_58 () (_ BitVec 1))
(declare-fun ge_57 () (_ BitVec 1))
(declare-fun ge_56 () (_ BitVec 1))
(declare-fun ge_55 () (_ BitVec 1))
(declare-fun ge_54 () (_ BitVec 1))
(declare-fun ge_53 () (_ BitVec 1))
(declare-fun ge_52 () (_ BitVec 1))
(declare-fun ge_51 () (_ BitVec 1))
(declare-fun ge_50 () (_ BitVec 1))
(declare-fun ge_49 () (_ BitVec 1))
(declare-fun ge_48 () (_ BitVec 1))
(declare-fun ge_47 () (_ BitVec 1))
(declare-fun ge_46 () (_ BitVec 1))
(declare-fun ge_45 () (_ BitVec 1))
(declare-fun ge_44 () (_ BitVec 1))
(declare-fun ge_43 () (_ BitVec 1))
(declare-fun ge_42 () (_ BitVec 1))
(declare-fun ge_41 () (_ BitVec 1))
(declare-fun ge_40 () (_ BitVec 1))
(declare-fun ge_39 () (_ BitVec 1))
(declare-fun ge_38 () (_ BitVec 1))
(declare-fun ge_37 () (_ BitVec 1))
(declare-fun ge_36 () (_ BitVec 1))
(declare-fun ge_35 () (_ BitVec 1))
(declare-fun ge_34 () (_ BitVec 1))
(declare-fun ge_33 () (_ BitVec 1))
(declare-fun ge_32 () (_ BitVec 1))
(declare-fun ge_31 () (_ BitVec 1))
(declare-fun ge_30 () (_ BitVec 1))
(declare-fun ge_29 () (_ BitVec 1))
(declare-fun ge_28 () (_ BitVec 1))
(declare-fun ge_27 () (_ BitVec 1))
(declare-fun ge_26 () (_ BitVec 1))
(declare-fun ge_25 () (_ BitVec 1))
(declare-fun ge_24 () (_ BitVec 1))
(declare-fun ge_23 () (_ BitVec 1))
(declare-fun ge_22 () (_ BitVec 1))
(declare-fun ge_21 () (_ BitVec 1))
(declare-fun ge_20 () (_ BitVec 1))
(declare-fun ge_19 () (_ BitVec 1))
(declare-fun ge_18 () (_ BitVec 1))
(declare-fun ge_17 () (_ BitVec 1))
(declare-fun ge_16 () (_ BitVec 1))
(declare-fun ge_15 () (_ BitVec 1))
(declare-fun ge_14 () (_ BitVec 1))
(declare-fun ge_13 () (_ BitVec 1))
(declare-fun ge_12 () (_ BitVec 1))
(declare-fun ge_11 () (_ BitVec 1))
(declare-fun ge_10 () (_ BitVec 1))
(declare-fun ge_9 () (_ BitVec 1))
(declare-fun ge_8 () (_ BitVec 1))
(declare-fun ge_7 () (_ BitVec 1))
(declare-fun ge_6 () (_ BitVec 1))
(declare-fun ge_5 () (_ BitVec 1))
(declare-fun ge_4 () (_ BitVec 1))
(declare-fun ge_3 () (_ BitVec 1))
(declare-fun ge_2 () (_ BitVec 1))
(declare-fun ge_1 () (_ BitVec 1))
(declare-fun g_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun g_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun f_0_low60_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun dc_179 () (_ BitVec 64))
(declare-fun dc_178 () (_ BitVec 1))
(declare-fun dc_177 () (_ BitVec 1))
(declare-fun dc_176 () (_ BitVec 1))
(declare-fun dc_175 () (_ BitVec 63))
(declare-fun dc_174 () (_ BitVec 64))
(declare-fun dc_173 () (_ BitVec 1))
(declare-fun dc_172 () (_ BitVec 62))
(declare-fun dc_171 () (_ BitVec 1))
(declare-fun dc_170 () (_ BitVec 1))
(declare-fun dc_169 () (_ BitVec 1))
(declare-fun dc_168 () (_ BitVec 63))
(declare-fun dc_167 () (_ BitVec 64))
(declare-fun dc_166 () (_ BitVec 1))
(declare-fun dc_165 () (_ BitVec 62))
(declare-fun dc_164 () (_ BitVec 1))
(declare-fun dc_163 () (_ BitVec 1))
(declare-fun dc_162 () (_ BitVec 1))
(declare-fun dc_161 () (_ BitVec 63))
(declare-fun dc_160 () (_ BitVec 64))
(declare-fun dc_159 () (_ BitVec 1))
(declare-fun dc_158 () (_ BitVec 62))
(declare-fun dc_157 () (_ BitVec 1))
(declare-fun dc_156 () (_ BitVec 1))
(declare-fun dc_155 () (_ BitVec 1))
(declare-fun dc_154 () (_ BitVec 63))
(declare-fun dc_153 () (_ BitVec 64))
(declare-fun dc_152 () (_ BitVec 1))
(declare-fun dc_151 () (_ BitVec 62))
(declare-fun dc_150 () (_ BitVec 1))
(declare-fun dc_149 () (_ BitVec 1))
(declare-fun dc_148 () (_ BitVec 1))
(declare-fun dc_147 () (_ BitVec 63))
(declare-fun dc_146 () (_ BitVec 64))
(declare-fun dc_145 () (_ BitVec 1))
(declare-fun dc_144 () (_ BitVec 62))
(declare-fun dc_143 () (_ BitVec 1))
(declare-fun dc_142 () (_ BitVec 1))
(declare-fun dc_141 () (_ BitVec 1))
(declare-fun dc_140 () (_ BitVec 63))
(declare-fun dc_139 () (_ BitVec 64))
(declare-fun dc_138 () (_ BitVec 1))
(declare-fun dc_137 () (_ BitVec 62))
(declare-fun dc_136 () (_ BitVec 1))
(declare-fun dc_135 () (_ BitVec 1))
(declare-fun dc_134 () (_ BitVec 1))
(declare-fun dc_133 () (_ BitVec 63))
(declare-fun dc_132 () (_ BitVec 64))
(declare-fun dc_131 () (_ BitVec 1))
(declare-fun dc_130 () (_ BitVec 62))
(declare-fun dc_129 () (_ BitVec 1))
(declare-fun dc_128 () (_ BitVec 1))
(declare-fun dc_127 () (_ BitVec 1))
(declare-fun dc_126 () (_ BitVec 63))
(declare-fun dc_125 () (_ BitVec 64))
(declare-fun dc_124 () (_ BitVec 1))
(declare-fun dc_123 () (_ BitVec 62))
(declare-fun dc_122 () (_ BitVec 1))
(declare-fun dc_121 () (_ BitVec 1))
(declare-fun dc_120 () (_ BitVec 1))
(declare-fun dc_119 () (_ BitVec 63))
(declare-fun dc_118 () (_ BitVec 64))
(declare-fun dc_117 () (_ BitVec 1))
(declare-fun dc_116 () (_ BitVec 62))
(declare-fun dc_115 () (_ BitVec 1))
(declare-fun dc_114 () (_ BitVec 1))
(declare-fun dc_113 () (_ BitVec 1))
(declare-fun dc_112 () (_ BitVec 63))
(declare-fun dc_111 () (_ BitVec 64))
(declare-fun dc_110 () (_ BitVec 1))
(declare-fun dc_109 () (_ BitVec 62))
(declare-fun dc_108 () (_ BitVec 1))
(declare-fun dc_107 () (_ BitVec 1))
(declare-fun dc_106 () (_ BitVec 1))
(declare-fun dc_105 () (_ BitVec 63))
(declare-fun dc_104 () (_ BitVec 64))
(declare-fun dc_103 () (_ BitVec 1))
(declare-fun dc_102 () (_ BitVec 62))
(declare-fun dc_101 () (_ BitVec 1))
(declare-fun dc_100 () (_ BitVec 1))
(declare-fun dc_99 () (_ BitVec 1))
(declare-fun dc_98 () (_ BitVec 63))
(declare-fun dc_97 () (_ BitVec 64))
(declare-fun dc_96 () (_ BitVec 1))
(declare-fun dc_95 () (_ BitVec 62))
(declare-fun dc_94 () (_ BitVec 1))
(declare-fun dc_93 () (_ BitVec 1))
(declare-fun dc_92 () (_ BitVec 1))
(declare-fun dc_91 () (_ BitVec 63))
(declare-fun dc_90 () (_ BitVec 64))
(declare-fun dc_89 () (_ BitVec 1))
(declare-fun dc_88 () (_ BitVec 62))
(declare-fun dc_87 () (_ BitVec 1))
(declare-fun dc_86 () (_ BitVec 1))
(declare-fun dc_85 () (_ BitVec 1))
(declare-fun dc_84 () (_ BitVec 63))
(declare-fun dc_83 () (_ BitVec 64))
(declare-fun dc_82 () (_ BitVec 1))
(declare-fun dc_81 () (_ BitVec 62))
(declare-fun dc_80 () (_ BitVec 1))
(declare-fun dc_79 () (_ BitVec 1))
(declare-fun dc_78 () (_ BitVec 1))
(declare-fun dc_77 () (_ BitVec 63))
(declare-fun dc_76 () (_ BitVec 64))
(declare-fun dc_75 () (_ BitVec 1))
(declare-fun dc_74 () (_ BitVec 62))
(declare-fun dc_73 () (_ BitVec 1))
(declare-fun dc_72 () (_ BitVec 1))
(declare-fun dc_71 () (_ BitVec 1))
(declare-fun dc_70 () (_ BitVec 63))
(declare-fun dc_69 () (_ BitVec 64))
(declare-fun dc_68 () (_ BitVec 1))
(declare-fun dc_67 () (_ BitVec 62))
(declare-fun dc_66 () (_ BitVec 1))
(declare-fun dc_65 () (_ BitVec 1))
(declare-fun dc_64 () (_ BitVec 1))
(declare-fun dc_63 () (_ BitVec 63))
(declare-fun dc_62 () (_ BitVec 64))
(declare-fun dc_61 () (_ BitVec 1))
(declare-fun dc_60 () (_ BitVec 62))
(declare-fun dc_59 () (_ BitVec 1))
(declare-fun dc_58 () (_ BitVec 1))
(declare-fun dc_57 () (_ BitVec 1))
(declare-fun dc_56 () (_ BitVec 63))
(declare-fun dc_55 () (_ BitVec 64))
(declare-fun dc_54 () (_ BitVec 1))
(declare-fun dc_53 () (_ BitVec 62))
(declare-fun dc_52 () (_ BitVec 1))
(declare-fun dc_51 () (_ BitVec 1))
(declare-fun dc_50 () (_ BitVec 1))
(declare-fun dc_49 () (_ BitVec 63))
(declare-fun dc_48 () (_ BitVec 64))
(declare-fun dc_47 () (_ BitVec 1))
(declare-fun dc_46 () (_ BitVec 62))
(declare-fun dc_45 () (_ BitVec 1))
(declare-fun dc_44 () (_ BitVec 1))
(declare-fun dc_43 () (_ BitVec 1))
(declare-fun dc_42 () (_ BitVec 63))
(declare-fun dc_41 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (= x7_3 (bvadd (bvadd f_0_low60_0_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_2 (bvadd (bvadd g_0_low60_0_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_0_1)) (bvsle f_0_low60_0_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_0_1)) (bvsle g_0_low60_0_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_3) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #x0000000000000001 #x0000000000000001)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_41 ((_ extract 63 1) x8_2)) (= x8_lo_1 ((_ extract 0 0) x8_2))))
(assert (= ne_1 (bvand x8_lo_1 #b1)))
(assert (= x10_1 (ite (= ne_1 #b1) x7_3 #x0000000000000000)))
(assert (and (= ge_1 ((_ extract 63 63) #x0000000000000001)) (= dc_42 ((_ extract 62 0) #x0000000000000001))))
(assert (= ge_2 (bvnot ge_1)))
(assert (= ge_3 (ite (= ne_1 #b1) ge_2 #b0)))
(assert (and (= dc_43 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_2 (ite (= ge_3 #b1) x3_neg_1 #x0000000000000001)))
(assert (and (= dc_44 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_2 (ite (= ge_3 #b1) x10_neg_1 x10_1)))
(assert (= x7_4 (ite (= ge_3 #b1) x8_2 x7_3)))
(assert (and (= dc_45 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2)))) (= x8_3 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2))))))
(assert (= x3_3 (bvadd x3_2 #x0000000000000002)))
(assert (and (= dc_46 ((_ extract 63 2) x8_3)) (= x8_lo_2 ((_ extract 1 0) x8_3))))
(assert (and (= x8_target_1 ((_ extract 1 1) x8_lo_2)) (= dc_47 ((_ extract 0 0) x8_lo_2))))
(assert (= ne_2 (bvand x8_target_1 #b1)))
(assert (and (= x8_4 ((_ sign_extend 1) ((_ extract 63 1) x8_3))) (= dc_48 ((_ zero_extend 63) ((_ extract 0 0) x8_3)))))
(assert true)
(assert (= x10_3 (ite (= ne_2 #b1) x7_4 #x0000000000000000)))
(assert (and (= ge_4 ((_ extract 63 63) x3_3)) (= dc_49 ((_ extract 62 0) x3_3))))
(assert (= ge_5 (bvnot ge_4)))
(assert (= ge_6 (ite (= ne_2 #b1) ge_5 #b0)))
(assert (and (= dc_50 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_4 (ite (= ge_6 #b1) x3_neg_2 x3_3)))
(assert (and (= dc_51 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_4 (ite (= ge_6 #b1) x10_neg_2 x10_3)))
(assert (= x7_5 (ite (= ge_6 #b1) x8_4 x7_4)))
(assert (and (= dc_52 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4)))) (= x8_5 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4))))))
(assert (= x3_5 (bvadd x3_4 #x0000000000000002)))
(assert (and (= dc_53 ((_ extract 63 2) x8_5)) (= x8_lo_3 ((_ extract 1 0) x8_5))))
(assert (and (= x8_target_2 ((_ extract 1 1) x8_lo_3)) (= dc_54 ((_ extract 0 0) x8_lo_3))))
(assert (= ne_3 (bvand x8_target_2 #b1)))
(assert (and (= x8_6 ((_ sign_extend 1) ((_ extract 63 1) x8_5))) (= dc_55 ((_ zero_extend 63) ((_ extract 0 0) x8_5)))))
(assert true)
(assert (= x10_5 (ite (= ne_3 #b1) x7_5 #x0000000000000000)))
(assert (and (= ge_7 ((_ extract 63 63) x3_5)) (= dc_56 ((_ extract 62 0) x3_5))))
(assert (= ge_8 (bvnot ge_7)))
(assert (= ge_9 (ite (= ne_3 #b1) ge_8 #b0)))
(assert (and (= dc_57 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_6 (ite (= ge_9 #b1) x3_neg_3 x3_5)))
(assert (and (= dc_58 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_6 (ite (= ge_9 #b1) x10_neg_3 x10_5)))
(assert (= x7_6 (ite (= ge_9 #b1) x8_6 x7_5)))
(assert (and (= dc_59 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6)))) (= x8_7 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6))))))
(assert (= x3_7 (bvadd x3_6 #x0000000000000002)))
(assert (and (= dc_60 ((_ extract 63 2) x8_7)) (= x8_lo_4 ((_ extract 1 0) x8_7))))
(assert (and (= x8_target_3 ((_ extract 1 1) x8_lo_4)) (= dc_61 ((_ extract 0 0) x8_lo_4))))
(assert (= ne_4 (bvand x8_target_3 #b1)))
(assert (and (= x8_8 ((_ sign_extend 1) ((_ extract 63 1) x8_7))) (= dc_62 ((_ zero_extend 63) ((_ extract 0 0) x8_7)))))
(assert true)
(assert (= x10_7 (ite (= ne_4 #b1) x7_6 #x0000000000000000)))
(assert (and (= ge_10 ((_ extract 63 63) x3_7)) (= dc_63 ((_ extract 62 0) x3_7))))
(assert (= ge_11 (bvnot ge_10)))
(assert (= ge_12 (ite (= ne_4 #b1) ge_11 #b0)))
(assert (and (= dc_64 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_7))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_4 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_7))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_8 (ite (= ge_12 #b1) x3_neg_4 x3_7)))
(assert (and (= dc_65 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_7))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_4 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_7))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_8 (ite (= ge_12 #b1) x10_neg_4 x10_7)))
(assert (= x7_7 (ite (= ge_12 #b1) x8_8 x7_6)))
(assert (and (= dc_66 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_8) ((_ zero_extend 1) x10_8)))) (= x8_9 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_8) ((_ zero_extend 1) x10_8))))))
(assert (= x3_9 (bvadd x3_8 #x0000000000000002)))
(assert (and (= dc_67 ((_ extract 63 2) x8_9)) (= x8_lo_5 ((_ extract 1 0) x8_9))))
(assert (and (= x8_target_4 ((_ extract 1 1) x8_lo_5)) (= dc_68 ((_ extract 0 0) x8_lo_5))))
(assert (= ne_5 (bvand x8_target_4 #b1)))
(assert (and (= x8_10 ((_ sign_extend 1) ((_ extract 63 1) x8_9))) (= dc_69 ((_ zero_extend 63) ((_ extract 0 0) x8_9)))))
(assert true)
(assert (= x10_9 (ite (= ne_5 #b1) x7_7 #x0000000000000000)))
(assert (and (= ge_13 ((_ extract 63 63) x3_9)) (= dc_70 ((_ extract 62 0) x3_9))))
(assert (= ge_14 (bvnot ge_13)))
(assert (= ge_15 (ite (= ne_5 #b1) ge_14 #b0)))
(assert (and (= dc_71 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_9))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_5 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_9))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_10 (ite (= ge_15 #b1) x3_neg_5 x3_9)))
(assert (and (= dc_72 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_9))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_5 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_9))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_10 (ite (= ge_15 #b1) x10_neg_5 x10_9)))
(assert (= x7_8 (ite (= ge_15 #b1) x8_10 x7_7)))
(assert (and (= dc_73 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_10) ((_ zero_extend 1) x10_10)))) (= x8_11 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_10) ((_ zero_extend 1) x10_10))))))
(assert (= x3_11 (bvadd x3_10 #x0000000000000002)))
(assert (and (= dc_74 ((_ extract 63 2) x8_11)) (= x8_lo_6 ((_ extract 1 0) x8_11))))
(assert (and (= x8_target_5 ((_ extract 1 1) x8_lo_6)) (= dc_75 ((_ extract 0 0) x8_lo_6))))
(assert (= ne_6 (bvand x8_target_5 #b1)))
(assert (and (= x8_12 ((_ sign_extend 1) ((_ extract 63 1) x8_11))) (= dc_76 ((_ zero_extend 63) ((_ extract 0 0) x8_11)))))
(assert true)
(assert (= x10_11 (ite (= ne_6 #b1) x7_8 #x0000000000000000)))
(assert (and (= ge_16 ((_ extract 63 63) x3_11)) (= dc_77 ((_ extract 62 0) x3_11))))
(assert (= ge_17 (bvnot ge_16)))
(assert (= ge_18 (ite (= ne_6 #b1) ge_17 #b0)))
(assert (and (= dc_78 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_11))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_6 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_11))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_12 (ite (= ge_18 #b1) x3_neg_6 x3_11)))
(assert (and (= dc_79 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_11))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_6 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_11))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_12 (ite (= ge_18 #b1) x10_neg_6 x10_11)))
(assert (= x7_9 (ite (= ge_18 #b1) x8_12 x7_8)))
(assert (and (= dc_80 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_12) ((_ zero_extend 1) x10_12)))) (= x8_13 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_12) ((_ zero_extend 1) x10_12))))))
(assert (= x3_13 (bvadd x3_12 #x0000000000000002)))
(assert (and (= dc_81 ((_ extract 63 2) x8_13)) (= x8_lo_7 ((_ extract 1 0) x8_13))))
(assert (and (= x8_target_6 ((_ extract 1 1) x8_lo_7)) (= dc_82 ((_ extract 0 0) x8_lo_7))))
(assert (= ne_7 (bvand x8_target_6 #b1)))
(assert (and (= x8_14 ((_ sign_extend 1) ((_ extract 63 1) x8_13))) (= dc_83 ((_ zero_extend 63) ((_ extract 0 0) x8_13)))))
(assert true)
(assert (= x10_13 (ite (= ne_7 #b1) x7_9 #x0000000000000000)))
(assert (and (= ge_19 ((_ extract 63 63) x3_13)) (= dc_84 ((_ extract 62 0) x3_13))))
(assert (= ge_20 (bvnot ge_19)))
(assert (= ge_21 (ite (= ne_7 #b1) ge_20 #b0)))
(assert (and (= dc_85 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_13))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_7 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_13))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_14 (ite (= ge_21 #b1) x3_neg_7 x3_13)))
(assert (and (= dc_86 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_13))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_7 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_13))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_14 (ite (= ge_21 #b1) x10_neg_7 x10_13)))
(assert (= x7_10 (ite (= ge_21 #b1) x8_14 x7_9)))
(assert (and (= dc_87 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_14) ((_ zero_extend 1) x10_14)))) (= x8_15 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_14) ((_ zero_extend 1) x10_14))))))
(assert (= x3_15 (bvadd x3_14 #x0000000000000002)))
(assert (and (= dc_88 ((_ extract 63 2) x8_15)) (= x8_lo_8 ((_ extract 1 0) x8_15))))
(assert (and (= x8_target_7 ((_ extract 1 1) x8_lo_8)) (= dc_89 ((_ extract 0 0) x8_lo_8))))
(assert (= ne_8 (bvand x8_target_7 #b1)))
(assert (and (= x8_16 ((_ sign_extend 1) ((_ extract 63 1) x8_15))) (= dc_90 ((_ zero_extend 63) ((_ extract 0 0) x8_15)))))
(assert true)
(assert (= x10_15 (ite (= ne_8 #b1) x7_10 #x0000000000000000)))
(assert (and (= ge_22 ((_ extract 63 63) x3_15)) (= dc_91 ((_ extract 62 0) x3_15))))
(assert (= ge_23 (bvnot ge_22)))
(assert (= ge_24 (ite (= ne_8 #b1) ge_23 #b0)))
(assert (and (= dc_92 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_15))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_8 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_15))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_16 (ite (= ge_24 #b1) x3_neg_8 x3_15)))
(assert (and (= dc_93 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_15))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_8 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_15))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_16 (ite (= ge_24 #b1) x10_neg_8 x10_15)))
(assert (= x7_11 (ite (= ge_24 #b1) x8_16 x7_10)))
(assert (and (= dc_94 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_16) ((_ zero_extend 1) x10_16)))) (= x8_17 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_16) ((_ zero_extend 1) x10_16))))))
(assert (= x3_17 (bvadd x3_16 #x0000000000000002)))
(assert (and (= dc_95 ((_ extract 63 2) x8_17)) (= x8_lo_9 ((_ extract 1 0) x8_17))))
(assert (and (= x8_target_8 ((_ extract 1 1) x8_lo_9)) (= dc_96 ((_ extract 0 0) x8_lo_9))))
(assert (= ne_9 (bvand x8_target_8 #b1)))
(assert (and (= x8_18 ((_ sign_extend 1) ((_ extract 63 1) x8_17))) (= dc_97 ((_ zero_extend 63) ((_ extract 0 0) x8_17)))))
(assert true)
(assert (= x10_17 (ite (= ne_9 #b1) x7_11 #x0000000000000000)))
(assert (and (= ge_25 ((_ extract 63 63) x3_17)) (= dc_98 ((_ extract 62 0) x3_17))))
(assert (= ge_26 (bvnot ge_25)))
(assert (= ge_27 (ite (= ne_9 #b1) ge_26 #b0)))
(assert (and (= dc_99 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_17))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_9 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_17))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_18 (ite (= ge_27 #b1) x3_neg_9 x3_17)))
(assert (and (= dc_100 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_17))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_9 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_17))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_18 (ite (= ge_27 #b1) x10_neg_9 x10_17)))
(assert (= x7_12 (ite (= ge_27 #b1) x8_18 x7_11)))
(assert (and (= dc_101 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_18) ((_ zero_extend 1) x10_18)))) (= x8_19 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_18) ((_ zero_extend 1) x10_18))))))
(assert (= x3_19 (bvadd x3_18 #x0000000000000002)))
(assert (and (= dc_102 ((_ extract 63 2) x8_19)) (= x8_lo_10 ((_ extract 1 0) x8_19))))
(assert (and (= x8_target_9 ((_ extract 1 1) x8_lo_10)) (= dc_103 ((_ extract 0 0) x8_lo_10))))
(assert (= ne_10 (bvand x8_target_9 #b1)))
(assert (and (= x8_20 ((_ sign_extend 1) ((_ extract 63 1) x8_19))) (= dc_104 ((_ zero_extend 63) ((_ extract 0 0) x8_19)))))
(assert true)
(assert (= x10_19 (ite (= ne_10 #b1) x7_12 #x0000000000000000)))
(assert (and (= ge_28 ((_ extract 63 63) x3_19)) (= dc_105 ((_ extract 62 0) x3_19))))
(assert (= ge_29 (bvnot ge_28)))
(assert (= ge_30 (ite (= ne_10 #b1) ge_29 #b0)))
(assert (and (= dc_106 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_19))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_10 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_19))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_20 (ite (= ge_30 #b1) x3_neg_10 x3_19)))
(assert (and (= dc_107 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_19))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_10 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_19))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_20 (ite (= ge_30 #b1) x10_neg_10 x10_19)))
(assert (= x7_13 (ite (= ge_30 #b1) x8_20 x7_12)))
(assert (and (= dc_108 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_20) ((_ zero_extend 1) x10_20)))) (= x8_21 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_20) ((_ zero_extend 1) x10_20))))))
(assert (= x3_21 (bvadd x3_20 #x0000000000000002)))
(assert (and (= dc_109 ((_ extract 63 2) x8_21)) (= x8_lo_11 ((_ extract 1 0) x8_21))))
(assert (and (= x8_target_10 ((_ extract 1 1) x8_lo_11)) (= dc_110 ((_ extract 0 0) x8_lo_11))))
(assert (= ne_11 (bvand x8_target_10 #b1)))
(assert (and (= x8_22 ((_ sign_extend 1) ((_ extract 63 1) x8_21))) (= dc_111 ((_ zero_extend 63) ((_ extract 0 0) x8_21)))))
(assert true)
(assert (= x10_21 (ite (= ne_11 #b1) x7_13 #x0000000000000000)))
(assert (and (= ge_31 ((_ extract 63 63) x3_21)) (= dc_112 ((_ extract 62 0) x3_21))))
(assert (= ge_32 (bvnot ge_31)))
(assert (= ge_33 (ite (= ne_11 #b1) ge_32 #b0)))
(assert (and (= dc_113 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_21))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_11 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_21))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_22 (ite (= ge_33 #b1) x3_neg_11 x3_21)))
(assert (and (= dc_114 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_21))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_11 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_21))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_22 (ite (= ge_33 #b1) x10_neg_11 x10_21)))
(assert (= x7_14 (ite (= ge_33 #b1) x8_22 x7_13)))
(assert (and (= dc_115 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_22) ((_ zero_extend 1) x10_22)))) (= x8_23 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_22) ((_ zero_extend 1) x10_22))))))
(assert (= x3_23 (bvadd x3_22 #x0000000000000002)))
(assert (and (= dc_116 ((_ extract 63 2) x8_23)) (= x8_lo_12 ((_ extract 1 0) x8_23))))
(assert (and (= x8_target_11 ((_ extract 1 1) x8_lo_12)) (= dc_117 ((_ extract 0 0) x8_lo_12))))
(assert (= ne_12 (bvand x8_target_11 #b1)))
(assert (and (= x8_24 ((_ sign_extend 1) ((_ extract 63 1) x8_23))) (= dc_118 ((_ zero_extend 63) ((_ extract 0 0) x8_23)))))
(assert true)
(assert (= x10_23 (ite (= ne_12 #b1) x7_14 #x0000000000000000)))
(assert (and (= ge_34 ((_ extract 63 63) x3_23)) (= dc_119 ((_ extract 62 0) x3_23))))
(assert (= ge_35 (bvnot ge_34)))
(assert (= ge_36 (ite (= ne_12 #b1) ge_35 #b0)))
(assert (and (= dc_120 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_23))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_12 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_23))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_24 (ite (= ge_36 #b1) x3_neg_12 x3_23)))
(assert (and (= dc_121 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_23))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_12 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_23))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_24 (ite (= ge_36 #b1) x10_neg_12 x10_23)))
(assert (= x7_15 (ite (= ge_36 #b1) x8_24 x7_14)))
(assert (and (= dc_122 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_24) ((_ zero_extend 1) x10_24)))) (= x8_25 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_24) ((_ zero_extend 1) x10_24))))))
(assert (= x3_25 (bvadd x3_24 #x0000000000000002)))
(assert (and (= dc_123 ((_ extract 63 2) x8_25)) (= x8_lo_13 ((_ extract 1 0) x8_25))))
(assert (and (= x8_target_12 ((_ extract 1 1) x8_lo_13)) (= dc_124 ((_ extract 0 0) x8_lo_13))))
(assert (= ne_13 (bvand x8_target_12 #b1)))
(assert (and (= x8_26 ((_ sign_extend 1) ((_ extract 63 1) x8_25))) (= dc_125 ((_ zero_extend 63) ((_ extract 0 0) x8_25)))))
(assert true)
(assert (= x10_25 (ite (= ne_13 #b1) x7_15 #x0000000000000000)))
(assert (and (= ge_37 ((_ extract 63 63) x3_25)) (= dc_126 ((_ extract 62 0) x3_25))))
(assert (= ge_38 (bvnot ge_37)))
(assert (= ge_39 (ite (= ne_13 #b1) ge_38 #b0)))
(assert (and (= dc_127 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_25))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_13 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_25))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_26 (ite (= ge_39 #b1) x3_neg_13 x3_25)))
(assert (and (= dc_128 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_25))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_13 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_25))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_26 (ite (= ge_39 #b1) x10_neg_13 x10_25)))
(assert (= x7_16 (ite (= ge_39 #b1) x8_26 x7_15)))
(assert (and (= dc_129 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_26) ((_ zero_extend 1) x10_26)))) (= x8_27 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_26) ((_ zero_extend 1) x10_26))))))
(assert (= x3_27 (bvadd x3_26 #x0000000000000002)))
(assert (and (= dc_130 ((_ extract 63 2) x8_27)) (= x8_lo_14 ((_ extract 1 0) x8_27))))
(assert (and (= x8_target_13 ((_ extract 1 1) x8_lo_14)) (= dc_131 ((_ extract 0 0) x8_lo_14))))
(assert (= ne_14 (bvand x8_target_13 #b1)))
(assert (and (= x8_28 ((_ sign_extend 1) ((_ extract 63 1) x8_27))) (= dc_132 ((_ zero_extend 63) ((_ extract 0 0) x8_27)))))
(assert true)
(assert (= x10_27 (ite (= ne_14 #b1) x7_16 #x0000000000000000)))
(assert (and (= ge_40 ((_ extract 63 63) x3_27)) (= dc_133 ((_ extract 62 0) x3_27))))
(assert (= ge_41 (bvnot ge_40)))
(assert (= ge_42 (ite (= ne_14 #b1) ge_41 #b0)))
(assert (and (= dc_134 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_27))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_14 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_27))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_28 (ite (= ge_42 #b1) x3_neg_14 x3_27)))
(assert (and (= dc_135 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_27))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_14 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_27))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_28 (ite (= ge_42 #b1) x10_neg_14 x10_27)))
(assert (= x7_17 (ite (= ge_42 #b1) x8_28 x7_16)))
(assert (and (= dc_136 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_28) ((_ zero_extend 1) x10_28)))) (= x8_29 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_28) ((_ zero_extend 1) x10_28))))))
(assert (= x3_29 (bvadd x3_28 #x0000000000000002)))
(assert (and (= dc_137 ((_ extract 63 2) x8_29)) (= x8_lo_15 ((_ extract 1 0) x8_29))))
(assert (and (= x8_target_14 ((_ extract 1 1) x8_lo_15)) (= dc_138 ((_ extract 0 0) x8_lo_15))))
(assert (= ne_15 (bvand x8_target_14 #b1)))
(assert (and (= x8_30 ((_ sign_extend 1) ((_ extract 63 1) x8_29))) (= dc_139 ((_ zero_extend 63) ((_ extract 0 0) x8_29)))))
(assert true)
(assert (= x10_29 (ite (= ne_15 #b1) x7_17 #x0000000000000000)))
(assert (and (= ge_43 ((_ extract 63 63) x3_29)) (= dc_140 ((_ extract 62 0) x3_29))))
(assert (= ge_44 (bvnot ge_43)))
(assert (= ge_45 (ite (= ne_15 #b1) ge_44 #b0)))
(assert (and (= dc_141 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_29))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_15 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_29))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_30 (ite (= ge_45 #b1) x3_neg_15 x3_29)))
(assert (and (= dc_142 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_29))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_15 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_29))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_30 (ite (= ge_45 #b1) x10_neg_15 x10_29)))
(assert (= x7_18 (ite (= ge_45 #b1) x8_30 x7_17)))
(assert (and (= dc_143 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_30) ((_ zero_extend 1) x10_30)))) (= x8_31 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_30) ((_ zero_extend 1) x10_30))))))
(assert (= x3_31 (bvadd x3_30 #x0000000000000002)))
(assert (and (= dc_144 ((_ extract 63 2) x8_31)) (= x8_lo_16 ((_ extract 1 0) x8_31))))
(assert (and (= x8_target_15 ((_ extract 1 1) x8_lo_16)) (= dc_145 ((_ extract 0 0) x8_lo_16))))
(assert (= ne_16 (bvand x8_target_15 #b1)))
(assert (and (= x8_32 ((_ sign_extend 1) ((_ extract 63 1) x8_31))) (= dc_146 ((_ zero_extend 63) ((_ extract 0 0) x8_31)))))
(assert true)
(assert (= x10_31 (ite (= ne_16 #b1) x7_18 #x0000000000000000)))
(assert (and (= ge_46 ((_ extract 63 63) x3_31)) (= dc_147 ((_ extract 62 0) x3_31))))
(assert (= ge_47 (bvnot ge_46)))
(assert (= ge_48 (ite (= ne_16 #b1) ge_47 #b0)))
(assert (and (= dc_148 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_31))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_16 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_31))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_32 (ite (= ge_48 #b1) x3_neg_16 x3_31)))
(assert (and (= dc_149 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_31))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_16 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_31))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_32 (ite (= ge_48 #b1) x10_neg_16 x10_31)))
(assert (= x7_19 (ite (= ge_48 #b1) x8_32 x7_18)))
(assert (and (= dc_150 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_32) ((_ zero_extend 1) x10_32)))) (= x8_33 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_32) ((_ zero_extend 1) x10_32))))))
(assert (= x3_33 (bvadd x3_32 #x0000000000000002)))
(assert (and (= dc_151 ((_ extract 63 2) x8_33)) (= x8_lo_17 ((_ extract 1 0) x8_33))))
(assert (and (= x8_target_16 ((_ extract 1 1) x8_lo_17)) (= dc_152 ((_ extract 0 0) x8_lo_17))))
(assert (= ne_17 (bvand x8_target_16 #b1)))
(assert (and (= x8_34 ((_ sign_extend 1) ((_ extract 63 1) x8_33))) (= dc_153 ((_ zero_extend 63) ((_ extract 0 0) x8_33)))))
(assert true)
(assert (= x10_33 (ite (= ne_17 #b1) x7_19 #x0000000000000000)))
(assert (and (= ge_49 ((_ extract 63 63) x3_33)) (= dc_154 ((_ extract 62 0) x3_33))))
(assert (= ge_50 (bvnot ge_49)))
(assert (= ge_51 (ite (= ne_17 #b1) ge_50 #b0)))
(assert (and (= dc_155 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_33))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_17 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_33))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_34 (ite (= ge_51 #b1) x3_neg_17 x3_33)))
(assert (and (= dc_156 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_33))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_17 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_33))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_34 (ite (= ge_51 #b1) x10_neg_17 x10_33)))
(assert (= x7_20 (ite (= ge_51 #b1) x8_34 x7_19)))
(assert (and (= dc_157 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_34) ((_ zero_extend 1) x10_34)))) (= x8_35 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_34) ((_ zero_extend 1) x10_34))))))
(assert (= x3_35 (bvadd x3_34 #x0000000000000002)))
(assert (and (= dc_158 ((_ extract 63 2) x8_35)) (= x8_lo_18 ((_ extract 1 0) x8_35))))
(assert (and (= x8_target_17 ((_ extract 1 1) x8_lo_18)) (= dc_159 ((_ extract 0 0) x8_lo_18))))
(assert (= ne_18 (bvand x8_target_17 #b1)))
(assert (and (= x8_36 ((_ sign_extend 1) ((_ extract 63 1) x8_35))) (= dc_160 ((_ zero_extend 63) ((_ extract 0 0) x8_35)))))
(assert true)
(assert (= x10_35 (ite (= ne_18 #b1) x7_20 #x0000000000000000)))
(assert (and (= ge_52 ((_ extract 63 63) x3_35)) (= dc_161 ((_ extract 62 0) x3_35))))
(assert (= ge_53 (bvnot ge_52)))
(assert (= ge_54 (ite (= ne_18 #b1) ge_53 #b0)))
(assert (and (= dc_162 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_35))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_18 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_35))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_36 (ite (= ge_54 #b1) x3_neg_18 x3_35)))
(assert (and (= dc_163 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_35))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_18 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_35))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_36 (ite (= ge_54 #b1) x10_neg_18 x10_35)))
(assert (= x7_21 (ite (= ge_54 #b1) x8_36 x7_20)))
(assert (and (= dc_164 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_36) ((_ zero_extend 1) x10_36)))) (= x8_37 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_36) ((_ zero_extend 1) x10_36))))))
(assert (= x3_37 (bvadd x3_36 #x0000000000000002)))
(assert (and (= dc_165 ((_ extract 63 2) x8_37)) (= x8_lo_19 ((_ extract 1 0) x8_37))))
(assert (and (= x8_target_18 ((_ extract 1 1) x8_lo_19)) (= dc_166 ((_ extract 0 0) x8_lo_19))))
(assert (= ne_19 (bvand x8_target_18 #b1)))
(assert (and (= x8_38 ((_ sign_extend 1) ((_ extract 63 1) x8_37))) (= dc_167 ((_ zero_extend 63) ((_ extract 0 0) x8_37)))))
(assert true)
(assert (= x10_37 (ite (= ne_19 #b1) x7_21 #x0000000000000000)))
(assert (and (= ge_55 ((_ extract 63 63) x3_37)) (= dc_168 ((_ extract 62 0) x3_37))))
(assert (= ge_56 (bvnot ge_55)))
(assert (= ge_57 (ite (= ne_19 #b1) ge_56 #b0)))
(assert (and (= dc_169 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_37))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_19 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_37))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_38 (ite (= ge_57 #b1) x3_neg_19 x3_37)))
(assert (and (= dc_170 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_37))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_19 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_37))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_38 (ite (= ge_57 #b1) x10_neg_19 x10_37)))
(assert (= x7_22 (ite (= ge_57 #b1) x8_38 x7_21)))
(assert (and (= dc_171 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_38) ((_ zero_extend 1) x10_38)))) (= x8_39 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_38) ((_ zero_extend 1) x10_38))))))
(assert (= x3_39 (bvadd x3_38 #x0000000000000002)))
(assert (and (= dc_172 ((_ extract 63 2) x8_39)) (= x8_lo_20 ((_ extract 1 0) x8_39))))
(assert (and (= x8_target_19 ((_ extract 1 1) x8_lo_20)) (= dc_173 ((_ extract 0 0) x8_lo_20))))
(assert (= ne_20 (bvand x8_target_19 #b1)))
(assert (and (= x8_40 ((_ sign_extend 1) ((_ extract 63 1) x8_39))) (= dc_174 ((_ zero_extend 63) ((_ extract 0 0) x8_39)))))
(assert true)
(assert (= x10_39 (ite (= ne_20 #b1) x7_22 #x0000000000000000)))
(assert (and (= ge_58 ((_ extract 63 63) x3_39)) (= dc_175 ((_ extract 62 0) x3_39))))
(assert (= ge_59 (bvnot ge_58)))
(assert (= ge_60 (ite (= ne_20 #b1) ge_59 #b0)))
(assert (and (= dc_176 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_39))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_20 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_39))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_40 (ite (= ge_60 #b1) x3_neg_20 x3_39)))
(assert (and (= dc_177 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_39))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_20 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_39))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_40 (ite (= ge_60 #b1) x10_neg_20 x10_39)))
(assert (= x7_23 (ite (= ge_60 #b1) x8_40 x7_22)))
(assert (and (= dc_178 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_40) ((_ zero_extend 1) x10_40)))) (= x8_41 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_40) ((_ zero_extend 1) x10_40))))))
(assert (= x3_41 (bvadd x3_40 #x0000000000000002)))
(assert (and (= x8_42 ((_ sign_extend 1) ((_ extract 63 1) x8_41))) (= dc_179 ((_ zero_extend 63) ((_ extract 0 0) x8_41)))))
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (bvsle (bvsub (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000) (bvsle (bvadd (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (bvsle (bvsub r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvadd r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvsub u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvadd u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle s_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 s_0_20_2)) (bvsle r_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 r_0_20_2)) (bvsle v_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 v_0_20_2)) (bvsle u_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 u_0_20_2)) (bvsle x3_41 #x0000000000000029)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle g_0_low60_0_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_20_1)) (bvsle f_0_low60_0_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_20_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_23) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= x8_42 (bvadd (bvadd g_0_low60_0_low20_20_1 (bvmul r_0_20_2 #x0000000000200000)) (bvmul s_0_20_2 #x0000040000000000)))) (= x7_23 (bvadd (bvadd f_0_low60_0_low20_20_1 (bvmul u_0_20_2 #x0000000000200000)) (bvmul v_0_20_2 #x0000040000000000)))))
(assert true)
(assert true)
(assert (= (bvsmod (bvsub ((_ zero_extend 1) f_0_low60_20_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000))
(assert (not (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and true true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_2) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_2 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_2)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_2 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_4) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_4 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_4)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_4 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_6) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_6 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_6)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_6 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_8) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_8 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_8)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_8 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_10) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_10 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_10)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_10 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_12) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_12 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_12)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_12 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_14) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_14 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_14)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_14 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_16) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_16 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_16)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_16 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_18) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_18 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_18)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_18 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_20) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_20 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_20)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_20 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_22) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_22 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_22)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_22 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_24) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_24 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_24)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_24 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_26) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_26 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_26)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_26 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_28) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_28 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_28)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_28 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_30) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_30 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_30)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_30 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_32) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_32 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_32)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_32 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_34) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_34 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_34)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_34 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_36) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_36 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_36)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_36 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_38) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_38 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_38)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_38 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_40) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_40 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_40)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_40 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_305af8.smt2
Execution time of boolector: 0.0177 seconds
OUTPUT FROM boolector:
unsat

Execution of safety task: 0.0236 seconds
=== Cut #3 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: safety
; Track: default
; Cut: #3
; Verify: safety (all in one query)
; Output file: /tmp/outputqfbv_7884fa.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_42 () (_ BitVec 64))
(declare-fun x7_23 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x14_3 () (_ BitVec 64))
(declare-fun x14_2 () (_ BitVec 64))
(declare-fun x14_1 () (_ BitVec 64))
(declare-fun x13_5 () (_ BitVec 64))
(declare-fun x13_4 () (_ BitVec 64))
(declare-fun x13_3 () (_ BitVec 64))
(declare-fun x13_2 () (_ BitVec 64))
(declare-fun x13_1 () (_ BitVec 64))
(declare-fun x12_3 () (_ BitVec 64))
(declare-fun x12_2 () (_ BitVec 64))
(declare-fun x12_1 () (_ BitVec 64))
(declare-fun x11_5 () (_ BitVec 64))
(declare-fun x11_4 () (_ BitVec 64))
(declare-fun x11_3 () (_ BitVec 64))
(declare-fun x11_2 () (_ BitVec 64))
(declare-fun x11_1 () (_ BitVec 64))
(declare-fun v_0_20_2 () (_ BitVec 64))
(declare-fun u_0_20_2 () (_ BitVec 64))
(declare-fun s_0_20_2 () (_ BitVec 64))
(declare-fun r_0_20_2 () (_ BitVec 64))
(declare-fun g_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun dcH_2 () (_ BitVec 64))
(declare-fun dcH_1 () (_ BitVec 64))
(declare-fun dc_183 () (_ BitVec 64))
(declare-fun dc_182 () (_ BitVec 64))
(declare-fun dc_181 () (_ BitVec 64))
(declare-fun dc_180 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_23 (bvadd (bvadd f_0_low60_0_low20_20_1 (bvmul u_0_20_2 #x0000000000200000)) (bvmul v_0_20_2 #x0000040000000000))) (= x8_42 (bvadd (bvadd g_0_low60_0_low20_20_1 (bvmul r_0_20_2 #x0000000000200000)) (bvmul s_0_20_2 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_20_1)) (bvsle f_0_low60_0_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_20_1)) (bvsle g_0_low60_0_low20_20_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) f_0_low60_20_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (bvsle #xFFFFFFFFFFF00000 u_0_20_2)) (bvsle u_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 v_0_20_2)) (bvsle v_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 r_0_20_2)) (bvsle r_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 s_0_20_2)) (bvsle s_0_20_2 #x00000000000FFFFF)) (bvsle (bvadd u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvsub u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvadd r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvsub r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (= x6_2 #x0000020000100000)))
(assert (= x12_1 (bvadd x7_23 x6_2)))
(assert (= x12_2 x12_1))
(assert (and (= x12_3 ((_ sign_extend 42) ((_ extract 63 42) x12_2))) (= dc_180 ((_ zero_extend 22) ((_ extract 41 0) x12_2)))))
(assert (= x11_1 (bvadd x7_23 #x0000000000100000)))
(assert (and (= dcH_1 ((_ sign_extend 42) ((_ extract 63 42) x11_1))) (= x11_2 ((_ zero_extend 22) ((_ extract 41 0) x11_1)))))
(assert (= x11_3 (bvshl x11_2 #x0000000000000016)))
(assert (= x11_4 x11_3))
(assert (and (= x11_5 ((_ sign_extend 43) ((_ extract 63 43) x11_4))) (= dc_181 ((_ zero_extend 21) ((_ extract 42 0) x11_4)))))
(assert (= x14_1 (bvadd x8_42 x6_2)))
(assert (= x14_2 x14_1))
(assert (and (= x14_3 ((_ sign_extend 42) ((_ extract 63 42) x14_2))) (= dc_182 ((_ zero_extend 22) ((_ extract 41 0) x14_2)))))
(assert (= x13_1 (bvadd x8_42 #x0000000000100000)))
(assert (and (= dcH_2 ((_ sign_extend 42) ((_ extract 63 42) x13_1))) (= x13_2 ((_ zero_extend 22) ((_ extract 41 0) x13_1)))))
(assert (= x13_3 (bvshl x13_2 #x0000000000000016)))
(assert (= x13_4 x13_3))
(assert (and (= x13_5 ((_ sign_extend 43) ((_ extract 63 43) x13_4))) (= dc_183 ((_ zero_extend 21) ((_ extract 42 0) x13_4)))))
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert (not (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and true (not (= (bvor (bvand (bvand ((_ extract 63 63) x7_23) ((_ extract 63 63) x6_2)) (bvnot ((_ extract 63 63) (bvadd x7_23 x6_2)))) (bvand (bvand (bvnot ((_ extract 63 63) x7_23)) (bvnot ((_ extract 63 63) x6_2))) ((_ extract 63 63) (bvadd x7_23 x6_2)))) #b1))) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x7_23) ((_ extract 63 63) #x0000000000100000)) (bvnot ((_ extract 63 63) (bvadd x7_23 #x0000000000100000)))) (bvand (bvand (bvnot ((_ extract 63 63) x7_23)) (bvnot ((_ extract 63 63) #x0000000000100000))) ((_ extract 63 63) (bvadd x7_23 #x0000000000100000)))) #b1))) true) (= ((_ extract 63 42) x11_2) #b0000000000000000000000)) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x8_42) ((_ extract 63 63) x6_2)) (bvnot ((_ extract 63 63) (bvadd x8_42 x6_2)))) (bvand (bvand (bvnot ((_ extract 63 63) x8_42)) (bvnot ((_ extract 63 63) x6_2))) ((_ extract 63 63) (bvadd x8_42 x6_2)))) #b1))) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x8_42) ((_ extract 63 63) #x0000000000100000)) (bvnot ((_ extract 63 63) (bvadd x8_42 #x0000000000100000)))) (bvand (bvand (bvnot ((_ extract 63 63) x8_42)) (bvnot ((_ extract 63 63) #x0000000000100000))) ((_ extract 63 63) (bvadd x8_42 #x0000000000100000)))) #b1))) true) (= ((_ extract 63 42) x13_2) #b0000000000000000000000)) true) true) true) true) true) true) true) true) true) true)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_d74f85.smt2
Execution time of boolector: 0.0068 seconds
OUTPUT FROM boolector:
unsat

Execution of safety task: 0.0105 seconds
=== Cut #4 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: safety
; Track: default
; Cut: #4
; Verify: safety (all in one query)
; Output file: /tmp/outputqfbv_245531.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x9_3 () (_ BitVec 64))
(declare-fun x9_2 () (_ BitVec 64))
(declare-fun x9_1 () (_ BitVec 64))
(declare-fun x8_44 () (_ BitVec 64))
(declare-fun x8_43 () (_ BitVec 64))
(declare-fun x7_25 () (_ BitVec 64))
(declare-fun x7_24 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x2_7 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x14_3 () (_ BitVec 64))
(declare-fun x13_5 () (_ BitVec 64))
(declare-fun x12_3 () (_ BitVec 64))
(declare-fun x11_5 () (_ BitVec 64))
(declare-fun x10_42 () (_ BitVec 64))
(declare-fun x10_41 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun tmp_2 () (_ BitVec 64))
(declare-fun tmp_1 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun g_0_low60_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_20_1 () (_ BitVec 64))
(declare-fun dcH_6 () (_ BitVec 64))
(declare-fun dcH_5 () (_ BitVec 64))
(declare-fun dcH_4 () (_ BitVec 64))
(declare-fun dcH_3 () (_ BitVec 64))
(declare-fun dc_187 () (_ BitVec 64))
(declare-fun dc_186 () (_ BitVec 1))
(declare-fun dc_185 () (_ BitVec 64))
(declare-fun dc_184 () (_ BitVec 1))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) f_0_low60_20_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (bvsle #xFFFFFFFFFFF00000 x11_5)) (bvsle x11_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x12_3)) (bvsle x12_3 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x13_5)) (bvsle x13_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x14_3)) (bvsle x14_3 #x00000000000FFFFF)) (bvsle (bvadd x11_5 x12_3) #x0000000000100000)) (bvsle (bvsub x11_5 x12_3) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 x11_5) x12_3) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 x11_5) x12_3) #x0000000000100000)) (bvsle (bvadd x13_5 x14_3) #x0000000000100000)) (bvsle (bvsub x13_5 x14_3) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 x13_5) x14_3) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 x13_5) x14_3) #x0000000000100000)) (= x6_2 #x0000020000100000)))
(assert (and (= dcH_3 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x11_5) ((_ sign_extend 64) x1_2)))) (= x9_1 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x11_5) ((_ sign_extend 64) x1_2))))))
(assert (and (= dcH_4 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x12_3)))) (= tmp_1 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x12_3))))))
(assert (and (= dc_184 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x9_1) ((_ zero_extend 1) tmp_1)))) (= x9_2 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x9_1) ((_ zero_extend 1) tmp_1))))))
(assert true)
(assert (and (= x9_2 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) f_0_low60_20_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x9_2) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x9_3 ((_ zero_extend 20) ((_ extract 63 20) x9_2))) (= dc_185 ((_ zero_extend 44) ((_ extract 19 0) x9_2)))))
(assert (and (= dcH_5 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x13_5) ((_ sign_extend 64) x1_2)))) (= x10_41 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x13_5) ((_ sign_extend 64) x1_2))))))
(assert (and (= dcH_6 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x14_3)))) (= tmp_2 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x14_3))))))
(assert (and (= dc_186 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x10_41) ((_ zero_extend 1) tmp_2)))) (= x10_42 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x10_41) ((_ zero_extend 1) tmp_2))))))
(assert true)
(assert (and (= x10_42 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) g_0_low60_20_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x10_42) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x2_7 ((_ zero_extend 20) ((_ extract 63 20) x10_42))) (= dc_187 ((_ zero_extend 44) ((_ extract 19 0) x10_42)))))
(assert true)
(assert true)
(assert (= x7_24 (bvand x9_3 #x00000000000FFFFF)))
(assert (= x8_43 (bvand x2_7 #x00000000000FFFFF)))
(assert (= x7_25 (bvor x7_24 #xFFFFFE0000000000)))
(assert (= x8_44 (bvor x8_43 #xC000000000000000)))
(assert (= neg_f_0_low60_20_low20_0_1 (bvand x9_3 #x00000000000FFFFF)))
(assert (= neg_g_0_low60_20_low20_0_1 (bvand x2_7 #x00000000000FFFFF)))
(assert (not (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and true true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_ad69f0.smt2
Execution time of boolector: 0.0007 seconds
OUTPUT FROM boolector:
unsat

Execution of safety task: 0.0042 seconds
=== Cut #5 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: safety
; Track: default
; Cut: #5
; Verify: safety (all in one query)
; Output file: /tmp/outputqfbv_118b58.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_44 () (_ BitVec 64))
(declare-fun x7_25 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_0_1 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_25 (bvadd (bvadd neg_f_0_low60_20_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_44 (bvadd (bvadd neg_g_0_low60_20_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_0_1)) (bvsle neg_f_0_low60_20_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_0_1)) (bvsle neg_g_0_low60_20_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_25) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (not true))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_f83001.smt2
Execution time of boolector: 0.0006 seconds
OUTPUT FROM boolector:
unsat

Execution of safety task: 0.0040 seconds
=== Cut #6 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: safety
; Track: default
; Cut: #6
; Verify: safety (all in one query)
; Output file: /tmp/outputqfbv_328295.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_37 () (_ BitVec 1))
(declare-fun x8_target_36 () (_ BitVec 1))
(declare-fun x8_target_35 () (_ BitVec 1))
(declare-fun x8_target_34 () (_ BitVec 1))
(declare-fun x8_target_33 () (_ BitVec 1))
(declare-fun x8_target_32 () (_ BitVec 1))
(declare-fun x8_target_31 () (_ BitVec 1))
(declare-fun x8_target_30 () (_ BitVec 1))
(declare-fun x8_target_29 () (_ BitVec 1))
(declare-fun x8_target_28 () (_ BitVec 1))
(declare-fun x8_target_27 () (_ BitVec 1))
(declare-fun x8_target_26 () (_ BitVec 1))
(declare-fun x8_target_25 () (_ BitVec 1))
(declare-fun x8_target_24 () (_ BitVec 1))
(declare-fun x8_target_23 () (_ BitVec 1))
(declare-fun x8_target_22 () (_ BitVec 1))
(declare-fun x8_target_21 () (_ BitVec 1))
(declare-fun x8_target_20 () (_ BitVec 1))
(declare-fun x8_lo_39 () (_ BitVec 2))
(declare-fun x8_lo_38 () (_ BitVec 2))
(declare-fun x8_lo_37 () (_ BitVec 2))
(declare-fun x8_lo_36 () (_ BitVec 2))
(declare-fun x8_lo_35 () (_ BitVec 2))
(declare-fun x8_lo_34 () (_ BitVec 2))
(declare-fun x8_lo_33 () (_ BitVec 2))
(declare-fun x8_lo_32 () (_ BitVec 2))
(declare-fun x8_lo_31 () (_ BitVec 2))
(declare-fun x8_lo_30 () (_ BitVec 2))
(declare-fun x8_lo_29 () (_ BitVec 2))
(declare-fun x8_lo_28 () (_ BitVec 2))
(declare-fun x8_lo_27 () (_ BitVec 2))
(declare-fun x8_lo_26 () (_ BitVec 2))
(declare-fun x8_lo_25 () (_ BitVec 2))
(declare-fun x8_lo_24 () (_ BitVec 2))
(declare-fun x8_lo_23 () (_ BitVec 2))
(declare-fun x8_lo_22 () (_ BitVec 2))
(declare-fun x8_lo_21 () (_ BitVec 1))
(declare-fun x8_82 () (_ BitVec 64))
(declare-fun x8_81 () (_ BitVec 64))
(declare-fun x8_80 () (_ BitVec 64))
(declare-fun x8_79 () (_ BitVec 64))
(declare-fun x8_78 () (_ BitVec 64))
(declare-fun x8_77 () (_ BitVec 64))
(declare-fun x8_76 () (_ BitVec 64))
(declare-fun x8_75 () (_ BitVec 64))
(declare-fun x8_74 () (_ BitVec 64))
(declare-fun x8_73 () (_ BitVec 64))
(declare-fun x8_72 () (_ BitVec 64))
(declare-fun x8_71 () (_ BitVec 64))
(declare-fun x8_70 () (_ BitVec 64))
(declare-fun x8_69 () (_ BitVec 64))
(declare-fun x8_68 () (_ BitVec 64))
(declare-fun x8_67 () (_ BitVec 64))
(declare-fun x8_66 () (_ BitVec 64))
(declare-fun x8_65 () (_ BitVec 64))
(declare-fun x8_64 () (_ BitVec 64))
(declare-fun x8_63 () (_ BitVec 64))
(declare-fun x8_62 () (_ BitVec 64))
(declare-fun x8_61 () (_ BitVec 64))
(declare-fun x8_60 () (_ BitVec 64))
(declare-fun x8_59 () (_ BitVec 64))
(declare-fun x8_58 () (_ BitVec 64))
(declare-fun x8_57 () (_ BitVec 64))
(declare-fun x8_56 () (_ BitVec 64))
(declare-fun x8_55 () (_ BitVec 64))
(declare-fun x8_54 () (_ BitVec 64))
(declare-fun x8_53 () (_ BitVec 64))
(declare-fun x8_52 () (_ BitVec 64))
(declare-fun x8_51 () (_ BitVec 64))
(declare-fun x8_50 () (_ BitVec 64))
(declare-fun x8_49 () (_ BitVec 64))
(declare-fun x8_48 () (_ BitVec 64))
(declare-fun x8_47 () (_ BitVec 64))
(declare-fun x8_46 () (_ BitVec 64))
(declare-fun x8_45 () (_ BitVec 64))
(declare-fun x8_44 () (_ BitVec 64))
(declare-fun x7_44 () (_ BitVec 64))
(declare-fun x7_43 () (_ BitVec 64))
(declare-fun x7_42 () (_ BitVec 64))
(declare-fun x7_41 () (_ BitVec 64))
(declare-fun x7_40 () (_ BitVec 64))
(declare-fun x7_39 () (_ BitVec 64))
(declare-fun x7_38 () (_ BitVec 64))
(declare-fun x7_37 () (_ BitVec 64))
(declare-fun x7_36 () (_ BitVec 64))
(declare-fun x7_35 () (_ BitVec 64))
(declare-fun x7_34 () (_ BitVec 64))
(declare-fun x7_33 () (_ BitVec 64))
(declare-fun x7_32 () (_ BitVec 64))
(declare-fun x7_31 () (_ BitVec 64))
(declare-fun x7_30 () (_ BitVec 64))
(declare-fun x7_29 () (_ BitVec 64))
(declare-fun x7_28 () (_ BitVec 64))
(declare-fun x7_27 () (_ BitVec 64))
(declare-fun x7_26 () (_ BitVec 64))
(declare-fun x7_25 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_39 () (_ BitVec 64))
(declare-fun x3_neg_38 () (_ BitVec 64))
(declare-fun x3_neg_37 () (_ BitVec 64))
(declare-fun x3_neg_36 () (_ BitVec 64))
(declare-fun x3_neg_35 () (_ BitVec 64))
(declare-fun x3_neg_34 () (_ BitVec 64))
(declare-fun x3_neg_33 () (_ BitVec 64))
(declare-fun x3_neg_32 () (_ BitVec 64))
(declare-fun x3_neg_31 () (_ BitVec 64))
(declare-fun x3_neg_30 () (_ BitVec 64))
(declare-fun x3_neg_29 () (_ BitVec 64))
(declare-fun x3_neg_28 () (_ BitVec 64))
(declare-fun x3_neg_27 () (_ BitVec 64))
(declare-fun x3_neg_26 () (_ BitVec 64))
(declare-fun x3_neg_25 () (_ BitVec 64))
(declare-fun x3_neg_24 () (_ BitVec 64))
(declare-fun x3_neg_23 () (_ BitVec 64))
(declare-fun x3_neg_22 () (_ BitVec 64))
(declare-fun x3_neg_21 () (_ BitVec 64))
(declare-fun x3_79 () (_ BitVec 64))
(declare-fun x3_78 () (_ BitVec 64))
(declare-fun x3_77 () (_ BitVec 64))
(declare-fun x3_76 () (_ BitVec 64))
(declare-fun x3_75 () (_ BitVec 64))
(declare-fun x3_74 () (_ BitVec 64))
(declare-fun x3_73 () (_ BitVec 64))
(declare-fun x3_72 () (_ BitVec 64))
(declare-fun x3_71 () (_ BitVec 64))
(declare-fun x3_70 () (_ BitVec 64))
(declare-fun x3_69 () (_ BitVec 64))
(declare-fun x3_68 () (_ BitVec 64))
(declare-fun x3_67 () (_ BitVec 64))
(declare-fun x3_66 () (_ BitVec 64))
(declare-fun x3_65 () (_ BitVec 64))
(declare-fun x3_64 () (_ BitVec 64))
(declare-fun x3_63 () (_ BitVec 64))
(declare-fun x3_62 () (_ BitVec 64))
(declare-fun x3_61 () (_ BitVec 64))
(declare-fun x3_60 () (_ BitVec 64))
(declare-fun x3_59 () (_ BitVec 64))
(declare-fun x3_58 () (_ BitVec 64))
(declare-fun x3_57 () (_ BitVec 64))
(declare-fun x3_56 () (_ BitVec 64))
(declare-fun x3_55 () (_ BitVec 64))
(declare-fun x3_54 () (_ BitVec 64))
(declare-fun x3_53 () (_ BitVec 64))
(declare-fun x3_52 () (_ BitVec 64))
(declare-fun x3_51 () (_ BitVec 64))
(declare-fun x3_50 () (_ BitVec 64))
(declare-fun x3_49 () (_ BitVec 64))
(declare-fun x3_48 () (_ BitVec 64))
(declare-fun x3_47 () (_ BitVec 64))
(declare-fun x3_46 () (_ BitVec 64))
(declare-fun x3_45 () (_ BitVec 64))
(declare-fun x3_44 () (_ BitVec 64))
(declare-fun x3_43 () (_ BitVec 64))
(declare-fun x3_42 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x10_neg_39 () (_ BitVec 64))
(declare-fun x10_neg_38 () (_ BitVec 64))
(declare-fun x10_neg_37 () (_ BitVec 64))
(declare-fun x10_neg_36 () (_ BitVec 64))
(declare-fun x10_neg_35 () (_ BitVec 64))
(declare-fun x10_neg_34 () (_ BitVec 64))
(declare-fun x10_neg_33 () (_ BitVec 64))
(declare-fun x10_neg_32 () (_ BitVec 64))
(declare-fun x10_neg_31 () (_ BitVec 64))
(declare-fun x10_neg_30 () (_ BitVec 64))
(declare-fun x10_neg_29 () (_ BitVec 64))
(declare-fun x10_neg_28 () (_ BitVec 64))
(declare-fun x10_neg_27 () (_ BitVec 64))
(declare-fun x10_neg_26 () (_ BitVec 64))
(declare-fun x10_neg_25 () (_ BitVec 64))
(declare-fun x10_neg_24 () (_ BitVec 64))
(declare-fun x10_neg_23 () (_ BitVec 64))
(declare-fun x10_neg_22 () (_ BitVec 64))
(declare-fun x10_neg_21 () (_ BitVec 64))
(declare-fun x10_80 () (_ BitVec 64))
(declare-fun x10_79 () (_ BitVec 64))
(declare-fun x10_78 () (_ BitVec 64))
(declare-fun x10_77 () (_ BitVec 64))
(declare-fun x10_76 () (_ BitVec 64))
(declare-fun x10_75 () (_ BitVec 64))
(declare-fun x10_74 () (_ BitVec 64))
(declare-fun x10_73 () (_ BitVec 64))
(declare-fun x10_72 () (_ BitVec 64))
(declare-fun x10_71 () (_ BitVec 64))
(declare-fun x10_70 () (_ BitVec 64))
(declare-fun x10_69 () (_ BitVec 64))
(declare-fun x10_68 () (_ BitVec 64))
(declare-fun x10_67 () (_ BitVec 64))
(declare-fun x10_66 () (_ BitVec 64))
(declare-fun x10_65 () (_ BitVec 64))
(declare-fun x10_64 () (_ BitVec 64))
(declare-fun x10_63 () (_ BitVec 64))
(declare-fun x10_62 () (_ BitVec 64))
(declare-fun x10_61 () (_ BitVec 64))
(declare-fun x10_60 () (_ BitVec 64))
(declare-fun x10_59 () (_ BitVec 64))
(declare-fun x10_58 () (_ BitVec 64))
(declare-fun x10_57 () (_ BitVec 64))
(declare-fun x10_56 () (_ BitVec 64))
(declare-fun x10_55 () (_ BitVec 64))
(declare-fun x10_54 () (_ BitVec 64))
(declare-fun x10_53 () (_ BitVec 64))
(declare-fun x10_52 () (_ BitVec 64))
(declare-fun x10_51 () (_ BitVec 64))
(declare-fun x10_50 () (_ BitVec 64))
(declare-fun x10_49 () (_ BitVec 64))
(declare-fun x10_48 () (_ BitVec 64))
(declare-fun x10_47 () (_ BitVec 64))
(declare-fun x10_46 () (_ BitVec 64))
(declare-fun x10_45 () (_ BitVec 64))
(declare-fun x10_44 () (_ BitVec 64))
(declare-fun x10_43 () (_ BitVec 64))
(declare-fun v_20_40_2 () (_ BitVec 64))
(declare-fun u_20_40_2 () (_ BitVec 64))
(declare-fun s_20_40_2 () (_ BitVec 64))
(declare-fun r_20_40_2 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_20_1 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_40_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_20_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun ne_39 () (_ BitVec 1))
(declare-fun ne_38 () (_ BitVec 1))
(declare-fun ne_37 () (_ BitVec 1))
(declare-fun ne_36 () (_ BitVec 1))
(declare-fun ne_35 () (_ BitVec 1))
(declare-fun ne_34 () (_ BitVec 1))
(declare-fun ne_33 () (_ BitVec 1))
(declare-fun ne_32 () (_ BitVec 1))
(declare-fun ne_31 () (_ BitVec 1))
(declare-fun ne_30 () (_ BitVec 1))
(declare-fun ne_29 () (_ BitVec 1))
(declare-fun ne_28 () (_ BitVec 1))
(declare-fun ne_27 () (_ BitVec 1))
(declare-fun ne_26 () (_ BitVec 1))
(declare-fun ne_25 () (_ BitVec 1))
(declare-fun ne_24 () (_ BitVec 1))
(declare-fun ne_23 () (_ BitVec 1))
(declare-fun ne_22 () (_ BitVec 1))
(declare-fun ne_21 () (_ BitVec 1))
(declare-fun ge_117 () (_ BitVec 1))
(declare-fun ge_116 () (_ BitVec 1))
(declare-fun ge_115 () (_ BitVec 1))
(declare-fun ge_114 () (_ BitVec 1))
(declare-fun ge_113 () (_ BitVec 1))
(declare-fun ge_112 () (_ BitVec 1))
(declare-fun ge_111 () (_ BitVec 1))
(declare-fun ge_110 () (_ BitVec 1))
(declare-fun ge_109 () (_ BitVec 1))
(declare-fun ge_108 () (_ BitVec 1))
(declare-fun ge_107 () (_ BitVec 1))
(declare-fun ge_106 () (_ BitVec 1))
(declare-fun ge_105 () (_ BitVec 1))
(declare-fun ge_104 () (_ BitVec 1))
(declare-fun ge_103 () (_ BitVec 1))
(declare-fun ge_102 () (_ BitVec 1))
(declare-fun ge_101 () (_ BitVec 1))
(declare-fun ge_100 () (_ BitVec 1))
(declare-fun ge_99 () (_ BitVec 1))
(declare-fun ge_98 () (_ BitVec 1))
(declare-fun ge_97 () (_ BitVec 1))
(declare-fun ge_96 () (_ BitVec 1))
(declare-fun ge_95 () (_ BitVec 1))
(declare-fun ge_94 () (_ BitVec 1))
(declare-fun ge_93 () (_ BitVec 1))
(declare-fun ge_92 () (_ BitVec 1))
(declare-fun ge_91 () (_ BitVec 1))
(declare-fun ge_90 () (_ BitVec 1))
(declare-fun ge_89 () (_ BitVec 1))
(declare-fun ge_88 () (_ BitVec 1))
(declare-fun ge_87 () (_ BitVec 1))
(declare-fun ge_86 () (_ BitVec 1))
(declare-fun ge_85 () (_ BitVec 1))
(declare-fun ge_84 () (_ BitVec 1))
(declare-fun ge_83 () (_ BitVec 1))
(declare-fun ge_82 () (_ BitVec 1))
(declare-fun ge_81 () (_ BitVec 1))
(declare-fun ge_80 () (_ BitVec 1))
(declare-fun ge_79 () (_ BitVec 1))
(declare-fun ge_78 () (_ BitVec 1))
(declare-fun ge_77 () (_ BitVec 1))
(declare-fun ge_76 () (_ BitVec 1))
(declare-fun ge_75 () (_ BitVec 1))
(declare-fun ge_74 () (_ BitVec 1))
(declare-fun ge_73 () (_ BitVec 1))
(declare-fun ge_72 () (_ BitVec 1))
(declare-fun ge_71 () (_ BitVec 1))
(declare-fun ge_70 () (_ BitVec 1))
(declare-fun ge_69 () (_ BitVec 1))
(declare-fun ge_68 () (_ BitVec 1))
(declare-fun ge_67 () (_ BitVec 1))
(declare-fun ge_66 () (_ BitVec 1))
(declare-fun ge_65 () (_ BitVec 1))
(declare-fun ge_64 () (_ BitVec 1))
(declare-fun ge_63 () (_ BitVec 1))
(declare-fun ge_62 () (_ BitVec 1))
(declare-fun ge_61 () (_ BitVec 1))
(declare-fun dc_319 () (_ BitVec 64))
(declare-fun dc_318 () (_ BitVec 1))
(declare-fun dc_317 () (_ BitVec 1))
(declare-fun dc_316 () (_ BitVec 1))
(declare-fun dc_315 () (_ BitVec 63))
(declare-fun dc_314 () (_ BitVec 64))
(declare-fun dc_313 () (_ BitVec 1))
(declare-fun dc_312 () (_ BitVec 62))
(declare-fun dc_311 () (_ BitVec 1))
(declare-fun dc_310 () (_ BitVec 1))
(declare-fun dc_309 () (_ BitVec 1))
(declare-fun dc_308 () (_ BitVec 63))
(declare-fun dc_307 () (_ BitVec 64))
(declare-fun dc_306 () (_ BitVec 1))
(declare-fun dc_305 () (_ BitVec 62))
(declare-fun dc_304 () (_ BitVec 1))
(declare-fun dc_303 () (_ BitVec 1))
(declare-fun dc_302 () (_ BitVec 1))
(declare-fun dc_301 () (_ BitVec 63))
(declare-fun dc_300 () (_ BitVec 64))
(declare-fun dc_299 () (_ BitVec 1))
(declare-fun dc_298 () (_ BitVec 62))
(declare-fun dc_297 () (_ BitVec 1))
(declare-fun dc_296 () (_ BitVec 1))
(declare-fun dc_295 () (_ BitVec 1))
(declare-fun dc_294 () (_ BitVec 63))
(declare-fun dc_293 () (_ BitVec 64))
(declare-fun dc_292 () (_ BitVec 1))
(declare-fun dc_291 () (_ BitVec 62))
(declare-fun dc_290 () (_ BitVec 1))
(declare-fun dc_289 () (_ BitVec 1))
(declare-fun dc_288 () (_ BitVec 1))
(declare-fun dc_287 () (_ BitVec 63))
(declare-fun dc_286 () (_ BitVec 64))
(declare-fun dc_285 () (_ BitVec 1))
(declare-fun dc_284 () (_ BitVec 62))
(declare-fun dc_283 () (_ BitVec 1))
(declare-fun dc_282 () (_ BitVec 1))
(declare-fun dc_281 () (_ BitVec 1))
(declare-fun dc_280 () (_ BitVec 63))
(declare-fun dc_279 () (_ BitVec 64))
(declare-fun dc_278 () (_ BitVec 1))
(declare-fun dc_277 () (_ BitVec 62))
(declare-fun dc_276 () (_ BitVec 1))
(declare-fun dc_275 () (_ BitVec 1))
(declare-fun dc_274 () (_ BitVec 1))
(declare-fun dc_273 () (_ BitVec 63))
(declare-fun dc_272 () (_ BitVec 64))
(declare-fun dc_271 () (_ BitVec 1))
(declare-fun dc_270 () (_ BitVec 62))
(declare-fun dc_269 () (_ BitVec 1))
(declare-fun dc_268 () (_ BitVec 1))
(declare-fun dc_267 () (_ BitVec 1))
(declare-fun dc_266 () (_ BitVec 63))
(declare-fun dc_265 () (_ BitVec 64))
(declare-fun dc_264 () (_ BitVec 1))
(declare-fun dc_263 () (_ BitVec 62))
(declare-fun dc_262 () (_ BitVec 1))
(declare-fun dc_261 () (_ BitVec 1))
(declare-fun dc_260 () (_ BitVec 1))
(declare-fun dc_259 () (_ BitVec 63))
(declare-fun dc_258 () (_ BitVec 64))
(declare-fun dc_257 () (_ BitVec 1))
(declare-fun dc_256 () (_ BitVec 62))
(declare-fun dc_255 () (_ BitVec 1))
(declare-fun dc_254 () (_ BitVec 1))
(declare-fun dc_253 () (_ BitVec 1))
(declare-fun dc_252 () (_ BitVec 63))
(declare-fun dc_251 () (_ BitVec 64))
(declare-fun dc_250 () (_ BitVec 1))
(declare-fun dc_249 () (_ BitVec 62))
(declare-fun dc_248 () (_ BitVec 1))
(declare-fun dc_247 () (_ BitVec 1))
(declare-fun dc_246 () (_ BitVec 1))
(declare-fun dc_245 () (_ BitVec 63))
(declare-fun dc_244 () (_ BitVec 64))
(declare-fun dc_243 () (_ BitVec 1))
(declare-fun dc_242 () (_ BitVec 62))
(declare-fun dc_241 () (_ BitVec 1))
(declare-fun dc_240 () (_ BitVec 1))
(declare-fun dc_239 () (_ BitVec 1))
(declare-fun dc_238 () (_ BitVec 63))
(declare-fun dc_237 () (_ BitVec 64))
(declare-fun dc_236 () (_ BitVec 1))
(declare-fun dc_235 () (_ BitVec 62))
(declare-fun dc_234 () (_ BitVec 1))
(declare-fun dc_233 () (_ BitVec 1))
(declare-fun dc_232 () (_ BitVec 1))
(declare-fun dc_231 () (_ BitVec 63))
(declare-fun dc_230 () (_ BitVec 64))
(declare-fun dc_229 () (_ BitVec 1))
(declare-fun dc_228 () (_ BitVec 62))
(declare-fun dc_227 () (_ BitVec 1))
(declare-fun dc_226 () (_ BitVec 1))
(declare-fun dc_225 () (_ BitVec 1))
(declare-fun dc_224 () (_ BitVec 63))
(declare-fun dc_223 () (_ BitVec 64))
(declare-fun dc_222 () (_ BitVec 1))
(declare-fun dc_221 () (_ BitVec 62))
(declare-fun dc_220 () (_ BitVec 1))
(declare-fun dc_219 () (_ BitVec 1))
(declare-fun dc_218 () (_ BitVec 1))
(declare-fun dc_217 () (_ BitVec 63))
(declare-fun dc_216 () (_ BitVec 64))
(declare-fun dc_215 () (_ BitVec 1))
(declare-fun dc_214 () (_ BitVec 62))
(declare-fun dc_213 () (_ BitVec 1))
(declare-fun dc_212 () (_ BitVec 1))
(declare-fun dc_211 () (_ BitVec 1))
(declare-fun dc_210 () (_ BitVec 63))
(declare-fun dc_209 () (_ BitVec 64))
(declare-fun dc_208 () (_ BitVec 1))
(declare-fun dc_207 () (_ BitVec 62))
(declare-fun dc_206 () (_ BitVec 1))
(declare-fun dc_205 () (_ BitVec 1))
(declare-fun dc_204 () (_ BitVec 1))
(declare-fun dc_203 () (_ BitVec 63))
(declare-fun dc_202 () (_ BitVec 64))
(declare-fun dc_201 () (_ BitVec 1))
(declare-fun dc_200 () (_ BitVec 62))
(declare-fun dc_199 () (_ BitVec 1))
(declare-fun dc_198 () (_ BitVec 1))
(declare-fun dc_197 () (_ BitVec 1))
(declare-fun dc_196 () (_ BitVec 63))
(declare-fun dc_195 () (_ BitVec 64))
(declare-fun dc_194 () (_ BitVec 1))
(declare-fun dc_193 () (_ BitVec 62))
(declare-fun dc_192 () (_ BitVec 1))
(declare-fun dc_191 () (_ BitVec 1))
(declare-fun dc_190 () (_ BitVec 1))
(declare-fun dc_189 () (_ BitVec 63))
(declare-fun dc_188 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_25 (bvadd (bvadd neg_f_0_low60_20_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_44 (bvadd (bvadd neg_g_0_low60_20_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_0_1)) (bvsle neg_f_0_low60_20_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_0_1)) (bvsle neg_g_0_low60_20_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_25) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_188 ((_ extract 63 1) x8_44)) (= x8_lo_21 ((_ extract 0 0) x8_44))))
(assert (= ne_21 (bvand x8_lo_21 #b1)))
(assert (= x10_43 (ite (= ne_21 #b1) x7_25 #x0000000000000000)))
(assert (and (= ge_61 ((_ extract 63 63) x3_41)) (= dc_189 ((_ extract 62 0) x3_41))))
(assert (= ge_62 (bvnot ge_61)))
(assert (= ge_63 (ite (= ne_21 #b1) ge_62 #b0)))
(assert (and (= dc_190 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_42 (ite (= ge_63 #b1) x3_neg_21 x3_41)))
(assert (and (= dc_191 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_44 (ite (= ge_63 #b1) x10_neg_21 x10_43)))
(assert (= x7_26 (ite (= ge_63 #b1) x8_44 x7_25)))
(assert (and (= dc_192 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44)))) (= x8_45 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44))))))
(assert (= x3_43 (bvadd x3_42 #x0000000000000002)))
(assert (and (= dc_193 ((_ extract 63 2) x8_45)) (= x8_lo_22 ((_ extract 1 0) x8_45))))
(assert (and (= x8_target_20 ((_ extract 1 1) x8_lo_22)) (= dc_194 ((_ extract 0 0) x8_lo_22))))
(assert (= ne_22 (bvand x8_target_20 #b1)))
(assert (and (= x8_46 ((_ sign_extend 1) ((_ extract 63 1) x8_45))) (= dc_195 ((_ zero_extend 63) ((_ extract 0 0) x8_45)))))
(assert true)
(assert (= x10_45 (ite (= ne_22 #b1) x7_26 #x0000000000000000)))
(assert (and (= ge_64 ((_ extract 63 63) x3_43)) (= dc_196 ((_ extract 62 0) x3_43))))
(assert (= ge_65 (bvnot ge_64)))
(assert (= ge_66 (ite (= ne_22 #b1) ge_65 #b0)))
(assert (and (= dc_197 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_44 (ite (= ge_66 #b1) x3_neg_22 x3_43)))
(assert (and (= dc_198 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_46 (ite (= ge_66 #b1) x10_neg_22 x10_45)))
(assert (= x7_27 (ite (= ge_66 #b1) x8_46 x7_26)))
(assert (and (= dc_199 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46)))) (= x8_47 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46))))))
(assert (= x3_45 (bvadd x3_44 #x0000000000000002)))
(assert (and (= dc_200 ((_ extract 63 2) x8_47)) (= x8_lo_23 ((_ extract 1 0) x8_47))))
(assert (and (= x8_target_21 ((_ extract 1 1) x8_lo_23)) (= dc_201 ((_ extract 0 0) x8_lo_23))))
(assert (= ne_23 (bvand x8_target_21 #b1)))
(assert (and (= x8_48 ((_ sign_extend 1) ((_ extract 63 1) x8_47))) (= dc_202 ((_ zero_extend 63) ((_ extract 0 0) x8_47)))))
(assert true)
(assert (= x10_47 (ite (= ne_23 #b1) x7_27 #x0000000000000000)))
(assert (and (= ge_67 ((_ extract 63 63) x3_45)) (= dc_203 ((_ extract 62 0) x3_45))))
(assert (= ge_68 (bvnot ge_67)))
(assert (= ge_69 (ite (= ne_23 #b1) ge_68 #b0)))
(assert (and (= dc_204 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_46 (ite (= ge_69 #b1) x3_neg_23 x3_45)))
(assert (and (= dc_205 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_48 (ite (= ge_69 #b1) x10_neg_23 x10_47)))
(assert (= x7_28 (ite (= ge_69 #b1) x8_48 x7_27)))
(assert (and (= dc_206 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48)))) (= x8_49 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48))))))
(assert (= x3_47 (bvadd x3_46 #x0000000000000002)))
(assert (and (= dc_207 ((_ extract 63 2) x8_49)) (= x8_lo_24 ((_ extract 1 0) x8_49))))
(assert (and (= x8_target_22 ((_ extract 1 1) x8_lo_24)) (= dc_208 ((_ extract 0 0) x8_lo_24))))
(assert (= ne_24 (bvand x8_target_22 #b1)))
(assert (and (= x8_50 ((_ sign_extend 1) ((_ extract 63 1) x8_49))) (= dc_209 ((_ zero_extend 63) ((_ extract 0 0) x8_49)))))
(assert true)
(assert (= x10_49 (ite (= ne_24 #b1) x7_28 #x0000000000000000)))
(assert (and (= ge_70 ((_ extract 63 63) x3_47)) (= dc_210 ((_ extract 62 0) x3_47))))
(assert (= ge_71 (bvnot ge_70)))
(assert (= ge_72 (ite (= ne_24 #b1) ge_71 #b0)))
(assert (and (= dc_211 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_47))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_24 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_47))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_48 (ite (= ge_72 #b1) x3_neg_24 x3_47)))
(assert (and (= dc_212 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_49))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_24 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_49))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_50 (ite (= ge_72 #b1) x10_neg_24 x10_49)))
(assert (= x7_29 (ite (= ge_72 #b1) x8_50 x7_28)))
(assert (and (= dc_213 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_50) ((_ zero_extend 1) x10_50)))) (= x8_51 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_50) ((_ zero_extend 1) x10_50))))))
(assert (= x3_49 (bvadd x3_48 #x0000000000000002)))
(assert (and (= dc_214 ((_ extract 63 2) x8_51)) (= x8_lo_25 ((_ extract 1 0) x8_51))))
(assert (and (= x8_target_23 ((_ extract 1 1) x8_lo_25)) (= dc_215 ((_ extract 0 0) x8_lo_25))))
(assert (= ne_25 (bvand x8_target_23 #b1)))
(assert (and (= x8_52 ((_ sign_extend 1) ((_ extract 63 1) x8_51))) (= dc_216 ((_ zero_extend 63) ((_ extract 0 0) x8_51)))))
(assert true)
(assert (= x10_51 (ite (= ne_25 #b1) x7_29 #x0000000000000000)))
(assert (and (= ge_73 ((_ extract 63 63) x3_49)) (= dc_217 ((_ extract 62 0) x3_49))))
(assert (= ge_74 (bvnot ge_73)))
(assert (= ge_75 (ite (= ne_25 #b1) ge_74 #b0)))
(assert (and (= dc_218 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_49))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_25 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_49))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_50 (ite (= ge_75 #b1) x3_neg_25 x3_49)))
(assert (and (= dc_219 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_51))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_25 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_51))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_52 (ite (= ge_75 #b1) x10_neg_25 x10_51)))
(assert (= x7_30 (ite (= ge_75 #b1) x8_52 x7_29)))
(assert (and (= dc_220 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_52) ((_ zero_extend 1) x10_52)))) (= x8_53 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_52) ((_ zero_extend 1) x10_52))))))
(assert (= x3_51 (bvadd x3_50 #x0000000000000002)))
(assert (and (= dc_221 ((_ extract 63 2) x8_53)) (= x8_lo_26 ((_ extract 1 0) x8_53))))
(assert (and (= x8_target_24 ((_ extract 1 1) x8_lo_26)) (= dc_222 ((_ extract 0 0) x8_lo_26))))
(assert (= ne_26 (bvand x8_target_24 #b1)))
(assert (and (= x8_54 ((_ sign_extend 1) ((_ extract 63 1) x8_53))) (= dc_223 ((_ zero_extend 63) ((_ extract 0 0) x8_53)))))
(assert true)
(assert (= x10_53 (ite (= ne_26 #b1) x7_30 #x0000000000000000)))
(assert (and (= ge_76 ((_ extract 63 63) x3_51)) (= dc_224 ((_ extract 62 0) x3_51))))
(assert (= ge_77 (bvnot ge_76)))
(assert (= ge_78 (ite (= ne_26 #b1) ge_77 #b0)))
(assert (and (= dc_225 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_51))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_26 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_51))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_52 (ite (= ge_78 #b1) x3_neg_26 x3_51)))
(assert (and (= dc_226 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_53))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_26 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_53))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_54 (ite (= ge_78 #b1) x10_neg_26 x10_53)))
(assert (= x7_31 (ite (= ge_78 #b1) x8_54 x7_30)))
(assert (and (= dc_227 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_54) ((_ zero_extend 1) x10_54)))) (= x8_55 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_54) ((_ zero_extend 1) x10_54))))))
(assert (= x3_53 (bvadd x3_52 #x0000000000000002)))
(assert (and (= dc_228 ((_ extract 63 2) x8_55)) (= x8_lo_27 ((_ extract 1 0) x8_55))))
(assert (and (= x8_target_25 ((_ extract 1 1) x8_lo_27)) (= dc_229 ((_ extract 0 0) x8_lo_27))))
(assert (= ne_27 (bvand x8_target_25 #b1)))
(assert (and (= x8_56 ((_ sign_extend 1) ((_ extract 63 1) x8_55))) (= dc_230 ((_ zero_extend 63) ((_ extract 0 0) x8_55)))))
(assert true)
(assert (= x10_55 (ite (= ne_27 #b1) x7_31 #x0000000000000000)))
(assert (and (= ge_79 ((_ extract 63 63) x3_53)) (= dc_231 ((_ extract 62 0) x3_53))))
(assert (= ge_80 (bvnot ge_79)))
(assert (= ge_81 (ite (= ne_27 #b1) ge_80 #b0)))
(assert (and (= dc_232 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_53))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_27 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_53))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_54 (ite (= ge_81 #b1) x3_neg_27 x3_53)))
(assert (and (= dc_233 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_55))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_27 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_55))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_56 (ite (= ge_81 #b1) x10_neg_27 x10_55)))
(assert (= x7_32 (ite (= ge_81 #b1) x8_56 x7_31)))
(assert (and (= dc_234 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_56) ((_ zero_extend 1) x10_56)))) (= x8_57 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_56) ((_ zero_extend 1) x10_56))))))
(assert (= x3_55 (bvadd x3_54 #x0000000000000002)))
(assert (and (= dc_235 ((_ extract 63 2) x8_57)) (= x8_lo_28 ((_ extract 1 0) x8_57))))
(assert (and (= x8_target_26 ((_ extract 1 1) x8_lo_28)) (= dc_236 ((_ extract 0 0) x8_lo_28))))
(assert (= ne_28 (bvand x8_target_26 #b1)))
(assert (and (= x8_58 ((_ sign_extend 1) ((_ extract 63 1) x8_57))) (= dc_237 ((_ zero_extend 63) ((_ extract 0 0) x8_57)))))
(assert true)
(assert (= x10_57 (ite (= ne_28 #b1) x7_32 #x0000000000000000)))
(assert (and (= ge_82 ((_ extract 63 63) x3_55)) (= dc_238 ((_ extract 62 0) x3_55))))
(assert (= ge_83 (bvnot ge_82)))
(assert (= ge_84 (ite (= ne_28 #b1) ge_83 #b0)))
(assert (and (= dc_239 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_55))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_28 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_55))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_56 (ite (= ge_84 #b1) x3_neg_28 x3_55)))
(assert (and (= dc_240 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_57))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_28 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_57))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_58 (ite (= ge_84 #b1) x10_neg_28 x10_57)))
(assert (= x7_33 (ite (= ge_84 #b1) x8_58 x7_32)))
(assert (and (= dc_241 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_58) ((_ zero_extend 1) x10_58)))) (= x8_59 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_58) ((_ zero_extend 1) x10_58))))))
(assert (= x3_57 (bvadd x3_56 #x0000000000000002)))
(assert (and (= dc_242 ((_ extract 63 2) x8_59)) (= x8_lo_29 ((_ extract 1 0) x8_59))))
(assert (and (= x8_target_27 ((_ extract 1 1) x8_lo_29)) (= dc_243 ((_ extract 0 0) x8_lo_29))))
(assert (= ne_29 (bvand x8_target_27 #b1)))
(assert (and (= x8_60 ((_ sign_extend 1) ((_ extract 63 1) x8_59))) (= dc_244 ((_ zero_extend 63) ((_ extract 0 0) x8_59)))))
(assert true)
(assert (= x10_59 (ite (= ne_29 #b1) x7_33 #x0000000000000000)))
(assert (and (= ge_85 ((_ extract 63 63) x3_57)) (= dc_245 ((_ extract 62 0) x3_57))))
(assert (= ge_86 (bvnot ge_85)))
(assert (= ge_87 (ite (= ne_29 #b1) ge_86 #b0)))
(assert (and (= dc_246 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_57))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_29 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_57))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_58 (ite (= ge_87 #b1) x3_neg_29 x3_57)))
(assert (and (= dc_247 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_59))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_29 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_59))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_60 (ite (= ge_87 #b1) x10_neg_29 x10_59)))
(assert (= x7_34 (ite (= ge_87 #b1) x8_60 x7_33)))
(assert (and (= dc_248 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_60) ((_ zero_extend 1) x10_60)))) (= x8_61 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_60) ((_ zero_extend 1) x10_60))))))
(assert (= x3_59 (bvadd x3_58 #x0000000000000002)))
(assert (and (= dc_249 ((_ extract 63 2) x8_61)) (= x8_lo_30 ((_ extract 1 0) x8_61))))
(assert (and (= x8_target_28 ((_ extract 1 1) x8_lo_30)) (= dc_250 ((_ extract 0 0) x8_lo_30))))
(assert (= ne_30 (bvand x8_target_28 #b1)))
(assert (and (= x8_62 ((_ sign_extend 1) ((_ extract 63 1) x8_61))) (= dc_251 ((_ zero_extend 63) ((_ extract 0 0) x8_61)))))
(assert true)
(assert (= x10_61 (ite (= ne_30 #b1) x7_34 #x0000000000000000)))
(assert (and (= ge_88 ((_ extract 63 63) x3_59)) (= dc_252 ((_ extract 62 0) x3_59))))
(assert (= ge_89 (bvnot ge_88)))
(assert (= ge_90 (ite (= ne_30 #b1) ge_89 #b0)))
(assert (and (= dc_253 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_59))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_30 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_59))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_60 (ite (= ge_90 #b1) x3_neg_30 x3_59)))
(assert (and (= dc_254 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_61))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_30 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_61))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_62 (ite (= ge_90 #b1) x10_neg_30 x10_61)))
(assert (= x7_35 (ite (= ge_90 #b1) x8_62 x7_34)))
(assert (and (= dc_255 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_62) ((_ zero_extend 1) x10_62)))) (= x8_63 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_62) ((_ zero_extend 1) x10_62))))))
(assert (= x3_61 (bvadd x3_60 #x0000000000000002)))
(assert (and (= dc_256 ((_ extract 63 2) x8_63)) (= x8_lo_31 ((_ extract 1 0) x8_63))))
(assert (and (= x8_target_29 ((_ extract 1 1) x8_lo_31)) (= dc_257 ((_ extract 0 0) x8_lo_31))))
(assert (= ne_31 (bvand x8_target_29 #b1)))
(assert (and (= x8_64 ((_ sign_extend 1) ((_ extract 63 1) x8_63))) (= dc_258 ((_ zero_extend 63) ((_ extract 0 0) x8_63)))))
(assert true)
(assert (= x10_63 (ite (= ne_31 #b1) x7_35 #x0000000000000000)))
(assert (and (= ge_91 ((_ extract 63 63) x3_61)) (= dc_259 ((_ extract 62 0) x3_61))))
(assert (= ge_92 (bvnot ge_91)))
(assert (= ge_93 (ite (= ne_31 #b1) ge_92 #b0)))
(assert (and (= dc_260 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_61))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_31 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_61))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_62 (ite (= ge_93 #b1) x3_neg_31 x3_61)))
(assert (and (= dc_261 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_63))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_31 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_63))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_64 (ite (= ge_93 #b1) x10_neg_31 x10_63)))
(assert (= x7_36 (ite (= ge_93 #b1) x8_64 x7_35)))
(assert (and (= dc_262 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_64) ((_ zero_extend 1) x10_64)))) (= x8_65 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_64) ((_ zero_extend 1) x10_64))))))
(assert (= x3_63 (bvadd x3_62 #x0000000000000002)))
(assert (and (= dc_263 ((_ extract 63 2) x8_65)) (= x8_lo_32 ((_ extract 1 0) x8_65))))
(assert (and (= x8_target_30 ((_ extract 1 1) x8_lo_32)) (= dc_264 ((_ extract 0 0) x8_lo_32))))
(assert (= ne_32 (bvand x8_target_30 #b1)))
(assert (and (= x8_66 ((_ sign_extend 1) ((_ extract 63 1) x8_65))) (= dc_265 ((_ zero_extend 63) ((_ extract 0 0) x8_65)))))
(assert true)
(assert (= x10_65 (ite (= ne_32 #b1) x7_36 #x0000000000000000)))
(assert (and (= ge_94 ((_ extract 63 63) x3_63)) (= dc_266 ((_ extract 62 0) x3_63))))
(assert (= ge_95 (bvnot ge_94)))
(assert (= ge_96 (ite (= ne_32 #b1) ge_95 #b0)))
(assert (and (= dc_267 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_63))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_32 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_63))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_64 (ite (= ge_96 #b1) x3_neg_32 x3_63)))
(assert (and (= dc_268 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_65))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_32 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_65))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_66 (ite (= ge_96 #b1) x10_neg_32 x10_65)))
(assert (= x7_37 (ite (= ge_96 #b1) x8_66 x7_36)))
(assert (and (= dc_269 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_66) ((_ zero_extend 1) x10_66)))) (= x8_67 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_66) ((_ zero_extend 1) x10_66))))))
(assert (= x3_65 (bvadd x3_64 #x0000000000000002)))
(assert (and (= dc_270 ((_ extract 63 2) x8_67)) (= x8_lo_33 ((_ extract 1 0) x8_67))))
(assert (and (= x8_target_31 ((_ extract 1 1) x8_lo_33)) (= dc_271 ((_ extract 0 0) x8_lo_33))))
(assert (= ne_33 (bvand x8_target_31 #b1)))
(assert (and (= x8_68 ((_ sign_extend 1) ((_ extract 63 1) x8_67))) (= dc_272 ((_ zero_extend 63) ((_ extract 0 0) x8_67)))))
(assert true)
(assert (= x10_67 (ite (= ne_33 #b1) x7_37 #x0000000000000000)))
(assert (and (= ge_97 ((_ extract 63 63) x3_65)) (= dc_273 ((_ extract 62 0) x3_65))))
(assert (= ge_98 (bvnot ge_97)))
(assert (= ge_99 (ite (= ne_33 #b1) ge_98 #b0)))
(assert (and (= dc_274 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_65))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_33 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_65))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_66 (ite (= ge_99 #b1) x3_neg_33 x3_65)))
(assert (and (= dc_275 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_67))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_33 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_67))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_68 (ite (= ge_99 #b1) x10_neg_33 x10_67)))
(assert (= x7_38 (ite (= ge_99 #b1) x8_68 x7_37)))
(assert (and (= dc_276 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_68) ((_ zero_extend 1) x10_68)))) (= x8_69 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_68) ((_ zero_extend 1) x10_68))))))
(assert (= x3_67 (bvadd x3_66 #x0000000000000002)))
(assert (and (= dc_277 ((_ extract 63 2) x8_69)) (= x8_lo_34 ((_ extract 1 0) x8_69))))
(assert (and (= x8_target_32 ((_ extract 1 1) x8_lo_34)) (= dc_278 ((_ extract 0 0) x8_lo_34))))
(assert (= ne_34 (bvand x8_target_32 #b1)))
(assert (and (= x8_70 ((_ sign_extend 1) ((_ extract 63 1) x8_69))) (= dc_279 ((_ zero_extend 63) ((_ extract 0 0) x8_69)))))
(assert true)
(assert (= x10_69 (ite (= ne_34 #b1) x7_38 #x0000000000000000)))
(assert (and (= ge_100 ((_ extract 63 63) x3_67)) (= dc_280 ((_ extract 62 0) x3_67))))
(assert (= ge_101 (bvnot ge_100)))
(assert (= ge_102 (ite (= ne_34 #b1) ge_101 #b0)))
(assert (and (= dc_281 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_67))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_34 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_67))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_68 (ite (= ge_102 #b1) x3_neg_34 x3_67)))
(assert (and (= dc_282 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_69))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_34 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_69))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_70 (ite (= ge_102 #b1) x10_neg_34 x10_69)))
(assert (= x7_39 (ite (= ge_102 #b1) x8_70 x7_38)))
(assert (and (= dc_283 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_70) ((_ zero_extend 1) x10_70)))) (= x8_71 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_70) ((_ zero_extend 1) x10_70))))))
(assert (= x3_69 (bvadd x3_68 #x0000000000000002)))
(assert (and (= dc_284 ((_ extract 63 2) x8_71)) (= x8_lo_35 ((_ extract 1 0) x8_71))))
(assert (and (= x8_target_33 ((_ extract 1 1) x8_lo_35)) (= dc_285 ((_ extract 0 0) x8_lo_35))))
(assert (= ne_35 (bvand x8_target_33 #b1)))
(assert (and (= x8_72 ((_ sign_extend 1) ((_ extract 63 1) x8_71))) (= dc_286 ((_ zero_extend 63) ((_ extract 0 0) x8_71)))))
(assert true)
(assert (= x10_71 (ite (= ne_35 #b1) x7_39 #x0000000000000000)))
(assert (and (= ge_103 ((_ extract 63 63) x3_69)) (= dc_287 ((_ extract 62 0) x3_69))))
(assert (= ge_104 (bvnot ge_103)))
(assert (= ge_105 (ite (= ne_35 #b1) ge_104 #b0)))
(assert (and (= dc_288 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_69))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_35 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_69))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_70 (ite (= ge_105 #b1) x3_neg_35 x3_69)))
(assert (and (= dc_289 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_71))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_35 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_71))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_72 (ite (= ge_105 #b1) x10_neg_35 x10_71)))
(assert (= x7_40 (ite (= ge_105 #b1) x8_72 x7_39)))
(assert (and (= dc_290 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_72) ((_ zero_extend 1) x10_72)))) (= x8_73 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_72) ((_ zero_extend 1) x10_72))))))
(assert (= x3_71 (bvadd x3_70 #x0000000000000002)))
(assert (and (= dc_291 ((_ extract 63 2) x8_73)) (= x8_lo_36 ((_ extract 1 0) x8_73))))
(assert (and (= x8_target_34 ((_ extract 1 1) x8_lo_36)) (= dc_292 ((_ extract 0 0) x8_lo_36))))
(assert (= ne_36 (bvand x8_target_34 #b1)))
(assert (and (= x8_74 ((_ sign_extend 1) ((_ extract 63 1) x8_73))) (= dc_293 ((_ zero_extend 63) ((_ extract 0 0) x8_73)))))
(assert true)
(assert (= x10_73 (ite (= ne_36 #b1) x7_40 #x0000000000000000)))
(assert (and (= ge_106 ((_ extract 63 63) x3_71)) (= dc_294 ((_ extract 62 0) x3_71))))
(assert (= ge_107 (bvnot ge_106)))
(assert (= ge_108 (ite (= ne_36 #b1) ge_107 #b0)))
(assert (and (= dc_295 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_71))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_36 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_71))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_72 (ite (= ge_108 #b1) x3_neg_36 x3_71)))
(assert (and (= dc_296 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_73))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_36 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_73))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_74 (ite (= ge_108 #b1) x10_neg_36 x10_73)))
(assert (= x7_41 (ite (= ge_108 #b1) x8_74 x7_40)))
(assert (and (= dc_297 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_74) ((_ zero_extend 1) x10_74)))) (= x8_75 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_74) ((_ zero_extend 1) x10_74))))))
(assert (= x3_73 (bvadd x3_72 #x0000000000000002)))
(assert (and (= dc_298 ((_ extract 63 2) x8_75)) (= x8_lo_37 ((_ extract 1 0) x8_75))))
(assert (and (= x8_target_35 ((_ extract 1 1) x8_lo_37)) (= dc_299 ((_ extract 0 0) x8_lo_37))))
(assert (= ne_37 (bvand x8_target_35 #b1)))
(assert (and (= x8_76 ((_ sign_extend 1) ((_ extract 63 1) x8_75))) (= dc_300 ((_ zero_extend 63) ((_ extract 0 0) x8_75)))))
(assert true)
(assert (= x10_75 (ite (= ne_37 #b1) x7_41 #x0000000000000000)))
(assert (and (= ge_109 ((_ extract 63 63) x3_73)) (= dc_301 ((_ extract 62 0) x3_73))))
(assert (= ge_110 (bvnot ge_109)))
(assert (= ge_111 (ite (= ne_37 #b1) ge_110 #b0)))
(assert (and (= dc_302 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_73))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_37 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_73))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_74 (ite (= ge_111 #b1) x3_neg_37 x3_73)))
(assert (and (= dc_303 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_75))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_37 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_75))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_76 (ite (= ge_111 #b1) x10_neg_37 x10_75)))
(assert (= x7_42 (ite (= ge_111 #b1) x8_76 x7_41)))
(assert (and (= dc_304 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_76) ((_ zero_extend 1) x10_76)))) (= x8_77 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_76) ((_ zero_extend 1) x10_76))))))
(assert (= x3_75 (bvadd x3_74 #x0000000000000002)))
(assert (and (= dc_305 ((_ extract 63 2) x8_77)) (= x8_lo_38 ((_ extract 1 0) x8_77))))
(assert (and (= x8_target_36 ((_ extract 1 1) x8_lo_38)) (= dc_306 ((_ extract 0 0) x8_lo_38))))
(assert (= ne_38 (bvand x8_target_36 #b1)))
(assert (and (= x8_78 ((_ sign_extend 1) ((_ extract 63 1) x8_77))) (= dc_307 ((_ zero_extend 63) ((_ extract 0 0) x8_77)))))
(assert true)
(assert (= x10_77 (ite (= ne_38 #b1) x7_42 #x0000000000000000)))
(assert (and (= ge_112 ((_ extract 63 63) x3_75)) (= dc_308 ((_ extract 62 0) x3_75))))
(assert (= ge_113 (bvnot ge_112)))
(assert (= ge_114 (ite (= ne_38 #b1) ge_113 #b0)))
(assert (and (= dc_309 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_75))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_38 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_75))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_76 (ite (= ge_114 #b1) x3_neg_38 x3_75)))
(assert (and (= dc_310 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_77))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_38 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_77))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_78 (ite (= ge_114 #b1) x10_neg_38 x10_77)))
(assert (= x7_43 (ite (= ge_114 #b1) x8_78 x7_42)))
(assert (and (= dc_311 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_78) ((_ zero_extend 1) x10_78)))) (= x8_79 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_78) ((_ zero_extend 1) x10_78))))))
(assert (= x3_77 (bvadd x3_76 #x0000000000000002)))
(assert (and (= dc_312 ((_ extract 63 2) x8_79)) (= x8_lo_39 ((_ extract 1 0) x8_79))))
(assert (and (= x8_target_37 ((_ extract 1 1) x8_lo_39)) (= dc_313 ((_ extract 0 0) x8_lo_39))))
(assert (= ne_39 (bvand x8_target_37 #b1)))
(assert (and (= x8_80 ((_ sign_extend 1) ((_ extract 63 1) x8_79))) (= dc_314 ((_ zero_extend 63) ((_ extract 0 0) x8_79)))))
(assert true)
(assert (= x10_79 (ite (= ne_39 #b1) x7_43 #x0000000000000000)))
(assert (and (= ge_115 ((_ extract 63 63) x3_77)) (= dc_315 ((_ extract 62 0) x3_77))))
(assert (= ge_116 (bvnot ge_115)))
(assert (= ge_117 (ite (= ne_39 #b1) ge_116 #b0)))
(assert (and (= dc_316 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_77))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_39 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_77))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_78 (ite (= ge_117 #b1) x3_neg_39 x3_77)))
(assert (and (= dc_317 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_79))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_39 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_79))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_80 (ite (= ge_117 #b1) x10_neg_39 x10_79)))
(assert (= x7_44 (ite (= ge_117 #b1) x8_80 x7_43)))
(assert (and (= dc_318 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_80) ((_ zero_extend 1) x10_80)))) (= x8_81 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_80) ((_ zero_extend 1) x10_80))))))
(assert (= x3_79 (bvadd x3_78 #x0000000000000002)))
(assert (and (= x8_82 ((_ sign_extend 1) ((_ extract 63 1) x8_81))) (= dc_319 ((_ zero_extend 63) ((_ extract 0 0) x8_81)))))
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (bvsle s_20_40_2 #x00000000000FFFFF) (bvsle #xFFFFFFFFFFF00000 s_20_40_2)) (bvsle r_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 r_20_40_2)) (bvsle v_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 v_20_40_2)) (bvsle u_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 u_20_40_2)) (bvsle neg_g_0_low60_20_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_20_1)) (bvsle neg_f_0_low60_20_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_20_1)) (bvsle x3_79 #x0000000000000051)) (bvsle #xFFFFFFFFFFFFFFB1 x3_79)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_44) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= x8_82 (bvadd (bvadd neg_g_0_low60_20_low20_20_1 (bvmul r_20_40_2 #x0000000000200000)) (bvmul s_20_40_2 #x0000040000000000)))) (= x7_44 (bvadd (bvadd neg_f_0_low60_20_low20_20_1 (bvmul u_20_40_2 #x0000000000200000)) (bvmul v_20_40_2 #x0000040000000000)))))
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert (= (bvsmod (bvsub ((_ zero_extend 1) neg_f_0_low60_40_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000))
(assert (not (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and true true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_42) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_42 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_42)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_42 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_44) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_44 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_44)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_44 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_46) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_46 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_46)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_46 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_48) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_48 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_48)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_48 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_50) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_50 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_50)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_50 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_52) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_52 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_52)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_52 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_54) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_54 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_54)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_54 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_56) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_56 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_56)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_56 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_58) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_58 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_58)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_58 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_60) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_60 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_60)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_60 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_62) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_62 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_62)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_62 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_64) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_64 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_64)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_64 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_66) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_66 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_66)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_66 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_68) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_68 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_68)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_68 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_70) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_70 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_70)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_70 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_72) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_72 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_72)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_72 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_74) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_74 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_74)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_74 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_76) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_76 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_76)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_76 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x3_78) ((_ extract 63 63) #x0000000000000002)) (bvnot ((_ extract 63 63) (bvadd x3_78 #x0000000000000002)))) (bvand (bvand (bvnot ((_ extract 63 63) x3_78)) (bvnot ((_ extract 63 63) #x0000000000000002))) ((_ extract 63 63) (bvadd x3_78 #x0000000000000002)))) #b1))) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_165bba.smt2
Execution time of boolector: 0.0279 seconds
OUTPUT FROM boolector:
unsat

Execution of safety task: 0.0335 seconds
=== Cut #7 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: safety
; Track: default
; Cut: #7
; Verify: safety (all in one query)
; Output file: /tmp/outputqfbv_6f5b6b.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_82 () (_ BitVec 64))
(declare-fun x7_44 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_79 () (_ BitVec 64))
(declare-fun x20_3 () (_ BitVec 64))
(declare-fun x20_2 () (_ BitVec 64))
(declare-fun x20_1 () (_ BitVec 64))
(declare-fun x17_5 () (_ BitVec 64))
(declare-fun x17_4 () (_ BitVec 64))
(declare-fun x17_3 () (_ BitVec 64))
(declare-fun x17_2 () (_ BitVec 64))
(declare-fun x17_1 () (_ BitVec 64))
(declare-fun x16_3 () (_ BitVec 64))
(declare-fun x16_2 () (_ BitVec 64))
(declare-fun x16_1 () (_ BitVec 64))
(declare-fun x15_5 () (_ BitVec 64))
(declare-fun x15_4 () (_ BitVec 64))
(declare-fun x15_3 () (_ BitVec 64))
(declare-fun x15_2 () (_ BitVec 64))
(declare-fun x15_1 () (_ BitVec 64))
(declare-fun v_20_40_2 () (_ BitVec 64))
(declare-fun u_20_40_2 () (_ BitVec 64))
(declare-fun s_20_40_2 () (_ BitVec 64))
(declare-fun r_20_40_2 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_20_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_40_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_20_1 () (_ BitVec 64))
(declare-fun dcH_8 () (_ BitVec 64))
(declare-fun dcH_7 () (_ BitVec 64))
(declare-fun dc_323 () (_ BitVec 64))
(declare-fun dc_322 () (_ BitVec 64))
(declare-fun dc_321 () (_ BitVec 64))
(declare-fun dc_320 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_44 (bvadd (bvadd neg_f_0_low60_20_low20_20_1 (bvmul u_20_40_2 #x0000000000200000)) (bvmul v_20_40_2 #x0000040000000000))) (= x8_82 (bvadd (bvadd neg_g_0_low60_20_low20_20_1 (bvmul r_20_40_2 #x0000000000200000)) (bvmul s_20_40_2 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_20_1)) (bvsle neg_f_0_low60_20_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_20_1)) (bvsle neg_g_0_low60_20_low20_20_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) neg_f_0_low60_40_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_79) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFB1 x3_79)) (bvsle x3_79 #x0000000000000051)) (bvsle #xFFFFFFFFFFF00000 u_20_40_2)) (bvsle u_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 v_20_40_2)) (bvsle v_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 r_20_40_2)) (bvsle r_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 s_20_40_2)) (bvsle s_20_40_2 #x00000000000FFFFF)) (= x6_2 #x0000020000100000)))
(assert (= x16_1 (bvadd x7_44 x6_2)))
(assert (= x16_2 x16_1))
(assert (and (= x16_3 ((_ sign_extend 42) ((_ extract 63 42) x16_2))) (= dc_320 ((_ zero_extend 22) ((_ extract 41 0) x16_2)))))
(assert (= x15_1 (bvadd x7_44 #x0000000000100000)))
(assert (and (= dcH_7 ((_ sign_extend 42) ((_ extract 63 42) x15_1))) (= x15_2 ((_ zero_extend 22) ((_ extract 41 0) x15_1)))))
(assert (= x15_3 (bvshl x15_2 #x0000000000000016)))
(assert (= x15_4 x15_3))
(assert (and (= x15_5 ((_ sign_extend 43) ((_ extract 63 43) x15_4))) (= dc_321 ((_ zero_extend 21) ((_ extract 42 0) x15_4)))))
(assert (= x20_1 (bvadd x8_82 x6_2)))
(assert (= x20_2 x20_1))
(assert (and (= x20_3 ((_ sign_extend 42) ((_ extract 63 42) x20_2))) (= dc_322 ((_ zero_extend 22) ((_ extract 41 0) x20_2)))))
(assert (= x17_1 (bvadd x8_82 #x0000000000100000)))
(assert (and (= dcH_8 ((_ sign_extend 42) ((_ extract 63 42) x17_1))) (= x17_2 ((_ zero_extend 22) ((_ extract 41 0) x17_1)))))
(assert (= x17_3 (bvshl x17_2 #x0000000000000016)))
(assert (= x17_4 x17_3))
(assert (and (= x17_5 ((_ sign_extend 43) ((_ extract 63 43) x17_4))) (= dc_323 ((_ zero_extend 21) ((_ extract 42 0) x17_4)))))
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert (not (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and true (not (= (bvor (bvand (bvand ((_ extract 63 63) x7_44) ((_ extract 63 63) x6_2)) (bvnot ((_ extract 63 63) (bvadd x7_44 x6_2)))) (bvand (bvand (bvnot ((_ extract 63 63) x7_44)) (bvnot ((_ extract 63 63) x6_2))) ((_ extract 63 63) (bvadd x7_44 x6_2)))) #b1))) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x7_44) ((_ extract 63 63) #x0000000000100000)) (bvnot ((_ extract 63 63) (bvadd x7_44 #x0000000000100000)))) (bvand (bvand (bvnot ((_ extract 63 63) x7_44)) (bvnot ((_ extract 63 63) #x0000000000100000))) ((_ extract 63 63) (bvadd x7_44 #x0000000000100000)))) #b1))) true) (= ((_ extract 63 42) x15_2) #b0000000000000000000000)) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x8_82) ((_ extract 63 63) x6_2)) (bvnot ((_ extract 63 63) (bvadd x8_82 x6_2)))) (bvand (bvand (bvnot ((_ extract 63 63) x8_82)) (bvnot ((_ extract 63 63) x6_2))) ((_ extract 63 63) (bvadd x8_82 x6_2)))) #b1))) true) true) (not (= (bvor (bvand (bvand ((_ extract 63 63) x8_82) ((_ extract 63 63) #x0000000000100000)) (bvnot ((_ extract 63 63) (bvadd x8_82 #x0000000000100000)))) (bvand (bvand (bvnot ((_ extract 63 63) x8_82)) (bvnot ((_ extract 63 63) #x0000000000100000))) ((_ extract 63 63) (bvadd x8_82 #x0000000000100000)))) #b1))) true) (= ((_ extract 63 42) x17_2) #b0000000000000000000000)) true) true) true) true) true) true) true) true) true) true)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_f63fa9.smt2
Execution time of boolector: 0.0039 seconds
OUTPUT FROM boolector:
unsat

Execution of safety task: 0.0074 seconds
=== Cut #8 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: safety
; Track: default
; Cut: #8
; Verify: safety (all in one query)
; Output file: /tmp/outputqfbv_e07625.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x9_10 () (_ BitVec 64))
(declare-fun x9_9 () (_ BitVec 64))
(declare-fun x9_8 () (_ BitVec 64))
(declare-fun x9_7 () (_ BitVec 64))
(declare-fun x9_6 () (_ BitVec 64))
(declare-fun x9_5 () (_ BitVec 64))
(declare-fun x9_4 () (_ BitVec 64))
(declare-fun x9_3 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_79 () (_ BitVec 64))
(declare-fun x20_3 () (_ BitVec 64))
(declare-fun x2_10 () (_ BitVec 64))
(declare-fun x2_9 () (_ BitVec 64))
(declare-fun x2_7 () (_ BitVec 64))
(declare-fun x17_5 () (_ BitVec 64))
(declare-fun x16_3 () (_ BitVec 64))
(declare-fun x15_5 () (_ BitVec 64))
(declare-fun x14_4 () (_ BitVec 64))
(declare-fun x14_3 () (_ BitVec 64))
(declare-fun x13_6 () (_ BitVec 64))
(declare-fun x13_5 () (_ BitVec 64))
(declare-fun x12_3 () (_ BitVec 64))
(declare-fun x11_5 () (_ BitVec 64))
(declare-fun x10_84 () (_ BitVec 64))
(declare-fun x10_83 () (_ BitVec 64))
(declare-fun x10_82 () (_ BitVec 64))
(declare-fun x10_81 () (_ BitVec 64))
(declare-fun x1_5 () (_ BitVec 64))
(declare-fun tmp_8 () (_ BitVec 64))
(declare-fun tmp_7 () (_ BitVec 64))
(declare-fun tmp_6 () (_ BitVec 64))
(declare-fun tmp_5 () (_ BitVec 64))
(declare-fun tmp_4 () (_ BitVec 64))
(declare-fun tmp_3 () (_ BitVec 64))
(declare-fun neg_g_0_low60_40_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_40_1 () (_ BitVec 64))
(declare-fun dcH_21 () (_ BitVec 64))
(declare-fun dcH_20 () (_ BitVec 64))
(declare-fun dcH_19 () (_ BitVec 64))
(declare-fun dcH_18 () (_ BitVec 64))
(declare-fun dcH_17 () (_ BitVec 64))
(declare-fun dcH_16 () (_ BitVec 64))
(declare-fun dcH_15 () (_ BitVec 64))
(declare-fun dcH_14 () (_ BitVec 64))
(declare-fun dcH_13 () (_ BitVec 64))
(declare-fun dcH_12 () (_ BitVec 64))
(declare-fun dcH_11 () (_ BitVec 64))
(declare-fun dcH_10 () (_ BitVec 64))
(declare-fun dc_331 () (_ BitVec 1))
(declare-fun dc_330 () (_ BitVec 1))
(declare-fun dc_329 () (_ BitVec 1))
(declare-fun dc_328 () (_ BitVec 1))
(declare-fun dc_327 () (_ BitVec 64))
(declare-fun dc_326 () (_ BitVec 1))
(declare-fun dc_325 () (_ BitVec 64))
(declare-fun dc_324 () (_ BitVec 1))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) neg_f_0_low60_40_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= (bvsmod (bvsub ((_ zero_extend 1) x3_79) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFB1 x3_79)) (bvsle x3_79 #x0000000000000051)) (bvsle #xFFFFFFFFFFF00000 x15_5)) (bvsle x15_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x16_3)) (bvsle x16_3 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x17_5)) (bvsle x17_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x20_3)) (bvsle x20_3 #x00000000000FFFFF)) (= x6_2 #x0000020000100000)))
(assert (= x1_5 x9_3))
(assert (= x2_9 x2_7))
(assert true)
(assert (and (= dcH_10 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x15_5) ((_ sign_extend 64) x1_5)))) (= x9_4 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x15_5) ((_ sign_extend 64) x1_5))))))
(assert (and (= dcH_11 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_9) ((_ sign_extend 64) x16_3)))) (= tmp_3 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_9) ((_ sign_extend 64) x16_3))))))
(assert (and (= dc_324 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x9_4) ((_ zero_extend 1) tmp_3)))) (= x9_5 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x9_4) ((_ zero_extend 1) tmp_3))))))
(assert true)
(assert (and (= x9_5 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) neg_f_0_low60_40_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x9_5) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x9_6 ((_ zero_extend 20) ((_ extract 63 20) x9_5))) (= dc_325 ((_ zero_extend 44) ((_ extract 19 0) x9_5)))))
(assert true)
(assert true)
(assert (and (= dcH_12 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x17_5) ((_ sign_extend 64) x1_5)))) (= x10_81 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x17_5) ((_ sign_extend 64) x1_5))))))
(assert (and (= dcH_13 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_9) ((_ sign_extend 64) x20_3)))) (= tmp_4 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_9) ((_ sign_extend 64) x20_3))))))
(assert (and (= dc_326 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x10_81) ((_ zero_extend 1) tmp_4)))) (= x10_82 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x10_81) ((_ zero_extend 1) tmp_4))))))
(assert true)
(assert (and (= x10_82 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) neg_g_0_low60_40_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x10_82) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x2_10 ((_ zero_extend 20) ((_ extract 63 20) x10_82))) (= dc_327 ((_ zero_extend 44) ((_ extract 19 0) x10_82)))))
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert (and (= dcH_14 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x15_5) ((_ sign_extend 64) x11_5)))) (= x9_7 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x15_5) ((_ sign_extend 64) x11_5))))))
(assert (and (= dcH_15 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x13_5) ((_ sign_extend 64) x16_3)))) (= tmp_5 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x13_5) ((_ sign_extend 64) x16_3))))))
(assert (and (= dc_328 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x9_7) ((_ zero_extend 1) tmp_5)))) (= x10_83 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x9_7) ((_ zero_extend 1) tmp_5))))))
(assert (and (= dcH_16 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x17_5) ((_ sign_extend 64) x11_5)))) (= x9_8 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x17_5) ((_ sign_extend 64) x11_5))))))
(assert (and (= dcH_17 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x13_5) ((_ sign_extend 64) x20_3)))) (= tmp_6 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x13_5) ((_ sign_extend 64) x20_3))))))
(assert (and (= dc_329 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x9_8) ((_ zero_extend 1) tmp_6)))) (= x13_6 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x9_8) ((_ zero_extend 1) tmp_6))))))
(assert (and (= dcH_18 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x15_5) ((_ sign_extend 64) x12_3)))) (= x9_9 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x15_5) ((_ sign_extend 64) x12_3))))))
(assert (and (= dcH_19 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x14_3) ((_ sign_extend 64) x16_3)))) (= tmp_7 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x14_3) ((_ sign_extend 64) x16_3))))))
(assert (and (= dc_330 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x9_9) ((_ zero_extend 1) tmp_7)))) (= x10_84 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x9_9) ((_ zero_extend 1) tmp_7))))))
(assert (and (= dcH_20 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x17_5) ((_ sign_extend 64) x12_3)))) (= x9_10 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x17_5) ((_ sign_extend 64) x12_3))))))
(assert (and (= dcH_21 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x14_3) ((_ sign_extend 64) x20_3)))) (= tmp_8 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x14_3) ((_ sign_extend 64) x20_3))))))
(assert (and (= dc_331 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x9_10) ((_ zero_extend 1) tmp_8)))) (= x14_4 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x9_10) ((_ zero_extend 1) tmp_8))))))
(assert (not (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and true true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true) true)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_5b87eb.smt2
Execution time of boolector: 0.0008 seconds
OUTPUT FROM boolector:
unsat

Execution of safety task: 0.0044 seconds
===== Verifying range assertions =====
=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #0
; Range assertion #0: v1_uint64_1_1 = 1073741823@64
; Range condition: v1_uint64_1_1 = 1073741823
; Output file: /tmp/outputqfbv_8b5e1e.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (not (= v1_uint64_1_1 #x000000003FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_70446a.smt2
Execution time of boolector: 0.0007 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #0
; Range assertion #2: v1_uint64_1_1 = 1073741823@64
; Range condition: v1_uint64_1_1 = 1073741823
; Output file: /tmp/outputqfbv_d7816c.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (not (= v1_uint64_1_1 #x000000003FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_930503.smt2
Execution time of boolector: 0.0007 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #0
; Range assertion #1: v1_uint64_0_1 = 1073741823@64
; Range condition: v1_uint64_0_1 = 1073741823
; Output file: /tmp/outputqfbv_93c903.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (not (= v1_uint64_0_1 #x000000003FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_7470ef.smt2
Execution time of boolector: 0.0008 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #0
; Range assertion #3: v1_uint64_0_1 = 1073741823@64
; Range condition: v1_uint64_0_1 = 1073741823
; Output file: /tmp/outputqfbv_919502.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert (not (= v1_uint64_0_1 #x000000003FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_5dd81e.smt2
Execution time of boolector: 0.0007 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #0
; Range assertion #4: v3_sint32_3_1 <=s 1073741823@32
; Range condition: v3_sint32_3_1 <=s 1073741823
; Output file: /tmp/outputqfbv_f8d2d9.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert (not (bvsle v3_sint32_3_1 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_4cb718.smt2
Execution time of boolector: 0.0008 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #0
; Range assertion #5: 0@32 <=s v3_sint32_3_1
; Range condition: 0 <=s v3_sint32_3_1
; Output file: /tmp/outputqfbv_58d38c.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert (not (bvsle #x00000000 v3_sint32_3_1)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_545f8c.smt2
Execution time of boolector: 0.0008 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #0
; Range assertion #6: v3_sint32_2_1 <=s 1073741823@32
; Range condition: v3_sint32_2_1 <=s 1073741823
; Output file: /tmp/outputqfbv_e1a5e6.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert (not (bvsle v3_sint32_2_1 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_420537.smt2
Execution time of boolector: 0.0007 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #0
; Range assertion #7: 0@32 <=s v3_sint32_2_1
; Range condition: 0 <=s v3_sint32_2_1
; Output file: /tmp/outputqfbv_6f365b.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert (not (bvsle #x00000000 v3_sint32_2_1)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_fe98dd.smt2
Execution time of boolector: 0.0007 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #0
; Range assertion #8: v3_sint32_1_1 <=s 1073741823@32
; Range condition: v3_sint32_1_1 <=s 1073741823
; Output file: /tmp/outputqfbv_91f150.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert (not (bvsle v3_sint32_1_1 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_32f5d9.smt2
Execution time of boolector: 0.0007 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #0
; Range assertion #9: 0@32 <=s v3_sint32_1_1
; Range condition: 0 <=s v3_sint32_1_1
; Output file: /tmp/outputqfbv_e2f4d4.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert (not (bvsle #x00000000 v3_sint32_1_1)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_e38c4f.smt2
Execution time of boolector: 0.0006 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #0
; Range assertion #10: v3_sint32_0_1 <=s 1073741823@32
; Range condition: v3_sint32_0_1 <=s 1073741823
; Output file: /tmp/outputqfbv_8ba8d8.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert (not (bvsle v3_sint32_0_1 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_fa52a1.smt2
Execution time of boolector: 0.0006 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #0
; Range assertion #11: 0@32 <=s v3_sint32_0_1
; Range condition: 0 <=s v3_sint32_0_1
; Output file: /tmp/outputqfbv_a4cbda.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert (not (bvsle #x00000000 v3_sint32_0_1)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_8201af.smt2
Execution time of boolector: 0.0007 seconds
OUTPUT FROM boolector:
unsat

=== Cut #2 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #2
; Range assertion #12: or [and [smod (sub (uext x8_2 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_4 = x7_3, mul x8_4 2@64 = x8_2, x3_3 = add 2@64 1@64], and [smod (sub (uext x8_2 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, 1@64 <s 0@64, x7_4 = x7_3, mul x8_4 2@64 = add x8_2 x7_3, x3_3 = add 2@64 1@64], and [smod (sub (uext x8_2 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, 1@64 >=s 0@64, x7_4 = x8_2, mul x8_4 2@64 = sub x8_2 x7_3, x3_3 = sub 2@64 1@64]]
; Range condition: ((x8_2@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_4 = x7_3 /\ x8_4 * 2 = x8_2 /\ x3_3 = 2 + 1 \/ ((x8_2@e1) - (1@e1)) smod (2@e1) = 0 /\ 1 <s 0 /\ x7_4 = x7_3 /\ x8_4 * 2 = x8_2 + x7_3 /\ x3_3 = 2 + 1 \/ ((x8_2@e1) - (1@e1)) smod (2@e1) = 0 /\ 1 >=s 0 /\ x7_4 = x8_2 /\ x8_4 * 2 = x8_2 - x7_3 /\ x3_3 = 2 - 1
; Output file: /tmp/outputqfbv_6a548e.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_1 () (_ BitVec 1))
(declare-fun x8_lo_2 () (_ BitVec 2))
(declare-fun x8_lo_1 () (_ BitVec 1))
(declare-fun x8_4 () (_ BitVec 64))
(declare-fun x8_3 () (_ BitVec 64))
(declare-fun x8_2 () (_ BitVec 64))
(declare-fun x7_4 () (_ BitVec 64))
(declare-fun x7_3 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_1 () (_ BitVec 64))
(declare-fun x3_3 () (_ BitVec 64))
(declare-fun x3_2 () (_ BitVec 64))
(declare-fun x10_neg_1 () (_ BitVec 64))
(declare-fun x10_2 () (_ BitVec 64))
(declare-fun x10_1 () (_ BitVec 64))
(declare-fun ne_2 () (_ BitVec 1))
(declare-fun ne_1 () (_ BitVec 1))
(declare-fun ge_3 () (_ BitVec 1))
(declare-fun ge_2 () (_ BitVec 1))
(declare-fun ge_1 () (_ BitVec 1))
(declare-fun g_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun dc_48 () (_ BitVec 64))
(declare-fun dc_47 () (_ BitVec 1))
(declare-fun dc_46 () (_ BitVec 62))
(declare-fun dc_45 () (_ BitVec 1))
(declare-fun dc_44 () (_ BitVec 1))
(declare-fun dc_43 () (_ BitVec 1))
(declare-fun dc_42 () (_ BitVec 63))
(declare-fun dc_41 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (= x7_3 (bvadd (bvadd f_0_low60_0_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_2 (bvadd (bvadd g_0_low60_0_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_0_1)) (bvsle f_0_low60_0_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_0_1)) (bvsle g_0_low60_0_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_3) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #x0000000000000001 #x0000000000000001)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_41 ((_ extract 63 1) x8_2)) (= x8_lo_1 ((_ extract 0 0) x8_2))))
(assert (= ne_1 (bvand x8_lo_1 #b1)))
(assert (= x10_1 (ite (= ne_1 #b1) x7_3 #x0000000000000000)))
(assert (and (= ge_1 ((_ extract 63 63) #x0000000000000001)) (= dc_42 ((_ extract 62 0) #x0000000000000001))))
(assert (= ge_2 (bvnot ge_1)))
(assert (= ge_3 (ite (= ne_1 #b1) ge_2 #b0)))
(assert (and (= dc_43 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_2 (ite (= ge_3 #b1) x3_neg_1 #x0000000000000001)))
(assert (and (= dc_44 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_2 (ite (= ge_3 #b1) x10_neg_1 x10_1)))
(assert (= x7_4 (ite (= ge_3 #b1) x8_2 x7_3)))
(assert (and (= dc_45 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2)))) (= x8_3 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2))))))
(assert (= x3_3 (bvadd x3_2 #x0000000000000002)))
(assert (and (= dc_46 ((_ extract 63 2) x8_3)) (= x8_lo_2 ((_ extract 1 0) x8_3))))
(assert (and (= x8_target_1 ((_ extract 1 1) x8_lo_2)) (= dc_47 ((_ extract 0 0) x8_lo_2))))
(assert (= ne_2 (bvand x8_target_1 #b1)))
(assert (and (= x8_4 ((_ sign_extend 1) ((_ extract 63 1) x8_3))) (= dc_48 ((_ zero_extend 63) ((_ extract 0 0) x8_3)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_2) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_4 x7_3)) (= (bvmul x8_4 #x0000000000000002) x8_2)) (= x3_3 (bvadd #x0000000000000002 #x0000000000000001))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_2) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt #x0000000000000001 #x0000000000000000)) (= x7_4 x7_3)) (= (bvmul x8_4 #x0000000000000002) (bvadd x8_2 x7_3))) (= x3_3 (bvadd #x0000000000000002 #x0000000000000001)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_2) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge #x0000000000000001 #x0000000000000000)) (= x7_4 x8_2)) (= (bvmul x8_4 #x0000000000000002) (bvsub x8_2 x7_3))) (= x3_3 (bvsub #x0000000000000002 #x0000000000000001))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_378176.smt2
Execution time of boolector: 0.0089 seconds
OUTPUT FROM boolector:
unsat

=== Cut #2 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #2
; Range assertion #13: or [and [smod (sub (uext x8_4 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_5 = x7_4, mul x8_6 2@64 = x8_4, x3_5 = add 2@64 x3_3], and [smod (sub (uext x8_4 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_3 <s 0@64, x7_5 = x7_4, mul x8_6 2@64 = add x8_4 x7_4, x3_5 = add 2@64 x3_3], and [smod (sub (uext x8_4 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_3 >=s 0@64, x7_5 = x8_4, mul x8_6 2@64 = sub x8_4 x7_4, x3_5 = sub 2@64 x3_3]]
; Range condition: ((x8_4@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_5 = x7_4 /\ x8_6 * 2 = x8_4 /\ x3_5 = 2 + x3_3 \/ ((x8_4@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_3 <s 0 /\ x7_5 = x7_4 /\ x8_6 * 2 = x8_4 + x7_4 /\ x3_5 = 2 + x3_3 \/ ((x8_4@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_3 >=s 0 /\ x7_5 = x8_4 /\ x8_6 * 2 = x8_4 - x7_4 /\ x3_5 = 2 - x3_3
; Output file: /tmp/outputqfbv_0b4219.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_2 () (_ BitVec 1))
(declare-fun x8_target_1 () (_ BitVec 1))
(declare-fun x8_lo_3 () (_ BitVec 2))
(declare-fun x8_lo_2 () (_ BitVec 2))
(declare-fun x8_lo_1 () (_ BitVec 1))
(declare-fun x8_6 () (_ BitVec 64))
(declare-fun x8_5 () (_ BitVec 64))
(declare-fun x8_4 () (_ BitVec 64))
(declare-fun x8_3 () (_ BitVec 64))
(declare-fun x8_2 () (_ BitVec 64))
(declare-fun x7_5 () (_ BitVec 64))
(declare-fun x7_4 () (_ BitVec 64))
(declare-fun x7_3 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_2 () (_ BitVec 64))
(declare-fun x3_neg_1 () (_ BitVec 64))
(declare-fun x3_5 () (_ BitVec 64))
(declare-fun x3_4 () (_ BitVec 64))
(declare-fun x3_3 () (_ BitVec 64))
(declare-fun x3_2 () (_ BitVec 64))
(declare-fun x10_neg_2 () (_ BitVec 64))
(declare-fun x10_neg_1 () (_ BitVec 64))
(declare-fun x10_4 () (_ BitVec 64))
(declare-fun x10_3 () (_ BitVec 64))
(declare-fun x10_2 () (_ BitVec 64))
(declare-fun x10_1 () (_ BitVec 64))
(declare-fun ne_3 () (_ BitVec 1))
(declare-fun ne_2 () (_ BitVec 1))
(declare-fun ne_1 () (_ BitVec 1))
(declare-fun ge_6 () (_ BitVec 1))
(declare-fun ge_5 () (_ BitVec 1))
(declare-fun ge_4 () (_ BitVec 1))
(declare-fun ge_3 () (_ BitVec 1))
(declare-fun ge_2 () (_ BitVec 1))
(declare-fun ge_1 () (_ BitVec 1))
(declare-fun g_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun dc_55 () (_ BitVec 64))
(declare-fun dc_54 () (_ BitVec 1))
(declare-fun dc_53 () (_ BitVec 62))
(declare-fun dc_52 () (_ BitVec 1))
(declare-fun dc_51 () (_ BitVec 1))
(declare-fun dc_50 () (_ BitVec 1))
(declare-fun dc_49 () (_ BitVec 63))
(declare-fun dc_48 () (_ BitVec 64))
(declare-fun dc_47 () (_ BitVec 1))
(declare-fun dc_46 () (_ BitVec 62))
(declare-fun dc_45 () (_ BitVec 1))
(declare-fun dc_44 () (_ BitVec 1))
(declare-fun dc_43 () (_ BitVec 1))
(declare-fun dc_42 () (_ BitVec 63))
(declare-fun dc_41 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (= x7_3 (bvadd (bvadd f_0_low60_0_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_2 (bvadd (bvadd g_0_low60_0_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_0_1)) (bvsle f_0_low60_0_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_0_1)) (bvsle g_0_low60_0_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_3) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #x0000000000000001 #x0000000000000001)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_41 ((_ extract 63 1) x8_2)) (= x8_lo_1 ((_ extract 0 0) x8_2))))
(assert (= ne_1 (bvand x8_lo_1 #b1)))
(assert (= x10_1 (ite (= ne_1 #b1) x7_3 #x0000000000000000)))
(assert (and (= ge_1 ((_ extract 63 63) #x0000000000000001)) (= dc_42 ((_ extract 62 0) #x0000000000000001))))
(assert (= ge_2 (bvnot ge_1)))
(assert (= ge_3 (ite (= ne_1 #b1) ge_2 #b0)))
(assert (and (= dc_43 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_2 (ite (= ge_3 #b1) x3_neg_1 #x0000000000000001)))
(assert (and (= dc_44 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_2 (ite (= ge_3 #b1) x10_neg_1 x10_1)))
(assert (= x7_4 (ite (= ge_3 #b1) x8_2 x7_3)))
(assert (and (= dc_45 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2)))) (= x8_3 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2))))))
(assert (= x3_3 (bvadd x3_2 #x0000000000000002)))
(assert (and (= dc_46 ((_ extract 63 2) x8_3)) (= x8_lo_2 ((_ extract 1 0) x8_3))))
(assert (and (= x8_target_1 ((_ extract 1 1) x8_lo_2)) (= dc_47 ((_ extract 0 0) x8_lo_2))))
(assert (= ne_2 (bvand x8_target_1 #b1)))
(assert (and (= x8_4 ((_ sign_extend 1) ((_ extract 63 1) x8_3))) (= dc_48 ((_ zero_extend 63) ((_ extract 0 0) x8_3)))))
(assert true)
(assert (= x10_3 (ite (= ne_2 #b1) x7_4 #x0000000000000000)))
(assert (and (= ge_4 ((_ extract 63 63) x3_3)) (= dc_49 ((_ extract 62 0) x3_3))))
(assert (= ge_5 (bvnot ge_4)))
(assert (= ge_6 (ite (= ne_2 #b1) ge_5 #b0)))
(assert (and (= dc_50 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_4 (ite (= ge_6 #b1) x3_neg_2 x3_3)))
(assert (and (= dc_51 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_4 (ite (= ge_6 #b1) x10_neg_2 x10_3)))
(assert (= x7_5 (ite (= ge_6 #b1) x8_4 x7_4)))
(assert (and (= dc_52 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4)))) (= x8_5 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4))))))
(assert (= x3_5 (bvadd x3_4 #x0000000000000002)))
(assert (and (= dc_53 ((_ extract 63 2) x8_5)) (= x8_lo_3 ((_ extract 1 0) x8_5))))
(assert (and (= x8_target_2 ((_ extract 1 1) x8_lo_3)) (= dc_54 ((_ extract 0 0) x8_lo_3))))
(assert (= ne_3 (bvand x8_target_2 #b1)))
(assert (and (= x8_6 ((_ sign_extend 1) ((_ extract 63 1) x8_5))) (= dc_55 ((_ zero_extend 63) ((_ extract 0 0) x8_5)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_4) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_5 x7_4)) (= (bvmul x8_6 #x0000000000000002) x8_4)) (= x3_5 (bvadd #x0000000000000002 x3_3))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_4) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_3 #x0000000000000000)) (= x7_5 x7_4)) (= (bvmul x8_6 #x0000000000000002) (bvadd x8_4 x7_4))) (= x3_5 (bvadd #x0000000000000002 x3_3)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_4) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_3 #x0000000000000000)) (= x7_5 x8_4)) (= (bvmul x8_6 #x0000000000000002) (bvsub x8_4 x7_4))) (= x3_5 (bvsub #x0000000000000002 x3_3))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_30b65b.smt2
Execution time of boolector: 0.0150 seconds
OUTPUT FROM boolector:
unsat

=== Cut #2 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #2
; Range assertion #14: or [and [smod (sub (uext x8_6 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_6 = x7_5, mul x8_8 2@64 = x8_6, x3_7 = add 2@64 x3_5], and [smod (sub (uext x8_6 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_5 <s 0@64, x7_6 = x7_5, mul x8_8 2@64 = add x8_6 x7_5, x3_7 = add 2@64 x3_5], and [smod (sub (uext x8_6 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_5 >=s 0@64, x7_6 = x8_6, mul x8_8 2@64 = sub x8_6 x7_5, x3_7 = sub 2@64 x3_5]]
; Range condition: ((x8_6@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_6 = x7_5 /\ x8_8 * 2 = x8_6 /\ x3_7 = 2 + x3_5 \/ ((x8_6@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_5 <s 0 /\ x7_6 = x7_5 /\ x8_8 * 2 = x8_6 + x7_5 /\ x3_7 = 2 + x3_5 \/ ((x8_6@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_5 >=s 0 /\ x7_6 = x8_6 /\ x8_8 * 2 = x8_6 - x7_5 /\ x3_7 = 2 - x3_5
; Output file: /tmp/outputqfbv_44e71b.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_3 () (_ BitVec 1))
(declare-fun x8_target_2 () (_ BitVec 1))
(declare-fun x8_target_1 () (_ BitVec 1))
(declare-fun x8_lo_4 () (_ BitVec 2))
(declare-fun x8_lo_3 () (_ BitVec 2))
(declare-fun x8_lo_2 () (_ BitVec 2))
(declare-fun x8_lo_1 () (_ BitVec 1))
(declare-fun x8_8 () (_ BitVec 64))
(declare-fun x8_7 () (_ BitVec 64))
(declare-fun x8_6 () (_ BitVec 64))
(declare-fun x8_5 () (_ BitVec 64))
(declare-fun x8_4 () (_ BitVec 64))
(declare-fun x8_3 () (_ BitVec 64))
(declare-fun x8_2 () (_ BitVec 64))
(declare-fun x7_6 () (_ BitVec 64))
(declare-fun x7_5 () (_ BitVec 64))
(declare-fun x7_4 () (_ BitVec 64))
(declare-fun x7_3 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_3 () (_ BitVec 64))
(declare-fun x3_neg_2 () (_ BitVec 64))
(declare-fun x3_neg_1 () (_ BitVec 64))
(declare-fun x3_7 () (_ BitVec 64))
(declare-fun x3_6 () (_ BitVec 64))
(declare-fun x3_5 () (_ BitVec 64))
(declare-fun x3_4 () (_ BitVec 64))
(declare-fun x3_3 () (_ BitVec 64))
(declare-fun x3_2 () (_ BitVec 64))
(declare-fun x10_neg_3 () (_ BitVec 64))
(declare-fun x10_neg_2 () (_ BitVec 64))
(declare-fun x10_neg_1 () (_ BitVec 64))
(declare-fun x10_6 () (_ BitVec 64))
(declare-fun x10_5 () (_ BitVec 64))
(declare-fun x10_4 () (_ BitVec 64))
(declare-fun x10_3 () (_ BitVec 64))
(declare-fun x10_2 () (_ BitVec 64))
(declare-fun x10_1 () (_ BitVec 64))
(declare-fun ne_4 () (_ BitVec 1))
(declare-fun ne_3 () (_ BitVec 1))
(declare-fun ne_2 () (_ BitVec 1))
(declare-fun ne_1 () (_ BitVec 1))
(declare-fun ge_9 () (_ BitVec 1))
(declare-fun ge_8 () (_ BitVec 1))
(declare-fun ge_7 () (_ BitVec 1))
(declare-fun ge_6 () (_ BitVec 1))
(declare-fun ge_5 () (_ BitVec 1))
(declare-fun ge_4 () (_ BitVec 1))
(declare-fun ge_3 () (_ BitVec 1))
(declare-fun ge_2 () (_ BitVec 1))
(declare-fun ge_1 () (_ BitVec 1))
(declare-fun g_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun dc_62 () (_ BitVec 64))
(declare-fun dc_61 () (_ BitVec 1))
(declare-fun dc_60 () (_ BitVec 62))
(declare-fun dc_59 () (_ BitVec 1))
(declare-fun dc_58 () (_ BitVec 1))
(declare-fun dc_57 () (_ BitVec 1))
(declare-fun dc_56 () (_ BitVec 63))
(declare-fun dc_55 () (_ BitVec 64))
(declare-fun dc_54 () (_ BitVec 1))
(declare-fun dc_53 () (_ BitVec 62))
(declare-fun dc_52 () (_ BitVec 1))
(declare-fun dc_51 () (_ BitVec 1))
(declare-fun dc_50 () (_ BitVec 1))
(declare-fun dc_49 () (_ BitVec 63))
(declare-fun dc_48 () (_ BitVec 64))
(declare-fun dc_47 () (_ BitVec 1))
(declare-fun dc_46 () (_ BitVec 62))
(declare-fun dc_45 () (_ BitVec 1))
(declare-fun dc_44 () (_ BitVec 1))
(declare-fun dc_43 () (_ BitVec 1))
(declare-fun dc_42 () (_ BitVec 63))
(declare-fun dc_41 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (= x7_3 (bvadd (bvadd f_0_low60_0_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_2 (bvadd (bvadd g_0_low60_0_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_0_1)) (bvsle f_0_low60_0_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_0_1)) (bvsle g_0_low60_0_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_3) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #x0000000000000001 #x0000000000000001)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_41 ((_ extract 63 1) x8_2)) (= x8_lo_1 ((_ extract 0 0) x8_2))))
(assert (= ne_1 (bvand x8_lo_1 #b1)))
(assert (= x10_1 (ite (= ne_1 #b1) x7_3 #x0000000000000000)))
(assert (and (= ge_1 ((_ extract 63 63) #x0000000000000001)) (= dc_42 ((_ extract 62 0) #x0000000000000001))))
(assert (= ge_2 (bvnot ge_1)))
(assert (= ge_3 (ite (= ne_1 #b1) ge_2 #b0)))
(assert (and (= dc_43 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_2 (ite (= ge_3 #b1) x3_neg_1 #x0000000000000001)))
(assert (and (= dc_44 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_2 (ite (= ge_3 #b1) x10_neg_1 x10_1)))
(assert (= x7_4 (ite (= ge_3 #b1) x8_2 x7_3)))
(assert (and (= dc_45 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2)))) (= x8_3 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2))))))
(assert (= x3_3 (bvadd x3_2 #x0000000000000002)))
(assert (and (= dc_46 ((_ extract 63 2) x8_3)) (= x8_lo_2 ((_ extract 1 0) x8_3))))
(assert (and (= x8_target_1 ((_ extract 1 1) x8_lo_2)) (= dc_47 ((_ extract 0 0) x8_lo_2))))
(assert (= ne_2 (bvand x8_target_1 #b1)))
(assert (and (= x8_4 ((_ sign_extend 1) ((_ extract 63 1) x8_3))) (= dc_48 ((_ zero_extend 63) ((_ extract 0 0) x8_3)))))
(assert true)
(assert (= x10_3 (ite (= ne_2 #b1) x7_4 #x0000000000000000)))
(assert (and (= ge_4 ((_ extract 63 63) x3_3)) (= dc_49 ((_ extract 62 0) x3_3))))
(assert (= ge_5 (bvnot ge_4)))
(assert (= ge_6 (ite (= ne_2 #b1) ge_5 #b0)))
(assert (and (= dc_50 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_4 (ite (= ge_6 #b1) x3_neg_2 x3_3)))
(assert (and (= dc_51 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_4 (ite (= ge_6 #b1) x10_neg_2 x10_3)))
(assert (= x7_5 (ite (= ge_6 #b1) x8_4 x7_4)))
(assert (and (= dc_52 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4)))) (= x8_5 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4))))))
(assert (= x3_5 (bvadd x3_4 #x0000000000000002)))
(assert (and (= dc_53 ((_ extract 63 2) x8_5)) (= x8_lo_3 ((_ extract 1 0) x8_5))))
(assert (and (= x8_target_2 ((_ extract 1 1) x8_lo_3)) (= dc_54 ((_ extract 0 0) x8_lo_3))))
(assert (= ne_3 (bvand x8_target_2 #b1)))
(assert (and (= x8_6 ((_ sign_extend 1) ((_ extract 63 1) x8_5))) (= dc_55 ((_ zero_extend 63) ((_ extract 0 0) x8_5)))))
(assert true)
(assert (= x10_5 (ite (= ne_3 #b1) x7_5 #x0000000000000000)))
(assert (and (= ge_7 ((_ extract 63 63) x3_5)) (= dc_56 ((_ extract 62 0) x3_5))))
(assert (= ge_8 (bvnot ge_7)))
(assert (= ge_9 (ite (= ne_3 #b1) ge_8 #b0)))
(assert (and (= dc_57 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_6 (ite (= ge_9 #b1) x3_neg_3 x3_5)))
(assert (and (= dc_58 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_6 (ite (= ge_9 #b1) x10_neg_3 x10_5)))
(assert (= x7_6 (ite (= ge_9 #b1) x8_6 x7_5)))
(assert (and (= dc_59 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6)))) (= x8_7 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6))))))
(assert (= x3_7 (bvadd x3_6 #x0000000000000002)))
(assert (and (= dc_60 ((_ extract 63 2) x8_7)) (= x8_lo_4 ((_ extract 1 0) x8_7))))
(assert (and (= x8_target_3 ((_ extract 1 1) x8_lo_4)) (= dc_61 ((_ extract 0 0) x8_lo_4))))
(assert (= ne_4 (bvand x8_target_3 #b1)))
(assert (and (= x8_8 ((_ sign_extend 1) ((_ extract 63 1) x8_7))) (= dc_62 ((_ zero_extend 63) ((_ extract 0 0) x8_7)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_6) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_6 x7_5)) (= (bvmul x8_8 #x0000000000000002) x8_6)) (= x3_7 (bvadd #x0000000000000002 x3_5))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_6) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_5 #x0000000000000000)) (= x7_6 x7_5)) (= (bvmul x8_8 #x0000000000000002) (bvadd x8_6 x7_5))) (= x3_7 (bvadd #x0000000000000002 x3_5)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_6) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_5 #x0000000000000000)) (= x7_6 x8_6)) (= (bvmul x8_8 #x0000000000000002) (bvsub x8_6 x7_5))) (= x3_7 (bvsub #x0000000000000002 x3_5))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_e1b784.smt2
Execution time of boolector: 0.0746 seconds
OUTPUT FROM boolector:
unsat

=== Cut #2 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #2
; Range assertion #15: or [and [smod (sub (uext x8_8 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_7 = x7_6, mul x8_10 2@64 = x8_8, x3_9 = add 2@64 x3_7], and [smod (sub (uext x8_8 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_7 <s 0@64, x7_7 = x7_6, mul x8_10 2@64 = add x8_8 x7_6, x3_9 = add 2@64 x3_7], and [smod (sub (uext x8_8 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_7 >=s 0@64, x7_7 = x8_8, mul x8_10 2@64 = sub x8_8 x7_6, x3_9 = sub 2@64 x3_7]]
; Range condition: ((x8_8@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_7 = x7_6 /\ x8_10 * 2 = x8_8 /\ x3_9 = 2 + x3_7 \/ ((x8_8@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_7 <s 0 /\ x7_7 = x7_6 /\ x8_10 * 2 = x8_8 + x7_6 /\ x3_9 = 2 + x3_7 \/ ((x8_8@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_7 >=s 0 /\ x7_7 = x8_8 /\ x8_10 * 2 = x8_8 - x7_6 /\ x3_9 = 2 - x3_7
; Output file: /tmp/outputqfbv_6abb36.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_4 () (_ BitVec 1))
(declare-fun x8_target_3 () (_ BitVec 1))
(declare-fun x8_target_2 () (_ BitVec 1))
(declare-fun x8_target_1 () (_ BitVec 1))
(declare-fun x8_lo_5 () (_ BitVec 2))
(declare-fun x8_lo_4 () (_ BitVec 2))
(declare-fun x8_lo_3 () (_ BitVec 2))
(declare-fun x8_lo_2 () (_ BitVec 2))
(declare-fun x8_lo_1 () (_ BitVec 1))
(declare-fun x8_10 () (_ BitVec 64))
(declare-fun x8_9 () (_ BitVec 64))
(declare-fun x8_8 () (_ BitVec 64))
(declare-fun x8_7 () (_ BitVec 64))
(declare-fun x8_6 () (_ BitVec 64))
(declare-fun x8_5 () (_ BitVec 64))
(declare-fun x8_4 () (_ BitVec 64))
(declare-fun x8_3 () (_ BitVec 64))
(declare-fun x8_2 () (_ BitVec 64))
(declare-fun x7_7 () (_ BitVec 64))
(declare-fun x7_6 () (_ BitVec 64))
(declare-fun x7_5 () (_ BitVec 64))
(declare-fun x7_4 () (_ BitVec 64))
(declare-fun x7_3 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_4 () (_ BitVec 64))
(declare-fun x3_neg_3 () (_ BitVec 64))
(declare-fun x3_neg_2 () (_ BitVec 64))
(declare-fun x3_neg_1 () (_ BitVec 64))
(declare-fun x3_9 () (_ BitVec 64))
(declare-fun x3_8 () (_ BitVec 64))
(declare-fun x3_7 () (_ BitVec 64))
(declare-fun x3_6 () (_ BitVec 64))
(declare-fun x3_5 () (_ BitVec 64))
(declare-fun x3_4 () (_ BitVec 64))
(declare-fun x3_3 () (_ BitVec 64))
(declare-fun x3_2 () (_ BitVec 64))
(declare-fun x10_neg_4 () (_ BitVec 64))
(declare-fun x10_neg_3 () (_ BitVec 64))
(declare-fun x10_neg_2 () (_ BitVec 64))
(declare-fun x10_neg_1 () (_ BitVec 64))
(declare-fun x10_8 () (_ BitVec 64))
(declare-fun x10_7 () (_ BitVec 64))
(declare-fun x10_6 () (_ BitVec 64))
(declare-fun x10_5 () (_ BitVec 64))
(declare-fun x10_4 () (_ BitVec 64))
(declare-fun x10_3 () (_ BitVec 64))
(declare-fun x10_2 () (_ BitVec 64))
(declare-fun x10_1 () (_ BitVec 64))
(declare-fun ne_5 () (_ BitVec 1))
(declare-fun ne_4 () (_ BitVec 1))
(declare-fun ne_3 () (_ BitVec 1))
(declare-fun ne_2 () (_ BitVec 1))
(declare-fun ne_1 () (_ BitVec 1))
(declare-fun ge_12 () (_ BitVec 1))
(declare-fun ge_11 () (_ BitVec 1))
(declare-fun ge_10 () (_ BitVec 1))
(declare-fun ge_9 () (_ BitVec 1))
(declare-fun ge_8 () (_ BitVec 1))
(declare-fun ge_7 () (_ BitVec 1))
(declare-fun ge_6 () (_ BitVec 1))
(declare-fun ge_5 () (_ BitVec 1))
(declare-fun ge_4 () (_ BitVec 1))
(declare-fun ge_3 () (_ BitVec 1))
(declare-fun ge_2 () (_ BitVec 1))
(declare-fun ge_1 () (_ BitVec 1))
(declare-fun g_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun dc_69 () (_ BitVec 64))
(declare-fun dc_68 () (_ BitVec 1))
(declare-fun dc_67 () (_ BitVec 62))
(declare-fun dc_66 () (_ BitVec 1))
(declare-fun dc_65 () (_ BitVec 1))
(declare-fun dc_64 () (_ BitVec 1))
(declare-fun dc_63 () (_ BitVec 63))
(declare-fun dc_62 () (_ BitVec 64))
(declare-fun dc_61 () (_ BitVec 1))
(declare-fun dc_60 () (_ BitVec 62))
(declare-fun dc_59 () (_ BitVec 1))
(declare-fun dc_58 () (_ BitVec 1))
(declare-fun dc_57 () (_ BitVec 1))
(declare-fun dc_56 () (_ BitVec 63))
(declare-fun dc_55 () (_ BitVec 64))
(declare-fun dc_54 () (_ BitVec 1))
(declare-fun dc_53 () (_ BitVec 62))
(declare-fun dc_52 () (_ BitVec 1))
(declare-fun dc_51 () (_ BitVec 1))
(declare-fun dc_50 () (_ BitVec 1))
(declare-fun dc_49 () (_ BitVec 63))
(declare-fun dc_48 () (_ BitVec 64))
(declare-fun dc_47 () (_ BitVec 1))
(declare-fun dc_46 () (_ BitVec 62))
(declare-fun dc_45 () (_ BitVec 1))
(declare-fun dc_44 () (_ BitVec 1))
(declare-fun dc_43 () (_ BitVec 1))
(declare-fun dc_42 () (_ BitVec 63))
(declare-fun dc_41 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (= x7_3 (bvadd (bvadd f_0_low60_0_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_2 (bvadd (bvadd g_0_low60_0_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_0_1)) (bvsle f_0_low60_0_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_0_1)) (bvsle g_0_low60_0_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_3) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #x0000000000000001 #x0000000000000001)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_41 ((_ extract 63 1) x8_2)) (= x8_lo_1 ((_ extract 0 0) x8_2))))
(assert (= ne_1 (bvand x8_lo_1 #b1)))
(assert (= x10_1 (ite (= ne_1 #b1) x7_3 #x0000000000000000)))
(assert (and (= ge_1 ((_ extract 63 63) #x0000000000000001)) (= dc_42 ((_ extract 62 0) #x0000000000000001))))
(assert (= ge_2 (bvnot ge_1)))
(assert (= ge_3 (ite (= ne_1 #b1) ge_2 #b0)))
(assert (and (= dc_43 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_2 (ite (= ge_3 #b1) x3_neg_1 #x0000000000000001)))
(assert (and (= dc_44 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_2 (ite (= ge_3 #b1) x10_neg_1 x10_1)))
(assert (= x7_4 (ite (= ge_3 #b1) x8_2 x7_3)))
(assert (and (= dc_45 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2)))) (= x8_3 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2))))))
(assert (= x3_3 (bvadd x3_2 #x0000000000000002)))
(assert (and (= dc_46 ((_ extract 63 2) x8_3)) (= x8_lo_2 ((_ extract 1 0) x8_3))))
(assert (and (= x8_target_1 ((_ extract 1 1) x8_lo_2)) (= dc_47 ((_ extract 0 0) x8_lo_2))))
(assert (= ne_2 (bvand x8_target_1 #b1)))
(assert (and (= x8_4 ((_ sign_extend 1) ((_ extract 63 1) x8_3))) (= dc_48 ((_ zero_extend 63) ((_ extract 0 0) x8_3)))))
(assert true)
(assert (= x10_3 (ite (= ne_2 #b1) x7_4 #x0000000000000000)))
(assert (and (= ge_4 ((_ extract 63 63) x3_3)) (= dc_49 ((_ extract 62 0) x3_3))))
(assert (= ge_5 (bvnot ge_4)))
(assert (= ge_6 (ite (= ne_2 #b1) ge_5 #b0)))
(assert (and (= dc_50 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_4 (ite (= ge_6 #b1) x3_neg_2 x3_3)))
(assert (and (= dc_51 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_4 (ite (= ge_6 #b1) x10_neg_2 x10_3)))
(assert (= x7_5 (ite (= ge_6 #b1) x8_4 x7_4)))
(assert (and (= dc_52 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4)))) (= x8_5 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4))))))
(assert (= x3_5 (bvadd x3_4 #x0000000000000002)))
(assert (and (= dc_53 ((_ extract 63 2) x8_5)) (= x8_lo_3 ((_ extract 1 0) x8_5))))
(assert (and (= x8_target_2 ((_ extract 1 1) x8_lo_3)) (= dc_54 ((_ extract 0 0) x8_lo_3))))
(assert (= ne_3 (bvand x8_target_2 #b1)))
(assert (and (= x8_6 ((_ sign_extend 1) ((_ extract 63 1) x8_5))) (= dc_55 ((_ zero_extend 63) ((_ extract 0 0) x8_5)))))
(assert true)
(assert (= x10_5 (ite (= ne_3 #b1) x7_5 #x0000000000000000)))
(assert (and (= ge_7 ((_ extract 63 63) x3_5)) (= dc_56 ((_ extract 62 0) x3_5))))
(assert (= ge_8 (bvnot ge_7)))
(assert (= ge_9 (ite (= ne_3 #b1) ge_8 #b0)))
(assert (and (= dc_57 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_6 (ite (= ge_9 #b1) x3_neg_3 x3_5)))
(assert (and (= dc_58 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_6 (ite (= ge_9 #b1) x10_neg_3 x10_5)))
(assert (= x7_6 (ite (= ge_9 #b1) x8_6 x7_5)))
(assert (and (= dc_59 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6)))) (= x8_7 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6))))))
(assert (= x3_7 (bvadd x3_6 #x0000000000000002)))
(assert (and (= dc_60 ((_ extract 63 2) x8_7)) (= x8_lo_4 ((_ extract 1 0) x8_7))))
(assert (and (= x8_target_3 ((_ extract 1 1) x8_lo_4)) (= dc_61 ((_ extract 0 0) x8_lo_4))))
(assert (= ne_4 (bvand x8_target_3 #b1)))
(assert (and (= x8_8 ((_ sign_extend 1) ((_ extract 63 1) x8_7))) (= dc_62 ((_ zero_extend 63) ((_ extract 0 0) x8_7)))))
(assert true)
(assert (= x10_7 (ite (= ne_4 #b1) x7_6 #x0000000000000000)))
(assert (and (= ge_10 ((_ extract 63 63) x3_7)) (= dc_63 ((_ extract 62 0) x3_7))))
(assert (= ge_11 (bvnot ge_10)))
(assert (= ge_12 (ite (= ne_4 #b1) ge_11 #b0)))
(assert (and (= dc_64 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_7))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_4 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_7))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_8 (ite (= ge_12 #b1) x3_neg_4 x3_7)))
(assert (and (= dc_65 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_7))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_4 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_7))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_8 (ite (= ge_12 #b1) x10_neg_4 x10_7)))
(assert (= x7_7 (ite (= ge_12 #b1) x8_8 x7_6)))
(assert (and (= dc_66 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_8) ((_ zero_extend 1) x10_8)))) (= x8_9 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_8) ((_ zero_extend 1) x10_8))))))
(assert (= x3_9 (bvadd x3_8 #x0000000000000002)))
(assert (and (= dc_67 ((_ extract 63 2) x8_9)) (= x8_lo_5 ((_ extract 1 0) x8_9))))
(assert (and (= x8_target_4 ((_ extract 1 1) x8_lo_5)) (= dc_68 ((_ extract 0 0) x8_lo_5))))
(assert (= ne_5 (bvand x8_target_4 #b1)))
(assert (and (= x8_10 ((_ sign_extend 1) ((_ extract 63 1) x8_9))) (= dc_69 ((_ zero_extend 63) ((_ extract 0 0) x8_9)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_8) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_7 x7_6)) (= (bvmul x8_10 #x0000000000000002) x8_8)) (= x3_9 (bvadd #x0000000000000002 x3_7))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_8) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_7 #x0000000000000000)) (= x7_7 x7_6)) (= (bvmul x8_10 #x0000000000000002) (bvadd x8_8 x7_6))) (= x3_9 (bvadd #x0000000000000002 x3_7)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_8) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_7 #x0000000000000000)) (= x7_7 x8_8)) (= (bvmul x8_10 #x0000000000000002) (bvsub x8_8 x7_6))) (= x3_9 (bvsub #x0000000000000002 x3_7))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_ddf824.smt2
Execution time of boolector: 0.2152 seconds
OUTPUT FROM boolector:
unsat

=== Cut #2 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #2
; Range assertion #16: or [and [smod (sub (uext x8_10 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_8 = x7_7, mul x8_12 2@64 = x8_10, x3_11 = add 2@64 x3_9], and [smod (sub (uext x8_10 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_9 <s 0@64, x7_8 = x7_7, mul x8_12 2@64 = add x8_10 x7_7, x3_11 = add 2@64 x3_9], and [smod (sub (uext x8_10 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_9 >=s 0@64, x7_8 = x8_10, mul x8_12 2@64 = sub x8_10 x7_7, x3_11 = sub 2@64 x3_9]]
; Range condition: ((x8_10@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_8 = x7_7 /\ x8_12 * 2 = x8_10 /\ x3_11 = 2 + x3_9 \/ ((x8_10@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_9 <s 0 /\ x7_8 = x7_7 /\ x8_12 * 2 = x8_10 + x7_7 /\ x3_11 = 2 + x3_9 \/ ((x8_10@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_9 >=s 0 /\ x7_8 = x8_10 /\ x8_12 * 2 = x8_10 - x7_7 /\ x3_11 = 2 - x3_9
; Output file: /tmp/outputqfbv_3844ed.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_5 () (_ BitVec 1))
(declare-fun x8_target_4 () (_ BitVec 1))
(declare-fun x8_target_3 () (_ BitVec 1))
(declare-fun x8_target_2 () (_ BitVec 1))
(declare-fun x8_target_1 () (_ BitVec 1))
(declare-fun x8_lo_6 () (_ BitVec 2))
(declare-fun x8_lo_5 () (_ BitVec 2))
(declare-fun x8_lo_4 () (_ BitVec 2))
(declare-fun x8_lo_3 () (_ BitVec 2))
(declare-fun x8_lo_2 () (_ BitVec 2))
(declare-fun x8_lo_1 () (_ BitVec 1))
(declare-fun x8_12 () (_ BitVec 64))
(declare-fun x8_11 () (_ BitVec 64))
(declare-fun x8_10 () (_ BitVec 64))
(declare-fun x8_9 () (_ BitVec 64))
(declare-fun x8_8 () (_ BitVec 64))
(declare-fun x8_7 () (_ BitVec 64))
(declare-fun x8_6 () (_ BitVec 64))
(declare-fun x8_5 () (_ BitVec 64))
(declare-fun x8_4 () (_ BitVec 64))
(declare-fun x8_3 () (_ BitVec 64))
(declare-fun x8_2 () (_ BitVec 64))
(declare-fun x7_8 () (_ BitVec 64))
(declare-fun x7_7 () (_ BitVec 64))
(declare-fun x7_6 () (_ BitVec 64))
(declare-fun x7_5 () (_ BitVec 64))
(declare-fun x7_4 () (_ BitVec 64))
(declare-fun x7_3 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_5 () (_ BitVec 64))
(declare-fun x3_neg_4 () (_ BitVec 64))
(declare-fun x3_neg_3 () (_ BitVec 64))
(declare-fun x3_neg_2 () (_ BitVec 64))
(declare-fun x3_neg_1 () (_ BitVec 64))
(declare-fun x3_11 () (_ BitVec 64))
(declare-fun x3_10 () (_ BitVec 64))
(declare-fun x3_9 () (_ BitVec 64))
(declare-fun x3_8 () (_ BitVec 64))
(declare-fun x3_7 () (_ BitVec 64))
(declare-fun x3_6 () (_ BitVec 64))
(declare-fun x3_5 () (_ BitVec 64))
(declare-fun x3_4 () (_ BitVec 64))
(declare-fun x3_3 () (_ BitVec 64))
(declare-fun x3_2 () (_ BitVec 64))
(declare-fun x10_neg_5 () (_ BitVec 64))
(declare-fun x10_neg_4 () (_ BitVec 64))
(declare-fun x10_neg_3 () (_ BitVec 64))
(declare-fun x10_neg_2 () (_ BitVec 64))
(declare-fun x10_neg_1 () (_ BitVec 64))
(declare-fun x10_10 () (_ BitVec 64))
(declare-fun x10_9 () (_ BitVec 64))
(declare-fun x10_8 () (_ BitVec 64))
(declare-fun x10_7 () (_ BitVec 64))
(declare-fun x10_6 () (_ BitVec 64))
(declare-fun x10_5 () (_ BitVec 64))
(declare-fun x10_4 () (_ BitVec 64))
(declare-fun x10_3 () (_ BitVec 64))
(declare-fun x10_2 () (_ BitVec 64))
(declare-fun x10_1 () (_ BitVec 64))
(declare-fun ne_6 () (_ BitVec 1))
(declare-fun ne_5 () (_ BitVec 1))
(declare-fun ne_4 () (_ BitVec 1))
(declare-fun ne_3 () (_ BitVec 1))
(declare-fun ne_2 () (_ BitVec 1))
(declare-fun ne_1 () (_ BitVec 1))
(declare-fun ge_15 () (_ BitVec 1))
(declare-fun ge_14 () (_ BitVec 1))
(declare-fun ge_13 () (_ BitVec 1))
(declare-fun ge_12 () (_ BitVec 1))
(declare-fun ge_11 () (_ BitVec 1))
(declare-fun ge_10 () (_ BitVec 1))
(declare-fun ge_9 () (_ BitVec 1))
(declare-fun ge_8 () (_ BitVec 1))
(declare-fun ge_7 () (_ BitVec 1))
(declare-fun ge_6 () (_ BitVec 1))
(declare-fun ge_5 () (_ BitVec 1))
(declare-fun ge_4 () (_ BitVec 1))
(declare-fun ge_3 () (_ BitVec 1))
(declare-fun ge_2 () (_ BitVec 1))
(declare-fun ge_1 () (_ BitVec 1))
(declare-fun g_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun dc_76 () (_ BitVec 64))
(declare-fun dc_75 () (_ BitVec 1))
(declare-fun dc_74 () (_ BitVec 62))
(declare-fun dc_73 () (_ BitVec 1))
(declare-fun dc_72 () (_ BitVec 1))
(declare-fun dc_71 () (_ BitVec 1))
(declare-fun dc_70 () (_ BitVec 63))
(declare-fun dc_69 () (_ BitVec 64))
(declare-fun dc_68 () (_ BitVec 1))
(declare-fun dc_67 () (_ BitVec 62))
(declare-fun dc_66 () (_ BitVec 1))
(declare-fun dc_65 () (_ BitVec 1))
(declare-fun dc_64 () (_ BitVec 1))
(declare-fun dc_63 () (_ BitVec 63))
(declare-fun dc_62 () (_ BitVec 64))
(declare-fun dc_61 () (_ BitVec 1))
(declare-fun dc_60 () (_ BitVec 62))
(declare-fun dc_59 () (_ BitVec 1))
(declare-fun dc_58 () (_ BitVec 1))
(declare-fun dc_57 () (_ BitVec 1))
(declare-fun dc_56 () (_ BitVec 63))
(declare-fun dc_55 () (_ BitVec 64))
(declare-fun dc_54 () (_ BitVec 1))
(declare-fun dc_53 () (_ BitVec 62))
(declare-fun dc_52 () (_ BitVec 1))
(declare-fun dc_51 () (_ BitVec 1))
(declare-fun dc_50 () (_ BitVec 1))
(declare-fun dc_49 () (_ BitVec 63))
(declare-fun dc_48 () (_ BitVec 64))
(declare-fun dc_47 () (_ BitVec 1))
(declare-fun dc_46 () (_ BitVec 62))
(declare-fun dc_45 () (_ BitVec 1))
(declare-fun dc_44 () (_ BitVec 1))
(declare-fun dc_43 () (_ BitVec 1))
(declare-fun dc_42 () (_ BitVec 63))
(declare-fun dc_41 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (= x7_3 (bvadd (bvadd f_0_low60_0_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_2 (bvadd (bvadd g_0_low60_0_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_0_1)) (bvsle f_0_low60_0_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_0_1)) (bvsle g_0_low60_0_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_3) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #x0000000000000001 #x0000000000000001)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_41 ((_ extract 63 1) x8_2)) (= x8_lo_1 ((_ extract 0 0) x8_2))))
(assert (= ne_1 (bvand x8_lo_1 #b1)))
(assert (= x10_1 (ite (= ne_1 #b1) x7_3 #x0000000000000000)))
(assert (and (= ge_1 ((_ extract 63 63) #x0000000000000001)) (= dc_42 ((_ extract 62 0) #x0000000000000001))))
(assert (= ge_2 (bvnot ge_1)))
(assert (= ge_3 (ite (= ne_1 #b1) ge_2 #b0)))
(assert (and (= dc_43 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_2 (ite (= ge_3 #b1) x3_neg_1 #x0000000000000001)))
(assert (and (= dc_44 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_2 (ite (= ge_3 #b1) x10_neg_1 x10_1)))
(assert (= x7_4 (ite (= ge_3 #b1) x8_2 x7_3)))
(assert (and (= dc_45 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2)))) (= x8_3 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2))))))
(assert (= x3_3 (bvadd x3_2 #x0000000000000002)))
(assert (and (= dc_46 ((_ extract 63 2) x8_3)) (= x8_lo_2 ((_ extract 1 0) x8_3))))
(assert (and (= x8_target_1 ((_ extract 1 1) x8_lo_2)) (= dc_47 ((_ extract 0 0) x8_lo_2))))
(assert (= ne_2 (bvand x8_target_1 #b1)))
(assert (and (= x8_4 ((_ sign_extend 1) ((_ extract 63 1) x8_3))) (= dc_48 ((_ zero_extend 63) ((_ extract 0 0) x8_3)))))
(assert true)
(assert (= x10_3 (ite (= ne_2 #b1) x7_4 #x0000000000000000)))
(assert (and (= ge_4 ((_ extract 63 63) x3_3)) (= dc_49 ((_ extract 62 0) x3_3))))
(assert (= ge_5 (bvnot ge_4)))
(assert (= ge_6 (ite (= ne_2 #b1) ge_5 #b0)))
(assert (and (= dc_50 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_4 (ite (= ge_6 #b1) x3_neg_2 x3_3)))
(assert (and (= dc_51 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_4 (ite (= ge_6 #b1) x10_neg_2 x10_3)))
(assert (= x7_5 (ite (= ge_6 #b1) x8_4 x7_4)))
(assert (and (= dc_52 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4)))) (= x8_5 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4))))))
(assert (= x3_5 (bvadd x3_4 #x0000000000000002)))
(assert (and (= dc_53 ((_ extract 63 2) x8_5)) (= x8_lo_3 ((_ extract 1 0) x8_5))))
(assert (and (= x8_target_2 ((_ extract 1 1) x8_lo_3)) (= dc_54 ((_ extract 0 0) x8_lo_3))))
(assert (= ne_3 (bvand x8_target_2 #b1)))
(assert (and (= x8_6 ((_ sign_extend 1) ((_ extract 63 1) x8_5))) (= dc_55 ((_ zero_extend 63) ((_ extract 0 0) x8_5)))))
(assert true)
(assert (= x10_5 (ite (= ne_3 #b1) x7_5 #x0000000000000000)))
(assert (and (= ge_7 ((_ extract 63 63) x3_5)) (= dc_56 ((_ extract 62 0) x3_5))))
(assert (= ge_8 (bvnot ge_7)))
(assert (= ge_9 (ite (= ne_3 #b1) ge_8 #b0)))
(assert (and (= dc_57 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_6 (ite (= ge_9 #b1) x3_neg_3 x3_5)))
(assert (and (= dc_58 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_6 (ite (= ge_9 #b1) x10_neg_3 x10_5)))
(assert (= x7_6 (ite (= ge_9 #b1) x8_6 x7_5)))
(assert (and (= dc_59 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6)))) (= x8_7 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6))))))
(assert (= x3_7 (bvadd x3_6 #x0000000000000002)))
(assert (and (= dc_60 ((_ extract 63 2) x8_7)) (= x8_lo_4 ((_ extract 1 0) x8_7))))
(assert (and (= x8_target_3 ((_ extract 1 1) x8_lo_4)) (= dc_61 ((_ extract 0 0) x8_lo_4))))
(assert (= ne_4 (bvand x8_target_3 #b1)))
(assert (and (= x8_8 ((_ sign_extend 1) ((_ extract 63 1) x8_7))) (= dc_62 ((_ zero_extend 63) ((_ extract 0 0) x8_7)))))
(assert true)
(assert (= x10_7 (ite (= ne_4 #b1) x7_6 #x0000000000000000)))
(assert (and (= ge_10 ((_ extract 63 63) x3_7)) (= dc_63 ((_ extract 62 0) x3_7))))
(assert (= ge_11 (bvnot ge_10)))
(assert (= ge_12 (ite (= ne_4 #b1) ge_11 #b0)))
(assert (and (= dc_64 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_7))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_4 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_7))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_8 (ite (= ge_12 #b1) x3_neg_4 x3_7)))
(assert (and (= dc_65 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_7))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_4 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_7))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_8 (ite (= ge_12 #b1) x10_neg_4 x10_7)))
(assert (= x7_7 (ite (= ge_12 #b1) x8_8 x7_6)))
(assert (and (= dc_66 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_8) ((_ zero_extend 1) x10_8)))) (= x8_9 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_8) ((_ zero_extend 1) x10_8))))))
(assert (= x3_9 (bvadd x3_8 #x0000000000000002)))
(assert (and (= dc_67 ((_ extract 63 2) x8_9)) (= x8_lo_5 ((_ extract 1 0) x8_9))))
(assert (and (= x8_target_4 ((_ extract 1 1) x8_lo_5)) (= dc_68 ((_ extract 0 0) x8_lo_5))))
(assert (= ne_5 (bvand x8_target_4 #b1)))
(assert (and (= x8_10 ((_ sign_extend 1) ((_ extract 63 1) x8_9))) (= dc_69 ((_ zero_extend 63) ((_ extract 0 0) x8_9)))))
(assert true)
(assert (= x10_9 (ite (= ne_5 #b1) x7_7 #x0000000000000000)))
(assert (and (= ge_13 ((_ extract 63 63) x3_9)) (= dc_70 ((_ extract 62 0) x3_9))))
(assert (= ge_14 (bvnot ge_13)))
(assert (= ge_15 (ite (= ne_5 #b1) ge_14 #b0)))
(assert (and (= dc_71 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_9))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_5 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_9))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_10 (ite (= ge_15 #b1) x3_neg_5 x3_9)))
(assert (and (= dc_72 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_9))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_5 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_9))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_10 (ite (= ge_15 #b1) x10_neg_5 x10_9)))
(assert (= x7_8 (ite (= ge_15 #b1) x8_10 x7_7)))
(assert (and (= dc_73 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_10) ((_ zero_extend 1) x10_10)))) (= x8_11 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_10) ((_ zero_extend 1) x10_10))))))
(assert (= x3_11 (bvadd x3_10 #x0000000000000002)))
(assert (and (= dc_74 ((_ extract 63 2) x8_11)) (= x8_lo_6 ((_ extract 1 0) x8_11))))
(assert (and (= x8_target_5 ((_ extract 1 1) x8_lo_6)) (= dc_75 ((_ extract 0 0) x8_lo_6))))
(assert (= ne_6 (bvand x8_target_5 #b1)))
(assert (and (= x8_12 ((_ sign_extend 1) ((_ extract 63 1) x8_11))) (= dc_76 ((_ zero_extend 63) ((_ extract 0 0) x8_11)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_10) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_8 x7_7)) (= (bvmul x8_12 #x0000000000000002) x8_10)) (= x3_11 (bvadd #x0000000000000002 x3_9))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_10) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_9 #x0000000000000000)) (= x7_8 x7_7)) (= (bvmul x8_12 #x0000000000000002) (bvadd x8_10 x7_7))) (= x3_11 (bvadd #x0000000000000002 x3_9)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_10) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_9 #x0000000000000000)) (= x7_8 x8_10)) (= (bvmul x8_12 #x0000000000000002) (bvsub x8_10 x7_7))) (= x3_11 (bvsub #x0000000000000002 x3_9))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_9c2698.smt2
Execution time of boolector: 0.2621 seconds
OUTPUT FROM boolector:
unsat

=== Cut #2 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #2
; Range assertion #17: or [and [smod (sub (uext x8_12 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_9 = x7_8, mul x8_14 2@64 = x8_12, x3_13 = add 2@64 x3_11], and [smod (sub (uext x8_12 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_11 <s 0@64, x7_9 = x7_8, mul x8_14 2@64 = add x8_12 x7_8, x3_13 = add 2@64 x3_11], and [smod (sub (uext x8_12 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_11 >=s 0@64, x7_9 = x8_12, mul x8_14 2@64 = sub x8_12 x7_8, x3_13 = sub 2@64 x3_11]]
; Range condition: ((x8_12@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_9 = x7_8 /\ x8_14 * 2 = x8_12 /\ x3_13 = 2 + x3_11 \/ ((x8_12@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_11 <s 0 /\ x7_9 = x7_8 /\ x8_14 * 2 = x8_12 + x7_8 /\ x3_13 = 2 + x3_11 \/ ((x8_12@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_11 >=s 0 /\ x7_9 = x8_12 /\ x8_14 * 2 = x8_12 - x7_8 /\ x3_13 = 2 - x3_11
; Output file: /tmp/outputqfbv_5a20ca.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_6 () (_ BitVec 1))
(declare-fun x8_target_5 () (_ BitVec 1))
(declare-fun x8_target_4 () (_ BitVec 1))
(declare-fun x8_target_3 () (_ BitVec 1))
(declare-fun x8_target_2 () (_ BitVec 1))
(declare-fun x8_target_1 () (_ BitVec 1))
(declare-fun x8_lo_7 () (_ BitVec 2))
(declare-fun x8_lo_6 () (_ BitVec 2))
(declare-fun x8_lo_5 () (_ BitVec 2))
(declare-fun x8_lo_4 () (_ BitVec 2))
(declare-fun x8_lo_3 () (_ BitVec 2))
(declare-fun x8_lo_2 () (_ BitVec 2))
(declare-fun x8_lo_1 () (_ BitVec 1))
(declare-fun x8_14 () (_ BitVec 64))
(declare-fun x8_13 () (_ BitVec 64))
(declare-fun x8_12 () (_ BitVec 64))
(declare-fun x8_11 () (_ BitVec 64))
(declare-fun x8_10 () (_ BitVec 64))
(declare-fun x8_9 () (_ BitVec 64))
(declare-fun x8_8 () (_ BitVec 64))
(declare-fun x8_7 () (_ BitVec 64))
(declare-fun x8_6 () (_ BitVec 64))
(declare-fun x8_5 () (_ BitVec 64))
(declare-fun x8_4 () (_ BitVec 64))
(declare-fun x8_3 () (_ BitVec 64))
(declare-fun x8_2 () (_ BitVec 64))
(declare-fun x7_9 () (_ BitVec 64))
(declare-fun x7_8 () (_ BitVec 64))
(declare-fun x7_7 () (_ BitVec 64))
(declare-fun x7_6 () (_ BitVec 64))
(declare-fun x7_5 () (_ BitVec 64))
(declare-fun x7_4 () (_ BitVec 64))
(declare-fun x7_3 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_6 () (_ BitVec 64))
(declare-fun x3_neg_5 () (_ BitVec 64))
(declare-fun x3_neg_4 () (_ BitVec 64))
(declare-fun x3_neg_3 () (_ BitVec 64))
(declare-fun x3_neg_2 () (_ BitVec 64))
(declare-fun x3_neg_1 () (_ BitVec 64))
(declare-fun x3_13 () (_ BitVec 64))
(declare-fun x3_12 () (_ BitVec 64))
(declare-fun x3_11 () (_ BitVec 64))
(declare-fun x3_10 () (_ BitVec 64))
(declare-fun x3_9 () (_ BitVec 64))
(declare-fun x3_8 () (_ BitVec 64))
(declare-fun x3_7 () (_ BitVec 64))
(declare-fun x3_6 () (_ BitVec 64))
(declare-fun x3_5 () (_ BitVec 64))
(declare-fun x3_4 () (_ BitVec 64))
(declare-fun x3_3 () (_ BitVec 64))
(declare-fun x3_2 () (_ BitVec 64))
(declare-fun x10_neg_6 () (_ BitVec 64))
(declare-fun x10_neg_5 () (_ BitVec 64))
(declare-fun x10_neg_4 () (_ BitVec 64))
(declare-fun x10_neg_3 () (_ BitVec 64))
(declare-fun x10_neg_2 () (_ BitVec 64))
(declare-fun x10_neg_1 () (_ BitVec 64))
(declare-fun x10_12 () (_ BitVec 64))
(declare-fun x10_11 () (_ BitVec 64))
(declare-fun x10_10 () (_ BitVec 64))
(declare-fun x10_9 () (_ BitVec 64))
(declare-fun x10_8 () (_ BitVec 64))
(declare-fun x10_7 () (_ BitVec 64))
(declare-fun x10_6 () (_ BitVec 64))
(declare-fun x10_5 () (_ BitVec 64))
(declare-fun x10_4 () (_ BitVec 64))
(declare-fun x10_3 () (_ BitVec 64))
(declare-fun x10_2 () (_ BitVec 64))
(declare-fun x10_1 () (_ BitVec 64))
(declare-fun ne_7 () (_ BitVec 1))
(declare-fun ne_6 () (_ BitVec 1))
(declare-fun ne_5 () (_ BitVec 1))
(declare-fun ne_4 () (_ BitVec 1))
(declare-fun ne_3 () (_ BitVec 1))
(declare-fun ne_2 () (_ BitVec 1))
(declare-fun ne_1 () (_ BitVec 1))
(declare-fun ge_18 () (_ BitVec 1))
(declare-fun ge_17 () (_ BitVec 1))
(declare-fun ge_16 () (_ BitVec 1))
(declare-fun ge_15 () (_ BitVec 1))
(declare-fun ge_14 () (_ BitVec 1))
(declare-fun ge_13 () (_ BitVec 1))
(declare-fun ge_12 () (_ BitVec 1))
(declare-fun ge_11 () (_ BitVec 1))
(declare-fun ge_10 () (_ BitVec 1))
(declare-fun ge_9 () (_ BitVec 1))
(declare-fun ge_8 () (_ BitVec 1))
(declare-fun ge_7 () (_ BitVec 1))
(declare-fun ge_6 () (_ BitVec 1))
(declare-fun ge_5 () (_ BitVec 1))
(declare-fun ge_4 () (_ BitVec 1))
(declare-fun ge_3 () (_ BitVec 1))
(declare-fun ge_2 () (_ BitVec 1))
(declare-fun ge_1 () (_ BitVec 1))
(declare-fun g_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun dc_83 () (_ BitVec 64))
(declare-fun dc_82 () (_ BitVec 1))
(declare-fun dc_81 () (_ BitVec 62))
(declare-fun dc_80 () (_ BitVec 1))
(declare-fun dc_79 () (_ BitVec 1))
(declare-fun dc_78 () (_ BitVec 1))
(declare-fun dc_77 () (_ BitVec 63))
(declare-fun dc_76 () (_ BitVec 64))
(declare-fun dc_75 () (_ BitVec 1))
(declare-fun dc_74 () (_ BitVec 62))
(declare-fun dc_73 () (_ BitVec 1))
(declare-fun dc_72 () (_ BitVec 1))
(declare-fun dc_71 () (_ BitVec 1))
(declare-fun dc_70 () (_ BitVec 63))
(declare-fun dc_69 () (_ BitVec 64))
(declare-fun dc_68 () (_ BitVec 1))
(declare-fun dc_67 () (_ BitVec 62))
(declare-fun dc_66 () (_ BitVec 1))
(declare-fun dc_65 () (_ BitVec 1))
(declare-fun dc_64 () (_ BitVec 1))
(declare-fun dc_63 () (_ BitVec 63))
(declare-fun dc_62 () (_ BitVec 64))
(declare-fun dc_61 () (_ BitVec 1))
(declare-fun dc_60 () (_ BitVec 62))
(declare-fun dc_59 () (_ BitVec 1))
(declare-fun dc_58 () (_ BitVec 1))
(declare-fun dc_57 () (_ BitVec 1))
(declare-fun dc_56 () (_ BitVec 63))
(declare-fun dc_55 () (_ BitVec 64))
(declare-fun dc_54 () (_ BitVec 1))
(declare-fun dc_53 () (_ BitVec 62))
(declare-fun dc_52 () (_ BitVec 1))
(declare-fun dc_51 () (_ BitVec 1))
(declare-fun dc_50 () (_ BitVec 1))
(declare-fun dc_49 () (_ BitVec 63))
(declare-fun dc_48 () (_ BitVec 64))
(declare-fun dc_47 () (_ BitVec 1))
(declare-fun dc_46 () (_ BitVec 62))
(declare-fun dc_45 () (_ BitVec 1))
(declare-fun dc_44 () (_ BitVec 1))
(declare-fun dc_43 () (_ BitVec 1))
(declare-fun dc_42 () (_ BitVec 63))
(declare-fun dc_41 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (= x7_3 (bvadd (bvadd f_0_low60_0_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_2 (bvadd (bvadd g_0_low60_0_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_0_1)) (bvsle f_0_low60_0_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_0_1)) (bvsle g_0_low60_0_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_3) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #x0000000000000001 #x0000000000000001)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_41 ((_ extract 63 1) x8_2)) (= x8_lo_1 ((_ extract 0 0) x8_2))))
(assert (= ne_1 (bvand x8_lo_1 #b1)))
(assert (= x10_1 (ite (= ne_1 #b1) x7_3 #x0000000000000000)))
(assert (and (= ge_1 ((_ extract 63 63) #x0000000000000001)) (= dc_42 ((_ extract 62 0) #x0000000000000001))))
(assert (= ge_2 (bvnot ge_1)))
(assert (= ge_3 (ite (= ne_1 #b1) ge_2 #b0)))
(assert (and (= dc_43 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_2 (ite (= ge_3 #b1) x3_neg_1 #x0000000000000001)))
(assert (and (= dc_44 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_2 (ite (= ge_3 #b1) x10_neg_1 x10_1)))
(assert (= x7_4 (ite (= ge_3 #b1) x8_2 x7_3)))
(assert (and (= dc_45 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2)))) (= x8_3 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2))))))
(assert (= x3_3 (bvadd x3_2 #x0000000000000002)))
(assert (and (= dc_46 ((_ extract 63 2) x8_3)) (= x8_lo_2 ((_ extract 1 0) x8_3))))
(assert (and (= x8_target_1 ((_ extract 1 1) x8_lo_2)) (= dc_47 ((_ extract 0 0) x8_lo_2))))
(assert (= ne_2 (bvand x8_target_1 #b1)))
(assert (and (= x8_4 ((_ sign_extend 1) ((_ extract 63 1) x8_3))) (= dc_48 ((_ zero_extend 63) ((_ extract 0 0) x8_3)))))
(assert true)
(assert (= x10_3 (ite (= ne_2 #b1) x7_4 #x0000000000000000)))
(assert (and (= ge_4 ((_ extract 63 63) x3_3)) (= dc_49 ((_ extract 62 0) x3_3))))
(assert (= ge_5 (bvnot ge_4)))
(assert (= ge_6 (ite (= ne_2 #b1) ge_5 #b0)))
(assert (and (= dc_50 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_4 (ite (= ge_6 #b1) x3_neg_2 x3_3)))
(assert (and (= dc_51 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_4 (ite (= ge_6 #b1) x10_neg_2 x10_3)))
(assert (= x7_5 (ite (= ge_6 #b1) x8_4 x7_4)))
(assert (and (= dc_52 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4)))) (= x8_5 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4))))))
(assert (= x3_5 (bvadd x3_4 #x0000000000000002)))
(assert (and (= dc_53 ((_ extract 63 2) x8_5)) (= x8_lo_3 ((_ extract 1 0) x8_5))))
(assert (and (= x8_target_2 ((_ extract 1 1) x8_lo_3)) (= dc_54 ((_ extract 0 0) x8_lo_3))))
(assert (= ne_3 (bvand x8_target_2 #b1)))
(assert (and (= x8_6 ((_ sign_extend 1) ((_ extract 63 1) x8_5))) (= dc_55 ((_ zero_extend 63) ((_ extract 0 0) x8_5)))))
(assert true)
(assert (= x10_5 (ite (= ne_3 #b1) x7_5 #x0000000000000000)))
(assert (and (= ge_7 ((_ extract 63 63) x3_5)) (= dc_56 ((_ extract 62 0) x3_5))))
(assert (= ge_8 (bvnot ge_7)))
(assert (= ge_9 (ite (= ne_3 #b1) ge_8 #b0)))
(assert (and (= dc_57 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_6 (ite (= ge_9 #b1) x3_neg_3 x3_5)))
(assert (and (= dc_58 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_6 (ite (= ge_9 #b1) x10_neg_3 x10_5)))
(assert (= x7_6 (ite (= ge_9 #b1) x8_6 x7_5)))
(assert (and (= dc_59 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6)))) (= x8_7 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6))))))
(assert (= x3_7 (bvadd x3_6 #x0000000000000002)))
(assert (and (= dc_60 ((_ extract 63 2) x8_7)) (= x8_lo_4 ((_ extract 1 0) x8_7))))
(assert (and (= x8_target_3 ((_ extract 1 1) x8_lo_4)) (= dc_61 ((_ extract 0 0) x8_lo_4))))
(assert (= ne_4 (bvand x8_target_3 #b1)))
(assert (and (= x8_8 ((_ sign_extend 1) ((_ extract 63 1) x8_7))) (= dc_62 ((_ zero_extend 63) ((_ extract 0 0) x8_7)))))
(assert true)
(assert (= x10_7 (ite (= ne_4 #b1) x7_6 #x0000000000000000)))
(assert (and (= ge_10 ((_ extract 63 63) x3_7)) (= dc_63 ((_ extract 62 0) x3_7))))
(assert (= ge_11 (bvnot ge_10)))
(assert (= ge_12 (ite (= ne_4 #b1) ge_11 #b0)))
(assert (and (= dc_64 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_7))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_4 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_7))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_8 (ite (= ge_12 #b1) x3_neg_4 x3_7)))
(assert (and (= dc_65 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_7))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_4 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_7))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_8 (ite (= ge_12 #b1) x10_neg_4 x10_7)))
(assert (= x7_7 (ite (= ge_12 #b1) x8_8 x7_6)))
(assert (and (= dc_66 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_8) ((_ zero_extend 1) x10_8)))) (= x8_9 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_8) ((_ zero_extend 1) x10_8))))))
(assert (= x3_9 (bvadd x3_8 #x0000000000000002)))
(assert (and (= dc_67 ((_ extract 63 2) x8_9)) (= x8_lo_5 ((_ extract 1 0) x8_9))))
(assert (and (= x8_target_4 ((_ extract 1 1) x8_lo_5)) (= dc_68 ((_ extract 0 0) x8_lo_5))))
(assert (= ne_5 (bvand x8_target_4 #b1)))
(assert (and (= x8_10 ((_ sign_extend 1) ((_ extract 63 1) x8_9))) (= dc_69 ((_ zero_extend 63) ((_ extract 0 0) x8_9)))))
(assert true)
(assert (= x10_9 (ite (= ne_5 #b1) x7_7 #x0000000000000000)))
(assert (and (= ge_13 ((_ extract 63 63) x3_9)) (= dc_70 ((_ extract 62 0) x3_9))))
(assert (= ge_14 (bvnot ge_13)))
(assert (= ge_15 (ite (= ne_5 #b1) ge_14 #b0)))
(assert (and (= dc_71 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_9))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_5 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_9))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_10 (ite (= ge_15 #b1) x3_neg_5 x3_9)))
(assert (and (= dc_72 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_9))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_5 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_9))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_10 (ite (= ge_15 #b1) x10_neg_5 x10_9)))
(assert (= x7_8 (ite (= ge_15 #b1) x8_10 x7_7)))
(assert (and (= dc_73 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_10) ((_ zero_extend 1) x10_10)))) (= x8_11 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_10) ((_ zero_extend 1) x10_10))))))
(assert (= x3_11 (bvadd x3_10 #x0000000000000002)))
(assert (and (= dc_74 ((_ extract 63 2) x8_11)) (= x8_lo_6 ((_ extract 1 0) x8_11))))
(assert (and (= x8_target_5 ((_ extract 1 1) x8_lo_6)) (= dc_75 ((_ extract 0 0) x8_lo_6))))
(assert (= ne_6 (bvand x8_target_5 #b1)))
(assert (and (= x8_12 ((_ sign_extend 1) ((_ extract 63 1) x8_11))) (= dc_76 ((_ zero_extend 63) ((_ extract 0 0) x8_11)))))
(assert true)
(assert (= x10_11 (ite (= ne_6 #b1) x7_8 #x0000000000000000)))
(assert (and (= ge_16 ((_ extract 63 63) x3_11)) (= dc_77 ((_ extract 62 0) x3_11))))
(assert (= ge_17 (bvnot ge_16)))
(assert (= ge_18 (ite (= ne_6 #b1) ge_17 #b0)))
(assert (and (= dc_78 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_11))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_6 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_11))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_12 (ite (= ge_18 #b1) x3_neg_6 x3_11)))
(assert (and (= dc_79 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_11))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_6 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_11))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_12 (ite (= ge_18 #b1) x10_neg_6 x10_11)))
(assert (= x7_9 (ite (= ge_18 #b1) x8_12 x7_8)))
(assert (and (= dc_80 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_12) ((_ zero_extend 1) x10_12)))) (= x8_13 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_12) ((_ zero_extend 1) x10_12))))))
(assert (= x3_13 (bvadd x3_12 #x0000000000000002)))
(assert (and (= dc_81 ((_ extract 63 2) x8_13)) (= x8_lo_7 ((_ extract 1 0) x8_13))))
(assert (and (= x8_target_6 ((_ extract 1 1) x8_lo_7)) (= dc_82 ((_ extract 0 0) x8_lo_7))))
(assert (= ne_7 (bvand x8_target_6 #b1)))
(assert (and (= x8_14 ((_ sign_extend 1) ((_ extract 63 1) x8_13))) (= dc_83 ((_ zero_extend 63) ((_ extract 0 0) x8_13)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_12) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_9 x7_8)) (= (bvmul x8_14 #x0000000000000002) x8_12)) (= x3_13 (bvadd #x0000000000000002 x3_11))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_12) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_11 #x0000000000000000)) (= x7_9 x7_8)) (= (bvmul x8_14 #x0000000000000002) (bvadd x8_12 x7_8))) (= x3_13 (bvadd #x0000000000000002 x3_11)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_12) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_11 #x0000000000000000)) (= x7_9 x8_12)) (= (bvmul x8_14 #x0000000000000002) (bvsub x8_12 x7_8))) (= x3_13 (bvsub #x0000000000000002 x3_11))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_410130.smt2
Execution time of boolector: 0.3090 seconds
OUTPUT FROM boolector:
unsat

=== Cut #2 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #2
; Range assertion #18: or [and [smod (sub (uext x8_14 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_10 = x7_9, mul x8_16 2@64 = x8_14, x3_15 = add 2@64 x3_13], and [smod (sub (uext x8_14 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_13 <s 0@64, x7_10 = x7_9, mul x8_16 2@64 = add x8_14 x7_9, x3_15 = add 2@64 x3_13], and [smod (sub (uext x8_14 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_13 >=s 0@64, x7_10 = x8_14, mul x8_16 2@64 = sub x8_14 x7_9, x3_15 = sub 2@64 x3_13]]
; Range condition: ((x8_14@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_10 = x7_9 /\ x8_16 * 2 = x8_14 /\ x3_15 = 2 + x3_13 \/ ((x8_14@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_13 <s 0 /\ x7_10 = x7_9 /\ x8_16 * 2 = x8_14 + x7_9 /\ x3_15 = 2 + x3_13 \/ ((x8_14@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_13 >=s 0 /\ x7_10 = x8_14 /\ x8_16 * 2 = x8_14 - x7_9 /\ x3_15 = 2 - x3_13
; Output file: /tmp/outputqfbv_a33a3e.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_7 () (_ BitVec 1))
(declare-fun x8_target_6 () (_ BitVec 1))
(declare-fun x8_target_5 () (_ BitVec 1))
(declare-fun x8_target_4 () (_ BitVec 1))
(declare-fun x8_target_3 () (_ BitVec 1))
(declare-fun x8_target_2 () (_ BitVec 1))
(declare-fun x8_target_1 () (_ BitVec 1))
(declare-fun x8_lo_8 () (_ BitVec 2))
(declare-fun x8_lo_7 () (_ BitVec 2))
(declare-fun x8_lo_6 () (_ BitVec 2))
(declare-fun x8_lo_5 () (_ BitVec 2))
(declare-fun x8_lo_4 () (_ BitVec 2))
(declare-fun x8_lo_3 () (_ BitVec 2))
(declare-fun x8_lo_2 () (_ BitVec 2))
(declare-fun x8_lo_1 () (_ BitVec 1))
(declare-fun x8_16 () (_ BitVec 64))
(declare-fun x8_15 () (_ BitVec 64))
(declare-fun x8_14 () (_ BitVec 64))
(declare-fun x8_13 () (_ BitVec 64))
(declare-fun x8_12 () (_ BitVec 64))
(declare-fun x8_11 () (_ BitVec 64))
(declare-fun x8_10 () (_ BitVec 64))
(declare-fun x8_9 () (_ BitVec 64))
(declare-fun x8_8 () (_ BitVec 64))
(declare-fun x8_7 () (_ BitVec 64))
(declare-fun x8_6 () (_ BitVec 64))
(declare-fun x8_5 () (_ BitVec 64))
(declare-fun x8_4 () (_ BitVec 64))
(declare-fun x8_3 () (_ BitVec 64))
(declare-fun x8_2 () (_ BitVec 64))
(declare-fun x7_10 () (_ BitVec 64))
(declare-fun x7_9 () (_ BitVec 64))
(declare-fun x7_8 () (_ BitVec 64))
(declare-fun x7_7 () (_ BitVec 64))
(declare-fun x7_6 () (_ BitVec 64))
(declare-fun x7_5 () (_ BitVec 64))
(declare-fun x7_4 () (_ BitVec 64))
(declare-fun x7_3 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_7 () (_ BitVec 64))
(declare-fun x3_neg_6 () (_ BitVec 64))
(declare-fun x3_neg_5 () (_ BitVec 64))
(declare-fun x3_neg_4 () (_ BitVec 64))
(declare-fun x3_neg_3 () (_ BitVec 64))
(declare-fun x3_neg_2 () (_ BitVec 64))
(declare-fun x3_neg_1 () (_ BitVec 64))
(declare-fun x3_15 () (_ BitVec 64))
(declare-fun x3_14 () (_ BitVec 64))
(declare-fun x3_13 () (_ BitVec 64))
(declare-fun x3_12 () (_ BitVec 64))
(declare-fun x3_11 () (_ BitVec 64))
(declare-fun x3_10 () (_ BitVec 64))
(declare-fun x3_9 () (_ BitVec 64))
(declare-fun x3_8 () (_ BitVec 64))
(declare-fun x3_7 () (_ BitVec 64))
(declare-fun x3_6 () (_ BitVec 64))
(declare-fun x3_5 () (_ BitVec 64))
(declare-fun x3_4 () (_ BitVec 64))
(declare-fun x3_3 () (_ BitVec 64))
(declare-fun x3_2 () (_ BitVec 64))
(declare-fun x10_neg_7 () (_ BitVec 64))
(declare-fun x10_neg_6 () (_ BitVec 64))
(declare-fun x10_neg_5 () (_ BitVec 64))
(declare-fun x10_neg_4 () (_ BitVec 64))
(declare-fun x10_neg_3 () (_ BitVec 64))
(declare-fun x10_neg_2 () (_ BitVec 64))
(declare-fun x10_neg_1 () (_ BitVec 64))
(declare-fun x10_14 () (_ BitVec 64))
(declare-fun x10_13 () (_ BitVec 64))
(declare-fun x10_12 () (_ BitVec 64))
(declare-fun x10_11 () (_ BitVec 64))
(declare-fun x10_10 () (_ BitVec 64))
(declare-fun x10_9 () (_ BitVec 64))
(declare-fun x10_8 () (_ BitVec 64))
(declare-fun x10_7 () (_ BitVec 64))
(declare-fun x10_6 () (_ BitVec 64))
(declare-fun x10_5 () (_ BitVec 64))
(declare-fun x10_4 () (_ BitVec 64))
(declare-fun x10_3 () (_ BitVec 64))
(declare-fun x10_2 () (_ BitVec 64))
(declare-fun x10_1 () (_ BitVec 64))
(declare-fun ne_8 () (_ BitVec 1))
(declare-fun ne_7 () (_ BitVec 1))
(declare-fun ne_6 () (_ BitVec 1))
(declare-fun ne_5 () (_ BitVec 1))
(declare-fun ne_4 () (_ BitVec 1))
(declare-fun ne_3 () (_ BitVec 1))
(declare-fun ne_2 () (_ BitVec 1))
(declare-fun ne_1 () (_ BitVec 1))
(declare-fun ge_21 () (_ BitVec 1))
(declare-fun ge_20 () (_ BitVec 1))
(declare-fun ge_19 () (_ BitVec 1))
(declare-fun ge_18 () (_ BitVec 1))
(declare-fun ge_17 () (_ BitVec 1))
(declare-fun ge_16 () (_ BitVec 1))
(declare-fun ge_15 () (_ BitVec 1))
(declare-fun ge_14 () (_ BitVec 1))
(declare-fun ge_13 () (_ BitVec 1))
(declare-fun ge_12 () (_ BitVec 1))
(declare-fun ge_11 () (_ BitVec 1))
(declare-fun ge_10 () (_ BitVec 1))
(declare-fun ge_9 () (_ BitVec 1))
(declare-fun ge_8 () (_ BitVec 1))
(declare-fun ge_7 () (_ BitVec 1))
(declare-fun ge_6 () (_ BitVec 1))
(declare-fun ge_5 () (_ BitVec 1))
(declare-fun ge_4 () (_ BitVec 1))
(declare-fun ge_3 () (_ BitVec 1))
(declare-fun ge_2 () (_ BitVec 1))
(declare-fun ge_1 () (_ BitVec 1))
(declare-fun g_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun dc_90 () (_ BitVec 64))
(declare-fun dc_89 () (_ BitVec 1))
(declare-fun dc_88 () (_ BitVec 62))
(declare-fun dc_87 () (_ BitVec 1))
(declare-fun dc_86 () (_ BitVec 1))
(declare-fun dc_85 () (_ BitVec 1))
(declare-fun dc_84 () (_ BitVec 63))
(declare-fun dc_83 () (_ BitVec 64))
(declare-fun dc_82 () (_ BitVec 1))
(declare-fun dc_81 () (_ BitVec 62))
(declare-fun dc_80 () (_ BitVec 1))
(declare-fun dc_79 () (_ BitVec 1))
(declare-fun dc_78 () (_ BitVec 1))
(declare-fun dc_77 () (_ BitVec 63))
(declare-fun dc_76 () (_ BitVec 64))
(declare-fun dc_75 () (_ BitVec 1))
(declare-fun dc_74 () (_ BitVec 62))
(declare-fun dc_73 () (_ BitVec 1))
(declare-fun dc_72 () (_ BitVec 1))
(declare-fun dc_71 () (_ BitVec 1))
(declare-fun dc_70 () (_ BitVec 63))
(declare-fun dc_69 () (_ BitVec 64))
(declare-fun dc_68 () (_ BitVec 1))
(declare-fun dc_67 () (_ BitVec 62))
(declare-fun dc_66 () (_ BitVec 1))
(declare-fun dc_65 () (_ BitVec 1))
(declare-fun dc_64 () (_ BitVec 1))
(declare-fun dc_63 () (_ BitVec 63))
(declare-fun dc_62 () (_ BitVec 64))
(declare-fun dc_61 () (_ BitVec 1))
(declare-fun dc_60 () (_ BitVec 62))
(declare-fun dc_59 () (_ BitVec 1))
(declare-fun dc_58 () (_ BitVec 1))
(declare-fun dc_57 () (_ BitVec 1))
(declare-fun dc_56 () (_ BitVec 63))
(declare-fun dc_55 () (_ BitVec 64))
(declare-fun dc_54 () (_ BitVec 1))
(declare-fun dc_53 () (_ BitVec 62))
(declare-fun dc_52 () (_ BitVec 1))
(declare-fun dc_51 () (_ BitVec 1))
(declare-fun dc_50 () (_ BitVec 1))
(declare-fun dc_49 () (_ BitVec 63))
(declare-fun dc_48 () (_ BitVec 64))
(declare-fun dc_47 () (_ BitVec 1))
(declare-fun dc_46 () (_ BitVec 62))
(declare-fun dc_45 () (_ BitVec 1))
(declare-fun dc_44 () (_ BitVec 1))
(declare-fun dc_43 () (_ BitVec 1))
(declare-fun dc_42 () (_ BitVec 63))
(declare-fun dc_41 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (= x7_3 (bvadd (bvadd f_0_low60_0_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_2 (bvadd (bvadd g_0_low60_0_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_0_1)) (bvsle f_0_low60_0_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_0_1)) (bvsle g_0_low60_0_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_3) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #x0000000000000001 #x0000000000000001)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_41 ((_ extract 63 1) x8_2)) (= x8_lo_1 ((_ extract 0 0) x8_2))))
(assert (= ne_1 (bvand x8_lo_1 #b1)))
(assert (= x10_1 (ite (= ne_1 #b1) x7_3 #x0000000000000000)))
(assert (and (= ge_1 ((_ extract 63 63) #x0000000000000001)) (= dc_42 ((_ extract 62 0) #x0000000000000001))))
(assert (= ge_2 (bvnot ge_1)))
(assert (= ge_3 (ite (= ne_1 #b1) ge_2 #b0)))
(assert (and (= dc_43 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_2 (ite (= ge_3 #b1) x3_neg_1 #x0000000000000001)))
(assert (and (= dc_44 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_2 (ite (= ge_3 #b1) x10_neg_1 x10_1)))
(assert (= x7_4 (ite (= ge_3 #b1) x8_2 x7_3)))
(assert (and (= dc_45 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2)))) (= x8_3 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2))))))
(assert (= x3_3 (bvadd x3_2 #x0000000000000002)))
(assert (and (= dc_46 ((_ extract 63 2) x8_3)) (= x8_lo_2 ((_ extract 1 0) x8_3))))
(assert (and (= x8_target_1 ((_ extract 1 1) x8_lo_2)) (= dc_47 ((_ extract 0 0) x8_lo_2))))
(assert (= ne_2 (bvand x8_target_1 #b1)))
(assert (and (= x8_4 ((_ sign_extend 1) ((_ extract 63 1) x8_3))) (= dc_48 ((_ zero_extend 63) ((_ extract 0 0) x8_3)))))
(assert true)
(assert (= x10_3 (ite (= ne_2 #b1) x7_4 #x0000000000000000)))
(assert (and (= ge_4 ((_ extract 63 63) x3_3)) (= dc_49 ((_ extract 62 0) x3_3))))
(assert (= ge_5 (bvnot ge_4)))
(assert (= ge_6 (ite (= ne_2 #b1) ge_5 #b0)))
(assert (and (= dc_50 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_4 (ite (= ge_6 #b1) x3_neg_2 x3_3)))
(assert (and (= dc_51 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_4 (ite (= ge_6 #b1) x10_neg_2 x10_3)))
(assert (= x7_5 (ite (= ge_6 #b1) x8_4 x7_4)))
(assert (and (= dc_52 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4)))) (= x8_5 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4))))))
(assert (= x3_5 (bvadd x3_4 #x0000000000000002)))
(assert (and (= dc_53 ((_ extract 63 2) x8_5)) (= x8_lo_3 ((_ extract 1 0) x8_5))))
(assert (and (= x8_target_2 ((_ extract 1 1) x8_lo_3)) (= dc_54 ((_ extract 0 0) x8_lo_3))))
(assert (= ne_3 (bvand x8_target_2 #b1)))
(assert (and (= x8_6 ((_ sign_extend 1) ((_ extract 63 1) x8_5))) (= dc_55 ((_ zero_extend 63) ((_ extract 0 0) x8_5)))))
(assert true)
(assert (= x10_5 (ite (= ne_3 #b1) x7_5 #x0000000000000000)))
(assert (and (= ge_7 ((_ extract 63 63) x3_5)) (= dc_56 ((_ extract 62 0) x3_5))))
(assert (= ge_8 (bvnot ge_7)))
(assert (= ge_9 (ite (= ne_3 #b1) ge_8 #b0)))
(assert (and (= dc_57 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_6 (ite (= ge_9 #b1) x3_neg_3 x3_5)))
(assert (and (= dc_58 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_6 (ite (= ge_9 #b1) x10_neg_3 x10_5)))
(assert (= x7_6 (ite (= ge_9 #b1) x8_6 x7_5)))
(assert (and (= dc_59 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6)))) (= x8_7 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6))))))
(assert (= x3_7 (bvadd x3_6 #x0000000000000002)))
(assert (and (= dc_60 ((_ extract 63 2) x8_7)) (= x8_lo_4 ((_ extract 1 0) x8_7))))
(assert (and (= x8_target_3 ((_ extract 1 1) x8_lo_4)) (= dc_61 ((_ extract 0 0) x8_lo_4))))
(assert (= ne_4 (bvand x8_target_3 #b1)))
(assert (and (= x8_8 ((_ sign_extend 1) ((_ extract 63 1) x8_7))) (= dc_62 ((_ zero_extend 63) ((_ extract 0 0) x8_7)))))
(assert true)
(assert (= x10_7 (ite (= ne_4 #b1) x7_6 #x0000000000000000)))
(assert (and (= ge_10 ((_ extract 63 63) x3_7)) (= dc_63 ((_ extract 62 0) x3_7))))
(assert (= ge_11 (bvnot ge_10)))
(assert (= ge_12 (ite (= ne_4 #b1) ge_11 #b0)))
(assert (and (= dc_64 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_7))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_4 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_7))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_8 (ite (= ge_12 #b1) x3_neg_4 x3_7)))
(assert (and (= dc_65 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_7))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_4 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_7))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_8 (ite (= ge_12 #b1) x10_neg_4 x10_7)))
(assert (= x7_7 (ite (= ge_12 #b1) x8_8 x7_6)))
(assert (and (= dc_66 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_8) ((_ zero_extend 1) x10_8)))) (= x8_9 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_8) ((_ zero_extend 1) x10_8))))))
(assert (= x3_9 (bvadd x3_8 #x0000000000000002)))
(assert (and (= dc_67 ((_ extract 63 2) x8_9)) (= x8_lo_5 ((_ extract 1 0) x8_9))))
(assert (and (= x8_target_4 ((_ extract 1 1) x8_lo_5)) (= dc_68 ((_ extract 0 0) x8_lo_5))))
(assert (= ne_5 (bvand x8_target_4 #b1)))
(assert (and (= x8_10 ((_ sign_extend 1) ((_ extract 63 1) x8_9))) (= dc_69 ((_ zero_extend 63) ((_ extract 0 0) x8_9)))))
(assert true)
(assert (= x10_9 (ite (= ne_5 #b1) x7_7 #x0000000000000000)))
(assert (and (= ge_13 ((_ extract 63 63) x3_9)) (= dc_70 ((_ extract 62 0) x3_9))))
(assert (= ge_14 (bvnot ge_13)))
(assert (= ge_15 (ite (= ne_5 #b1) ge_14 #b0)))
(assert (and (= dc_71 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_9))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_5 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_9))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_10 (ite (= ge_15 #b1) x3_neg_5 x3_9)))
(assert (and (= dc_72 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_9))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_5 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_9))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_10 (ite (= ge_15 #b1) x10_neg_5 x10_9)))
(assert (= x7_8 (ite (= ge_15 #b1) x8_10 x7_7)))
(assert (and (= dc_73 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_10) ((_ zero_extend 1) x10_10)))) (= x8_11 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_10) ((_ zero_extend 1) x10_10))))))
(assert (= x3_11 (bvadd x3_10 #x0000000000000002)))
(assert (and (= dc_74 ((_ extract 63 2) x8_11)) (= x8_lo_6 ((_ extract 1 0) x8_11))))
(assert (and (= x8_target_5 ((_ extract 1 1) x8_lo_6)) (= dc_75 ((_ extract 0 0) x8_lo_6))))
(assert (= ne_6 (bvand x8_target_5 #b1)))
(assert (and (= x8_12 ((_ sign_extend 1) ((_ extract 63 1) x8_11))) (= dc_76 ((_ zero_extend 63) ((_ extract 0 0) x8_11)))))
(assert true)
(assert (= x10_11 (ite (= ne_6 #b1) x7_8 #x0000000000000000)))
(assert (and (= ge_16 ((_ extract 63 63) x3_11)) (= dc_77 ((_ extract 62 0) x3_11))))
(assert (= ge_17 (bvnot ge_16)))
(assert (= ge_18 (ite (= ne_6 #b1) ge_17 #b0)))
(assert (and (= dc_78 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_11))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_6 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_11))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_12 (ite (= ge_18 #b1) x3_neg_6 x3_11)))
(assert (and (= dc_79 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_11))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_6 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_11))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_12 (ite (= ge_18 #b1) x10_neg_6 x10_11)))
(assert (= x7_9 (ite (= ge_18 #b1) x8_12 x7_8)))
(assert (and (= dc_80 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_12) ((_ zero_extend 1) x10_12)))) (= x8_13 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_12) ((_ zero_extend 1) x10_12))))))
(assert (= x3_13 (bvadd x3_12 #x0000000000000002)))
(assert (and (= dc_81 ((_ extract 63 2) x8_13)) (= x8_lo_7 ((_ extract 1 0) x8_13))))
(assert (and (= x8_target_6 ((_ extract 1 1) x8_lo_7)) (= dc_82 ((_ extract 0 0) x8_lo_7))))
(assert (= ne_7 (bvand x8_target_6 #b1)))
(assert (and (= x8_14 ((_ sign_extend 1) ((_ extract 63 1) x8_13))) (= dc_83 ((_ zero_extend 63) ((_ extract 0 0) x8_13)))))
(assert true)
(assert (= x10_13 (ite (= ne_7 #b1) x7_9 #x0000000000000000)))
(assert (and (= ge_19 ((_ extract 63 63) x3_13)) (= dc_84 ((_ extract 62 0) x3_13))))
(assert (= ge_20 (bvnot ge_19)))
(assert (= ge_21 (ite (= ne_7 #b1) ge_20 #b0)))
(assert (and (= dc_85 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_13))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_7 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_13))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_14 (ite (= ge_21 #b1) x3_neg_7 x3_13)))
(assert (and (= dc_86 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_13))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_7 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_13))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_14 (ite (= ge_21 #b1) x10_neg_7 x10_13)))
(assert (= x7_10 (ite (= ge_21 #b1) x8_14 x7_9)))
(assert (and (= dc_87 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_14) ((_ zero_extend 1) x10_14)))) (= x8_15 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_14) ((_ zero_extend 1) x10_14))))))
(assert (= x3_15 (bvadd x3_14 #x0000000000000002)))
(assert (and (= dc_88 ((_ extract 63 2) x8_15)) (= x8_lo_8 ((_ extract 1 0) x8_15))))
(assert (and (= x8_target_7 ((_ extract 1 1) x8_lo_8)) (= dc_89 ((_ extract 0 0) x8_lo_8))))
(assert (= ne_8 (bvand x8_target_7 #b1)))
(assert (and (= x8_16 ((_ sign_extend 1) ((_ extract 63 1) x8_15))) (= dc_90 ((_ zero_extend 63) ((_ extract 0 0) x8_15)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_14) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_10 x7_9)) (= (bvmul x8_16 #x0000000000000002) x8_14)) (= x3_15 (bvadd #x0000000000000002 x3_13))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_14) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_13 #x0000000000000000)) (= x7_10 x7_9)) (= (bvmul x8_16 #x0000000000000002) (bvadd x8_14 x7_9))) (= x3_15 (bvadd #x0000000000000002 x3_13)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_14) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_13 #x0000000000000000)) (= x7_10 x8_14)) (= (bvmul x8_16 #x0000000000000002) (bvsub x8_14 x7_9))) (= x3_15 (bvsub #x0000000000000002 x3_13))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_8785bd.smt2
Execution time of boolector: 0.3624 seconds
OUTPUT FROM boolector:
unsat

=== Cut #2 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #2
; Range assertion #21: or [and [smod (sub (uext x8_20 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_13 = x7_12, mul x8_22 2@64 = x8_20, x3_21 = add 2@64 x3_19], and [smod (sub (uext x8_20 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_19 <s 0@64, x7_13 = x7_12, mul x8_22 2@64 = add x8_20 x7_12, x3_21 = add 2@64 x3_19], and [smod (sub (uext x8_20 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_19 >=s 0@64, x7_13 = x8_20, mul x8_22 2@64 = sub x8_20 x7_12, x3_21 = sub 2@64 x3_19]]
; Range condition: ((x8_20@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_13 = x7_12 /\ x8_22 * 2 = x8_20 /\ x3_21 = 2 + x3_19 \/ ((x8_20@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_19 <s 0 /\ x7_13 = x7_12 /\ x8_22 * 2 = x8_20 + x7_12 /\ x3_21 = 2 + x3_19 \/ ((x8_20@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_19 >=s 0 /\ x7_13 = x8_20 /\ x8_22 * 2 = x8_20 - x7_12 /\ x3_21 = 2 - x3_19
; Output file: /tmp/outputqfbv_dfd9be.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_10 () (_ BitVec 1))
(declare-fun x8_target_9 () (_ BitVec 1))
(declare-fun x8_target_8 () (_ BitVec 1))
(declare-fun x8_target_7 () (_ BitVec 1))
(declare-fun x8_target_6 () (_ BitVec 1))
(declare-fun x8_target_5 () (_ BitVec 1))
(declare-fun x8_target_4 () (_ BitVec 1))
(declare-fun x8_target_3 () (_ BitVec 1))
(declare-fun x8_target_2 () (_ BitVec 1))
(declare-fun x8_target_1 () (_ BitVec 1))
(declare-fun x8_lo_11 () (_ BitVec 2))
(declare-fun x8_lo_10 () (_ BitVec 2))
(declare-fun x8_lo_9 () (_ BitVec 2))
(declare-fun x8_lo_8 () (_ BitVec 2))
(declare-fun x8_lo_7 () (_ BitVec 2))
(declare-fun x8_lo_6 () (_ BitVec 2))
(declare-fun x8_lo_5 () (_ BitVec 2))
(declare-fun x8_lo_4 () (_ BitVec 2))
(declare-fun x8_lo_3 () (_ BitVec 2))
(declare-fun x8_lo_2 () (_ BitVec 2))
(declare-fun x8_lo_1 () (_ BitVec 1))
(declare-fun x8_22 () (_ BitVec 64))
(declare-fun x8_21 () (_ BitVec 64))
(declare-fun x8_20 () (_ BitVec 64))
(declare-fun x8_19 () (_ BitVec 64))
(declare-fun x8_18 () (_ BitVec 64))
(declare-fun x8_17 () (_ BitVec 64))
(declare-fun x8_16 () (_ BitVec 64))
(declare-fun x8_15 () (_ BitVec 64))
(declare-fun x8_14 () (_ BitVec 64))
(declare-fun x8_13 () (_ BitVec 64))
(declare-fun x8_12 () (_ BitVec 64))
(declare-fun x8_11 () (_ BitVec 64))
(declare-fun x8_10 () (_ BitVec 64))
(declare-fun x8_9 () (_ BitVec 64))
(declare-fun x8_8 () (_ BitVec 64))
(declare-fun x8_7 () (_ BitVec 64))
(declare-fun x8_6 () (_ BitVec 64))
(declare-fun x8_5 () (_ BitVec 64))
(declare-fun x8_4 () (_ BitVec 64))
(declare-fun x8_3 () (_ BitVec 64))
(declare-fun x8_2 () (_ BitVec 64))
(declare-fun x7_13 () (_ BitVec 64))
(declare-fun x7_12 () (_ BitVec 64))
(declare-fun x7_11 () (_ BitVec 64))
(declare-fun x7_10 () (_ BitVec 64))
(declare-fun x7_9 () (_ BitVec 64))
(declare-fun x7_8 () (_ BitVec 64))
(declare-fun x7_7 () (_ BitVec 64))
(declare-fun x7_6 () (_ BitVec 64))
(declare-fun x7_5 () (_ BitVec 64))
(declare-fun x7_4 () (_ BitVec 64))
(declare-fun x7_3 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_10 () (_ BitVec 64))
(declare-fun x3_neg_9 () (_ BitVec 64))
(declare-fun x3_neg_8 () (_ BitVec 64))
(declare-fun x3_neg_7 () (_ BitVec 64))
(declare-fun x3_neg_6 () (_ BitVec 64))
(declare-fun x3_neg_5 () (_ BitVec 64))
(declare-fun x3_neg_4 () (_ BitVec 64))
(declare-fun x3_neg_3 () (_ BitVec 64))
(declare-fun x3_neg_2 () (_ BitVec 64))
(declare-fun x3_neg_1 () (_ BitVec 64))
(declare-fun x3_21 () (_ BitVec 64))
(declare-fun x3_20 () (_ BitVec 64))
(declare-fun x3_19 () (_ BitVec 64))
(declare-fun x3_18 () (_ BitVec 64))
(declare-fun x3_17 () (_ BitVec 64))
(declare-fun x3_16 () (_ BitVec 64))
(declare-fun x3_15 () (_ BitVec 64))
(declare-fun x3_14 () (_ BitVec 64))
(declare-fun x3_13 () (_ BitVec 64))
(declare-fun x3_12 () (_ BitVec 64))
(declare-fun x3_11 () (_ BitVec 64))
(declare-fun x3_10 () (_ BitVec 64))
(declare-fun x3_9 () (_ BitVec 64))
(declare-fun x3_8 () (_ BitVec 64))
(declare-fun x3_7 () (_ BitVec 64))
(declare-fun x3_6 () (_ BitVec 64))
(declare-fun x3_5 () (_ BitVec 64))
(declare-fun x3_4 () (_ BitVec 64))
(declare-fun x3_3 () (_ BitVec 64))
(declare-fun x3_2 () (_ BitVec 64))
(declare-fun x10_neg_10 () (_ BitVec 64))
(declare-fun x10_neg_9 () (_ BitVec 64))
(declare-fun x10_neg_8 () (_ BitVec 64))
(declare-fun x10_neg_7 () (_ BitVec 64))
(declare-fun x10_neg_6 () (_ BitVec 64))
(declare-fun x10_neg_5 () (_ BitVec 64))
(declare-fun x10_neg_4 () (_ BitVec 64))
(declare-fun x10_neg_3 () (_ BitVec 64))
(declare-fun x10_neg_2 () (_ BitVec 64))
(declare-fun x10_neg_1 () (_ BitVec 64))
(declare-fun x10_20 () (_ BitVec 64))
(declare-fun x10_19 () (_ BitVec 64))
(declare-fun x10_18 () (_ BitVec 64))
(declare-fun x10_17 () (_ BitVec 64))
(declare-fun x10_16 () (_ BitVec 64))
(declare-fun x10_15 () (_ BitVec 64))
(declare-fun x10_14 () (_ BitVec 64))
(declare-fun x10_13 () (_ BitVec 64))
(declare-fun x10_12 () (_ BitVec 64))
(declare-fun x10_11 () (_ BitVec 64))
(declare-fun x10_10 () (_ BitVec 64))
(declare-fun x10_9 () (_ BitVec 64))
(declare-fun x10_8 () (_ BitVec 64))
(declare-fun x10_7 () (_ BitVec 64))
(declare-fun x10_6 () (_ BitVec 64))
(declare-fun x10_5 () (_ BitVec 64))
(declare-fun x10_4 () (_ BitVec 64))
(declare-fun x10_3 () (_ BitVec 64))
(declare-fun x10_2 () (_ BitVec 64))
(declare-fun x10_1 () (_ BitVec 64))
(declare-fun ne_11 () (_ BitVec 1))
(declare-fun ne_10 () (_ BitVec 1))
(declare-fun ne_9 () (_ BitVec 1))
(declare-fun ne_8 () (_ BitVec 1))
(declare-fun ne_7 () (_ BitVec 1))
(declare-fun ne_6 () (_ BitVec 1))
(declare-fun ne_5 () (_ BitVec 1))
(declare-fun ne_4 () (_ BitVec 1))
(declare-fun ne_3 () (_ BitVec 1))
(declare-fun ne_2 () (_ BitVec 1))
(declare-fun ne_1 () (_ BitVec 1))
(declare-fun ge_30 () (_ BitVec 1))
(declare-fun ge_29 () (_ BitVec 1))
(declare-fun ge_28 () (_ BitVec 1))
(declare-fun ge_27 () (_ BitVec 1))
(declare-fun ge_26 () (_ BitVec 1))
(declare-fun ge_25 () (_ BitVec 1))
(declare-fun ge_24 () (_ BitVec 1))
(declare-fun ge_23 () (_ BitVec 1))
(declare-fun ge_22 () (_ BitVec 1))
(declare-fun ge_21 () (_ BitVec 1))
(declare-fun ge_20 () (_ BitVec 1))
(declare-fun ge_19 () (_ BitVec 1))
(declare-fun ge_18 () (_ BitVec 1))
(declare-fun ge_17 () (_ BitVec 1))
(declare-fun ge_16 () (_ BitVec 1))
(declare-fun ge_15 () (_ BitVec 1))
(declare-fun ge_14 () (_ BitVec 1))
(declare-fun ge_13 () (_ BitVec 1))
(declare-fun ge_12 () (_ BitVec 1))
(declare-fun ge_11 () (_ BitVec 1))
(declare-fun ge_10 () (_ BitVec 1))
(declare-fun ge_9 () (_ BitVec 1))
(declare-fun ge_8 () (_ BitVec 1))
(declare-fun ge_7 () (_ BitVec 1))
(declare-fun ge_6 () (_ BitVec 1))
(declare-fun ge_5 () (_ BitVec 1))
(declare-fun ge_4 () (_ BitVec 1))
(declare-fun ge_3 () (_ BitVec 1))
(declare-fun ge_2 () (_ BitVec 1))
(declare-fun ge_1 () (_ BitVec 1))
(declare-fun g_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun dc_111 () (_ BitVec 64))
(declare-fun dc_110 () (_ BitVec 1))
(declare-fun dc_109 () (_ BitVec 62))
(declare-fun dc_108 () (_ BitVec 1))
(declare-fun dc_107 () (_ BitVec 1))
(declare-fun dc_106 () (_ BitVec 1))
(declare-fun dc_105 () (_ BitVec 63))
(declare-fun dc_104 () (_ BitVec 64))
(declare-fun dc_103 () (_ BitVec 1))
(declare-fun dc_102 () (_ BitVec 62))
(declare-fun dc_101 () (_ BitVec 1))
(declare-fun dc_100 () (_ BitVec 1))
(declare-fun dc_99 () (_ BitVec 1))
(declare-fun dc_98 () (_ BitVec 63))
(declare-fun dc_97 () (_ BitVec 64))
(declare-fun dc_96 () (_ BitVec 1))
(declare-fun dc_95 () (_ BitVec 62))
(declare-fun dc_94 () (_ BitVec 1))
(declare-fun dc_93 () (_ BitVec 1))
(declare-fun dc_92 () (_ BitVec 1))
(declare-fun dc_91 () (_ BitVec 63))
(declare-fun dc_90 () (_ BitVec 64))
(declare-fun dc_89 () (_ BitVec 1))
(declare-fun dc_88 () (_ BitVec 62))
(declare-fun dc_87 () (_ BitVec 1))
(declare-fun dc_86 () (_ BitVec 1))
(declare-fun dc_85 () (_ BitVec 1))
(declare-fun dc_84 () (_ BitVec 63))
(declare-fun dc_83 () (_ BitVec 64))
(declare-fun dc_82 () (_ BitVec 1))
(declare-fun dc_81 () (_ BitVec 62))
(declare-fun dc_80 () (_ BitVec 1))
(declare-fun dc_79 () (_ BitVec 1))
(declare-fun dc_78 () (_ BitVec 1))
(declare-fun dc_77 () (_ BitVec 63))
(declare-fun dc_76 () (_ BitVec 64))
(declare-fun dc_75 () (_ BitVec 1))
(declare-fun dc_74 () (_ BitVec 62))
(declare-fun dc_73 () (_ BitVec 1))
(declare-fun dc_72 () (_ BitVec 1))
(declare-fun dc_71 () (_ BitVec 1))
(declare-fun dc_70 () (_ BitVec 63))
(declare-fun dc_69 () (_ BitVec 64))
(declare-fun dc_68 () (_ BitVec 1))
(declare-fun dc_67 () (_ BitVec 62))
(declare-fun dc_66 () (_ BitVec 1))
(declare-fun dc_65 () (_ BitVec 1))
(declare-fun dc_64 () (_ BitVec 1))
(declare-fun dc_63 () (_ BitVec 63))
(declare-fun dc_62 () (_ BitVec 64))
(declare-fun dc_61 () (_ BitVec 1))
(declare-fun dc_60 () (_ BitVec 62))
(declare-fun dc_59 () (_ BitVec 1))
(declare-fun dc_58 () (_ BitVec 1))
(declare-fun dc_57 () (_ BitVec 1))
(declare-fun dc_56 () (_ BitVec 63))
(declare-fun dc_55 () (_ BitVec 64))
(declare-fun dc_54 () (_ BitVec 1))
(declare-fun dc_53 () (_ BitVec 62))
(declare-fun dc_52 () (_ BitVec 1))
(declare-fun dc_51 () (_ BitVec 1))
(declare-fun dc_50 () (_ BitVec 1))
(declare-fun dc_49 () (_ BitVec 63))
(declare-fun dc_48 () (_ BitVec 64))
(declare-fun dc_47 () (_ BitVec 1))
(declare-fun dc_46 () (_ BitVec 62))
(declare-fun dc_45 () (_ BitVec 1))
(declare-fun dc_44 () (_ BitVec 1))
(declare-fun dc_43 () (_ BitVec 1))
(declare-fun dc_42 () (_ BitVec 63))
(declare-fun dc_41 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (= x7_3 (bvadd (bvadd f_0_low60_0_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_2 (bvadd (bvadd g_0_low60_0_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_0_1)) (bvsle f_0_low60_0_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_0_1)) (bvsle g_0_low60_0_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_3) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #x0000000000000001 #x0000000000000001)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_41 ((_ extract 63 1) x8_2)) (= x8_lo_1 ((_ extract 0 0) x8_2))))
(assert (= ne_1 (bvand x8_lo_1 #b1)))
(assert (= x10_1 (ite (= ne_1 #b1) x7_3 #x0000000000000000)))
(assert (and (= ge_1 ((_ extract 63 63) #x0000000000000001)) (= dc_42 ((_ extract 62 0) #x0000000000000001))))
(assert (= ge_2 (bvnot ge_1)))
(assert (= ge_3 (ite (= ne_1 #b1) ge_2 #b0)))
(assert (and (= dc_43 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_2 (ite (= ge_3 #b1) x3_neg_1 #x0000000000000001)))
(assert (and (= dc_44 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_2 (ite (= ge_3 #b1) x10_neg_1 x10_1)))
(assert (= x7_4 (ite (= ge_3 #b1) x8_2 x7_3)))
(assert (and (= dc_45 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2)))) (= x8_3 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2))))))
(assert (= x3_3 (bvadd x3_2 #x0000000000000002)))
(assert (and (= dc_46 ((_ extract 63 2) x8_3)) (= x8_lo_2 ((_ extract 1 0) x8_3))))
(assert (and (= x8_target_1 ((_ extract 1 1) x8_lo_2)) (= dc_47 ((_ extract 0 0) x8_lo_2))))
(assert (= ne_2 (bvand x8_target_1 #b1)))
(assert (and (= x8_4 ((_ sign_extend 1) ((_ extract 63 1) x8_3))) (= dc_48 ((_ zero_extend 63) ((_ extract 0 0) x8_3)))))
(assert true)
(assert (= x10_3 (ite (= ne_2 #b1) x7_4 #x0000000000000000)))
(assert (and (= ge_4 ((_ extract 63 63) x3_3)) (= dc_49 ((_ extract 62 0) x3_3))))
(assert (= ge_5 (bvnot ge_4)))
(assert (= ge_6 (ite (= ne_2 #b1) ge_5 #b0)))
(assert (and (= dc_50 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_4 (ite (= ge_6 #b1) x3_neg_2 x3_3)))
(assert (and (= dc_51 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_4 (ite (= ge_6 #b1) x10_neg_2 x10_3)))
(assert (= x7_5 (ite (= ge_6 #b1) x8_4 x7_4)))
(assert (and (= dc_52 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4)))) (= x8_5 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4))))))
(assert (= x3_5 (bvadd x3_4 #x0000000000000002)))
(assert (and (= dc_53 ((_ extract 63 2) x8_5)) (= x8_lo_3 ((_ extract 1 0) x8_5))))
(assert (and (= x8_target_2 ((_ extract 1 1) x8_lo_3)) (= dc_54 ((_ extract 0 0) x8_lo_3))))
(assert (= ne_3 (bvand x8_target_2 #b1)))
(assert (and (= x8_6 ((_ sign_extend 1) ((_ extract 63 1) x8_5))) (= dc_55 ((_ zero_extend 63) ((_ extract 0 0) x8_5)))))
(assert true)
(assert (= x10_5 (ite (= ne_3 #b1) x7_5 #x0000000000000000)))
(assert (and (= ge_7 ((_ extract 63 63) x3_5)) (= dc_56 ((_ extract 62 0) x3_5))))
(assert (= ge_8 (bvnot ge_7)))
(assert (= ge_9 (ite (= ne_3 #b1) ge_8 #b0)))
(assert (and (= dc_57 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_6 (ite (= ge_9 #b1) x3_neg_3 x3_5)))
(assert (and (= dc_58 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_6 (ite (= ge_9 #b1) x10_neg_3 x10_5)))
(assert (= x7_6 (ite (= ge_9 #b1) x8_6 x7_5)))
(assert (and (= dc_59 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6)))) (= x8_7 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6))))))
(assert (= x3_7 (bvadd x3_6 #x0000000000000002)))
(assert (and (= dc_60 ((_ extract 63 2) x8_7)) (= x8_lo_4 ((_ extract 1 0) x8_7))))
(assert (and (= x8_target_3 ((_ extract 1 1) x8_lo_4)) (= dc_61 ((_ extract 0 0) x8_lo_4))))
(assert (= ne_4 (bvand x8_target_3 #b1)))
(assert (and (= x8_8 ((_ sign_extend 1) ((_ extract 63 1) x8_7))) (= dc_62 ((_ zero_extend 63) ((_ extract 0 0) x8_7)))))
(assert true)
(assert (= x10_7 (ite (= ne_4 #b1) x7_6 #x0000000000000000)))
(assert (and (= ge_10 ((_ extract 63 63) x3_7)) (= dc_63 ((_ extract 62 0) x3_7))))
(assert (= ge_11 (bvnot ge_10)))
(assert (= ge_12 (ite (= ne_4 #b1) ge_11 #b0)))
(assert (and (= dc_64 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_7))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_4 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_7))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_8 (ite (= ge_12 #b1) x3_neg_4 x3_7)))
(assert (and (= dc_65 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_7))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_4 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_7))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_8 (ite (= ge_12 #b1) x10_neg_4 x10_7)))
(assert (= x7_7 (ite (= ge_12 #b1) x8_8 x7_6)))
(assert (and (= dc_66 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_8) ((_ zero_extend 1) x10_8)))) (= x8_9 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_8) ((_ zero_extend 1) x10_8))))))
(assert (= x3_9 (bvadd x3_8 #x0000000000000002)))
(assert (and (= dc_67 ((_ extract 63 2) x8_9)) (= x8_lo_5 ((_ extract 1 0) x8_9))))
(assert (and (= x8_target_4 ((_ extract 1 1) x8_lo_5)) (= dc_68 ((_ extract 0 0) x8_lo_5))))
(assert (= ne_5 (bvand x8_target_4 #b1)))
(assert (and (= x8_10 ((_ sign_extend 1) ((_ extract 63 1) x8_9))) (= dc_69 ((_ zero_extend 63) ((_ extract 0 0) x8_9)))))
(assert true)
(assert (= x10_9 (ite (= ne_5 #b1) x7_7 #x0000000000000000)))
(assert (and (= ge_13 ((_ extract 63 63) x3_9)) (= dc_70 ((_ extract 62 0) x3_9))))
(assert (= ge_14 (bvnot ge_13)))
(assert (= ge_15 (ite (= ne_5 #b1) ge_14 #b0)))
(assert (and (= dc_71 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_9))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_5 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_9))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_10 (ite (= ge_15 #b1) x3_neg_5 x3_9)))
(assert (and (= dc_72 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_9))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_5 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_9))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_10 (ite (= ge_15 #b1) x10_neg_5 x10_9)))
(assert (= x7_8 (ite (= ge_15 #b1) x8_10 x7_7)))
(assert (and (= dc_73 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_10) ((_ zero_extend 1) x10_10)))) (= x8_11 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_10) ((_ zero_extend 1) x10_10))))))
(assert (= x3_11 (bvadd x3_10 #x0000000000000002)))
(assert (and (= dc_74 ((_ extract 63 2) x8_11)) (= x8_lo_6 ((_ extract 1 0) x8_11))))
(assert (and (= x8_target_5 ((_ extract 1 1) x8_lo_6)) (= dc_75 ((_ extract 0 0) x8_lo_6))))
(assert (= ne_6 (bvand x8_target_5 #b1)))
(assert (and (= x8_12 ((_ sign_extend 1) ((_ extract 63 1) x8_11))) (= dc_76 ((_ zero_extend 63) ((_ extract 0 0) x8_11)))))
(assert true)
(assert (= x10_11 (ite (= ne_6 #b1) x7_8 #x0000000000000000)))
(assert (and (= ge_16 ((_ extract 63 63) x3_11)) (= dc_77 ((_ extract 62 0) x3_11))))
(assert (= ge_17 (bvnot ge_16)))
(assert (= ge_18 (ite (= ne_6 #b1) ge_17 #b0)))
(assert (and (= dc_78 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_11))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_6 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_11))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_12 (ite (= ge_18 #b1) x3_neg_6 x3_11)))
(assert (and (= dc_79 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_11))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_6 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_11))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_12 (ite (= ge_18 #b1) x10_neg_6 x10_11)))
(assert (= x7_9 (ite (= ge_18 #b1) x8_12 x7_8)))
(assert (and (= dc_80 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_12) ((_ zero_extend 1) x10_12)))) (= x8_13 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_12) ((_ zero_extend 1) x10_12))))))
(assert (= x3_13 (bvadd x3_12 #x0000000000000002)))
(assert (and (= dc_81 ((_ extract 63 2) x8_13)) (= x8_lo_7 ((_ extract 1 0) x8_13))))
(assert (and (= x8_target_6 ((_ extract 1 1) x8_lo_7)) (= dc_82 ((_ extract 0 0) x8_lo_7))))
(assert (= ne_7 (bvand x8_target_6 #b1)))
(assert (and (= x8_14 ((_ sign_extend 1) ((_ extract 63 1) x8_13))) (= dc_83 ((_ zero_extend 63) ((_ extract 0 0) x8_13)))))
(assert true)
(assert (= x10_13 (ite (= ne_7 #b1) x7_9 #x0000000000000000)))
(assert (and (= ge_19 ((_ extract 63 63) x3_13)) (= dc_84 ((_ extract 62 0) x3_13))))
(assert (= ge_20 (bvnot ge_19)))
(assert (= ge_21 (ite (= ne_7 #b1) ge_20 #b0)))
(assert (and (= dc_85 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_13))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_7 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_13))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_14 (ite (= ge_21 #b1) x3_neg_7 x3_13)))
(assert (and (= dc_86 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_13))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_7 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_13))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_14 (ite (= ge_21 #b1) x10_neg_7 x10_13)))
(assert (= x7_10 (ite (= ge_21 #b1) x8_14 x7_9)))
(assert (and (= dc_87 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_14) ((_ zero_extend 1) x10_14)))) (= x8_15 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_14) ((_ zero_extend 1) x10_14))))))
(assert (= x3_15 (bvadd x3_14 #x0000000000000002)))
(assert (and (= dc_88 ((_ extract 63 2) x8_15)) (= x8_lo_8 ((_ extract 1 0) x8_15))))
(assert (and (= x8_target_7 ((_ extract 1 1) x8_lo_8)) (= dc_89 ((_ extract 0 0) x8_lo_8))))
(assert (= ne_8 (bvand x8_target_7 #b1)))
(assert (and (= x8_16 ((_ sign_extend 1) ((_ extract 63 1) x8_15))) (= dc_90 ((_ zero_extend 63) ((_ extract 0 0) x8_15)))))
(assert true)
(assert (= x10_15 (ite (= ne_8 #b1) x7_10 #x0000000000000000)))
(assert (and (= ge_22 ((_ extract 63 63) x3_15)) (= dc_91 ((_ extract 62 0) x3_15))))
(assert (= ge_23 (bvnot ge_22)))
(assert (= ge_24 (ite (= ne_8 #b1) ge_23 #b0)))
(assert (and (= dc_92 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_15))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_8 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_15))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_16 (ite (= ge_24 #b1) x3_neg_8 x3_15)))
(assert (and (= dc_93 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_15))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_8 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_15))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_16 (ite (= ge_24 #b1) x10_neg_8 x10_15)))
(assert (= x7_11 (ite (= ge_24 #b1) x8_16 x7_10)))
(assert (and (= dc_94 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_16) ((_ zero_extend 1) x10_16)))) (= x8_17 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_16) ((_ zero_extend 1) x10_16))))))
(assert (= x3_17 (bvadd x3_16 #x0000000000000002)))
(assert (and (= dc_95 ((_ extract 63 2) x8_17)) (= x8_lo_9 ((_ extract 1 0) x8_17))))
(assert (and (= x8_target_8 ((_ extract 1 1) x8_lo_9)) (= dc_96 ((_ extract 0 0) x8_lo_9))))
(assert (= ne_9 (bvand x8_target_8 #b1)))
(assert (and (= x8_18 ((_ sign_extend 1) ((_ extract 63 1) x8_17))) (= dc_97 ((_ zero_extend 63) ((_ extract 0 0) x8_17)))))
(assert true)
(assert (= x10_17 (ite (= ne_9 #b1) x7_11 #x0000000000000000)))
(assert (and (= ge_25 ((_ extract 63 63) x3_17)) (= dc_98 ((_ extract 62 0) x3_17))))
(assert (= ge_26 (bvnot ge_25)))
(assert (= ge_27 (ite (= ne_9 #b1) ge_26 #b0)))
(assert (and (= dc_99 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_17))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_9 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_17))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_18 (ite (= ge_27 #b1) x3_neg_9 x3_17)))
(assert (and (= dc_100 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_17))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_9 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_17))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_18 (ite (= ge_27 #b1) x10_neg_9 x10_17)))
(assert (= x7_12 (ite (= ge_27 #b1) x8_18 x7_11)))
(assert (and (= dc_101 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_18) ((_ zero_extend 1) x10_18)))) (= x8_19 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_18) ((_ zero_extend 1) x10_18))))))
(assert (= x3_19 (bvadd x3_18 #x0000000000000002)))
(assert (and (= dc_102 ((_ extract 63 2) x8_19)) (= x8_lo_10 ((_ extract 1 0) x8_19))))
(assert (and (= x8_target_9 ((_ extract 1 1) x8_lo_10)) (= dc_103 ((_ extract 0 0) x8_lo_10))))
(assert (= ne_10 (bvand x8_target_9 #b1)))
(assert (and (= x8_20 ((_ sign_extend 1) ((_ extract 63 1) x8_19))) (= dc_104 ((_ zero_extend 63) ((_ extract 0 0) x8_19)))))
(assert true)
(assert (= x10_19 (ite (= ne_10 #b1) x7_12 #x0000000000000000)))
(assert (and (= ge_28 ((_ extract 63 63) x3_19)) (= dc_105 ((_ extract 62 0) x3_19))))
(assert (= ge_29 (bvnot ge_28)))
(assert (= ge_30 (ite (= ne_10 #b1) ge_29 #b0)))
(assert (and (= dc_106 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_19))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_10 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_19))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_20 (ite (= ge_30 #b1) x3_neg_10 x3_19)))
(assert (and (= dc_107 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_19))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_10 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_19))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_20 (ite (= ge_30 #b1) x10_neg_10 x10_19)))
(assert (= x7_13 (ite (= ge_30 #b1) x8_20 x7_12)))
(assert (and (= dc_108 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_20) ((_ zero_extend 1) x10_20)))) (= x8_21 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_20) ((_ zero_extend 1) x10_20))))))
(assert (= x3_21 (bvadd x3_20 #x0000000000000002)))
(assert (and (= dc_109 ((_ extract 63 2) x8_21)) (= x8_lo_11 ((_ extract 1 0) x8_21))))
(assert (and (= x8_target_10 ((_ extract 1 1) x8_lo_11)) (= dc_110 ((_ extract 0 0) x8_lo_11))))
(assert (= ne_11 (bvand x8_target_10 #b1)))
(assert (and (= x8_22 ((_ sign_extend 1) ((_ extract 63 1) x8_21))) (= dc_111 ((_ zero_extend 63) ((_ extract 0 0) x8_21)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_20) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_13 x7_12)) (= (bvmul x8_22 #x0000000000000002) x8_20)) (= x3_21 (bvadd #x0000000000000002 x3_19))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_20) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_19 #x0000000000000000)) (= x7_13 x7_12)) (= (bvmul x8_22 #x0000000000000002) (bvadd x8_20 x7_12))) (= x3_21 (bvadd #x0000000000000002 x3_19)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_20) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_19 #x0000000000000000)) (= x7_13 x8_20)) (= (bvmul x8_22 #x0000000000000002) (bvsub x8_20 x7_12))) (= x3_21 (bvsub #x0000000000000002 x3_19))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_7b1a43.smt2
Execution time of boolector: 0.7527 seconds
OUTPUT FROM boolector:
unsat

=== Cut #2 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #2
; Range assertion #20: or [and [smod (sub (uext x8_18 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_12 = x7_11, mul x8_20 2@64 = x8_18, x3_19 = add 2@64 x3_17], and [smod (sub (uext x8_18 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_17 <s 0@64, x7_12 = x7_11, mul x8_20 2@64 = add x8_18 x7_11, x3_19 = add 2@64 x3_17], and [smod (sub (uext x8_18 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_17 >=s 0@64, x7_12 = x8_18, mul x8_20 2@64 = sub x8_18 x7_11, x3_19 = sub 2@64 x3_17]]
; Range condition: ((x8_18@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_12 = x7_11 /\ x8_20 * 2 = x8_18 /\ x3_19 = 2 + x3_17 \/ ((x8_18@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_17 <s 0 /\ x7_12 = x7_11 /\ x8_20 * 2 = x8_18 + x7_11 /\ x3_19 = 2 + x3_17 \/ ((x8_18@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_17 >=s 0 /\ x7_12 = x8_18 /\ x8_20 * 2 = x8_18 - x7_11 /\ x3_19 = 2 - x3_17
; Output file: /tmp/outputqfbv_8d57b9.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_9 () (_ BitVec 1))
(declare-fun x8_target_8 () (_ BitVec 1))
(declare-fun x8_target_7 () (_ BitVec 1))
(declare-fun x8_target_6 () (_ BitVec 1))
(declare-fun x8_target_5 () (_ BitVec 1))
(declare-fun x8_target_4 () (_ BitVec 1))
(declare-fun x8_target_3 () (_ BitVec 1))
(declare-fun x8_target_2 () (_ BitVec 1))
(declare-fun x8_target_1 () (_ BitVec 1))
(declare-fun x8_lo_10 () (_ BitVec 2))
(declare-fun x8_lo_9 () (_ BitVec 2))
(declare-fun x8_lo_8 () (_ BitVec 2))
(declare-fun x8_lo_7 () (_ BitVec 2))
(declare-fun x8_lo_6 () (_ BitVec 2))
(declare-fun x8_lo_5 () (_ BitVec 2))
(declare-fun x8_lo_4 () (_ BitVec 2))
(declare-fun x8_lo_3 () (_ BitVec 2))
(declare-fun x8_lo_2 () (_ BitVec 2))
(declare-fun x8_lo_1 () (_ BitVec 1))
(declare-fun x8_20 () (_ BitVec 64))
(declare-fun x8_19 () (_ BitVec 64))
(declare-fun x8_18 () (_ BitVec 64))
(declare-fun x8_17 () (_ BitVec 64))
(declare-fun x8_16 () (_ BitVec 64))
(declare-fun x8_15 () (_ BitVec 64))
(declare-fun x8_14 () (_ BitVec 64))
(declare-fun x8_13 () (_ BitVec 64))
(declare-fun x8_12 () (_ BitVec 64))
(declare-fun x8_11 () (_ BitVec 64))
(declare-fun x8_10 () (_ BitVec 64))
(declare-fun x8_9 () (_ BitVec 64))
(declare-fun x8_8 () (_ BitVec 64))
(declare-fun x8_7 () (_ BitVec 64))
(declare-fun x8_6 () (_ BitVec 64))
(declare-fun x8_5 () (_ BitVec 64))
(declare-fun x8_4 () (_ BitVec 64))
(declare-fun x8_3 () (_ BitVec 64))
(declare-fun x8_2 () (_ BitVec 64))
(declare-fun x7_12 () (_ BitVec 64))
(declare-fun x7_11 () (_ BitVec 64))
(declare-fun x7_10 () (_ BitVec 64))
(declare-fun x7_9 () (_ BitVec 64))
(declare-fun x7_8 () (_ BitVec 64))
(declare-fun x7_7 () (_ BitVec 64))
(declare-fun x7_6 () (_ BitVec 64))
(declare-fun x7_5 () (_ BitVec 64))
(declare-fun x7_4 () (_ BitVec 64))
(declare-fun x7_3 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_9 () (_ BitVec 64))
(declare-fun x3_neg_8 () (_ BitVec 64))
(declare-fun x3_neg_7 () (_ BitVec 64))
(declare-fun x3_neg_6 () (_ BitVec 64))
(declare-fun x3_neg_5 () (_ BitVec 64))
(declare-fun x3_neg_4 () (_ BitVec 64))
(declare-fun x3_neg_3 () (_ BitVec 64))
(declare-fun x3_neg_2 () (_ BitVec 64))
(declare-fun x3_neg_1 () (_ BitVec 64))
(declare-fun x3_19 () (_ BitVec 64))
(declare-fun x3_18 () (_ BitVec 64))
(declare-fun x3_17 () (_ BitVec 64))
(declare-fun x3_16 () (_ BitVec 64))
(declare-fun x3_15 () (_ BitVec 64))
(declare-fun x3_14 () (_ BitVec 64))
(declare-fun x3_13 () (_ BitVec 64))
(declare-fun x3_12 () (_ BitVec 64))
(declare-fun x3_11 () (_ BitVec 64))
(declare-fun x3_10 () (_ BitVec 64))
(declare-fun x3_9 () (_ BitVec 64))
(declare-fun x3_8 () (_ BitVec 64))
(declare-fun x3_7 () (_ BitVec 64))
(declare-fun x3_6 () (_ BitVec 64))
(declare-fun x3_5 () (_ BitVec 64))
(declare-fun x3_4 () (_ BitVec 64))
(declare-fun x3_3 () (_ BitVec 64))
(declare-fun x3_2 () (_ BitVec 64))
(declare-fun x10_neg_9 () (_ BitVec 64))
(declare-fun x10_neg_8 () (_ BitVec 64))
(declare-fun x10_neg_7 () (_ BitVec 64))
(declare-fun x10_neg_6 () (_ BitVec 64))
(declare-fun x10_neg_5 () (_ BitVec 64))
(declare-fun x10_neg_4 () (_ BitVec 64))
(declare-fun x10_neg_3 () (_ BitVec 64))
(declare-fun x10_neg_2 () (_ BitVec 64))
(declare-fun x10_neg_1 () (_ BitVec 64))
(declare-fun x10_18 () (_ BitVec 64))
(declare-fun x10_17 () (_ BitVec 64))
(declare-fun x10_16 () (_ BitVec 64))
(declare-fun x10_15 () (_ BitVec 64))
(declare-fun x10_14 () (_ BitVec 64))
(declare-fun x10_13 () (_ BitVec 64))
(declare-fun x10_12 () (_ BitVec 64))
(declare-fun x10_11 () (_ BitVec 64))
(declare-fun x10_10 () (_ BitVec 64))
(declare-fun x10_9 () (_ BitVec 64))
(declare-fun x10_8 () (_ BitVec 64))
(declare-fun x10_7 () (_ BitVec 64))
(declare-fun x10_6 () (_ BitVec 64))
(declare-fun x10_5 () (_ BitVec 64))
(declare-fun x10_4 () (_ BitVec 64))
(declare-fun x10_3 () (_ BitVec 64))
(declare-fun x10_2 () (_ BitVec 64))
(declare-fun x10_1 () (_ BitVec 64))
(declare-fun ne_10 () (_ BitVec 1))
(declare-fun ne_9 () (_ BitVec 1))
(declare-fun ne_8 () (_ BitVec 1))
(declare-fun ne_7 () (_ BitVec 1))
(declare-fun ne_6 () (_ BitVec 1))
(declare-fun ne_5 () (_ BitVec 1))
(declare-fun ne_4 () (_ BitVec 1))
(declare-fun ne_3 () (_ BitVec 1))
(declare-fun ne_2 () (_ BitVec 1))
(declare-fun ne_1 () (_ BitVec 1))
(declare-fun ge_27 () (_ BitVec 1))
(declare-fun ge_26 () (_ BitVec 1))
(declare-fun ge_25 () (_ BitVec 1))
(declare-fun ge_24 () (_ BitVec 1))
(declare-fun ge_23 () (_ BitVec 1))
(declare-fun ge_22 () (_ BitVec 1))
(declare-fun ge_21 () (_ BitVec 1))
(declare-fun ge_20 () (_ BitVec 1))
(declare-fun ge_19 () (_ BitVec 1))
(declare-fun ge_18 () (_ BitVec 1))
(declare-fun ge_17 () (_ BitVec 1))
(declare-fun ge_16 () (_ BitVec 1))
(declare-fun ge_15 () (_ BitVec 1))
(declare-fun ge_14 () (_ BitVec 1))
(declare-fun ge_13 () (_ BitVec 1))
(declare-fun ge_12 () (_ BitVec 1))
(declare-fun ge_11 () (_ BitVec 1))
(declare-fun ge_10 () (_ BitVec 1))
(declare-fun ge_9 () (_ BitVec 1))
(declare-fun ge_8 () (_ BitVec 1))
(declare-fun ge_7 () (_ BitVec 1))
(declare-fun ge_6 () (_ BitVec 1))
(declare-fun ge_5 () (_ BitVec 1))
(declare-fun ge_4 () (_ BitVec 1))
(declare-fun ge_3 () (_ BitVec 1))
(declare-fun ge_2 () (_ BitVec 1))
(declare-fun ge_1 () (_ BitVec 1))
(declare-fun g_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun dc_104 () (_ BitVec 64))
(declare-fun dc_103 () (_ BitVec 1))
(declare-fun dc_102 () (_ BitVec 62))
(declare-fun dc_101 () (_ BitVec 1))
(declare-fun dc_100 () (_ BitVec 1))
(declare-fun dc_99 () (_ BitVec 1))
(declare-fun dc_98 () (_ BitVec 63))
(declare-fun dc_97 () (_ BitVec 64))
(declare-fun dc_96 () (_ BitVec 1))
(declare-fun dc_95 () (_ BitVec 62))
(declare-fun dc_94 () (_ BitVec 1))
(declare-fun dc_93 () (_ BitVec 1))
(declare-fun dc_92 () (_ BitVec 1))
(declare-fun dc_91 () (_ BitVec 63))
(declare-fun dc_90 () (_ BitVec 64))
(declare-fun dc_89 () (_ BitVec 1))
(declare-fun dc_88 () (_ BitVec 62))
(declare-fun dc_87 () (_ BitVec 1))
(declare-fun dc_86 () (_ BitVec 1))
(declare-fun dc_85 () (_ BitVec 1))
(declare-fun dc_84 () (_ BitVec 63))
(declare-fun dc_83 () (_ BitVec 64))
(declare-fun dc_82 () (_ BitVec 1))
(declare-fun dc_81 () (_ BitVec 62))
(declare-fun dc_80 () (_ BitVec 1))
(declare-fun dc_79 () (_ BitVec 1))
(declare-fun dc_78 () (_ BitVec 1))
(declare-fun dc_77 () (_ BitVec 63))
(declare-fun dc_76 () (_ BitVec 64))
(declare-fun dc_75 () (_ BitVec 1))
(declare-fun dc_74 () (_ BitVec 62))
(declare-fun dc_73 () (_ BitVec 1))
(declare-fun dc_72 () (_ BitVec 1))
(declare-fun dc_71 () (_ BitVec 1))
(declare-fun dc_70 () (_ BitVec 63))
(declare-fun dc_69 () (_ BitVec 64))
(declare-fun dc_68 () (_ BitVec 1))
(declare-fun dc_67 () (_ BitVec 62))
(declare-fun dc_66 () (_ BitVec 1))
(declare-fun dc_65 () (_ BitVec 1))
(declare-fun dc_64 () (_ BitVec 1))
(declare-fun dc_63 () (_ BitVec 63))
(declare-fun dc_62 () (_ BitVec 64))
(declare-fun dc_61 () (_ BitVec 1))
(declare-fun dc_60 () (_ BitVec 62))
(declare-fun dc_59 () (_ BitVec 1))
(declare-fun dc_58 () (_ BitVec 1))
(declare-fun dc_57 () (_ BitVec 1))
(declare-fun dc_56 () (_ BitVec 63))
(declare-fun dc_55 () (_ BitVec 64))
(declare-fun dc_54 () (_ BitVec 1))
(declare-fun dc_53 () (_ BitVec 62))
(declare-fun dc_52 () (_ BitVec 1))
(declare-fun dc_51 () (_ BitVec 1))
(declare-fun dc_50 () (_ BitVec 1))
(declare-fun dc_49 () (_ BitVec 63))
(declare-fun dc_48 () (_ BitVec 64))
(declare-fun dc_47 () (_ BitVec 1))
(declare-fun dc_46 () (_ BitVec 62))
(declare-fun dc_45 () (_ BitVec 1))
(declare-fun dc_44 () (_ BitVec 1))
(declare-fun dc_43 () (_ BitVec 1))
(declare-fun dc_42 () (_ BitVec 63))
(declare-fun dc_41 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (= x7_3 (bvadd (bvadd f_0_low60_0_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_2 (bvadd (bvadd g_0_low60_0_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_0_1)) (bvsle f_0_low60_0_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_0_1)) (bvsle g_0_low60_0_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_3) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #x0000000000000001 #x0000000000000001)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_41 ((_ extract 63 1) x8_2)) (= x8_lo_1 ((_ extract 0 0) x8_2))))
(assert (= ne_1 (bvand x8_lo_1 #b1)))
(assert (= x10_1 (ite (= ne_1 #b1) x7_3 #x0000000000000000)))
(assert (and (= ge_1 ((_ extract 63 63) #x0000000000000001)) (= dc_42 ((_ extract 62 0) #x0000000000000001))))
(assert (= ge_2 (bvnot ge_1)))
(assert (= ge_3 (ite (= ne_1 #b1) ge_2 #b0)))
(assert (and (= dc_43 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_2 (ite (= ge_3 #b1) x3_neg_1 #x0000000000000001)))
(assert (and (= dc_44 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_2 (ite (= ge_3 #b1) x10_neg_1 x10_1)))
(assert (= x7_4 (ite (= ge_3 #b1) x8_2 x7_3)))
(assert (and (= dc_45 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2)))) (= x8_3 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2))))))
(assert (= x3_3 (bvadd x3_2 #x0000000000000002)))
(assert (and (= dc_46 ((_ extract 63 2) x8_3)) (= x8_lo_2 ((_ extract 1 0) x8_3))))
(assert (and (= x8_target_1 ((_ extract 1 1) x8_lo_2)) (= dc_47 ((_ extract 0 0) x8_lo_2))))
(assert (= ne_2 (bvand x8_target_1 #b1)))
(assert (and (= x8_4 ((_ sign_extend 1) ((_ extract 63 1) x8_3))) (= dc_48 ((_ zero_extend 63) ((_ extract 0 0) x8_3)))))
(assert true)
(assert (= x10_3 (ite (= ne_2 #b1) x7_4 #x0000000000000000)))
(assert (and (= ge_4 ((_ extract 63 63) x3_3)) (= dc_49 ((_ extract 62 0) x3_3))))
(assert (= ge_5 (bvnot ge_4)))
(assert (= ge_6 (ite (= ne_2 #b1) ge_5 #b0)))
(assert (and (= dc_50 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_4 (ite (= ge_6 #b1) x3_neg_2 x3_3)))
(assert (and (= dc_51 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_4 (ite (= ge_6 #b1) x10_neg_2 x10_3)))
(assert (= x7_5 (ite (= ge_6 #b1) x8_4 x7_4)))
(assert (and (= dc_52 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4)))) (= x8_5 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4))))))
(assert (= x3_5 (bvadd x3_4 #x0000000000000002)))
(assert (and (= dc_53 ((_ extract 63 2) x8_5)) (= x8_lo_3 ((_ extract 1 0) x8_5))))
(assert (and (= x8_target_2 ((_ extract 1 1) x8_lo_3)) (= dc_54 ((_ extract 0 0) x8_lo_3))))
(assert (= ne_3 (bvand x8_target_2 #b1)))
(assert (and (= x8_6 ((_ sign_extend 1) ((_ extract 63 1) x8_5))) (= dc_55 ((_ zero_extend 63) ((_ extract 0 0) x8_5)))))
(assert true)
(assert (= x10_5 (ite (= ne_3 #b1) x7_5 #x0000000000000000)))
(assert (and (= ge_7 ((_ extract 63 63) x3_5)) (= dc_56 ((_ extract 62 0) x3_5))))
(assert (= ge_8 (bvnot ge_7)))
(assert (= ge_9 (ite (= ne_3 #b1) ge_8 #b0)))
(assert (and (= dc_57 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_6 (ite (= ge_9 #b1) x3_neg_3 x3_5)))
(assert (and (= dc_58 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_6 (ite (= ge_9 #b1) x10_neg_3 x10_5)))
(assert (= x7_6 (ite (= ge_9 #b1) x8_6 x7_5)))
(assert (and (= dc_59 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6)))) (= x8_7 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6))))))
(assert (= x3_7 (bvadd x3_6 #x0000000000000002)))
(assert (and (= dc_60 ((_ extract 63 2) x8_7)) (= x8_lo_4 ((_ extract 1 0) x8_7))))
(assert (and (= x8_target_3 ((_ extract 1 1) x8_lo_4)) (= dc_61 ((_ extract 0 0) x8_lo_4))))
(assert (= ne_4 (bvand x8_target_3 #b1)))
(assert (and (= x8_8 ((_ sign_extend 1) ((_ extract 63 1) x8_7))) (= dc_62 ((_ zero_extend 63) ((_ extract 0 0) x8_7)))))
(assert true)
(assert (= x10_7 (ite (= ne_4 #b1) x7_6 #x0000000000000000)))
(assert (and (= ge_10 ((_ extract 63 63) x3_7)) (= dc_63 ((_ extract 62 0) x3_7))))
(assert (= ge_11 (bvnot ge_10)))
(assert (= ge_12 (ite (= ne_4 #b1) ge_11 #b0)))
(assert (and (= dc_64 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_7))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_4 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_7))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_8 (ite (= ge_12 #b1) x3_neg_4 x3_7)))
(assert (and (= dc_65 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_7))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_4 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_7))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_8 (ite (= ge_12 #b1) x10_neg_4 x10_7)))
(assert (= x7_7 (ite (= ge_12 #b1) x8_8 x7_6)))
(assert (and (= dc_66 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_8) ((_ zero_extend 1) x10_8)))) (= x8_9 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_8) ((_ zero_extend 1) x10_8))))))
(assert (= x3_9 (bvadd x3_8 #x0000000000000002)))
(assert (and (= dc_67 ((_ extract 63 2) x8_9)) (= x8_lo_5 ((_ extract 1 0) x8_9))))
(assert (and (= x8_target_4 ((_ extract 1 1) x8_lo_5)) (= dc_68 ((_ extract 0 0) x8_lo_5))))
(assert (= ne_5 (bvand x8_target_4 #b1)))
(assert (and (= x8_10 ((_ sign_extend 1) ((_ extract 63 1) x8_9))) (= dc_69 ((_ zero_extend 63) ((_ extract 0 0) x8_9)))))
(assert true)
(assert (= x10_9 (ite (= ne_5 #b1) x7_7 #x0000000000000000)))
(assert (and (= ge_13 ((_ extract 63 63) x3_9)) (= dc_70 ((_ extract 62 0) x3_9))))
(assert (= ge_14 (bvnot ge_13)))
(assert (= ge_15 (ite (= ne_5 #b1) ge_14 #b0)))
(assert (and (= dc_71 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_9))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_5 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_9))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_10 (ite (= ge_15 #b1) x3_neg_5 x3_9)))
(assert (and (= dc_72 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_9))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_5 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_9))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_10 (ite (= ge_15 #b1) x10_neg_5 x10_9)))
(assert (= x7_8 (ite (= ge_15 #b1) x8_10 x7_7)))
(assert (and (= dc_73 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_10) ((_ zero_extend 1) x10_10)))) (= x8_11 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_10) ((_ zero_extend 1) x10_10))))))
(assert (= x3_11 (bvadd x3_10 #x0000000000000002)))
(assert (and (= dc_74 ((_ extract 63 2) x8_11)) (= x8_lo_6 ((_ extract 1 0) x8_11))))
(assert (and (= x8_target_5 ((_ extract 1 1) x8_lo_6)) (= dc_75 ((_ extract 0 0) x8_lo_6))))
(assert (= ne_6 (bvand x8_target_5 #b1)))
(assert (and (= x8_12 ((_ sign_extend 1) ((_ extract 63 1) x8_11))) (= dc_76 ((_ zero_extend 63) ((_ extract 0 0) x8_11)))))
(assert true)
(assert (= x10_11 (ite (= ne_6 #b1) x7_8 #x0000000000000000)))
(assert (and (= ge_16 ((_ extract 63 63) x3_11)) (= dc_77 ((_ extract 62 0) x3_11))))
(assert (= ge_17 (bvnot ge_16)))
(assert (= ge_18 (ite (= ne_6 #b1) ge_17 #b0)))
(assert (and (= dc_78 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_11))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_6 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_11))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_12 (ite (= ge_18 #b1) x3_neg_6 x3_11)))
(assert (and (= dc_79 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_11))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_6 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_11))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_12 (ite (= ge_18 #b1) x10_neg_6 x10_11)))
(assert (= x7_9 (ite (= ge_18 #b1) x8_12 x7_8)))
(assert (and (= dc_80 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_12) ((_ zero_extend 1) x10_12)))) (= x8_13 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_12) ((_ zero_extend 1) x10_12))))))
(assert (= x3_13 (bvadd x3_12 #x0000000000000002)))
(assert (and (= dc_81 ((_ extract 63 2) x8_13)) (= x8_lo_7 ((_ extract 1 0) x8_13))))
(assert (and (= x8_target_6 ((_ extract 1 1) x8_lo_7)) (= dc_82 ((_ extract 0 0) x8_lo_7))))
(assert (= ne_7 (bvand x8_target_6 #b1)))
(assert (and (= x8_14 ((_ sign_extend 1) ((_ extract 63 1) x8_13))) (= dc_83 ((_ zero_extend 63) ((_ extract 0 0) x8_13)))))
(assert true)
(assert (= x10_13 (ite (= ne_7 #b1) x7_9 #x0000000000000000)))
(assert (and (= ge_19 ((_ extract 63 63) x3_13)) (= dc_84 ((_ extract 62 0) x3_13))))
(assert (= ge_20 (bvnot ge_19)))
(assert (= ge_21 (ite (= ne_7 #b1) ge_20 #b0)))
(assert (and (= dc_85 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_13))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_7 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_13))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_14 (ite (= ge_21 #b1) x3_neg_7 x3_13)))
(assert (and (= dc_86 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_13))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_7 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_13))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_14 (ite (= ge_21 #b1) x10_neg_7 x10_13)))
(assert (= x7_10 (ite (= ge_21 #b1) x8_14 x7_9)))
(assert (and (= dc_87 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_14) ((_ zero_extend 1) x10_14)))) (= x8_15 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_14) ((_ zero_extend 1) x10_14))))))
(assert (= x3_15 (bvadd x3_14 #x0000000000000002)))
(assert (and (= dc_88 ((_ extract 63 2) x8_15)) (= x8_lo_8 ((_ extract 1 0) x8_15))))
(assert (and (= x8_target_7 ((_ extract 1 1) x8_lo_8)) (= dc_89 ((_ extract 0 0) x8_lo_8))))
(assert (= ne_8 (bvand x8_target_7 #b1)))
(assert (and (= x8_16 ((_ sign_extend 1) ((_ extract 63 1) x8_15))) (= dc_90 ((_ zero_extend 63) ((_ extract 0 0) x8_15)))))
(assert true)
(assert (= x10_15 (ite (= ne_8 #b1) x7_10 #x0000000000000000)))
(assert (and (= ge_22 ((_ extract 63 63) x3_15)) (= dc_91 ((_ extract 62 0) x3_15))))
(assert (= ge_23 (bvnot ge_22)))
(assert (= ge_24 (ite (= ne_8 #b1) ge_23 #b0)))
(assert (and (= dc_92 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_15))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_8 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_15))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_16 (ite (= ge_24 #b1) x3_neg_8 x3_15)))
(assert (and (= dc_93 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_15))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_8 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_15))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_16 (ite (= ge_24 #b1) x10_neg_8 x10_15)))
(assert (= x7_11 (ite (= ge_24 #b1) x8_16 x7_10)))
(assert (and (= dc_94 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_16) ((_ zero_extend 1) x10_16)))) (= x8_17 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_16) ((_ zero_extend 1) x10_16))))))
(assert (= x3_17 (bvadd x3_16 #x0000000000000002)))
(assert (and (= dc_95 ((_ extract 63 2) x8_17)) (= x8_lo_9 ((_ extract 1 0) x8_17))))
(assert (and (= x8_target_8 ((_ extract 1 1) x8_lo_9)) (= dc_96 ((_ extract 0 0) x8_lo_9))))
(assert (= ne_9 (bvand x8_target_8 #b1)))
(assert (and (= x8_18 ((_ sign_extend 1) ((_ extract 63 1) x8_17))) (= dc_97 ((_ zero_extend 63) ((_ extract 0 0) x8_17)))))
(assert true)
(assert (= x10_17 (ite (= ne_9 #b1) x7_11 #x0000000000000000)))
(assert (and (= ge_25 ((_ extract 63 63) x3_17)) (= dc_98 ((_ extract 62 0) x3_17))))
(assert (= ge_26 (bvnot ge_25)))
(assert (= ge_27 (ite (= ne_9 #b1) ge_26 #b0)))
(assert (and (= dc_99 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_17))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_9 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_17))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_18 (ite (= ge_27 #b1) x3_neg_9 x3_17)))
(assert (and (= dc_100 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_17))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_9 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_17))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_18 (ite (= ge_27 #b1) x10_neg_9 x10_17)))
(assert (= x7_12 (ite (= ge_27 #b1) x8_18 x7_11)))
(assert (and (= dc_101 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_18) ((_ zero_extend 1) x10_18)))) (= x8_19 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_18) ((_ zero_extend 1) x10_18))))))
(assert (= x3_19 (bvadd x3_18 #x0000000000000002)))
(assert (and (= dc_102 ((_ extract 63 2) x8_19)) (= x8_lo_10 ((_ extract 1 0) x8_19))))
(assert (and (= x8_target_9 ((_ extract 1 1) x8_lo_10)) (= dc_103 ((_ extract 0 0) x8_lo_10))))
(assert (= ne_10 (bvand x8_target_9 #b1)))
(assert (and (= x8_20 ((_ sign_extend 1) ((_ extract 63 1) x8_19))) (= dc_104 ((_ zero_extend 63) ((_ extract 0 0) x8_19)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_18) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_12 x7_11)) (= (bvmul x8_20 #x0000000000000002) x8_18)) (= x3_19 (bvadd #x0000000000000002 x3_17))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_18) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_17 #x0000000000000000)) (= x7_12 x7_11)) (= (bvmul x8_20 #x0000000000000002) (bvadd x8_18 x7_11))) (= x3_19 (bvadd #x0000000000000002 x3_17)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_18) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_17 #x0000000000000000)) (= x7_12 x8_18)) (= (bvmul x8_20 #x0000000000000002) (bvsub x8_18 x7_11))) (= x3_19 (bvsub #x0000000000000002 x3_17))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_ad24a5.smt2
Execution time of boolector: 0.8289 seconds
OUTPUT FROM boolector:
unsat

=== Cut #2 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #2
; Range assertion #19: or [and [smod (sub (uext x8_16 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_11 = x7_10, mul x8_18 2@64 = x8_16, x3_17 = add 2@64 x3_15], and [smod (sub (uext x8_16 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_15 <s 0@64, x7_11 = x7_10, mul x8_18 2@64 = add x8_16 x7_10, x3_17 = add 2@64 x3_15], and [smod (sub (uext x8_16 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_15 >=s 0@64, x7_11 = x8_16, mul x8_18 2@64 = sub x8_16 x7_10, x3_17 = sub 2@64 x3_15]]
; Range condition: ((x8_16@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_11 = x7_10 /\ x8_18 * 2 = x8_16 /\ x3_17 = 2 + x3_15 \/ ((x8_16@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_15 <s 0 /\ x7_11 = x7_10 /\ x8_18 * 2 = x8_16 + x7_10 /\ x3_17 = 2 + x3_15 \/ ((x8_16@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_15 >=s 0 /\ x7_11 = x8_16 /\ x8_18 * 2 = x8_16 - x7_10 /\ x3_17 = 2 - x3_15
; Output file: /tmp/outputqfbv_57fd39.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_8 () (_ BitVec 1))
(declare-fun x8_target_7 () (_ BitVec 1))
(declare-fun x8_target_6 () (_ BitVec 1))
(declare-fun x8_target_5 () (_ BitVec 1))
(declare-fun x8_target_4 () (_ BitVec 1))
(declare-fun x8_target_3 () (_ BitVec 1))
(declare-fun x8_target_2 () (_ BitVec 1))
(declare-fun x8_target_1 () (_ BitVec 1))
(declare-fun x8_lo_9 () (_ BitVec 2))
(declare-fun x8_lo_8 () (_ BitVec 2))
(declare-fun x8_lo_7 () (_ BitVec 2))
(declare-fun x8_lo_6 () (_ BitVec 2))
(declare-fun x8_lo_5 () (_ BitVec 2))
(declare-fun x8_lo_4 () (_ BitVec 2))
(declare-fun x8_lo_3 () (_ BitVec 2))
(declare-fun x8_lo_2 () (_ BitVec 2))
(declare-fun x8_lo_1 () (_ BitVec 1))
(declare-fun x8_18 () (_ BitVec 64))
(declare-fun x8_17 () (_ BitVec 64))
(declare-fun x8_16 () (_ BitVec 64))
(declare-fun x8_15 () (_ BitVec 64))
(declare-fun x8_14 () (_ BitVec 64))
(declare-fun x8_13 () (_ BitVec 64))
(declare-fun x8_12 () (_ BitVec 64))
(declare-fun x8_11 () (_ BitVec 64))
(declare-fun x8_10 () (_ BitVec 64))
(declare-fun x8_9 () (_ BitVec 64))
(declare-fun x8_8 () (_ BitVec 64))
(declare-fun x8_7 () (_ BitVec 64))
(declare-fun x8_6 () (_ BitVec 64))
(declare-fun x8_5 () (_ BitVec 64))
(declare-fun x8_4 () (_ BitVec 64))
(declare-fun x8_3 () (_ BitVec 64))
(declare-fun x8_2 () (_ BitVec 64))
(declare-fun x7_11 () (_ BitVec 64))
(declare-fun x7_10 () (_ BitVec 64))
(declare-fun x7_9 () (_ BitVec 64))
(declare-fun x7_8 () (_ BitVec 64))
(declare-fun x7_7 () (_ BitVec 64))
(declare-fun x7_6 () (_ BitVec 64))
(declare-fun x7_5 () (_ BitVec 64))
(declare-fun x7_4 () (_ BitVec 64))
(declare-fun x7_3 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_8 () (_ BitVec 64))
(declare-fun x3_neg_7 () (_ BitVec 64))
(declare-fun x3_neg_6 () (_ BitVec 64))
(declare-fun x3_neg_5 () (_ BitVec 64))
(declare-fun x3_neg_4 () (_ BitVec 64))
(declare-fun x3_neg_3 () (_ BitVec 64))
(declare-fun x3_neg_2 () (_ BitVec 64))
(declare-fun x3_neg_1 () (_ BitVec 64))
(declare-fun x3_17 () (_ BitVec 64))
(declare-fun x3_16 () (_ BitVec 64))
(declare-fun x3_15 () (_ BitVec 64))
(declare-fun x3_14 () (_ BitVec 64))
(declare-fun x3_13 () (_ BitVec 64))
(declare-fun x3_12 () (_ BitVec 64))
(declare-fun x3_11 () (_ BitVec 64))
(declare-fun x3_10 () (_ BitVec 64))
(declare-fun x3_9 () (_ BitVec 64))
(declare-fun x3_8 () (_ BitVec 64))
(declare-fun x3_7 () (_ BitVec 64))
(declare-fun x3_6 () (_ BitVec 64))
(declare-fun x3_5 () (_ BitVec 64))
(declare-fun x3_4 () (_ BitVec 64))
(declare-fun x3_3 () (_ BitVec 64))
(declare-fun x3_2 () (_ BitVec 64))
(declare-fun x10_neg_8 () (_ BitVec 64))
(declare-fun x10_neg_7 () (_ BitVec 64))
(declare-fun x10_neg_6 () (_ BitVec 64))
(declare-fun x10_neg_5 () (_ BitVec 64))
(declare-fun x10_neg_4 () (_ BitVec 64))
(declare-fun x10_neg_3 () (_ BitVec 64))
(declare-fun x10_neg_2 () (_ BitVec 64))
(declare-fun x10_neg_1 () (_ BitVec 64))
(declare-fun x10_16 () (_ BitVec 64))
(declare-fun x10_15 () (_ BitVec 64))
(declare-fun x10_14 () (_ BitVec 64))
(declare-fun x10_13 () (_ BitVec 64))
(declare-fun x10_12 () (_ BitVec 64))
(declare-fun x10_11 () (_ BitVec 64))
(declare-fun x10_10 () (_ BitVec 64))
(declare-fun x10_9 () (_ BitVec 64))
(declare-fun x10_8 () (_ BitVec 64))
(declare-fun x10_7 () (_ BitVec 64))
(declare-fun x10_6 () (_ BitVec 64))
(declare-fun x10_5 () (_ BitVec 64))
(declare-fun x10_4 () (_ BitVec 64))
(declare-fun x10_3 () (_ BitVec 64))
(declare-fun x10_2 () (_ BitVec 64))
(declare-fun x10_1 () (_ BitVec 64))
(declare-fun ne_9 () (_ BitVec 1))
(declare-fun ne_8 () (_ BitVec 1))
(declare-fun ne_7 () (_ BitVec 1))
(declare-fun ne_6 () (_ BitVec 1))
(declare-fun ne_5 () (_ BitVec 1))
(declare-fun ne_4 () (_ BitVec 1))
(declare-fun ne_3 () (_ BitVec 1))
(declare-fun ne_2 () (_ BitVec 1))
(declare-fun ne_1 () (_ BitVec 1))
(declare-fun ge_24 () (_ BitVec 1))
(declare-fun ge_23 () (_ BitVec 1))
(declare-fun ge_22 () (_ BitVec 1))
(declare-fun ge_21 () (_ BitVec 1))
(declare-fun ge_20 () (_ BitVec 1))
(declare-fun ge_19 () (_ BitVec 1))
(declare-fun ge_18 () (_ BitVec 1))
(declare-fun ge_17 () (_ BitVec 1))
(declare-fun ge_16 () (_ BitVec 1))
(declare-fun ge_15 () (_ BitVec 1))
(declare-fun ge_14 () (_ BitVec 1))
(declare-fun ge_13 () (_ BitVec 1))
(declare-fun ge_12 () (_ BitVec 1))
(declare-fun ge_11 () (_ BitVec 1))
(declare-fun ge_10 () (_ BitVec 1))
(declare-fun ge_9 () (_ BitVec 1))
(declare-fun ge_8 () (_ BitVec 1))
(declare-fun ge_7 () (_ BitVec 1))
(declare-fun ge_6 () (_ BitVec 1))
(declare-fun ge_5 () (_ BitVec 1))
(declare-fun ge_4 () (_ BitVec 1))
(declare-fun ge_3 () (_ BitVec 1))
(declare-fun ge_2 () (_ BitVec 1))
(declare-fun ge_1 () (_ BitVec 1))
(declare-fun g_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun dc_97 () (_ BitVec 64))
(declare-fun dc_96 () (_ BitVec 1))
(declare-fun dc_95 () (_ BitVec 62))
(declare-fun dc_94 () (_ BitVec 1))
(declare-fun dc_93 () (_ BitVec 1))
(declare-fun dc_92 () (_ BitVec 1))
(declare-fun dc_91 () (_ BitVec 63))
(declare-fun dc_90 () (_ BitVec 64))
(declare-fun dc_89 () (_ BitVec 1))
(declare-fun dc_88 () (_ BitVec 62))
(declare-fun dc_87 () (_ BitVec 1))
(declare-fun dc_86 () (_ BitVec 1))
(declare-fun dc_85 () (_ BitVec 1))
(declare-fun dc_84 () (_ BitVec 63))
(declare-fun dc_83 () (_ BitVec 64))
(declare-fun dc_82 () (_ BitVec 1))
(declare-fun dc_81 () (_ BitVec 62))
(declare-fun dc_80 () (_ BitVec 1))
(declare-fun dc_79 () (_ BitVec 1))
(declare-fun dc_78 () (_ BitVec 1))
(declare-fun dc_77 () (_ BitVec 63))
(declare-fun dc_76 () (_ BitVec 64))
(declare-fun dc_75 () (_ BitVec 1))
(declare-fun dc_74 () (_ BitVec 62))
(declare-fun dc_73 () (_ BitVec 1))
(declare-fun dc_72 () (_ BitVec 1))
(declare-fun dc_71 () (_ BitVec 1))
(declare-fun dc_70 () (_ BitVec 63))
(declare-fun dc_69 () (_ BitVec 64))
(declare-fun dc_68 () (_ BitVec 1))
(declare-fun dc_67 () (_ BitVec 62))
(declare-fun dc_66 () (_ BitVec 1))
(declare-fun dc_65 () (_ BitVec 1))
(declare-fun dc_64 () (_ BitVec 1))
(declare-fun dc_63 () (_ BitVec 63))
(declare-fun dc_62 () (_ BitVec 64))
(declare-fun dc_61 () (_ BitVec 1))
(declare-fun dc_60 () (_ BitVec 62))
(declare-fun dc_59 () (_ BitVec 1))
(declare-fun dc_58 () (_ BitVec 1))
(declare-fun dc_57 () (_ BitVec 1))
(declare-fun dc_56 () (_ BitVec 63))
(declare-fun dc_55 () (_ BitVec 64))
(declare-fun dc_54 () (_ BitVec 1))
(declare-fun dc_53 () (_ BitVec 62))
(declare-fun dc_52 () (_ BitVec 1))
(declare-fun dc_51 () (_ BitVec 1))
(declare-fun dc_50 () (_ BitVec 1))
(declare-fun dc_49 () (_ BitVec 63))
(declare-fun dc_48 () (_ BitVec 64))
(declare-fun dc_47 () (_ BitVec 1))
(declare-fun dc_46 () (_ BitVec 62))
(declare-fun dc_45 () (_ BitVec 1))
(declare-fun dc_44 () (_ BitVec 1))
(declare-fun dc_43 () (_ BitVec 1))
(declare-fun dc_42 () (_ BitVec 63))
(declare-fun dc_41 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (= x7_3 (bvadd (bvadd f_0_low60_0_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_2 (bvadd (bvadd g_0_low60_0_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_0_1)) (bvsle f_0_low60_0_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_0_1)) (bvsle g_0_low60_0_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_3) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #x0000000000000001 #x0000000000000001)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_41 ((_ extract 63 1) x8_2)) (= x8_lo_1 ((_ extract 0 0) x8_2))))
(assert (= ne_1 (bvand x8_lo_1 #b1)))
(assert (= x10_1 (ite (= ne_1 #b1) x7_3 #x0000000000000000)))
(assert (and (= ge_1 ((_ extract 63 63) #x0000000000000001)) (= dc_42 ((_ extract 62 0) #x0000000000000001))))
(assert (= ge_2 (bvnot ge_1)))
(assert (= ge_3 (ite (= ne_1 #b1) ge_2 #b0)))
(assert (and (= dc_43 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_2 (ite (= ge_3 #b1) x3_neg_1 #x0000000000000001)))
(assert (and (= dc_44 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_2 (ite (= ge_3 #b1) x10_neg_1 x10_1)))
(assert (= x7_4 (ite (= ge_3 #b1) x8_2 x7_3)))
(assert (and (= dc_45 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2)))) (= x8_3 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2))))))
(assert (= x3_3 (bvadd x3_2 #x0000000000000002)))
(assert (and (= dc_46 ((_ extract 63 2) x8_3)) (= x8_lo_2 ((_ extract 1 0) x8_3))))
(assert (and (= x8_target_1 ((_ extract 1 1) x8_lo_2)) (= dc_47 ((_ extract 0 0) x8_lo_2))))
(assert (= ne_2 (bvand x8_target_1 #b1)))
(assert (and (= x8_4 ((_ sign_extend 1) ((_ extract 63 1) x8_3))) (= dc_48 ((_ zero_extend 63) ((_ extract 0 0) x8_3)))))
(assert true)
(assert (= x10_3 (ite (= ne_2 #b1) x7_4 #x0000000000000000)))
(assert (and (= ge_4 ((_ extract 63 63) x3_3)) (= dc_49 ((_ extract 62 0) x3_3))))
(assert (= ge_5 (bvnot ge_4)))
(assert (= ge_6 (ite (= ne_2 #b1) ge_5 #b0)))
(assert (and (= dc_50 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_4 (ite (= ge_6 #b1) x3_neg_2 x3_3)))
(assert (and (= dc_51 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_4 (ite (= ge_6 #b1) x10_neg_2 x10_3)))
(assert (= x7_5 (ite (= ge_6 #b1) x8_4 x7_4)))
(assert (and (= dc_52 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4)))) (= x8_5 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4))))))
(assert (= x3_5 (bvadd x3_4 #x0000000000000002)))
(assert (and (= dc_53 ((_ extract 63 2) x8_5)) (= x8_lo_3 ((_ extract 1 0) x8_5))))
(assert (and (= x8_target_2 ((_ extract 1 1) x8_lo_3)) (= dc_54 ((_ extract 0 0) x8_lo_3))))
(assert (= ne_3 (bvand x8_target_2 #b1)))
(assert (and (= x8_6 ((_ sign_extend 1) ((_ extract 63 1) x8_5))) (= dc_55 ((_ zero_extend 63) ((_ extract 0 0) x8_5)))))
(assert true)
(assert (= x10_5 (ite (= ne_3 #b1) x7_5 #x0000000000000000)))
(assert (and (= ge_7 ((_ extract 63 63) x3_5)) (= dc_56 ((_ extract 62 0) x3_5))))
(assert (= ge_8 (bvnot ge_7)))
(assert (= ge_9 (ite (= ne_3 #b1) ge_8 #b0)))
(assert (and (= dc_57 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_6 (ite (= ge_9 #b1) x3_neg_3 x3_5)))
(assert (and (= dc_58 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_6 (ite (= ge_9 #b1) x10_neg_3 x10_5)))
(assert (= x7_6 (ite (= ge_9 #b1) x8_6 x7_5)))
(assert (and (= dc_59 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6)))) (= x8_7 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6))))))
(assert (= x3_7 (bvadd x3_6 #x0000000000000002)))
(assert (and (= dc_60 ((_ extract 63 2) x8_7)) (= x8_lo_4 ((_ extract 1 0) x8_7))))
(assert (and (= x8_target_3 ((_ extract 1 1) x8_lo_4)) (= dc_61 ((_ extract 0 0) x8_lo_4))))
(assert (= ne_4 (bvand x8_target_3 #b1)))
(assert (and (= x8_8 ((_ sign_extend 1) ((_ extract 63 1) x8_7))) (= dc_62 ((_ zero_extend 63) ((_ extract 0 0) x8_7)))))
(assert true)
(assert (= x10_7 (ite (= ne_4 #b1) x7_6 #x0000000000000000)))
(assert (and (= ge_10 ((_ extract 63 63) x3_7)) (= dc_63 ((_ extract 62 0) x3_7))))
(assert (= ge_11 (bvnot ge_10)))
(assert (= ge_12 (ite (= ne_4 #b1) ge_11 #b0)))
(assert (and (= dc_64 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_7))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_4 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_7))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_8 (ite (= ge_12 #b1) x3_neg_4 x3_7)))
(assert (and (= dc_65 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_7))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_4 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_7))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_8 (ite (= ge_12 #b1) x10_neg_4 x10_7)))
(assert (= x7_7 (ite (= ge_12 #b1) x8_8 x7_6)))
(assert (and (= dc_66 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_8) ((_ zero_extend 1) x10_8)))) (= x8_9 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_8) ((_ zero_extend 1) x10_8))))))
(assert (= x3_9 (bvadd x3_8 #x0000000000000002)))
(assert (and (= dc_67 ((_ extract 63 2) x8_9)) (= x8_lo_5 ((_ extract 1 0) x8_9))))
(assert (and (= x8_target_4 ((_ extract 1 1) x8_lo_5)) (= dc_68 ((_ extract 0 0) x8_lo_5))))
(assert (= ne_5 (bvand x8_target_4 #b1)))
(assert (and (= x8_10 ((_ sign_extend 1) ((_ extract 63 1) x8_9))) (= dc_69 ((_ zero_extend 63) ((_ extract 0 0) x8_9)))))
(assert true)
(assert (= x10_9 (ite (= ne_5 #b1) x7_7 #x0000000000000000)))
(assert (and (= ge_13 ((_ extract 63 63) x3_9)) (= dc_70 ((_ extract 62 0) x3_9))))
(assert (= ge_14 (bvnot ge_13)))
(assert (= ge_15 (ite (= ne_5 #b1) ge_14 #b0)))
(assert (and (= dc_71 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_9))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_5 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_9))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_10 (ite (= ge_15 #b1) x3_neg_5 x3_9)))
(assert (and (= dc_72 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_9))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_5 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_9))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_10 (ite (= ge_15 #b1) x10_neg_5 x10_9)))
(assert (= x7_8 (ite (= ge_15 #b1) x8_10 x7_7)))
(assert (and (= dc_73 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_10) ((_ zero_extend 1) x10_10)))) (= x8_11 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_10) ((_ zero_extend 1) x10_10))))))
(assert (= x3_11 (bvadd x3_10 #x0000000000000002)))
(assert (and (= dc_74 ((_ extract 63 2) x8_11)) (= x8_lo_6 ((_ extract 1 0) x8_11))))
(assert (and (= x8_target_5 ((_ extract 1 1) x8_lo_6)) (= dc_75 ((_ extract 0 0) x8_lo_6))))
(assert (= ne_6 (bvand x8_target_5 #b1)))
(assert (and (= x8_12 ((_ sign_extend 1) ((_ extract 63 1) x8_11))) (= dc_76 ((_ zero_extend 63) ((_ extract 0 0) x8_11)))))
(assert true)
(assert (= x10_11 (ite (= ne_6 #b1) x7_8 #x0000000000000000)))
(assert (and (= ge_16 ((_ extract 63 63) x3_11)) (= dc_77 ((_ extract 62 0) x3_11))))
(assert (= ge_17 (bvnot ge_16)))
(assert (= ge_18 (ite (= ne_6 #b1) ge_17 #b0)))
(assert (and (= dc_78 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_11))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_6 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_11))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_12 (ite (= ge_18 #b1) x3_neg_6 x3_11)))
(assert (and (= dc_79 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_11))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_6 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_11))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_12 (ite (= ge_18 #b1) x10_neg_6 x10_11)))
(assert (= x7_9 (ite (= ge_18 #b1) x8_12 x7_8)))
(assert (and (= dc_80 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_12) ((_ zero_extend 1) x10_12)))) (= x8_13 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_12) ((_ zero_extend 1) x10_12))))))
(assert (= x3_13 (bvadd x3_12 #x0000000000000002)))
(assert (and (= dc_81 ((_ extract 63 2) x8_13)) (= x8_lo_7 ((_ extract 1 0) x8_13))))
(assert (and (= x8_target_6 ((_ extract 1 1) x8_lo_7)) (= dc_82 ((_ extract 0 0) x8_lo_7))))
(assert (= ne_7 (bvand x8_target_6 #b1)))
(assert (and (= x8_14 ((_ sign_extend 1) ((_ extract 63 1) x8_13))) (= dc_83 ((_ zero_extend 63) ((_ extract 0 0) x8_13)))))
(assert true)
(assert (= x10_13 (ite (= ne_7 #b1) x7_9 #x0000000000000000)))
(assert (and (= ge_19 ((_ extract 63 63) x3_13)) (= dc_84 ((_ extract 62 0) x3_13))))
(assert (= ge_20 (bvnot ge_19)))
(assert (= ge_21 (ite (= ne_7 #b1) ge_20 #b0)))
(assert (and (= dc_85 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_13))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_7 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_13))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_14 (ite (= ge_21 #b1) x3_neg_7 x3_13)))
(assert (and (= dc_86 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_13))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_7 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_13))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_14 (ite (= ge_21 #b1) x10_neg_7 x10_13)))
(assert (= x7_10 (ite (= ge_21 #b1) x8_14 x7_9)))
(assert (and (= dc_87 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_14) ((_ zero_extend 1) x10_14)))) (= x8_15 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_14) ((_ zero_extend 1) x10_14))))))
(assert (= x3_15 (bvadd x3_14 #x0000000000000002)))
(assert (and (= dc_88 ((_ extract 63 2) x8_15)) (= x8_lo_8 ((_ extract 1 0) x8_15))))
(assert (and (= x8_target_7 ((_ extract 1 1) x8_lo_8)) (= dc_89 ((_ extract 0 0) x8_lo_8))))
(assert (= ne_8 (bvand x8_target_7 #b1)))
(assert (and (= x8_16 ((_ sign_extend 1) ((_ extract 63 1) x8_15))) (= dc_90 ((_ zero_extend 63) ((_ extract 0 0) x8_15)))))
(assert true)
(assert (= x10_15 (ite (= ne_8 #b1) x7_10 #x0000000000000000)))
(assert (and (= ge_22 ((_ extract 63 63) x3_15)) (= dc_91 ((_ extract 62 0) x3_15))))
(assert (= ge_23 (bvnot ge_22)))
(assert (= ge_24 (ite (= ne_8 #b1) ge_23 #b0)))
(assert (and (= dc_92 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_15))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_8 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_15))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_16 (ite (= ge_24 #b1) x3_neg_8 x3_15)))
(assert (and (= dc_93 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_15))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_8 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_15))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_16 (ite (= ge_24 #b1) x10_neg_8 x10_15)))
(assert (= x7_11 (ite (= ge_24 #b1) x8_16 x7_10)))
(assert (and (= dc_94 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_16) ((_ zero_extend 1) x10_16)))) (= x8_17 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_16) ((_ zero_extend 1) x10_16))))))
(assert (= x3_17 (bvadd x3_16 #x0000000000000002)))
(assert (and (= dc_95 ((_ extract 63 2) x8_17)) (= x8_lo_9 ((_ extract 1 0) x8_17))))
(assert (and (= x8_target_8 ((_ extract 1 1) x8_lo_9)) (= dc_96 ((_ extract 0 0) x8_lo_9))))
(assert (= ne_9 (bvand x8_target_8 #b1)))
(assert (and (= x8_18 ((_ sign_extend 1) ((_ extract 63 1) x8_17))) (= dc_97 ((_ zero_extend 63) ((_ extract 0 0) x8_17)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_16) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_11 x7_10)) (= (bvmul x8_18 #x0000000000000002) x8_16)) (= x3_17 (bvadd #x0000000000000002 x3_15))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_16) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_15 #x0000000000000000)) (= x7_11 x7_10)) (= (bvmul x8_18 #x0000000000000002) (bvadd x8_16 x7_10))) (= x3_17 (bvadd #x0000000000000002 x3_15)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_16) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_15 #x0000000000000000)) (= x7_11 x8_16)) (= (bvmul x8_18 #x0000000000000002) (bvsub x8_16 x7_10))) (= x3_17 (bvsub #x0000000000000002 x3_15))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_acc5c8.smt2
Execution time of boolector: 0.9122 seconds
OUTPUT FROM boolector:
unsat

=== Cut #2 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #2
; Range assertion #22: or [and [smod (sub (uext x8_22 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_14 = x7_13, mul x8_24 2@64 = x8_22, x3_23 = add 2@64 x3_21], and [smod (sub (uext x8_22 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_21 <s 0@64, x7_14 = x7_13, mul x8_24 2@64 = add x8_22 x7_13, x3_23 = add 2@64 x3_21], and [smod (sub (uext x8_22 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_21 >=s 0@64, x7_14 = x8_22, mul x8_24 2@64 = sub x8_22 x7_13, x3_23 = sub 2@64 x3_21]]
; Range condition: ((x8_22@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_14 = x7_13 /\ x8_24 * 2 = x8_22 /\ x3_23 = 2 + x3_21 \/ ((x8_22@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_21 <s 0 /\ x7_14 = x7_13 /\ x8_24 * 2 = x8_22 + x7_13 /\ x3_23 = 2 + x3_21 \/ ((x8_22@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_21 >=s 0 /\ x7_14 = x8_22 /\ x8_24 * 2 = x8_22 - x7_13 /\ x3_23 = 2 - x3_21
; Output file: /tmp/outputqfbv_84387b.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_11 () (_ BitVec 1))
(declare-fun x8_target_10 () (_ BitVec 1))
(declare-fun x8_target_9 () (_ BitVec 1))
(declare-fun x8_target_8 () (_ BitVec 1))
(declare-fun x8_target_7 () (_ BitVec 1))
(declare-fun x8_target_6 () (_ BitVec 1))
(declare-fun x8_target_5 () (_ BitVec 1))
(declare-fun x8_target_4 () (_ BitVec 1))
(declare-fun x8_target_3 () (_ BitVec 1))
(declare-fun x8_target_2 () (_ BitVec 1))
(declare-fun x8_target_1 () (_ BitVec 1))
(declare-fun x8_lo_12 () (_ BitVec 2))
(declare-fun x8_lo_11 () (_ BitVec 2))
(declare-fun x8_lo_10 () (_ BitVec 2))
(declare-fun x8_lo_9 () (_ BitVec 2))
(declare-fun x8_lo_8 () (_ BitVec 2))
(declare-fun x8_lo_7 () (_ BitVec 2))
(declare-fun x8_lo_6 () (_ BitVec 2))
(declare-fun x8_lo_5 () (_ BitVec 2))
(declare-fun x8_lo_4 () (_ BitVec 2))
(declare-fun x8_lo_3 () (_ BitVec 2))
(declare-fun x8_lo_2 () (_ BitVec 2))
(declare-fun x8_lo_1 () (_ BitVec 1))
(declare-fun x8_24 () (_ BitVec 64))
(declare-fun x8_23 () (_ BitVec 64))
(declare-fun x8_22 () (_ BitVec 64))
(declare-fun x8_21 () (_ BitVec 64))
(declare-fun x8_20 () (_ BitVec 64))
(declare-fun x8_19 () (_ BitVec 64))
(declare-fun x8_18 () (_ BitVec 64))
(declare-fun x8_17 () (_ BitVec 64))
(declare-fun x8_16 () (_ BitVec 64))
(declare-fun x8_15 () (_ BitVec 64))
(declare-fun x8_14 () (_ BitVec 64))
(declare-fun x8_13 () (_ BitVec 64))
(declare-fun x8_12 () (_ BitVec 64))
(declare-fun x8_11 () (_ BitVec 64))
(declare-fun x8_10 () (_ BitVec 64))
(declare-fun x8_9 () (_ BitVec 64))
(declare-fun x8_8 () (_ BitVec 64))
(declare-fun x8_7 () (_ BitVec 64))
(declare-fun x8_6 () (_ BitVec 64))
(declare-fun x8_5 () (_ BitVec 64))
(declare-fun x8_4 () (_ BitVec 64))
(declare-fun x8_3 () (_ BitVec 64))
(declare-fun x8_2 () (_ BitVec 64))
(declare-fun x7_14 () (_ BitVec 64))
(declare-fun x7_13 () (_ BitVec 64))
(declare-fun x7_12 () (_ BitVec 64))
(declare-fun x7_11 () (_ BitVec 64))
(declare-fun x7_10 () (_ BitVec 64))
(declare-fun x7_9 () (_ BitVec 64))
(declare-fun x7_8 () (_ BitVec 64))
(declare-fun x7_7 () (_ BitVec 64))
(declare-fun x7_6 () (_ BitVec 64))
(declare-fun x7_5 () (_ BitVec 64))
(declare-fun x7_4 () (_ BitVec 64))
(declare-fun x7_3 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_11 () (_ BitVec 64))
(declare-fun x3_neg_10 () (_ BitVec 64))
(declare-fun x3_neg_9 () (_ BitVec 64))
(declare-fun x3_neg_8 () (_ BitVec 64))
(declare-fun x3_neg_7 () (_ BitVec 64))
(declare-fun x3_neg_6 () (_ BitVec 64))
(declare-fun x3_neg_5 () (_ BitVec 64))
(declare-fun x3_neg_4 () (_ BitVec 64))
(declare-fun x3_neg_3 () (_ BitVec 64))
(declare-fun x3_neg_2 () (_ BitVec 64))
(declare-fun x3_neg_1 () (_ BitVec 64))
(declare-fun x3_23 () (_ BitVec 64))
(declare-fun x3_22 () (_ BitVec 64))
(declare-fun x3_21 () (_ BitVec 64))
(declare-fun x3_20 () (_ BitVec 64))
(declare-fun x3_19 () (_ BitVec 64))
(declare-fun x3_18 () (_ BitVec 64))
(declare-fun x3_17 () (_ BitVec 64))
(declare-fun x3_16 () (_ BitVec 64))
(declare-fun x3_15 () (_ BitVec 64))
(declare-fun x3_14 () (_ BitVec 64))
(declare-fun x3_13 () (_ BitVec 64))
(declare-fun x3_12 () (_ BitVec 64))
(declare-fun x3_11 () (_ BitVec 64))
(declare-fun x3_10 () (_ BitVec 64))
(declare-fun x3_9 () (_ BitVec 64))
(declare-fun x3_8 () (_ BitVec 64))
(declare-fun x3_7 () (_ BitVec 64))
(declare-fun x3_6 () (_ BitVec 64))
(declare-fun x3_5 () (_ BitVec 64))
(declare-fun x3_4 () (_ BitVec 64))
(declare-fun x3_3 () (_ BitVec 64))
(declare-fun x3_2 () (_ BitVec 64))
(declare-fun x10_neg_11 () (_ BitVec 64))
(declare-fun x10_neg_10 () (_ BitVec 64))
(declare-fun x10_neg_9 () (_ BitVec 64))
(declare-fun x10_neg_8 () (_ BitVec 64))
(declare-fun x10_neg_7 () (_ BitVec 64))
(declare-fun x10_neg_6 () (_ BitVec 64))
(declare-fun x10_neg_5 () (_ BitVec 64))
(declare-fun x10_neg_4 () (_ BitVec 64))
(declare-fun x10_neg_3 () (_ BitVec 64))
(declare-fun x10_neg_2 () (_ BitVec 64))
(declare-fun x10_neg_1 () (_ BitVec 64))
(declare-fun x10_22 () (_ BitVec 64))
(declare-fun x10_21 () (_ BitVec 64))
(declare-fun x10_20 () (_ BitVec 64))
(declare-fun x10_19 () (_ BitVec 64))
(declare-fun x10_18 () (_ BitVec 64))
(declare-fun x10_17 () (_ BitVec 64))
(declare-fun x10_16 () (_ BitVec 64))
(declare-fun x10_15 () (_ BitVec 64))
(declare-fun x10_14 () (_ BitVec 64))
(declare-fun x10_13 () (_ BitVec 64))
(declare-fun x10_12 () (_ BitVec 64))
(declare-fun x10_11 () (_ BitVec 64))
(declare-fun x10_10 () (_ BitVec 64))
(declare-fun x10_9 () (_ BitVec 64))
(declare-fun x10_8 () (_ BitVec 64))
(declare-fun x10_7 () (_ BitVec 64))
(declare-fun x10_6 () (_ BitVec 64))
(declare-fun x10_5 () (_ BitVec 64))
(declare-fun x10_4 () (_ BitVec 64))
(declare-fun x10_3 () (_ BitVec 64))
(declare-fun x10_2 () (_ BitVec 64))
(declare-fun x10_1 () (_ BitVec 64))
(declare-fun ne_12 () (_ BitVec 1))
(declare-fun ne_11 () (_ BitVec 1))
(declare-fun ne_10 () (_ BitVec 1))
(declare-fun ne_9 () (_ BitVec 1))
(declare-fun ne_8 () (_ BitVec 1))
(declare-fun ne_7 () (_ BitVec 1))
(declare-fun ne_6 () (_ BitVec 1))
(declare-fun ne_5 () (_ BitVec 1))
(declare-fun ne_4 () (_ BitVec 1))
(declare-fun ne_3 () (_ BitVec 1))
(declare-fun ne_2 () (_ BitVec 1))
(declare-fun ne_1 () (_ BitVec 1))
(declare-fun ge_33 () (_ BitVec 1))
(declare-fun ge_32 () (_ BitVec 1))
(declare-fun ge_31 () (_ BitVec 1))
(declare-fun ge_30 () (_ BitVec 1))
(declare-fun ge_29 () (_ BitVec 1))
(declare-fun ge_28 () (_ BitVec 1))
(declare-fun ge_27 () (_ BitVec 1))
(declare-fun ge_26 () (_ BitVec 1))
(declare-fun ge_25 () (_ BitVec 1))
(declare-fun ge_24 () (_ BitVec 1))
(declare-fun ge_23 () (_ BitVec 1))
(declare-fun ge_22 () (_ BitVec 1))
(declare-fun ge_21 () (_ BitVec 1))
(declare-fun ge_20 () (_ BitVec 1))
(declare-fun ge_19 () (_ BitVec 1))
(declare-fun ge_18 () (_ BitVec 1))
(declare-fun ge_17 () (_ BitVec 1))
(declare-fun ge_16 () (_ BitVec 1))
(declare-fun ge_15 () (_ BitVec 1))
(declare-fun ge_14 () (_ BitVec 1))
(declare-fun ge_13 () (_ BitVec 1))
(declare-fun ge_12 () (_ BitVec 1))
(declare-fun ge_11 () (_ BitVec 1))
(declare-fun ge_10 () (_ BitVec 1))
(declare-fun ge_9 () (_ BitVec 1))
(declare-fun ge_8 () (_ BitVec 1))
(declare-fun ge_7 () (_ BitVec 1))
(declare-fun ge_6 () (_ BitVec 1))
(declare-fun ge_5 () (_ BitVec 1))
(declare-fun ge_4 () (_ BitVec 1))
(declare-fun ge_3 () (_ BitVec 1))
(declare-fun ge_2 () (_ BitVec 1))
(declare-fun ge_1 () (_ BitVec 1))
(declare-fun g_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun dc_118 () (_ BitVec 64))
(declare-fun dc_117 () (_ BitVec 1))
(declare-fun dc_116 () (_ BitVec 62))
(declare-fun dc_115 () (_ BitVec 1))
(declare-fun dc_114 () (_ BitVec 1))
(declare-fun dc_113 () (_ BitVec 1))
(declare-fun dc_112 () (_ BitVec 63))
(declare-fun dc_111 () (_ BitVec 64))
(declare-fun dc_110 () (_ BitVec 1))
(declare-fun dc_109 () (_ BitVec 62))
(declare-fun dc_108 () (_ BitVec 1))
(declare-fun dc_107 () (_ BitVec 1))
(declare-fun dc_106 () (_ BitVec 1))
(declare-fun dc_105 () (_ BitVec 63))
(declare-fun dc_104 () (_ BitVec 64))
(declare-fun dc_103 () (_ BitVec 1))
(declare-fun dc_102 () (_ BitVec 62))
(declare-fun dc_101 () (_ BitVec 1))
(declare-fun dc_100 () (_ BitVec 1))
(declare-fun dc_99 () (_ BitVec 1))
(declare-fun dc_98 () (_ BitVec 63))
(declare-fun dc_97 () (_ BitVec 64))
(declare-fun dc_96 () (_ BitVec 1))
(declare-fun dc_95 () (_ BitVec 62))
(declare-fun dc_94 () (_ BitVec 1))
(declare-fun dc_93 () (_ BitVec 1))
(declare-fun dc_92 () (_ BitVec 1))
(declare-fun dc_91 () (_ BitVec 63))
(declare-fun dc_90 () (_ BitVec 64))
(declare-fun dc_89 () (_ BitVec 1))
(declare-fun dc_88 () (_ BitVec 62))
(declare-fun dc_87 () (_ BitVec 1))
(declare-fun dc_86 () (_ BitVec 1))
(declare-fun dc_85 () (_ BitVec 1))
(declare-fun dc_84 () (_ BitVec 63))
(declare-fun dc_83 () (_ BitVec 64))
(declare-fun dc_82 () (_ BitVec 1))
(declare-fun dc_81 () (_ BitVec 62))
(declare-fun dc_80 () (_ BitVec 1))
(declare-fun dc_79 () (_ BitVec 1))
(declare-fun dc_78 () (_ BitVec 1))
(declare-fun dc_77 () (_ BitVec 63))
(declare-fun dc_76 () (_ BitVec 64))
(declare-fun dc_75 () (_ BitVec 1))
(declare-fun dc_74 () (_ BitVec 62))
(declare-fun dc_73 () (_ BitVec 1))
(declare-fun dc_72 () (_ BitVec 1))
(declare-fun dc_71 () (_ BitVec 1))
(declare-fun dc_70 () (_ BitVec 63))
(declare-fun dc_69 () (_ BitVec 64))
(declare-fun dc_68 () (_ BitVec 1))
(declare-fun dc_67 () (_ BitVec 62))
(declare-fun dc_66 () (_ BitVec 1))
(declare-fun dc_65 () (_ BitVec 1))
(declare-fun dc_64 () (_ BitVec 1))
(declare-fun dc_63 () (_ BitVec 63))
(declare-fun dc_62 () (_ BitVec 64))
(declare-fun dc_61 () (_ BitVec 1))
(declare-fun dc_60 () (_ BitVec 62))
(declare-fun dc_59 () (_ BitVec 1))
(declare-fun dc_58 () (_ BitVec 1))
(declare-fun dc_57 () (_ BitVec 1))
(declare-fun dc_56 () (_ BitVec 63))
(declare-fun dc_55 () (_ BitVec 64))
(declare-fun dc_54 () (_ BitVec 1))
(declare-fun dc_53 () (_ BitVec 62))
(declare-fun dc_52 () (_ BitVec 1))
(declare-fun dc_51 () (_ BitVec 1))
(declare-fun dc_50 () (_ BitVec 1))
(declare-fun dc_49 () (_ BitVec 63))
(declare-fun dc_48 () (_ BitVec 64))
(declare-fun dc_47 () (_ BitVec 1))
(declare-fun dc_46 () (_ BitVec 62))
(declare-fun dc_45 () (_ BitVec 1))
(declare-fun dc_44 () (_ BitVec 1))
(declare-fun dc_43 () (_ BitVec 1))
(declare-fun dc_42 () (_ BitVec 63))
(declare-fun dc_41 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (= x7_3 (bvadd (bvadd f_0_low60_0_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_2 (bvadd (bvadd g_0_low60_0_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_0_1)) (bvsle f_0_low60_0_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_0_1)) (bvsle g_0_low60_0_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_3) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #x0000000000000001 #x0000000000000001)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_41 ((_ extract 63 1) x8_2)) (= x8_lo_1 ((_ extract 0 0) x8_2))))
(assert (= ne_1 (bvand x8_lo_1 #b1)))
(assert (= x10_1 (ite (= ne_1 #b1) x7_3 #x0000000000000000)))
(assert (and (= ge_1 ((_ extract 63 63) #x0000000000000001)) (= dc_42 ((_ extract 62 0) #x0000000000000001))))
(assert (= ge_2 (bvnot ge_1)))
(assert (= ge_3 (ite (= ne_1 #b1) ge_2 #b0)))
(assert (and (= dc_43 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_2 (ite (= ge_3 #b1) x3_neg_1 #x0000000000000001)))
(assert (and (= dc_44 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_2 (ite (= ge_3 #b1) x10_neg_1 x10_1)))
(assert (= x7_4 (ite (= ge_3 #b1) x8_2 x7_3)))
(assert (and (= dc_45 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2)))) (= x8_3 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2))))))
(assert (= x3_3 (bvadd x3_2 #x0000000000000002)))
(assert (and (= dc_46 ((_ extract 63 2) x8_3)) (= x8_lo_2 ((_ extract 1 0) x8_3))))
(assert (and (= x8_target_1 ((_ extract 1 1) x8_lo_2)) (= dc_47 ((_ extract 0 0) x8_lo_2))))
(assert (= ne_2 (bvand x8_target_1 #b1)))
(assert (and (= x8_4 ((_ sign_extend 1) ((_ extract 63 1) x8_3))) (= dc_48 ((_ zero_extend 63) ((_ extract 0 0) x8_3)))))
(assert true)
(assert (= x10_3 (ite (= ne_2 #b1) x7_4 #x0000000000000000)))
(assert (and (= ge_4 ((_ extract 63 63) x3_3)) (= dc_49 ((_ extract 62 0) x3_3))))
(assert (= ge_5 (bvnot ge_4)))
(assert (= ge_6 (ite (= ne_2 #b1) ge_5 #b0)))
(assert (and (= dc_50 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_4 (ite (= ge_6 #b1) x3_neg_2 x3_3)))
(assert (and (= dc_51 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_4 (ite (= ge_6 #b1) x10_neg_2 x10_3)))
(assert (= x7_5 (ite (= ge_6 #b1) x8_4 x7_4)))
(assert (and (= dc_52 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4)))) (= x8_5 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4))))))
(assert (= x3_5 (bvadd x3_4 #x0000000000000002)))
(assert (and (= dc_53 ((_ extract 63 2) x8_5)) (= x8_lo_3 ((_ extract 1 0) x8_5))))
(assert (and (= x8_target_2 ((_ extract 1 1) x8_lo_3)) (= dc_54 ((_ extract 0 0) x8_lo_3))))
(assert (= ne_3 (bvand x8_target_2 #b1)))
(assert (and (= x8_6 ((_ sign_extend 1) ((_ extract 63 1) x8_5))) (= dc_55 ((_ zero_extend 63) ((_ extract 0 0) x8_5)))))
(assert true)
(assert (= x10_5 (ite (= ne_3 #b1) x7_5 #x0000000000000000)))
(assert (and (= ge_7 ((_ extract 63 63) x3_5)) (= dc_56 ((_ extract 62 0) x3_5))))
(assert (= ge_8 (bvnot ge_7)))
(assert (= ge_9 (ite (= ne_3 #b1) ge_8 #b0)))
(assert (and (= dc_57 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_6 (ite (= ge_9 #b1) x3_neg_3 x3_5)))
(assert (and (= dc_58 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_6 (ite (= ge_9 #b1) x10_neg_3 x10_5)))
(assert (= x7_6 (ite (= ge_9 #b1) x8_6 x7_5)))
(assert (and (= dc_59 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6)))) (= x8_7 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6))))))
(assert (= x3_7 (bvadd x3_6 #x0000000000000002)))
(assert (and (= dc_60 ((_ extract 63 2) x8_7)) (= x8_lo_4 ((_ extract 1 0) x8_7))))
(assert (and (= x8_target_3 ((_ extract 1 1) x8_lo_4)) (= dc_61 ((_ extract 0 0) x8_lo_4))))
(assert (= ne_4 (bvand x8_target_3 #b1)))
(assert (and (= x8_8 ((_ sign_extend 1) ((_ extract 63 1) x8_7))) (= dc_62 ((_ zero_extend 63) ((_ extract 0 0) x8_7)))))
(assert true)
(assert (= x10_7 (ite (= ne_4 #b1) x7_6 #x0000000000000000)))
(assert (and (= ge_10 ((_ extract 63 63) x3_7)) (= dc_63 ((_ extract 62 0) x3_7))))
(assert (= ge_11 (bvnot ge_10)))
(assert (= ge_12 (ite (= ne_4 #b1) ge_11 #b0)))
(assert (and (= dc_64 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_7))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_4 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_7))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_8 (ite (= ge_12 #b1) x3_neg_4 x3_7)))
(assert (and (= dc_65 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_7))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_4 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_7))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_8 (ite (= ge_12 #b1) x10_neg_4 x10_7)))
(assert (= x7_7 (ite (= ge_12 #b1) x8_8 x7_6)))
(assert (and (= dc_66 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_8) ((_ zero_extend 1) x10_8)))) (= x8_9 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_8) ((_ zero_extend 1) x10_8))))))
(assert (= x3_9 (bvadd x3_8 #x0000000000000002)))
(assert (and (= dc_67 ((_ extract 63 2) x8_9)) (= x8_lo_5 ((_ extract 1 0) x8_9))))
(assert (and (= x8_target_4 ((_ extract 1 1) x8_lo_5)) (= dc_68 ((_ extract 0 0) x8_lo_5))))
(assert (= ne_5 (bvand x8_target_4 #b1)))
(assert (and (= x8_10 ((_ sign_extend 1) ((_ extract 63 1) x8_9))) (= dc_69 ((_ zero_extend 63) ((_ extract 0 0) x8_9)))))
(assert true)
(assert (= x10_9 (ite (= ne_5 #b1) x7_7 #x0000000000000000)))
(assert (and (= ge_13 ((_ extract 63 63) x3_9)) (= dc_70 ((_ extract 62 0) x3_9))))
(assert (= ge_14 (bvnot ge_13)))
(assert (= ge_15 (ite (= ne_5 #b1) ge_14 #b0)))
(assert (and (= dc_71 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_9))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_5 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_9))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_10 (ite (= ge_15 #b1) x3_neg_5 x3_9)))
(assert (and (= dc_72 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_9))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_5 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_9))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_10 (ite (= ge_15 #b1) x10_neg_5 x10_9)))
(assert (= x7_8 (ite (= ge_15 #b1) x8_10 x7_7)))
(assert (and (= dc_73 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_10) ((_ zero_extend 1) x10_10)))) (= x8_11 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_10) ((_ zero_extend 1) x10_10))))))
(assert (= x3_11 (bvadd x3_10 #x0000000000000002)))
(assert (and (= dc_74 ((_ extract 63 2) x8_11)) (= x8_lo_6 ((_ extract 1 0) x8_11))))
(assert (and (= x8_target_5 ((_ extract 1 1) x8_lo_6)) (= dc_75 ((_ extract 0 0) x8_lo_6))))
(assert (= ne_6 (bvand x8_target_5 #b1)))
(assert (and (= x8_12 ((_ sign_extend 1) ((_ extract 63 1) x8_11))) (= dc_76 ((_ zero_extend 63) ((_ extract 0 0) x8_11)))))
(assert true)
(assert (= x10_11 (ite (= ne_6 #b1) x7_8 #x0000000000000000)))
(assert (and (= ge_16 ((_ extract 63 63) x3_11)) (= dc_77 ((_ extract 62 0) x3_11))))
(assert (= ge_17 (bvnot ge_16)))
(assert (= ge_18 (ite (= ne_6 #b1) ge_17 #b0)))
(assert (and (= dc_78 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_11))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_6 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_11))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_12 (ite (= ge_18 #b1) x3_neg_6 x3_11)))
(assert (and (= dc_79 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_11))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_6 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_11))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_12 (ite (= ge_18 #b1) x10_neg_6 x10_11)))
(assert (= x7_9 (ite (= ge_18 #b1) x8_12 x7_8)))
(assert (and (= dc_80 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_12) ((_ zero_extend 1) x10_12)))) (= x8_13 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_12) ((_ zero_extend 1) x10_12))))))
(assert (= x3_13 (bvadd x3_12 #x0000000000000002)))
(assert (and (= dc_81 ((_ extract 63 2) x8_13)) (= x8_lo_7 ((_ extract 1 0) x8_13))))
(assert (and (= x8_target_6 ((_ extract 1 1) x8_lo_7)) (= dc_82 ((_ extract 0 0) x8_lo_7))))
(assert (= ne_7 (bvand x8_target_6 #b1)))
(assert (and (= x8_14 ((_ sign_extend 1) ((_ extract 63 1) x8_13))) (= dc_83 ((_ zero_extend 63) ((_ extract 0 0) x8_13)))))
(assert true)
(assert (= x10_13 (ite (= ne_7 #b1) x7_9 #x0000000000000000)))
(assert (and (= ge_19 ((_ extract 63 63) x3_13)) (= dc_84 ((_ extract 62 0) x3_13))))
(assert (= ge_20 (bvnot ge_19)))
(assert (= ge_21 (ite (= ne_7 #b1) ge_20 #b0)))
(assert (and (= dc_85 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_13))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_7 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_13))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_14 (ite (= ge_21 #b1) x3_neg_7 x3_13)))
(assert (and (= dc_86 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_13))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_7 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_13))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_14 (ite (= ge_21 #b1) x10_neg_7 x10_13)))
(assert (= x7_10 (ite (= ge_21 #b1) x8_14 x7_9)))
(assert (and (= dc_87 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_14) ((_ zero_extend 1) x10_14)))) (= x8_15 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_14) ((_ zero_extend 1) x10_14))))))
(assert (= x3_15 (bvadd x3_14 #x0000000000000002)))
(assert (and (= dc_88 ((_ extract 63 2) x8_15)) (= x8_lo_8 ((_ extract 1 0) x8_15))))
(assert (and (= x8_target_7 ((_ extract 1 1) x8_lo_8)) (= dc_89 ((_ extract 0 0) x8_lo_8))))
(assert (= ne_8 (bvand x8_target_7 #b1)))
(assert (and (= x8_16 ((_ sign_extend 1) ((_ extract 63 1) x8_15))) (= dc_90 ((_ zero_extend 63) ((_ extract 0 0) x8_15)))))
(assert true)
(assert (= x10_15 (ite (= ne_8 #b1) x7_10 #x0000000000000000)))
(assert (and (= ge_22 ((_ extract 63 63) x3_15)) (= dc_91 ((_ extract 62 0) x3_15))))
(assert (= ge_23 (bvnot ge_22)))
(assert (= ge_24 (ite (= ne_8 #b1) ge_23 #b0)))
(assert (and (= dc_92 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_15))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_8 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_15))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_16 (ite (= ge_24 #b1) x3_neg_8 x3_15)))
(assert (and (= dc_93 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_15))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_8 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_15))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_16 (ite (= ge_24 #b1) x10_neg_8 x10_15)))
(assert (= x7_11 (ite (= ge_24 #b1) x8_16 x7_10)))
(assert (and (= dc_94 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_16) ((_ zero_extend 1) x10_16)))) (= x8_17 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_16) ((_ zero_extend 1) x10_16))))))
(assert (= x3_17 (bvadd x3_16 #x0000000000000002)))
(assert (and (= dc_95 ((_ extract 63 2) x8_17)) (= x8_lo_9 ((_ extract 1 0) x8_17))))
(assert (and (= x8_target_8 ((_ extract 1 1) x8_lo_9)) (= dc_96 ((_ extract 0 0) x8_lo_9))))
(assert (= ne_9 (bvand x8_target_8 #b1)))
(assert (and (= x8_18 ((_ sign_extend 1) ((_ extract 63 1) x8_17))) (= dc_97 ((_ zero_extend 63) ((_ extract 0 0) x8_17)))))
(assert true)
(assert (= x10_17 (ite (= ne_9 #b1) x7_11 #x0000000000000000)))
(assert (and (= ge_25 ((_ extract 63 63) x3_17)) (= dc_98 ((_ extract 62 0) x3_17))))
(assert (= ge_26 (bvnot ge_25)))
(assert (= ge_27 (ite (= ne_9 #b1) ge_26 #b0)))
(assert (and (= dc_99 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_17))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_9 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_17))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_18 (ite (= ge_27 #b1) x3_neg_9 x3_17)))
(assert (and (= dc_100 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_17))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_9 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_17))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_18 (ite (= ge_27 #b1) x10_neg_9 x10_17)))
(assert (= x7_12 (ite (= ge_27 #b1) x8_18 x7_11)))
(assert (and (= dc_101 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_18) ((_ zero_extend 1) x10_18)))) (= x8_19 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_18) ((_ zero_extend 1) x10_18))))))
(assert (= x3_19 (bvadd x3_18 #x0000000000000002)))
(assert (and (= dc_102 ((_ extract 63 2) x8_19)) (= x8_lo_10 ((_ extract 1 0) x8_19))))
(assert (and (= x8_target_9 ((_ extract 1 1) x8_lo_10)) (= dc_103 ((_ extract 0 0) x8_lo_10))))
(assert (= ne_10 (bvand x8_target_9 #b1)))
(assert (and (= x8_20 ((_ sign_extend 1) ((_ extract 63 1) x8_19))) (= dc_104 ((_ zero_extend 63) ((_ extract 0 0) x8_19)))))
(assert true)
(assert (= x10_19 (ite (= ne_10 #b1) x7_12 #x0000000000000000)))
(assert (and (= ge_28 ((_ extract 63 63) x3_19)) (= dc_105 ((_ extract 62 0) x3_19))))
(assert (= ge_29 (bvnot ge_28)))
(assert (= ge_30 (ite (= ne_10 #b1) ge_29 #b0)))
(assert (and (= dc_106 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_19))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_10 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_19))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_20 (ite (= ge_30 #b1) x3_neg_10 x3_19)))
(assert (and (= dc_107 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_19))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_10 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_19))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_20 (ite (= ge_30 #b1) x10_neg_10 x10_19)))
(assert (= x7_13 (ite (= ge_30 #b1) x8_20 x7_12)))
(assert (and (= dc_108 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_20) ((_ zero_extend 1) x10_20)))) (= x8_21 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_20) ((_ zero_extend 1) x10_20))))))
(assert (= x3_21 (bvadd x3_20 #x0000000000000002)))
(assert (and (= dc_109 ((_ extract 63 2) x8_21)) (= x8_lo_11 ((_ extract 1 0) x8_21))))
(assert (and (= x8_target_10 ((_ extract 1 1) x8_lo_11)) (= dc_110 ((_ extract 0 0) x8_lo_11))))
(assert (= ne_11 (bvand x8_target_10 #b1)))
(assert (and (= x8_22 ((_ sign_extend 1) ((_ extract 63 1) x8_21))) (= dc_111 ((_ zero_extend 63) ((_ extract 0 0) x8_21)))))
(assert true)
(assert (= x10_21 (ite (= ne_11 #b1) x7_13 #x0000000000000000)))
(assert (and (= ge_31 ((_ extract 63 63) x3_21)) (= dc_112 ((_ extract 62 0) x3_21))))
(assert (= ge_32 (bvnot ge_31)))
(assert (= ge_33 (ite (= ne_11 #b1) ge_32 #b0)))
(assert (and (= dc_113 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_21))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_11 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_21))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_22 (ite (= ge_33 #b1) x3_neg_11 x3_21)))
(assert (and (= dc_114 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_21))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_11 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_21))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_22 (ite (= ge_33 #b1) x10_neg_11 x10_21)))
(assert (= x7_14 (ite (= ge_33 #b1) x8_22 x7_13)))
(assert (and (= dc_115 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_22) ((_ zero_extend 1) x10_22)))) (= x8_23 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_22) ((_ zero_extend 1) x10_22))))))
(assert (= x3_23 (bvadd x3_22 #x0000000000000002)))
(assert (and (= dc_116 ((_ extract 63 2) x8_23)) (= x8_lo_12 ((_ extract 1 0) x8_23))))
(assert (and (= x8_target_11 ((_ extract 1 1) x8_lo_12)) (= dc_117 ((_ extract 0 0) x8_lo_12))))
(assert (= ne_12 (bvand x8_target_11 #b1)))
(assert (and (= x8_24 ((_ sign_extend 1) ((_ extract 63 1) x8_23))) (= dc_118 ((_ zero_extend 63) ((_ extract 0 0) x8_23)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_22) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_14 x7_13)) (= (bvmul x8_24 #x0000000000000002) x8_22)) (= x3_23 (bvadd #x0000000000000002 x3_21))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_22) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_21 #x0000000000000000)) (= x7_14 x7_13)) (= (bvmul x8_24 #x0000000000000002) (bvadd x8_22 x7_13))) (= x3_23 (bvadd #x0000000000000002 x3_21)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_22) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_21 #x0000000000000000)) (= x7_14 x8_22)) (= (bvmul x8_24 #x0000000000000002) (bvsub x8_22 x7_13))) (= x3_23 (bvsub #x0000000000000002 x3_21))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_9054a7.smt2
Execution time of boolector: 0.8660 seconds
OUTPUT FROM boolector:
unsat

=== Cut #2 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #2
; Range assertion #24: or [and [smod (sub (uext x8_26 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_16 = x7_15, mul x8_28 2@64 = x8_26, x3_27 = add 2@64 x3_25], and [smod (sub (uext x8_26 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_25 <s 0@64, x7_16 = x7_15, mul x8_28 2@64 = add x8_26 x7_15, x3_27 = add 2@64 x3_25], and [smod (sub (uext x8_26 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_25 >=s 0@64, x7_16 = x8_26, mul x8_28 2@64 = sub x8_26 x7_15, x3_27 = sub 2@64 x3_25]]
; Range condition: ((x8_26@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_16 = x7_15 /\ x8_28 * 2 = x8_26 /\ x3_27 = 2 + x3_25 \/ ((x8_26@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_25 <s 0 /\ x7_16 = x7_15 /\ x8_28 * 2 = x8_26 + x7_15 /\ x3_27 = 2 + x3_25 \/ ((x8_26@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_25 >=s 0 /\ x7_16 = x8_26 /\ x8_28 * 2 = x8_26 - x7_15 /\ x3_27 = 2 - x3_25
; Output file: /tmp/outputqfbv_23bcaa.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_13 () (_ BitVec 1))
(declare-fun x8_target_12 () (_ BitVec 1))
(declare-fun x8_target_11 () (_ BitVec 1))
(declare-fun x8_target_10 () (_ BitVec 1))
(declare-fun x8_target_9 () (_ BitVec 1))
(declare-fun x8_target_8 () (_ BitVec 1))
(declare-fun x8_target_7 () (_ BitVec 1))
(declare-fun x8_target_6 () (_ BitVec 1))
(declare-fun x8_target_5 () (_ BitVec 1))
(declare-fun x8_target_4 () (_ BitVec 1))
(declare-fun x8_target_3 () (_ BitVec 1))
(declare-fun x8_target_2 () (_ BitVec 1))
(declare-fun x8_target_1 () (_ BitVec 1))
(declare-fun x8_lo_14 () (_ BitVec 2))
(declare-fun x8_lo_13 () (_ BitVec 2))
(declare-fun x8_lo_12 () (_ BitVec 2))
(declare-fun x8_lo_11 () (_ BitVec 2))
(declare-fun x8_lo_10 () (_ BitVec 2))
(declare-fun x8_lo_9 () (_ BitVec 2))
(declare-fun x8_lo_8 () (_ BitVec 2))
(declare-fun x8_lo_7 () (_ BitVec 2))
(declare-fun x8_lo_6 () (_ BitVec 2))
(declare-fun x8_lo_5 () (_ BitVec 2))
(declare-fun x8_lo_4 () (_ BitVec 2))
(declare-fun x8_lo_3 () (_ BitVec 2))
(declare-fun x8_lo_2 () (_ BitVec 2))
(declare-fun x8_lo_1 () (_ BitVec 1))
(declare-fun x8_28 () (_ BitVec 64))
(declare-fun x8_27 () (_ BitVec 64))
(declare-fun x8_26 () (_ BitVec 64))
(declare-fun x8_25 () (_ BitVec 64))
(declare-fun x8_24 () (_ BitVec 64))
(declare-fun x8_23 () (_ BitVec 64))
(declare-fun x8_22 () (_ BitVec 64))
(declare-fun x8_21 () (_ BitVec 64))
(declare-fun x8_20 () (_ BitVec 64))
(declare-fun x8_19 () (_ BitVec 64))
(declare-fun x8_18 () (_ BitVec 64))
(declare-fun x8_17 () (_ BitVec 64))
(declare-fun x8_16 () (_ BitVec 64))
(declare-fun x8_15 () (_ BitVec 64))
(declare-fun x8_14 () (_ BitVec 64))
(declare-fun x8_13 () (_ BitVec 64))
(declare-fun x8_12 () (_ BitVec 64))
(declare-fun x8_11 () (_ BitVec 64))
(declare-fun x8_10 () (_ BitVec 64))
(declare-fun x8_9 () (_ BitVec 64))
(declare-fun x8_8 () (_ BitVec 64))
(declare-fun x8_7 () (_ BitVec 64))
(declare-fun x8_6 () (_ BitVec 64))
(declare-fun x8_5 () (_ BitVec 64))
(declare-fun x8_4 () (_ BitVec 64))
(declare-fun x8_3 () (_ BitVec 64))
(declare-fun x8_2 () (_ BitVec 64))
(declare-fun x7_16 () (_ BitVec 64))
(declare-fun x7_15 () (_ BitVec 64))
(declare-fun x7_14 () (_ BitVec 64))
(declare-fun x7_13 () (_ BitVec 64))
(declare-fun x7_12 () (_ BitVec 64))
(declare-fun x7_11 () (_ BitVec 64))
(declare-fun x7_10 () (_ BitVec 64))
(declare-fun x7_9 () (_ BitVec 64))
(declare-fun x7_8 () (_ BitVec 64))
(declare-fun x7_7 () (_ BitVec 64))
(declare-fun x7_6 () (_ BitVec 64))
(declare-fun x7_5 () (_ BitVec 64))
(declare-fun x7_4 () (_ BitVec 64))
(declare-fun x7_3 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_13 () (_ BitVec 64))
(declare-fun x3_neg_12 () (_ BitVec 64))
(declare-fun x3_neg_11 () (_ BitVec 64))
(declare-fun x3_neg_10 () (_ BitVec 64))
(declare-fun x3_neg_9 () (_ BitVec 64))
(declare-fun x3_neg_8 () (_ BitVec 64))
(declare-fun x3_neg_7 () (_ BitVec 64))
(declare-fun x3_neg_6 () (_ BitVec 64))
(declare-fun x3_neg_5 () (_ BitVec 64))
(declare-fun x3_neg_4 () (_ BitVec 64))
(declare-fun x3_neg_3 () (_ BitVec 64))
(declare-fun x3_neg_2 () (_ BitVec 64))
(declare-fun x3_neg_1 () (_ BitVec 64))
(declare-fun x3_27 () (_ BitVec 64))
(declare-fun x3_26 () (_ BitVec 64))
(declare-fun x3_25 () (_ BitVec 64))
(declare-fun x3_24 () (_ BitVec 64))
(declare-fun x3_23 () (_ BitVec 64))
(declare-fun x3_22 () (_ BitVec 64))
(declare-fun x3_21 () (_ BitVec 64))
(declare-fun x3_20 () (_ BitVec 64))
(declare-fun x3_19 () (_ BitVec 64))
(declare-fun x3_18 () (_ BitVec 64))
(declare-fun x3_17 () (_ BitVec 64))
(declare-fun x3_16 () (_ BitVec 64))
(declare-fun x3_15 () (_ BitVec 64))
(declare-fun x3_14 () (_ BitVec 64))
(declare-fun x3_13 () (_ BitVec 64))
(declare-fun x3_12 () (_ BitVec 64))
(declare-fun x3_11 () (_ BitVec 64))
(declare-fun x3_10 () (_ BitVec 64))
(declare-fun x3_9 () (_ BitVec 64))
(declare-fun x3_8 () (_ BitVec 64))
(declare-fun x3_7 () (_ BitVec 64))
(declare-fun x3_6 () (_ BitVec 64))
(declare-fun x3_5 () (_ BitVec 64))
(declare-fun x3_4 () (_ BitVec 64))
(declare-fun x3_3 () (_ BitVec 64))
(declare-fun x3_2 () (_ BitVec 64))
(declare-fun x10_neg_13 () (_ BitVec 64))
(declare-fun x10_neg_12 () (_ BitVec 64))
(declare-fun x10_neg_11 () (_ BitVec 64))
(declare-fun x10_neg_10 () (_ BitVec 64))
(declare-fun x10_neg_9 () (_ BitVec 64))
(declare-fun x10_neg_8 () (_ BitVec 64))
(declare-fun x10_neg_7 () (_ BitVec 64))
(declare-fun x10_neg_6 () (_ BitVec 64))
(declare-fun x10_neg_5 () (_ BitVec 64))
(declare-fun x10_neg_4 () (_ BitVec 64))
(declare-fun x10_neg_3 () (_ BitVec 64))
(declare-fun x10_neg_2 () (_ BitVec 64))
(declare-fun x10_neg_1 () (_ BitVec 64))
(declare-fun x10_26 () (_ BitVec 64))
(declare-fun x10_25 () (_ BitVec 64))
(declare-fun x10_24 () (_ BitVec 64))
(declare-fun x10_23 () (_ BitVec 64))
(declare-fun x10_22 () (_ BitVec 64))
(declare-fun x10_21 () (_ BitVec 64))
(declare-fun x10_20 () (_ BitVec 64))
(declare-fun x10_19 () (_ BitVec 64))
(declare-fun x10_18 () (_ BitVec 64))
(declare-fun x10_17 () (_ BitVec 64))
(declare-fun x10_16 () (_ BitVec 64))
(declare-fun x10_15 () (_ BitVec 64))
(declare-fun x10_14 () (_ BitVec 64))
(declare-fun x10_13 () (_ BitVec 64))
(declare-fun x10_12 () (_ BitVec 64))
(declare-fun x10_11 () (_ BitVec 64))
(declare-fun x10_10 () (_ BitVec 64))
(declare-fun x10_9 () (_ BitVec 64))
(declare-fun x10_8 () (_ BitVec 64))
(declare-fun x10_7 () (_ BitVec 64))
(declare-fun x10_6 () (_ BitVec 64))
(declare-fun x10_5 () (_ BitVec 64))
(declare-fun x10_4 () (_ BitVec 64))
(declare-fun x10_3 () (_ BitVec 64))
(declare-fun x10_2 () (_ BitVec 64))
(declare-fun x10_1 () (_ BitVec 64))
(declare-fun ne_14 () (_ BitVec 1))
(declare-fun ne_13 () (_ BitVec 1))
(declare-fun ne_12 () (_ BitVec 1))
(declare-fun ne_11 () (_ BitVec 1))
(declare-fun ne_10 () (_ BitVec 1))
(declare-fun ne_9 () (_ BitVec 1))
(declare-fun ne_8 () (_ BitVec 1))
(declare-fun ne_7 () (_ BitVec 1))
(declare-fun ne_6 () (_ BitVec 1))
(declare-fun ne_5 () (_ BitVec 1))
(declare-fun ne_4 () (_ BitVec 1))
(declare-fun ne_3 () (_ BitVec 1))
(declare-fun ne_2 () (_ BitVec 1))
(declare-fun ne_1 () (_ BitVec 1))
(declare-fun ge_39 () (_ BitVec 1))
(declare-fun ge_38 () (_ BitVec 1))
(declare-fun ge_37 () (_ BitVec 1))
(declare-fun ge_36 () (_ BitVec 1))
(declare-fun ge_35 () (_ BitVec 1))
(declare-fun ge_34 () (_ BitVec 1))
(declare-fun ge_33 () (_ BitVec 1))
(declare-fun ge_32 () (_ BitVec 1))
(declare-fun ge_31 () (_ BitVec 1))
(declare-fun ge_30 () (_ BitVec 1))
(declare-fun ge_29 () (_ BitVec 1))
(declare-fun ge_28 () (_ BitVec 1))
(declare-fun ge_27 () (_ BitVec 1))
(declare-fun ge_26 () (_ BitVec 1))
(declare-fun ge_25 () (_ BitVec 1))
(declare-fun ge_24 () (_ BitVec 1))
(declare-fun ge_23 () (_ BitVec 1))
(declare-fun ge_22 () (_ BitVec 1))
(declare-fun ge_21 () (_ BitVec 1))
(declare-fun ge_20 () (_ BitVec 1))
(declare-fun ge_19 () (_ BitVec 1))
(declare-fun ge_18 () (_ BitVec 1))
(declare-fun ge_17 () (_ BitVec 1))
(declare-fun ge_16 () (_ BitVec 1))
(declare-fun ge_15 () (_ BitVec 1))
(declare-fun ge_14 () (_ BitVec 1))
(declare-fun ge_13 () (_ BitVec 1))
(declare-fun ge_12 () (_ BitVec 1))
(declare-fun ge_11 () (_ BitVec 1))
(declare-fun ge_10 () (_ BitVec 1))
(declare-fun ge_9 () (_ BitVec 1))
(declare-fun ge_8 () (_ BitVec 1))
(declare-fun ge_7 () (_ BitVec 1))
(declare-fun ge_6 () (_ BitVec 1))
(declare-fun ge_5 () (_ BitVec 1))
(declare-fun ge_4 () (_ BitVec 1))
(declare-fun ge_3 () (_ BitVec 1))
(declare-fun ge_2 () (_ BitVec 1))
(declare-fun ge_1 () (_ BitVec 1))
(declare-fun g_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun dc_132 () (_ BitVec 64))
(declare-fun dc_131 () (_ BitVec 1))
(declare-fun dc_130 () (_ BitVec 62))
(declare-fun dc_129 () (_ BitVec 1))
(declare-fun dc_128 () (_ BitVec 1))
(declare-fun dc_127 () (_ BitVec 1))
(declare-fun dc_126 () (_ BitVec 63))
(declare-fun dc_125 () (_ BitVec 64))
(declare-fun dc_124 () (_ BitVec 1))
(declare-fun dc_123 () (_ BitVec 62))
(declare-fun dc_122 () (_ BitVec 1))
(declare-fun dc_121 () (_ BitVec 1))
(declare-fun dc_120 () (_ BitVec 1))
(declare-fun dc_119 () (_ BitVec 63))
(declare-fun dc_118 () (_ BitVec 64))
(declare-fun dc_117 () (_ BitVec 1))
(declare-fun dc_116 () (_ BitVec 62))
(declare-fun dc_115 () (_ BitVec 1))
(declare-fun dc_114 () (_ BitVec 1))
(declare-fun dc_113 () (_ BitVec 1))
(declare-fun dc_112 () (_ BitVec 63))
(declare-fun dc_111 () (_ BitVec 64))
(declare-fun dc_110 () (_ BitVec 1))
(declare-fun dc_109 () (_ BitVec 62))
(declare-fun dc_108 () (_ BitVec 1))
(declare-fun dc_107 () (_ BitVec 1))
(declare-fun dc_106 () (_ BitVec 1))
(declare-fun dc_105 () (_ BitVec 63))
(declare-fun dc_104 () (_ BitVec 64))
(declare-fun dc_103 () (_ BitVec 1))
(declare-fun dc_102 () (_ BitVec 62))
(declare-fun dc_101 () (_ BitVec 1))
(declare-fun dc_100 () (_ BitVec 1))
(declare-fun dc_99 () (_ BitVec 1))
(declare-fun dc_98 () (_ BitVec 63))
(declare-fun dc_97 () (_ BitVec 64))
(declare-fun dc_96 () (_ BitVec 1))
(declare-fun dc_95 () (_ BitVec 62))
(declare-fun dc_94 () (_ BitVec 1))
(declare-fun dc_93 () (_ BitVec 1))
(declare-fun dc_92 () (_ BitVec 1))
(declare-fun dc_91 () (_ BitVec 63))
(declare-fun dc_90 () (_ BitVec 64))
(declare-fun dc_89 () (_ BitVec 1))
(declare-fun dc_88 () (_ BitVec 62))
(declare-fun dc_87 () (_ BitVec 1))
(declare-fun dc_86 () (_ BitVec 1))
(declare-fun dc_85 () (_ BitVec 1))
(declare-fun dc_84 () (_ BitVec 63))
(declare-fun dc_83 () (_ BitVec 64))
(declare-fun dc_82 () (_ BitVec 1))
(declare-fun dc_81 () (_ BitVec 62))
(declare-fun dc_80 () (_ BitVec 1))
(declare-fun dc_79 () (_ BitVec 1))
(declare-fun dc_78 () (_ BitVec 1))
(declare-fun dc_77 () (_ BitVec 63))
(declare-fun dc_76 () (_ BitVec 64))
(declare-fun dc_75 () (_ BitVec 1))
(declare-fun dc_74 () (_ BitVec 62))
(declare-fun dc_73 () (_ BitVec 1))
(declare-fun dc_72 () (_ BitVec 1))
(declare-fun dc_71 () (_ BitVec 1))
(declare-fun dc_70 () (_ BitVec 63))
(declare-fun dc_69 () (_ BitVec 64))
(declare-fun dc_68 () (_ BitVec 1))
(declare-fun dc_67 () (_ BitVec 62))
(declare-fun dc_66 () (_ BitVec 1))
(declare-fun dc_65 () (_ BitVec 1))
(declare-fun dc_64 () (_ BitVec 1))
(declare-fun dc_63 () (_ BitVec 63))
(declare-fun dc_62 () (_ BitVec 64))
(declare-fun dc_61 () (_ BitVec 1))
(declare-fun dc_60 () (_ BitVec 62))
(declare-fun dc_59 () (_ BitVec 1))
(declare-fun dc_58 () (_ BitVec 1))
(declare-fun dc_57 () (_ BitVec 1))
(declare-fun dc_56 () (_ BitVec 63))
(declare-fun dc_55 () (_ BitVec 64))
(declare-fun dc_54 () (_ BitVec 1))
(declare-fun dc_53 () (_ BitVec 62))
(declare-fun dc_52 () (_ BitVec 1))
(declare-fun dc_51 () (_ BitVec 1))
(declare-fun dc_50 () (_ BitVec 1))
(declare-fun dc_49 () (_ BitVec 63))
(declare-fun dc_48 () (_ BitVec 64))
(declare-fun dc_47 () (_ BitVec 1))
(declare-fun dc_46 () (_ BitVec 62))
(declare-fun dc_45 () (_ BitVec 1))
(declare-fun dc_44 () (_ BitVec 1))
(declare-fun dc_43 () (_ BitVec 1))
(declare-fun dc_42 () (_ BitVec 63))
(declare-fun dc_41 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (= x7_3 (bvadd (bvadd f_0_low60_0_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_2 (bvadd (bvadd g_0_low60_0_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_0_1)) (bvsle f_0_low60_0_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_0_1)) (bvsle g_0_low60_0_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_3) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #x0000000000000001 #x0000000000000001)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_41 ((_ extract 63 1) x8_2)) (= x8_lo_1 ((_ extract 0 0) x8_2))))
(assert (= ne_1 (bvand x8_lo_1 #b1)))
(assert (= x10_1 (ite (= ne_1 #b1) x7_3 #x0000000000000000)))
(assert (and (= ge_1 ((_ extract 63 63) #x0000000000000001)) (= dc_42 ((_ extract 62 0) #x0000000000000001))))
(assert (= ge_2 (bvnot ge_1)))
(assert (= ge_3 (ite (= ne_1 #b1) ge_2 #b0)))
(assert (and (= dc_43 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_2 (ite (= ge_3 #b1) x3_neg_1 #x0000000000000001)))
(assert (and (= dc_44 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_2 (ite (= ge_3 #b1) x10_neg_1 x10_1)))
(assert (= x7_4 (ite (= ge_3 #b1) x8_2 x7_3)))
(assert (and (= dc_45 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2)))) (= x8_3 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2))))))
(assert (= x3_3 (bvadd x3_2 #x0000000000000002)))
(assert (and (= dc_46 ((_ extract 63 2) x8_3)) (= x8_lo_2 ((_ extract 1 0) x8_3))))
(assert (and (= x8_target_1 ((_ extract 1 1) x8_lo_2)) (= dc_47 ((_ extract 0 0) x8_lo_2))))
(assert (= ne_2 (bvand x8_target_1 #b1)))
(assert (and (= x8_4 ((_ sign_extend 1) ((_ extract 63 1) x8_3))) (= dc_48 ((_ zero_extend 63) ((_ extract 0 0) x8_3)))))
(assert true)
(assert (= x10_3 (ite (= ne_2 #b1) x7_4 #x0000000000000000)))
(assert (and (= ge_4 ((_ extract 63 63) x3_3)) (= dc_49 ((_ extract 62 0) x3_3))))
(assert (= ge_5 (bvnot ge_4)))
(assert (= ge_6 (ite (= ne_2 #b1) ge_5 #b0)))
(assert (and (= dc_50 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_4 (ite (= ge_6 #b1) x3_neg_2 x3_3)))
(assert (and (= dc_51 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_4 (ite (= ge_6 #b1) x10_neg_2 x10_3)))
(assert (= x7_5 (ite (= ge_6 #b1) x8_4 x7_4)))
(assert (and (= dc_52 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4)))) (= x8_5 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4))))))
(assert (= x3_5 (bvadd x3_4 #x0000000000000002)))
(assert (and (= dc_53 ((_ extract 63 2) x8_5)) (= x8_lo_3 ((_ extract 1 0) x8_5))))
(assert (and (= x8_target_2 ((_ extract 1 1) x8_lo_3)) (= dc_54 ((_ extract 0 0) x8_lo_3))))
(assert (= ne_3 (bvand x8_target_2 #b1)))
(assert (and (= x8_6 ((_ sign_extend 1) ((_ extract 63 1) x8_5))) (= dc_55 ((_ zero_extend 63) ((_ extract 0 0) x8_5)))))
(assert true)
(assert (= x10_5 (ite (= ne_3 #b1) x7_5 #x0000000000000000)))
(assert (and (= ge_7 ((_ extract 63 63) x3_5)) (= dc_56 ((_ extract 62 0) x3_5))))
(assert (= ge_8 (bvnot ge_7)))
(assert (= ge_9 (ite (= ne_3 #b1) ge_8 #b0)))
(assert (and (= dc_57 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_6 (ite (= ge_9 #b1) x3_neg_3 x3_5)))
(assert (and (= dc_58 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_6 (ite (= ge_9 #b1) x10_neg_3 x10_5)))
(assert (= x7_6 (ite (= ge_9 #b1) x8_6 x7_5)))
(assert (and (= dc_59 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6)))) (= x8_7 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6))))))
(assert (= x3_7 (bvadd x3_6 #x0000000000000002)))
(assert (and (= dc_60 ((_ extract 63 2) x8_7)) (= x8_lo_4 ((_ extract 1 0) x8_7))))
(assert (and (= x8_target_3 ((_ extract 1 1) x8_lo_4)) (= dc_61 ((_ extract 0 0) x8_lo_4))))
(assert (= ne_4 (bvand x8_target_3 #b1)))
(assert (and (= x8_8 ((_ sign_extend 1) ((_ extract 63 1) x8_7))) (= dc_62 ((_ zero_extend 63) ((_ extract 0 0) x8_7)))))
(assert true)
(assert (= x10_7 (ite (= ne_4 #b1) x7_6 #x0000000000000000)))
(assert (and (= ge_10 ((_ extract 63 63) x3_7)) (= dc_63 ((_ extract 62 0) x3_7))))
(assert (= ge_11 (bvnot ge_10)))
(assert (= ge_12 (ite (= ne_4 #b1) ge_11 #b0)))
(assert (and (= dc_64 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_7))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_4 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_7))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_8 (ite (= ge_12 #b1) x3_neg_4 x3_7)))
(assert (and (= dc_65 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_7))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_4 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_7))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_8 (ite (= ge_12 #b1) x10_neg_4 x10_7)))
(assert (= x7_7 (ite (= ge_12 #b1) x8_8 x7_6)))
(assert (and (= dc_66 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_8) ((_ zero_extend 1) x10_8)))) (= x8_9 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_8) ((_ zero_extend 1) x10_8))))))
(assert (= x3_9 (bvadd x3_8 #x0000000000000002)))
(assert (and (= dc_67 ((_ extract 63 2) x8_9)) (= x8_lo_5 ((_ extract 1 0) x8_9))))
(assert (and (= x8_target_4 ((_ extract 1 1) x8_lo_5)) (= dc_68 ((_ extract 0 0) x8_lo_5))))
(assert (= ne_5 (bvand x8_target_4 #b1)))
(assert (and (= x8_10 ((_ sign_extend 1) ((_ extract 63 1) x8_9))) (= dc_69 ((_ zero_extend 63) ((_ extract 0 0) x8_9)))))
(assert true)
(assert (= x10_9 (ite (= ne_5 #b1) x7_7 #x0000000000000000)))
(assert (and (= ge_13 ((_ extract 63 63) x3_9)) (= dc_70 ((_ extract 62 0) x3_9))))
(assert (= ge_14 (bvnot ge_13)))
(assert (= ge_15 (ite (= ne_5 #b1) ge_14 #b0)))
(assert (and (= dc_71 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_9))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_5 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_9))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_10 (ite (= ge_15 #b1) x3_neg_5 x3_9)))
(assert (and (= dc_72 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_9))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_5 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_9))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_10 (ite (= ge_15 #b1) x10_neg_5 x10_9)))
(assert (= x7_8 (ite (= ge_15 #b1) x8_10 x7_7)))
(assert (and (= dc_73 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_10) ((_ zero_extend 1) x10_10)))) (= x8_11 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_10) ((_ zero_extend 1) x10_10))))))
(assert (= x3_11 (bvadd x3_10 #x0000000000000002)))
(assert (and (= dc_74 ((_ extract 63 2) x8_11)) (= x8_lo_6 ((_ extract 1 0) x8_11))))
(assert (and (= x8_target_5 ((_ extract 1 1) x8_lo_6)) (= dc_75 ((_ extract 0 0) x8_lo_6))))
(assert (= ne_6 (bvand x8_target_5 #b1)))
(assert (and (= x8_12 ((_ sign_extend 1) ((_ extract 63 1) x8_11))) (= dc_76 ((_ zero_extend 63) ((_ extract 0 0) x8_11)))))
(assert true)
(assert (= x10_11 (ite (= ne_6 #b1) x7_8 #x0000000000000000)))
(assert (and (= ge_16 ((_ extract 63 63) x3_11)) (= dc_77 ((_ extract 62 0) x3_11))))
(assert (= ge_17 (bvnot ge_16)))
(assert (= ge_18 (ite (= ne_6 #b1) ge_17 #b0)))
(assert (and (= dc_78 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_11))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_6 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_11))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_12 (ite (= ge_18 #b1) x3_neg_6 x3_11)))
(assert (and (= dc_79 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_11))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_6 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_11))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_12 (ite (= ge_18 #b1) x10_neg_6 x10_11)))
(assert (= x7_9 (ite (= ge_18 #b1) x8_12 x7_8)))
(assert (and (= dc_80 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_12) ((_ zero_extend 1) x10_12)))) (= x8_13 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_12) ((_ zero_extend 1) x10_12))))))
(assert (= x3_13 (bvadd x3_12 #x0000000000000002)))
(assert (and (= dc_81 ((_ extract 63 2) x8_13)) (= x8_lo_7 ((_ extract 1 0) x8_13))))
(assert (and (= x8_target_6 ((_ extract 1 1) x8_lo_7)) (= dc_82 ((_ extract 0 0) x8_lo_7))))
(assert (= ne_7 (bvand x8_target_6 #b1)))
(assert (and (= x8_14 ((_ sign_extend 1) ((_ extract 63 1) x8_13))) (= dc_83 ((_ zero_extend 63) ((_ extract 0 0) x8_13)))))
(assert true)
(assert (= x10_13 (ite (= ne_7 #b1) x7_9 #x0000000000000000)))
(assert (and (= ge_19 ((_ extract 63 63) x3_13)) (= dc_84 ((_ extract 62 0) x3_13))))
(assert (= ge_20 (bvnot ge_19)))
(assert (= ge_21 (ite (= ne_7 #b1) ge_20 #b0)))
(assert (and (= dc_85 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_13))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_7 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_13))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_14 (ite (= ge_21 #b1) x3_neg_7 x3_13)))
(assert (and (= dc_86 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_13))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_7 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_13))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_14 (ite (= ge_21 #b1) x10_neg_7 x10_13)))
(assert (= x7_10 (ite (= ge_21 #b1) x8_14 x7_9)))
(assert (and (= dc_87 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_14) ((_ zero_extend 1) x10_14)))) (= x8_15 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_14) ((_ zero_extend 1) x10_14))))))
(assert (= x3_15 (bvadd x3_14 #x0000000000000002)))
(assert (and (= dc_88 ((_ extract 63 2) x8_15)) (= x8_lo_8 ((_ extract 1 0) x8_15))))
(assert (and (= x8_target_7 ((_ extract 1 1) x8_lo_8)) (= dc_89 ((_ extract 0 0) x8_lo_8))))
(assert (= ne_8 (bvand x8_target_7 #b1)))
(assert (and (= x8_16 ((_ sign_extend 1) ((_ extract 63 1) x8_15))) (= dc_90 ((_ zero_extend 63) ((_ extract 0 0) x8_15)))))
(assert true)
(assert (= x10_15 (ite (= ne_8 #b1) x7_10 #x0000000000000000)))
(assert (and (= ge_22 ((_ extract 63 63) x3_15)) (= dc_91 ((_ extract 62 0) x3_15))))
(assert (= ge_23 (bvnot ge_22)))
(assert (= ge_24 (ite (= ne_8 #b1) ge_23 #b0)))
(assert (and (= dc_92 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_15))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_8 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_15))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_16 (ite (= ge_24 #b1) x3_neg_8 x3_15)))
(assert (and (= dc_93 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_15))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_8 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_15))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_16 (ite (= ge_24 #b1) x10_neg_8 x10_15)))
(assert (= x7_11 (ite (= ge_24 #b1) x8_16 x7_10)))
(assert (and (= dc_94 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_16) ((_ zero_extend 1) x10_16)))) (= x8_17 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_16) ((_ zero_extend 1) x10_16))))))
(assert (= x3_17 (bvadd x3_16 #x0000000000000002)))
(assert (and (= dc_95 ((_ extract 63 2) x8_17)) (= x8_lo_9 ((_ extract 1 0) x8_17))))
(assert (and (= x8_target_8 ((_ extract 1 1) x8_lo_9)) (= dc_96 ((_ extract 0 0) x8_lo_9))))
(assert (= ne_9 (bvand x8_target_8 #b1)))
(assert (and (= x8_18 ((_ sign_extend 1) ((_ extract 63 1) x8_17))) (= dc_97 ((_ zero_extend 63) ((_ extract 0 0) x8_17)))))
(assert true)
(assert (= x10_17 (ite (= ne_9 #b1) x7_11 #x0000000000000000)))
(assert (and (= ge_25 ((_ extract 63 63) x3_17)) (= dc_98 ((_ extract 62 0) x3_17))))
(assert (= ge_26 (bvnot ge_25)))
(assert (= ge_27 (ite (= ne_9 #b1) ge_26 #b0)))
(assert (and (= dc_99 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_17))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_9 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_17))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_18 (ite (= ge_27 #b1) x3_neg_9 x3_17)))
(assert (and (= dc_100 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_17))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_9 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_17))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_18 (ite (= ge_27 #b1) x10_neg_9 x10_17)))
(assert (= x7_12 (ite (= ge_27 #b1) x8_18 x7_11)))
(assert (and (= dc_101 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_18) ((_ zero_extend 1) x10_18)))) (= x8_19 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_18) ((_ zero_extend 1) x10_18))))))
(assert (= x3_19 (bvadd x3_18 #x0000000000000002)))
(assert (and (= dc_102 ((_ extract 63 2) x8_19)) (= x8_lo_10 ((_ extract 1 0) x8_19))))
(assert (and (= x8_target_9 ((_ extract 1 1) x8_lo_10)) (= dc_103 ((_ extract 0 0) x8_lo_10))))
(assert (= ne_10 (bvand x8_target_9 #b1)))
(assert (and (= x8_20 ((_ sign_extend 1) ((_ extract 63 1) x8_19))) (= dc_104 ((_ zero_extend 63) ((_ extract 0 0) x8_19)))))
(assert true)
(assert (= x10_19 (ite (= ne_10 #b1) x7_12 #x0000000000000000)))
(assert (and (= ge_28 ((_ extract 63 63) x3_19)) (= dc_105 ((_ extract 62 0) x3_19))))
(assert (= ge_29 (bvnot ge_28)))
(assert (= ge_30 (ite (= ne_10 #b1) ge_29 #b0)))
(assert (and (= dc_106 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_19))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_10 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_19))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_20 (ite (= ge_30 #b1) x3_neg_10 x3_19)))
(assert (and (= dc_107 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_19))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_10 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_19))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_20 (ite (= ge_30 #b1) x10_neg_10 x10_19)))
(assert (= x7_13 (ite (= ge_30 #b1) x8_20 x7_12)))
(assert (and (= dc_108 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_20) ((_ zero_extend 1) x10_20)))) (= x8_21 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_20) ((_ zero_extend 1) x10_20))))))
(assert (= x3_21 (bvadd x3_20 #x0000000000000002)))
(assert (and (= dc_109 ((_ extract 63 2) x8_21)) (= x8_lo_11 ((_ extract 1 0) x8_21))))
(assert (and (= x8_target_10 ((_ extract 1 1) x8_lo_11)) (= dc_110 ((_ extract 0 0) x8_lo_11))))
(assert (= ne_11 (bvand x8_target_10 #b1)))
(assert (and (= x8_22 ((_ sign_extend 1) ((_ extract 63 1) x8_21))) (= dc_111 ((_ zero_extend 63) ((_ extract 0 0) x8_21)))))
(assert true)
(assert (= x10_21 (ite (= ne_11 #b1) x7_13 #x0000000000000000)))
(assert (and (= ge_31 ((_ extract 63 63) x3_21)) (= dc_112 ((_ extract 62 0) x3_21))))
(assert (= ge_32 (bvnot ge_31)))
(assert (= ge_33 (ite (= ne_11 #b1) ge_32 #b0)))
(assert (and (= dc_113 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_21))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_11 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_21))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_22 (ite (= ge_33 #b1) x3_neg_11 x3_21)))
(assert (and (= dc_114 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_21))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_11 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_21))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_22 (ite (= ge_33 #b1) x10_neg_11 x10_21)))
(assert (= x7_14 (ite (= ge_33 #b1) x8_22 x7_13)))
(assert (and (= dc_115 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_22) ((_ zero_extend 1) x10_22)))) (= x8_23 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_22) ((_ zero_extend 1) x10_22))))))
(assert (= x3_23 (bvadd x3_22 #x0000000000000002)))
(assert (and (= dc_116 ((_ extract 63 2) x8_23)) (= x8_lo_12 ((_ extract 1 0) x8_23))))
(assert (and (= x8_target_11 ((_ extract 1 1) x8_lo_12)) (= dc_117 ((_ extract 0 0) x8_lo_12))))
(assert (= ne_12 (bvand x8_target_11 #b1)))
(assert (and (= x8_24 ((_ sign_extend 1) ((_ extract 63 1) x8_23))) (= dc_118 ((_ zero_extend 63) ((_ extract 0 0) x8_23)))))
(assert true)
(assert (= x10_23 (ite (= ne_12 #b1) x7_14 #x0000000000000000)))
(assert (and (= ge_34 ((_ extract 63 63) x3_23)) (= dc_119 ((_ extract 62 0) x3_23))))
(assert (= ge_35 (bvnot ge_34)))
(assert (= ge_36 (ite (= ne_12 #b1) ge_35 #b0)))
(assert (and (= dc_120 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_23))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_12 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_23))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_24 (ite (= ge_36 #b1) x3_neg_12 x3_23)))
(assert (and (= dc_121 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_23))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_12 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_23))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_24 (ite (= ge_36 #b1) x10_neg_12 x10_23)))
(assert (= x7_15 (ite (= ge_36 #b1) x8_24 x7_14)))
(assert (and (= dc_122 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_24) ((_ zero_extend 1) x10_24)))) (= x8_25 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_24) ((_ zero_extend 1) x10_24))))))
(assert (= x3_25 (bvadd x3_24 #x0000000000000002)))
(assert (and (= dc_123 ((_ extract 63 2) x8_25)) (= x8_lo_13 ((_ extract 1 0) x8_25))))
(assert (and (= x8_target_12 ((_ extract 1 1) x8_lo_13)) (= dc_124 ((_ extract 0 0) x8_lo_13))))
(assert (= ne_13 (bvand x8_target_12 #b1)))
(assert (and (= x8_26 ((_ sign_extend 1) ((_ extract 63 1) x8_25))) (= dc_125 ((_ zero_extend 63) ((_ extract 0 0) x8_25)))))
(assert true)
(assert (= x10_25 (ite (= ne_13 #b1) x7_15 #x0000000000000000)))
(assert (and (= ge_37 ((_ extract 63 63) x3_25)) (= dc_126 ((_ extract 62 0) x3_25))))
(assert (= ge_38 (bvnot ge_37)))
(assert (= ge_39 (ite (= ne_13 #b1) ge_38 #b0)))
(assert (and (= dc_127 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_25))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_13 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_25))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_26 (ite (= ge_39 #b1) x3_neg_13 x3_25)))
(assert (and (= dc_128 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_25))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_13 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_25))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_26 (ite (= ge_39 #b1) x10_neg_13 x10_25)))
(assert (= x7_16 (ite (= ge_39 #b1) x8_26 x7_15)))
(assert (and (= dc_129 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_26) ((_ zero_extend 1) x10_26)))) (= x8_27 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_26) ((_ zero_extend 1) x10_26))))))
(assert (= x3_27 (bvadd x3_26 #x0000000000000002)))
(assert (and (= dc_130 ((_ extract 63 2) x8_27)) (= x8_lo_14 ((_ extract 1 0) x8_27))))
(assert (and (= x8_target_13 ((_ extract 1 1) x8_lo_14)) (= dc_131 ((_ extract 0 0) x8_lo_14))))
(assert (= ne_14 (bvand x8_target_13 #b1)))
(assert (and (= x8_28 ((_ sign_extend 1) ((_ extract 63 1) x8_27))) (= dc_132 ((_ zero_extend 63) ((_ extract 0 0) x8_27)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_26) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_16 x7_15)) (= (bvmul x8_28 #x0000000000000002) x8_26)) (= x3_27 (bvadd #x0000000000000002 x3_25))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_26) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_25 #x0000000000000000)) (= x7_16 x7_15)) (= (bvmul x8_28 #x0000000000000002) (bvadd x8_26 x7_15))) (= x3_27 (bvadd #x0000000000000002 x3_25)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_26) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_25 #x0000000000000000)) (= x7_16 x8_26)) (= (bvmul x8_28 #x0000000000000002) (bvsub x8_26 x7_15))) (= x3_27 (bvsub #x0000000000000002 x3_25))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_37f7bc.smt2
Execution time of boolector: 0.6074 seconds
OUTPUT FROM boolector:
unsat

=== Cut #2 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #2
; Range assertion #23: or [and [smod (sub (uext x8_24 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_15 = x7_14, mul x8_26 2@64 = x8_24, x3_25 = add 2@64 x3_23], and [smod (sub (uext x8_24 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_23 <s 0@64, x7_15 = x7_14, mul x8_26 2@64 = add x8_24 x7_14, x3_25 = add 2@64 x3_23], and [smod (sub (uext x8_24 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_23 >=s 0@64, x7_15 = x8_24, mul x8_26 2@64 = sub x8_24 x7_14, x3_25 = sub 2@64 x3_23]]
; Range condition: ((x8_24@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_15 = x7_14 /\ x8_26 * 2 = x8_24 /\ x3_25 = 2 + x3_23 \/ ((x8_24@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_23 <s 0 /\ x7_15 = x7_14 /\ x8_26 * 2 = x8_24 + x7_14 /\ x3_25 = 2 + x3_23 \/ ((x8_24@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_23 >=s 0 /\ x7_15 = x8_24 /\ x8_26 * 2 = x8_24 - x7_14 /\ x3_25 = 2 - x3_23
; Output file: /tmp/outputqfbv_8515e0.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_12 () (_ BitVec 1))
(declare-fun x8_target_11 () (_ BitVec 1))
(declare-fun x8_target_10 () (_ BitVec 1))
(declare-fun x8_target_9 () (_ BitVec 1))
(declare-fun x8_target_8 () (_ BitVec 1))
(declare-fun x8_target_7 () (_ BitVec 1))
(declare-fun x8_target_6 () (_ BitVec 1))
(declare-fun x8_target_5 () (_ BitVec 1))
(declare-fun x8_target_4 () (_ BitVec 1))
(declare-fun x8_target_3 () (_ BitVec 1))
(declare-fun x8_target_2 () (_ BitVec 1))
(declare-fun x8_target_1 () (_ BitVec 1))
(declare-fun x8_lo_13 () (_ BitVec 2))
(declare-fun x8_lo_12 () (_ BitVec 2))
(declare-fun x8_lo_11 () (_ BitVec 2))
(declare-fun x8_lo_10 () (_ BitVec 2))
(declare-fun x8_lo_9 () (_ BitVec 2))
(declare-fun x8_lo_8 () (_ BitVec 2))
(declare-fun x8_lo_7 () (_ BitVec 2))
(declare-fun x8_lo_6 () (_ BitVec 2))
(declare-fun x8_lo_5 () (_ BitVec 2))
(declare-fun x8_lo_4 () (_ BitVec 2))
(declare-fun x8_lo_3 () (_ BitVec 2))
(declare-fun x8_lo_2 () (_ BitVec 2))
(declare-fun x8_lo_1 () (_ BitVec 1))
(declare-fun x8_26 () (_ BitVec 64))
(declare-fun x8_25 () (_ BitVec 64))
(declare-fun x8_24 () (_ BitVec 64))
(declare-fun x8_23 () (_ BitVec 64))
(declare-fun x8_22 () (_ BitVec 64))
(declare-fun x8_21 () (_ BitVec 64))
(declare-fun x8_20 () (_ BitVec 64))
(declare-fun x8_19 () (_ BitVec 64))
(declare-fun x8_18 () (_ BitVec 64))
(declare-fun x8_17 () (_ BitVec 64))
(declare-fun x8_16 () (_ BitVec 64))
(declare-fun x8_15 () (_ BitVec 64))
(declare-fun x8_14 () (_ BitVec 64))
(declare-fun x8_13 () (_ BitVec 64))
(declare-fun x8_12 () (_ BitVec 64))
(declare-fun x8_11 () (_ BitVec 64))
(declare-fun x8_10 () (_ BitVec 64))
(declare-fun x8_9 () (_ BitVec 64))
(declare-fun x8_8 () (_ BitVec 64))
(declare-fun x8_7 () (_ BitVec 64))
(declare-fun x8_6 () (_ BitVec 64))
(declare-fun x8_5 () (_ BitVec 64))
(declare-fun x8_4 () (_ BitVec 64))
(declare-fun x8_3 () (_ BitVec 64))
(declare-fun x8_2 () (_ BitVec 64))
(declare-fun x7_15 () (_ BitVec 64))
(declare-fun x7_14 () (_ BitVec 64))
(declare-fun x7_13 () (_ BitVec 64))
(declare-fun x7_12 () (_ BitVec 64))
(declare-fun x7_11 () (_ BitVec 64))
(declare-fun x7_10 () (_ BitVec 64))
(declare-fun x7_9 () (_ BitVec 64))
(declare-fun x7_8 () (_ BitVec 64))
(declare-fun x7_7 () (_ BitVec 64))
(declare-fun x7_6 () (_ BitVec 64))
(declare-fun x7_5 () (_ BitVec 64))
(declare-fun x7_4 () (_ BitVec 64))
(declare-fun x7_3 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_12 () (_ BitVec 64))
(declare-fun x3_neg_11 () (_ BitVec 64))
(declare-fun x3_neg_10 () (_ BitVec 64))
(declare-fun x3_neg_9 () (_ BitVec 64))
(declare-fun x3_neg_8 () (_ BitVec 64))
(declare-fun x3_neg_7 () (_ BitVec 64))
(declare-fun x3_neg_6 () (_ BitVec 64))
(declare-fun x3_neg_5 () (_ BitVec 64))
(declare-fun x3_neg_4 () (_ BitVec 64))
(declare-fun x3_neg_3 () (_ BitVec 64))
(declare-fun x3_neg_2 () (_ BitVec 64))
(declare-fun x3_neg_1 () (_ BitVec 64))
(declare-fun x3_25 () (_ BitVec 64))
(declare-fun x3_24 () (_ BitVec 64))
(declare-fun x3_23 () (_ BitVec 64))
(declare-fun x3_22 () (_ BitVec 64))
(declare-fun x3_21 () (_ BitVec 64))
(declare-fun x3_20 () (_ BitVec 64))
(declare-fun x3_19 () (_ BitVec 64))
(declare-fun x3_18 () (_ BitVec 64))
(declare-fun x3_17 () (_ BitVec 64))
(declare-fun x3_16 () (_ BitVec 64))
(declare-fun x3_15 () (_ BitVec 64))
(declare-fun x3_14 () (_ BitVec 64))
(declare-fun x3_13 () (_ BitVec 64))
(declare-fun x3_12 () (_ BitVec 64))
(declare-fun x3_11 () (_ BitVec 64))
(declare-fun x3_10 () (_ BitVec 64))
(declare-fun x3_9 () (_ BitVec 64))
(declare-fun x3_8 () (_ BitVec 64))
(declare-fun x3_7 () (_ BitVec 64))
(declare-fun x3_6 () (_ BitVec 64))
(declare-fun x3_5 () (_ BitVec 64))
(declare-fun x3_4 () (_ BitVec 64))
(declare-fun x3_3 () (_ BitVec 64))
(declare-fun x3_2 () (_ BitVec 64))
(declare-fun x10_neg_12 () (_ BitVec 64))
(declare-fun x10_neg_11 () (_ BitVec 64))
(declare-fun x10_neg_10 () (_ BitVec 64))
(declare-fun x10_neg_9 () (_ BitVec 64))
(declare-fun x10_neg_8 () (_ BitVec 64))
(declare-fun x10_neg_7 () (_ BitVec 64))
(declare-fun x10_neg_6 () (_ BitVec 64))
(declare-fun x10_neg_5 () (_ BitVec 64))
(declare-fun x10_neg_4 () (_ BitVec 64))
(declare-fun x10_neg_3 () (_ BitVec 64))
(declare-fun x10_neg_2 () (_ BitVec 64))
(declare-fun x10_neg_1 () (_ BitVec 64))
(declare-fun x10_24 () (_ BitVec 64))
(declare-fun x10_23 () (_ BitVec 64))
(declare-fun x10_22 () (_ BitVec 64))
(declare-fun x10_21 () (_ BitVec 64))
(declare-fun x10_20 () (_ BitVec 64))
(declare-fun x10_19 () (_ BitVec 64))
(declare-fun x10_18 () (_ BitVec 64))
(declare-fun x10_17 () (_ BitVec 64))
(declare-fun x10_16 () (_ BitVec 64))
(declare-fun x10_15 () (_ BitVec 64))
(declare-fun x10_14 () (_ BitVec 64))
(declare-fun x10_13 () (_ BitVec 64))
(declare-fun x10_12 () (_ BitVec 64))
(declare-fun x10_11 () (_ BitVec 64))
(declare-fun x10_10 () (_ BitVec 64))
(declare-fun x10_9 () (_ BitVec 64))
(declare-fun x10_8 () (_ BitVec 64))
(declare-fun x10_7 () (_ BitVec 64))
(declare-fun x10_6 () (_ BitVec 64))
(declare-fun x10_5 () (_ BitVec 64))
(declare-fun x10_4 () (_ BitVec 64))
(declare-fun x10_3 () (_ BitVec 64))
(declare-fun x10_2 () (_ BitVec 64))
(declare-fun x10_1 () (_ BitVec 64))
(declare-fun ne_13 () (_ BitVec 1))
(declare-fun ne_12 () (_ BitVec 1))
(declare-fun ne_11 () (_ BitVec 1))
(declare-fun ne_10 () (_ BitVec 1))
(declare-fun ne_9 () (_ BitVec 1))
(declare-fun ne_8 () (_ BitVec 1))
(declare-fun ne_7 () (_ BitVec 1))
(declare-fun ne_6 () (_ BitVec 1))
(declare-fun ne_5 () (_ BitVec 1))
(declare-fun ne_4 () (_ BitVec 1))
(declare-fun ne_3 () (_ BitVec 1))
(declare-fun ne_2 () (_ BitVec 1))
(declare-fun ne_1 () (_ BitVec 1))
(declare-fun ge_36 () (_ BitVec 1))
(declare-fun ge_35 () (_ BitVec 1))
(declare-fun ge_34 () (_ BitVec 1))
(declare-fun ge_33 () (_ BitVec 1))
(declare-fun ge_32 () (_ BitVec 1))
(declare-fun ge_31 () (_ BitVec 1))
(declare-fun ge_30 () (_ BitVec 1))
(declare-fun ge_29 () (_ BitVec 1))
(declare-fun ge_28 () (_ BitVec 1))
(declare-fun ge_27 () (_ BitVec 1))
(declare-fun ge_26 () (_ BitVec 1))
(declare-fun ge_25 () (_ BitVec 1))
(declare-fun ge_24 () (_ BitVec 1))
(declare-fun ge_23 () (_ BitVec 1))
(declare-fun ge_22 () (_ BitVec 1))
(declare-fun ge_21 () (_ BitVec 1))
(declare-fun ge_20 () (_ BitVec 1))
(declare-fun ge_19 () (_ BitVec 1))
(declare-fun ge_18 () (_ BitVec 1))
(declare-fun ge_17 () (_ BitVec 1))
(declare-fun ge_16 () (_ BitVec 1))
(declare-fun ge_15 () (_ BitVec 1))
(declare-fun ge_14 () (_ BitVec 1))
(declare-fun ge_13 () (_ BitVec 1))
(declare-fun ge_12 () (_ BitVec 1))
(declare-fun ge_11 () (_ BitVec 1))
(declare-fun ge_10 () (_ BitVec 1))
(declare-fun ge_9 () (_ BitVec 1))
(declare-fun ge_8 () (_ BitVec 1))
(declare-fun ge_7 () (_ BitVec 1))
(declare-fun ge_6 () (_ BitVec 1))
(declare-fun ge_5 () (_ BitVec 1))
(declare-fun ge_4 () (_ BitVec 1))
(declare-fun ge_3 () (_ BitVec 1))
(declare-fun ge_2 () (_ BitVec 1))
(declare-fun ge_1 () (_ BitVec 1))
(declare-fun g_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun dc_125 () (_ BitVec 64))
(declare-fun dc_124 () (_ BitVec 1))
(declare-fun dc_123 () (_ BitVec 62))
(declare-fun dc_122 () (_ BitVec 1))
(declare-fun dc_121 () (_ BitVec 1))
(declare-fun dc_120 () (_ BitVec 1))
(declare-fun dc_119 () (_ BitVec 63))
(declare-fun dc_118 () (_ BitVec 64))
(declare-fun dc_117 () (_ BitVec 1))
(declare-fun dc_116 () (_ BitVec 62))
(declare-fun dc_115 () (_ BitVec 1))
(declare-fun dc_114 () (_ BitVec 1))
(declare-fun dc_113 () (_ BitVec 1))
(declare-fun dc_112 () (_ BitVec 63))
(declare-fun dc_111 () (_ BitVec 64))
(declare-fun dc_110 () (_ BitVec 1))
(declare-fun dc_109 () (_ BitVec 62))
(declare-fun dc_108 () (_ BitVec 1))
(declare-fun dc_107 () (_ BitVec 1))
(declare-fun dc_106 () (_ BitVec 1))
(declare-fun dc_105 () (_ BitVec 63))
(declare-fun dc_104 () (_ BitVec 64))
(declare-fun dc_103 () (_ BitVec 1))
(declare-fun dc_102 () (_ BitVec 62))
(declare-fun dc_101 () (_ BitVec 1))
(declare-fun dc_100 () (_ BitVec 1))
(declare-fun dc_99 () (_ BitVec 1))
(declare-fun dc_98 () (_ BitVec 63))
(declare-fun dc_97 () (_ BitVec 64))
(declare-fun dc_96 () (_ BitVec 1))
(declare-fun dc_95 () (_ BitVec 62))
(declare-fun dc_94 () (_ BitVec 1))
(declare-fun dc_93 () (_ BitVec 1))
(declare-fun dc_92 () (_ BitVec 1))
(declare-fun dc_91 () (_ BitVec 63))
(declare-fun dc_90 () (_ BitVec 64))
(declare-fun dc_89 () (_ BitVec 1))
(declare-fun dc_88 () (_ BitVec 62))
(declare-fun dc_87 () (_ BitVec 1))
(declare-fun dc_86 () (_ BitVec 1))
(declare-fun dc_85 () (_ BitVec 1))
(declare-fun dc_84 () (_ BitVec 63))
(declare-fun dc_83 () (_ BitVec 64))
(declare-fun dc_82 () (_ BitVec 1))
(declare-fun dc_81 () (_ BitVec 62))
(declare-fun dc_80 () (_ BitVec 1))
(declare-fun dc_79 () (_ BitVec 1))
(declare-fun dc_78 () (_ BitVec 1))
(declare-fun dc_77 () (_ BitVec 63))
(declare-fun dc_76 () (_ BitVec 64))
(declare-fun dc_75 () (_ BitVec 1))
(declare-fun dc_74 () (_ BitVec 62))
(declare-fun dc_73 () (_ BitVec 1))
(declare-fun dc_72 () (_ BitVec 1))
(declare-fun dc_71 () (_ BitVec 1))
(declare-fun dc_70 () (_ BitVec 63))
(declare-fun dc_69 () (_ BitVec 64))
(declare-fun dc_68 () (_ BitVec 1))
(declare-fun dc_67 () (_ BitVec 62))
(declare-fun dc_66 () (_ BitVec 1))
(declare-fun dc_65 () (_ BitVec 1))
(declare-fun dc_64 () (_ BitVec 1))
(declare-fun dc_63 () (_ BitVec 63))
(declare-fun dc_62 () (_ BitVec 64))
(declare-fun dc_61 () (_ BitVec 1))
(declare-fun dc_60 () (_ BitVec 62))
(declare-fun dc_59 () (_ BitVec 1))
(declare-fun dc_58 () (_ BitVec 1))
(declare-fun dc_57 () (_ BitVec 1))
(declare-fun dc_56 () (_ BitVec 63))
(declare-fun dc_55 () (_ BitVec 64))
(declare-fun dc_54 () (_ BitVec 1))
(declare-fun dc_53 () (_ BitVec 62))
(declare-fun dc_52 () (_ BitVec 1))
(declare-fun dc_51 () (_ BitVec 1))
(declare-fun dc_50 () (_ BitVec 1))
(declare-fun dc_49 () (_ BitVec 63))
(declare-fun dc_48 () (_ BitVec 64))
(declare-fun dc_47 () (_ BitVec 1))
(declare-fun dc_46 () (_ BitVec 62))
(declare-fun dc_45 () (_ BitVec 1))
(declare-fun dc_44 () (_ BitVec 1))
(declare-fun dc_43 () (_ BitVec 1))
(declare-fun dc_42 () (_ BitVec 63))
(declare-fun dc_41 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (= x7_3 (bvadd (bvadd f_0_low60_0_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_2 (bvadd (bvadd g_0_low60_0_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_0_1)) (bvsle f_0_low60_0_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_0_1)) (bvsle g_0_low60_0_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_3) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #x0000000000000001 #x0000000000000001)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_41 ((_ extract 63 1) x8_2)) (= x8_lo_1 ((_ extract 0 0) x8_2))))
(assert (= ne_1 (bvand x8_lo_1 #b1)))
(assert (= x10_1 (ite (= ne_1 #b1) x7_3 #x0000000000000000)))
(assert (and (= ge_1 ((_ extract 63 63) #x0000000000000001)) (= dc_42 ((_ extract 62 0) #x0000000000000001))))
(assert (= ge_2 (bvnot ge_1)))
(assert (= ge_3 (ite (= ne_1 #b1) ge_2 #b0)))
(assert (and (= dc_43 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_2 (ite (= ge_3 #b1) x3_neg_1 #x0000000000000001)))
(assert (and (= dc_44 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_2 (ite (= ge_3 #b1) x10_neg_1 x10_1)))
(assert (= x7_4 (ite (= ge_3 #b1) x8_2 x7_3)))
(assert (and (= dc_45 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2)))) (= x8_3 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2))))))
(assert (= x3_3 (bvadd x3_2 #x0000000000000002)))
(assert (and (= dc_46 ((_ extract 63 2) x8_3)) (= x8_lo_2 ((_ extract 1 0) x8_3))))
(assert (and (= x8_target_1 ((_ extract 1 1) x8_lo_2)) (= dc_47 ((_ extract 0 0) x8_lo_2))))
(assert (= ne_2 (bvand x8_target_1 #b1)))
(assert (and (= x8_4 ((_ sign_extend 1) ((_ extract 63 1) x8_3))) (= dc_48 ((_ zero_extend 63) ((_ extract 0 0) x8_3)))))
(assert true)
(assert (= x10_3 (ite (= ne_2 #b1) x7_4 #x0000000000000000)))
(assert (and (= ge_4 ((_ extract 63 63) x3_3)) (= dc_49 ((_ extract 62 0) x3_3))))
(assert (= ge_5 (bvnot ge_4)))
(assert (= ge_6 (ite (= ne_2 #b1) ge_5 #b0)))
(assert (and (= dc_50 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_4 (ite (= ge_6 #b1) x3_neg_2 x3_3)))
(assert (and (= dc_51 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_4 (ite (= ge_6 #b1) x10_neg_2 x10_3)))
(assert (= x7_5 (ite (= ge_6 #b1) x8_4 x7_4)))
(assert (and (= dc_52 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4)))) (= x8_5 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4))))))
(assert (= x3_5 (bvadd x3_4 #x0000000000000002)))
(assert (and (= dc_53 ((_ extract 63 2) x8_5)) (= x8_lo_3 ((_ extract 1 0) x8_5))))
(assert (and (= x8_target_2 ((_ extract 1 1) x8_lo_3)) (= dc_54 ((_ extract 0 0) x8_lo_3))))
(assert (= ne_3 (bvand x8_target_2 #b1)))
(assert (and (= x8_6 ((_ sign_extend 1) ((_ extract 63 1) x8_5))) (= dc_55 ((_ zero_extend 63) ((_ extract 0 0) x8_5)))))
(assert true)
(assert (= x10_5 (ite (= ne_3 #b1) x7_5 #x0000000000000000)))
(assert (and (= ge_7 ((_ extract 63 63) x3_5)) (= dc_56 ((_ extract 62 0) x3_5))))
(assert (= ge_8 (bvnot ge_7)))
(assert (= ge_9 (ite (= ne_3 #b1) ge_8 #b0)))
(assert (and (= dc_57 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_6 (ite (= ge_9 #b1) x3_neg_3 x3_5)))
(assert (and (= dc_58 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_6 (ite (= ge_9 #b1) x10_neg_3 x10_5)))
(assert (= x7_6 (ite (= ge_9 #b1) x8_6 x7_5)))
(assert (and (= dc_59 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6)))) (= x8_7 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6))))))
(assert (= x3_7 (bvadd x3_6 #x0000000000000002)))
(assert (and (= dc_60 ((_ extract 63 2) x8_7)) (= x8_lo_4 ((_ extract 1 0) x8_7))))
(assert (and (= x8_target_3 ((_ extract 1 1) x8_lo_4)) (= dc_61 ((_ extract 0 0) x8_lo_4))))
(assert (= ne_4 (bvand x8_target_3 #b1)))
(assert (and (= x8_8 ((_ sign_extend 1) ((_ extract 63 1) x8_7))) (= dc_62 ((_ zero_extend 63) ((_ extract 0 0) x8_7)))))
(assert true)
(assert (= x10_7 (ite (= ne_4 #b1) x7_6 #x0000000000000000)))
(assert (and (= ge_10 ((_ extract 63 63) x3_7)) (= dc_63 ((_ extract 62 0) x3_7))))
(assert (= ge_11 (bvnot ge_10)))
(assert (= ge_12 (ite (= ne_4 #b1) ge_11 #b0)))
(assert (and (= dc_64 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_7))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_4 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_7))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_8 (ite (= ge_12 #b1) x3_neg_4 x3_7)))
(assert (and (= dc_65 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_7))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_4 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_7))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_8 (ite (= ge_12 #b1) x10_neg_4 x10_7)))
(assert (= x7_7 (ite (= ge_12 #b1) x8_8 x7_6)))
(assert (and (= dc_66 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_8) ((_ zero_extend 1) x10_8)))) (= x8_9 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_8) ((_ zero_extend 1) x10_8))))))
(assert (= x3_9 (bvadd x3_8 #x0000000000000002)))
(assert (and (= dc_67 ((_ extract 63 2) x8_9)) (= x8_lo_5 ((_ extract 1 0) x8_9))))
(assert (and (= x8_target_4 ((_ extract 1 1) x8_lo_5)) (= dc_68 ((_ extract 0 0) x8_lo_5))))
(assert (= ne_5 (bvand x8_target_4 #b1)))
(assert (and (= x8_10 ((_ sign_extend 1) ((_ extract 63 1) x8_9))) (= dc_69 ((_ zero_extend 63) ((_ extract 0 0) x8_9)))))
(assert true)
(assert (= x10_9 (ite (= ne_5 #b1) x7_7 #x0000000000000000)))
(assert (and (= ge_13 ((_ extract 63 63) x3_9)) (= dc_70 ((_ extract 62 0) x3_9))))
(assert (= ge_14 (bvnot ge_13)))
(assert (= ge_15 (ite (= ne_5 #b1) ge_14 #b0)))
(assert (and (= dc_71 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_9))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_5 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_9))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_10 (ite (= ge_15 #b1) x3_neg_5 x3_9)))
(assert (and (= dc_72 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_9))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_5 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_9))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_10 (ite (= ge_15 #b1) x10_neg_5 x10_9)))
(assert (= x7_8 (ite (= ge_15 #b1) x8_10 x7_7)))
(assert (and (= dc_73 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_10) ((_ zero_extend 1) x10_10)))) (= x8_11 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_10) ((_ zero_extend 1) x10_10))))))
(assert (= x3_11 (bvadd x3_10 #x0000000000000002)))
(assert (and (= dc_74 ((_ extract 63 2) x8_11)) (= x8_lo_6 ((_ extract 1 0) x8_11))))
(assert (and (= x8_target_5 ((_ extract 1 1) x8_lo_6)) (= dc_75 ((_ extract 0 0) x8_lo_6))))
(assert (= ne_6 (bvand x8_target_5 #b1)))
(assert (and (= x8_12 ((_ sign_extend 1) ((_ extract 63 1) x8_11))) (= dc_76 ((_ zero_extend 63) ((_ extract 0 0) x8_11)))))
(assert true)
(assert (= x10_11 (ite (= ne_6 #b1) x7_8 #x0000000000000000)))
(assert (and (= ge_16 ((_ extract 63 63) x3_11)) (= dc_77 ((_ extract 62 0) x3_11))))
(assert (= ge_17 (bvnot ge_16)))
(assert (= ge_18 (ite (= ne_6 #b1) ge_17 #b0)))
(assert (and (= dc_78 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_11))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_6 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_11))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_12 (ite (= ge_18 #b1) x3_neg_6 x3_11)))
(assert (and (= dc_79 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_11))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_6 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_11))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_12 (ite (= ge_18 #b1) x10_neg_6 x10_11)))
(assert (= x7_9 (ite (= ge_18 #b1) x8_12 x7_8)))
(assert (and (= dc_80 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_12) ((_ zero_extend 1) x10_12)))) (= x8_13 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_12) ((_ zero_extend 1) x10_12))))))
(assert (= x3_13 (bvadd x3_12 #x0000000000000002)))
(assert (and (= dc_81 ((_ extract 63 2) x8_13)) (= x8_lo_7 ((_ extract 1 0) x8_13))))
(assert (and (= x8_target_6 ((_ extract 1 1) x8_lo_7)) (= dc_82 ((_ extract 0 0) x8_lo_7))))
(assert (= ne_7 (bvand x8_target_6 #b1)))
(assert (and (= x8_14 ((_ sign_extend 1) ((_ extract 63 1) x8_13))) (= dc_83 ((_ zero_extend 63) ((_ extract 0 0) x8_13)))))
(assert true)
(assert (= x10_13 (ite (= ne_7 #b1) x7_9 #x0000000000000000)))
(assert (and (= ge_19 ((_ extract 63 63) x3_13)) (= dc_84 ((_ extract 62 0) x3_13))))
(assert (= ge_20 (bvnot ge_19)))
(assert (= ge_21 (ite (= ne_7 #b1) ge_20 #b0)))
(assert (and (= dc_85 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_13))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_7 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_13))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_14 (ite (= ge_21 #b1) x3_neg_7 x3_13)))
(assert (and (= dc_86 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_13))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_7 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_13))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_14 (ite (= ge_21 #b1) x10_neg_7 x10_13)))
(assert (= x7_10 (ite (= ge_21 #b1) x8_14 x7_9)))
(assert (and (= dc_87 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_14) ((_ zero_extend 1) x10_14)))) (= x8_15 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_14) ((_ zero_extend 1) x10_14))))))
(assert (= x3_15 (bvadd x3_14 #x0000000000000002)))
(assert (and (= dc_88 ((_ extract 63 2) x8_15)) (= x8_lo_8 ((_ extract 1 0) x8_15))))
(assert (and (= x8_target_7 ((_ extract 1 1) x8_lo_8)) (= dc_89 ((_ extract 0 0) x8_lo_8))))
(assert (= ne_8 (bvand x8_target_7 #b1)))
(assert (and (= x8_16 ((_ sign_extend 1) ((_ extract 63 1) x8_15))) (= dc_90 ((_ zero_extend 63) ((_ extract 0 0) x8_15)))))
(assert true)
(assert (= x10_15 (ite (= ne_8 #b1) x7_10 #x0000000000000000)))
(assert (and (= ge_22 ((_ extract 63 63) x3_15)) (= dc_91 ((_ extract 62 0) x3_15))))
(assert (= ge_23 (bvnot ge_22)))
(assert (= ge_24 (ite (= ne_8 #b1) ge_23 #b0)))
(assert (and (= dc_92 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_15))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_8 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_15))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_16 (ite (= ge_24 #b1) x3_neg_8 x3_15)))
(assert (and (= dc_93 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_15))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_8 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_15))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_16 (ite (= ge_24 #b1) x10_neg_8 x10_15)))
(assert (= x7_11 (ite (= ge_24 #b1) x8_16 x7_10)))
(assert (and (= dc_94 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_16) ((_ zero_extend 1) x10_16)))) (= x8_17 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_16) ((_ zero_extend 1) x10_16))))))
(assert (= x3_17 (bvadd x3_16 #x0000000000000002)))
(assert (and (= dc_95 ((_ extract 63 2) x8_17)) (= x8_lo_9 ((_ extract 1 0) x8_17))))
(assert (and (= x8_target_8 ((_ extract 1 1) x8_lo_9)) (= dc_96 ((_ extract 0 0) x8_lo_9))))
(assert (= ne_9 (bvand x8_target_8 #b1)))
(assert (and (= x8_18 ((_ sign_extend 1) ((_ extract 63 1) x8_17))) (= dc_97 ((_ zero_extend 63) ((_ extract 0 0) x8_17)))))
(assert true)
(assert (= x10_17 (ite (= ne_9 #b1) x7_11 #x0000000000000000)))
(assert (and (= ge_25 ((_ extract 63 63) x3_17)) (= dc_98 ((_ extract 62 0) x3_17))))
(assert (= ge_26 (bvnot ge_25)))
(assert (= ge_27 (ite (= ne_9 #b1) ge_26 #b0)))
(assert (and (= dc_99 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_17))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_9 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_17))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_18 (ite (= ge_27 #b1) x3_neg_9 x3_17)))
(assert (and (= dc_100 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_17))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_9 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_17))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_18 (ite (= ge_27 #b1) x10_neg_9 x10_17)))
(assert (= x7_12 (ite (= ge_27 #b1) x8_18 x7_11)))
(assert (and (= dc_101 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_18) ((_ zero_extend 1) x10_18)))) (= x8_19 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_18) ((_ zero_extend 1) x10_18))))))
(assert (= x3_19 (bvadd x3_18 #x0000000000000002)))
(assert (and (= dc_102 ((_ extract 63 2) x8_19)) (= x8_lo_10 ((_ extract 1 0) x8_19))))
(assert (and (= x8_target_9 ((_ extract 1 1) x8_lo_10)) (= dc_103 ((_ extract 0 0) x8_lo_10))))
(assert (= ne_10 (bvand x8_target_9 #b1)))
(assert (and (= x8_20 ((_ sign_extend 1) ((_ extract 63 1) x8_19))) (= dc_104 ((_ zero_extend 63) ((_ extract 0 0) x8_19)))))
(assert true)
(assert (= x10_19 (ite (= ne_10 #b1) x7_12 #x0000000000000000)))
(assert (and (= ge_28 ((_ extract 63 63) x3_19)) (= dc_105 ((_ extract 62 0) x3_19))))
(assert (= ge_29 (bvnot ge_28)))
(assert (= ge_30 (ite (= ne_10 #b1) ge_29 #b0)))
(assert (and (= dc_106 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_19))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_10 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_19))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_20 (ite (= ge_30 #b1) x3_neg_10 x3_19)))
(assert (and (= dc_107 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_19))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_10 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_19))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_20 (ite (= ge_30 #b1) x10_neg_10 x10_19)))
(assert (= x7_13 (ite (= ge_30 #b1) x8_20 x7_12)))
(assert (and (= dc_108 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_20) ((_ zero_extend 1) x10_20)))) (= x8_21 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_20) ((_ zero_extend 1) x10_20))))))
(assert (= x3_21 (bvadd x3_20 #x0000000000000002)))
(assert (and (= dc_109 ((_ extract 63 2) x8_21)) (= x8_lo_11 ((_ extract 1 0) x8_21))))
(assert (and (= x8_target_10 ((_ extract 1 1) x8_lo_11)) (= dc_110 ((_ extract 0 0) x8_lo_11))))
(assert (= ne_11 (bvand x8_target_10 #b1)))
(assert (and (= x8_22 ((_ sign_extend 1) ((_ extract 63 1) x8_21))) (= dc_111 ((_ zero_extend 63) ((_ extract 0 0) x8_21)))))
(assert true)
(assert (= x10_21 (ite (= ne_11 #b1) x7_13 #x0000000000000000)))
(assert (and (= ge_31 ((_ extract 63 63) x3_21)) (= dc_112 ((_ extract 62 0) x3_21))))
(assert (= ge_32 (bvnot ge_31)))
(assert (= ge_33 (ite (= ne_11 #b1) ge_32 #b0)))
(assert (and (= dc_113 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_21))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_11 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_21))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_22 (ite (= ge_33 #b1) x3_neg_11 x3_21)))
(assert (and (= dc_114 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_21))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_11 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_21))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_22 (ite (= ge_33 #b1) x10_neg_11 x10_21)))
(assert (= x7_14 (ite (= ge_33 #b1) x8_22 x7_13)))
(assert (and (= dc_115 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_22) ((_ zero_extend 1) x10_22)))) (= x8_23 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_22) ((_ zero_extend 1) x10_22))))))
(assert (= x3_23 (bvadd x3_22 #x0000000000000002)))
(assert (and (= dc_116 ((_ extract 63 2) x8_23)) (= x8_lo_12 ((_ extract 1 0) x8_23))))
(assert (and (= x8_target_11 ((_ extract 1 1) x8_lo_12)) (= dc_117 ((_ extract 0 0) x8_lo_12))))
(assert (= ne_12 (bvand x8_target_11 #b1)))
(assert (and (= x8_24 ((_ sign_extend 1) ((_ extract 63 1) x8_23))) (= dc_118 ((_ zero_extend 63) ((_ extract 0 0) x8_23)))))
(assert true)
(assert (= x10_23 (ite (= ne_12 #b1) x7_14 #x0000000000000000)))
(assert (and (= ge_34 ((_ extract 63 63) x3_23)) (= dc_119 ((_ extract 62 0) x3_23))))
(assert (= ge_35 (bvnot ge_34)))
(assert (= ge_36 (ite (= ne_12 #b1) ge_35 #b0)))
(assert (and (= dc_120 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_23))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_12 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_23))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_24 (ite (= ge_36 #b1) x3_neg_12 x3_23)))
(assert (and (= dc_121 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_23))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_12 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_23))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_24 (ite (= ge_36 #b1) x10_neg_12 x10_23)))
(assert (= x7_15 (ite (= ge_36 #b1) x8_24 x7_14)))
(assert (and (= dc_122 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_24) ((_ zero_extend 1) x10_24)))) (= x8_25 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_24) ((_ zero_extend 1) x10_24))))))
(assert (= x3_25 (bvadd x3_24 #x0000000000000002)))
(assert (and (= dc_123 ((_ extract 63 2) x8_25)) (= x8_lo_13 ((_ extract 1 0) x8_25))))
(assert (and (= x8_target_12 ((_ extract 1 1) x8_lo_13)) (= dc_124 ((_ extract 0 0) x8_lo_13))))
(assert (= ne_13 (bvand x8_target_12 #b1)))
(assert (and (= x8_26 ((_ sign_extend 1) ((_ extract 63 1) x8_25))) (= dc_125 ((_ zero_extend 63) ((_ extract 0 0) x8_25)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_24) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_15 x7_14)) (= (bvmul x8_26 #x0000000000000002) x8_24)) (= x3_25 (bvadd #x0000000000000002 x3_23))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_24) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_23 #x0000000000000000)) (= x7_15 x7_14)) (= (bvmul x8_26 #x0000000000000002) (bvadd x8_24 x7_14))) (= x3_25 (bvadd #x0000000000000002 x3_23)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_24) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_23 #x0000000000000000)) (= x7_15 x8_24)) (= (bvmul x8_26 #x0000000000000002) (bvsub x8_24 x7_14))) (= x3_25 (bvsub #x0000000000000002 x3_23))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_53e073.smt2
Execution time of boolector: 1.0164 seconds
OUTPUT FROM boolector:
unsat

=== Cut #2 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #2
; Range assertion #25: or [and [smod (sub (uext x8_28 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_17 = x7_16, mul x8_30 2@64 = x8_28, x3_29 = add 2@64 x3_27], and [smod (sub (uext x8_28 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_27 <s 0@64, x7_17 = x7_16, mul x8_30 2@64 = add x8_28 x7_16, x3_29 = add 2@64 x3_27], and [smod (sub (uext x8_28 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_27 >=s 0@64, x7_17 = x8_28, mul x8_30 2@64 = sub x8_28 x7_16, x3_29 = sub 2@64 x3_27]]
; Range condition: ((x8_28@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_17 = x7_16 /\ x8_30 * 2 = x8_28 /\ x3_29 = 2 + x3_27 \/ ((x8_28@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_27 <s 0 /\ x7_17 = x7_16 /\ x8_30 * 2 = x8_28 + x7_16 /\ x3_29 = 2 + x3_27 \/ ((x8_28@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_27 >=s 0 /\ x7_17 = x8_28 /\ x8_30 * 2 = x8_28 - x7_16 /\ x3_29 = 2 - x3_27
; Output file: /tmp/outputqfbv_dc90fb.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_14 () (_ BitVec 1))
(declare-fun x8_target_13 () (_ BitVec 1))
(declare-fun x8_target_12 () (_ BitVec 1))
(declare-fun x8_target_11 () (_ BitVec 1))
(declare-fun x8_target_10 () (_ BitVec 1))
(declare-fun x8_target_9 () (_ BitVec 1))
(declare-fun x8_target_8 () (_ BitVec 1))
(declare-fun x8_target_7 () (_ BitVec 1))
(declare-fun x8_target_6 () (_ BitVec 1))
(declare-fun x8_target_5 () (_ BitVec 1))
(declare-fun x8_target_4 () (_ BitVec 1))
(declare-fun x8_target_3 () (_ BitVec 1))
(declare-fun x8_target_2 () (_ BitVec 1))
(declare-fun x8_target_1 () (_ BitVec 1))
(declare-fun x8_lo_15 () (_ BitVec 2))
(declare-fun x8_lo_14 () (_ BitVec 2))
(declare-fun x8_lo_13 () (_ BitVec 2))
(declare-fun x8_lo_12 () (_ BitVec 2))
(declare-fun x8_lo_11 () (_ BitVec 2))
(declare-fun x8_lo_10 () (_ BitVec 2))
(declare-fun x8_lo_9 () (_ BitVec 2))
(declare-fun x8_lo_8 () (_ BitVec 2))
(declare-fun x8_lo_7 () (_ BitVec 2))
(declare-fun x8_lo_6 () (_ BitVec 2))
(declare-fun x8_lo_5 () (_ BitVec 2))
(declare-fun x8_lo_4 () (_ BitVec 2))
(declare-fun x8_lo_3 () (_ BitVec 2))
(declare-fun x8_lo_2 () (_ BitVec 2))
(declare-fun x8_lo_1 () (_ BitVec 1))
(declare-fun x8_30 () (_ BitVec 64))
(declare-fun x8_29 () (_ BitVec 64))
(declare-fun x8_28 () (_ BitVec 64))
(declare-fun x8_27 () (_ BitVec 64))
(declare-fun x8_26 () (_ BitVec 64))
(declare-fun x8_25 () (_ BitVec 64))
(declare-fun x8_24 () (_ BitVec 64))
(declare-fun x8_23 () (_ BitVec 64))
(declare-fun x8_22 () (_ BitVec 64))
(declare-fun x8_21 () (_ BitVec 64))
(declare-fun x8_20 () (_ BitVec 64))
(declare-fun x8_19 () (_ BitVec 64))
(declare-fun x8_18 () (_ BitVec 64))
(declare-fun x8_17 () (_ BitVec 64))
(declare-fun x8_16 () (_ BitVec 64))
(declare-fun x8_15 () (_ BitVec 64))
(declare-fun x8_14 () (_ BitVec 64))
(declare-fun x8_13 () (_ BitVec 64))
(declare-fun x8_12 () (_ BitVec 64))
(declare-fun x8_11 () (_ BitVec 64))
(declare-fun x8_10 () (_ BitVec 64))
(declare-fun x8_9 () (_ BitVec 64))
(declare-fun x8_8 () (_ BitVec 64))
(declare-fun x8_7 () (_ BitVec 64))
(declare-fun x8_6 () (_ BitVec 64))
(declare-fun x8_5 () (_ BitVec 64))
(declare-fun x8_4 () (_ BitVec 64))
(declare-fun x8_3 () (_ BitVec 64))
(declare-fun x8_2 () (_ BitVec 64))
(declare-fun x7_17 () (_ BitVec 64))
(declare-fun x7_16 () (_ BitVec 64))
(declare-fun x7_15 () (_ BitVec 64))
(declare-fun x7_14 () (_ BitVec 64))
(declare-fun x7_13 () (_ BitVec 64))
(declare-fun x7_12 () (_ BitVec 64))
(declare-fun x7_11 () (_ BitVec 64))
(declare-fun x7_10 () (_ BitVec 64))
(declare-fun x7_9 () (_ BitVec 64))
(declare-fun x7_8 () (_ BitVec 64))
(declare-fun x7_7 () (_ BitVec 64))
(declare-fun x7_6 () (_ BitVec 64))
(declare-fun x7_5 () (_ BitVec 64))
(declare-fun x7_4 () (_ BitVec 64))
(declare-fun x7_3 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_14 () (_ BitVec 64))
(declare-fun x3_neg_13 () (_ BitVec 64))
(declare-fun x3_neg_12 () (_ BitVec 64))
(declare-fun x3_neg_11 () (_ BitVec 64))
(declare-fun x3_neg_10 () (_ BitVec 64))
(declare-fun x3_neg_9 () (_ BitVec 64))
(declare-fun x3_neg_8 () (_ BitVec 64))
(declare-fun x3_neg_7 () (_ BitVec 64))
(declare-fun x3_neg_6 () (_ BitVec 64))
(declare-fun x3_neg_5 () (_ BitVec 64))
(declare-fun x3_neg_4 () (_ BitVec 64))
(declare-fun x3_neg_3 () (_ BitVec 64))
(declare-fun x3_neg_2 () (_ BitVec 64))
(declare-fun x3_neg_1 () (_ BitVec 64))
(declare-fun x3_29 () (_ BitVec 64))
(declare-fun x3_28 () (_ BitVec 64))
(declare-fun x3_27 () (_ BitVec 64))
(declare-fun x3_26 () (_ BitVec 64))
(declare-fun x3_25 () (_ BitVec 64))
(declare-fun x3_24 () (_ BitVec 64))
(declare-fun x3_23 () (_ BitVec 64))
(declare-fun x3_22 () (_ BitVec 64))
(declare-fun x3_21 () (_ BitVec 64))
(declare-fun x3_20 () (_ BitVec 64))
(declare-fun x3_19 () (_ BitVec 64))
(declare-fun x3_18 () (_ BitVec 64))
(declare-fun x3_17 () (_ BitVec 64))
(declare-fun x3_16 () (_ BitVec 64))
(declare-fun x3_15 () (_ BitVec 64))
(declare-fun x3_14 () (_ BitVec 64))
(declare-fun x3_13 () (_ BitVec 64))
(declare-fun x3_12 () (_ BitVec 64))
(declare-fun x3_11 () (_ BitVec 64))
(declare-fun x3_10 () (_ BitVec 64))
(declare-fun x3_9 () (_ BitVec 64))
(declare-fun x3_8 () (_ BitVec 64))
(declare-fun x3_7 () (_ BitVec 64))
(declare-fun x3_6 () (_ BitVec 64))
(declare-fun x3_5 () (_ BitVec 64))
(declare-fun x3_4 () (_ BitVec 64))
(declare-fun x3_3 () (_ BitVec 64))
(declare-fun x3_2 () (_ BitVec 64))
(declare-fun x10_neg_14 () (_ BitVec 64))
(declare-fun x10_neg_13 () (_ BitVec 64))
(declare-fun x10_neg_12 () (_ BitVec 64))
(declare-fun x10_neg_11 () (_ BitVec 64))
(declare-fun x10_neg_10 () (_ BitVec 64))
(declare-fun x10_neg_9 () (_ BitVec 64))
(declare-fun x10_neg_8 () (_ BitVec 64))
(declare-fun x10_neg_7 () (_ BitVec 64))
(declare-fun x10_neg_6 () (_ BitVec 64))
(declare-fun x10_neg_5 () (_ BitVec 64))
(declare-fun x10_neg_4 () (_ BitVec 64))
(declare-fun x10_neg_3 () (_ BitVec 64))
(declare-fun x10_neg_2 () (_ BitVec 64))
(declare-fun x10_neg_1 () (_ BitVec 64))
(declare-fun x10_28 () (_ BitVec 64))
(declare-fun x10_27 () (_ BitVec 64))
(declare-fun x10_26 () (_ BitVec 64))
(declare-fun x10_25 () (_ BitVec 64))
(declare-fun x10_24 () (_ BitVec 64))
(declare-fun x10_23 () (_ BitVec 64))
(declare-fun x10_22 () (_ BitVec 64))
(declare-fun x10_21 () (_ BitVec 64))
(declare-fun x10_20 () (_ BitVec 64))
(declare-fun x10_19 () (_ BitVec 64))
(declare-fun x10_18 () (_ BitVec 64))
(declare-fun x10_17 () (_ BitVec 64))
(declare-fun x10_16 () (_ BitVec 64))
(declare-fun x10_15 () (_ BitVec 64))
(declare-fun x10_14 () (_ BitVec 64))
(declare-fun x10_13 () (_ BitVec 64))
(declare-fun x10_12 () (_ BitVec 64))
(declare-fun x10_11 () (_ BitVec 64))
(declare-fun x10_10 () (_ BitVec 64))
(declare-fun x10_9 () (_ BitVec 64))
(declare-fun x10_8 () (_ BitVec 64))
(declare-fun x10_7 () (_ BitVec 64))
(declare-fun x10_6 () (_ BitVec 64))
(declare-fun x10_5 () (_ BitVec 64))
(declare-fun x10_4 () (_ BitVec 64))
(declare-fun x10_3 () (_ BitVec 64))
(declare-fun x10_2 () (_ BitVec 64))
(declare-fun x10_1 () (_ BitVec 64))
(declare-fun ne_15 () (_ BitVec 1))
(declare-fun ne_14 () (_ BitVec 1))
(declare-fun ne_13 () (_ BitVec 1))
(declare-fun ne_12 () (_ BitVec 1))
(declare-fun ne_11 () (_ BitVec 1))
(declare-fun ne_10 () (_ BitVec 1))
(declare-fun ne_9 () (_ BitVec 1))
(declare-fun ne_8 () (_ BitVec 1))
(declare-fun ne_7 () (_ BitVec 1))
(declare-fun ne_6 () (_ BitVec 1))
(declare-fun ne_5 () (_ BitVec 1))
(declare-fun ne_4 () (_ BitVec 1))
(declare-fun ne_3 () (_ BitVec 1))
(declare-fun ne_2 () (_ BitVec 1))
(declare-fun ne_1 () (_ BitVec 1))
(declare-fun ge_42 () (_ BitVec 1))
(declare-fun ge_41 () (_ BitVec 1))
(declare-fun ge_40 () (_ BitVec 1))
(declare-fun ge_39 () (_ BitVec 1))
(declare-fun ge_38 () (_ BitVec 1))
(declare-fun ge_37 () (_ BitVec 1))
(declare-fun ge_36 () (_ BitVec 1))
(declare-fun ge_35 () (_ BitVec 1))
(declare-fun ge_34 () (_ BitVec 1))
(declare-fun ge_33 () (_ BitVec 1))
(declare-fun ge_32 () (_ BitVec 1))
(declare-fun ge_31 () (_ BitVec 1))
(declare-fun ge_30 () (_ BitVec 1))
(declare-fun ge_29 () (_ BitVec 1))
(declare-fun ge_28 () (_ BitVec 1))
(declare-fun ge_27 () (_ BitVec 1))
(declare-fun ge_26 () (_ BitVec 1))
(declare-fun ge_25 () (_ BitVec 1))
(declare-fun ge_24 () (_ BitVec 1))
(declare-fun ge_23 () (_ BitVec 1))
(declare-fun ge_22 () (_ BitVec 1))
(declare-fun ge_21 () (_ BitVec 1))
(declare-fun ge_20 () (_ BitVec 1))
(declare-fun ge_19 () (_ BitVec 1))
(declare-fun ge_18 () (_ BitVec 1))
(declare-fun ge_17 () (_ BitVec 1))
(declare-fun ge_16 () (_ BitVec 1))
(declare-fun ge_15 () (_ BitVec 1))
(declare-fun ge_14 () (_ BitVec 1))
(declare-fun ge_13 () (_ BitVec 1))
(declare-fun ge_12 () (_ BitVec 1))
(declare-fun ge_11 () (_ BitVec 1))
(declare-fun ge_10 () (_ BitVec 1))
(declare-fun ge_9 () (_ BitVec 1))
(declare-fun ge_8 () (_ BitVec 1))
(declare-fun ge_7 () (_ BitVec 1))
(declare-fun ge_6 () (_ BitVec 1))
(declare-fun ge_5 () (_ BitVec 1))
(declare-fun ge_4 () (_ BitVec 1))
(declare-fun ge_3 () (_ BitVec 1))
(declare-fun ge_2 () (_ BitVec 1))
(declare-fun ge_1 () (_ BitVec 1))
(declare-fun g_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun dc_139 () (_ BitVec 64))
(declare-fun dc_138 () (_ BitVec 1))
(declare-fun dc_137 () (_ BitVec 62))
(declare-fun dc_136 () (_ BitVec 1))
(declare-fun dc_135 () (_ BitVec 1))
(declare-fun dc_134 () (_ BitVec 1))
(declare-fun dc_133 () (_ BitVec 63))
(declare-fun dc_132 () (_ BitVec 64))
(declare-fun dc_131 () (_ BitVec 1))
(declare-fun dc_130 () (_ BitVec 62))
(declare-fun dc_129 () (_ BitVec 1))
(declare-fun dc_128 () (_ BitVec 1))
(declare-fun dc_127 () (_ BitVec 1))
(declare-fun dc_126 () (_ BitVec 63))
(declare-fun dc_125 () (_ BitVec 64))
(declare-fun dc_124 () (_ BitVec 1))
(declare-fun dc_123 () (_ BitVec 62))
(declare-fun dc_122 () (_ BitVec 1))
(declare-fun dc_121 () (_ BitVec 1))
(declare-fun dc_120 () (_ BitVec 1))
(declare-fun dc_119 () (_ BitVec 63))
(declare-fun dc_118 () (_ BitVec 64))
(declare-fun dc_117 () (_ BitVec 1))
(declare-fun dc_116 () (_ BitVec 62))
(declare-fun dc_115 () (_ BitVec 1))
(declare-fun dc_114 () (_ BitVec 1))
(declare-fun dc_113 () (_ BitVec 1))
(declare-fun dc_112 () (_ BitVec 63))
(declare-fun dc_111 () (_ BitVec 64))
(declare-fun dc_110 () (_ BitVec 1))
(declare-fun dc_109 () (_ BitVec 62))
(declare-fun dc_108 () (_ BitVec 1))
(declare-fun dc_107 () (_ BitVec 1))
(declare-fun dc_106 () (_ BitVec 1))
(declare-fun dc_105 () (_ BitVec 63))
(declare-fun dc_104 () (_ BitVec 64))
(declare-fun dc_103 () (_ BitVec 1))
(declare-fun dc_102 () (_ BitVec 62))
(declare-fun dc_101 () (_ BitVec 1))
(declare-fun dc_100 () (_ BitVec 1))
(declare-fun dc_99 () (_ BitVec 1))
(declare-fun dc_98 () (_ BitVec 63))
(declare-fun dc_97 () (_ BitVec 64))
(declare-fun dc_96 () (_ BitVec 1))
(declare-fun dc_95 () (_ BitVec 62))
(declare-fun dc_94 () (_ BitVec 1))
(declare-fun dc_93 () (_ BitVec 1))
(declare-fun dc_92 () (_ BitVec 1))
(declare-fun dc_91 () (_ BitVec 63))
(declare-fun dc_90 () (_ BitVec 64))
(declare-fun dc_89 () (_ BitVec 1))
(declare-fun dc_88 () (_ BitVec 62))
(declare-fun dc_87 () (_ BitVec 1))
(declare-fun dc_86 () (_ BitVec 1))
(declare-fun dc_85 () (_ BitVec 1))
(declare-fun dc_84 () (_ BitVec 63))
(declare-fun dc_83 () (_ BitVec 64))
(declare-fun dc_82 () (_ BitVec 1))
(declare-fun dc_81 () (_ BitVec 62))
(declare-fun dc_80 () (_ BitVec 1))
(declare-fun dc_79 () (_ BitVec 1))
(declare-fun dc_78 () (_ BitVec 1))
(declare-fun dc_77 () (_ BitVec 63))
(declare-fun dc_76 () (_ BitVec 64))
(declare-fun dc_75 () (_ BitVec 1))
(declare-fun dc_74 () (_ BitVec 62))
(declare-fun dc_73 () (_ BitVec 1))
(declare-fun dc_72 () (_ BitVec 1))
(declare-fun dc_71 () (_ BitVec 1))
(declare-fun dc_70 () (_ BitVec 63))
(declare-fun dc_69 () (_ BitVec 64))
(declare-fun dc_68 () (_ BitVec 1))
(declare-fun dc_67 () (_ BitVec 62))
(declare-fun dc_66 () (_ BitVec 1))
(declare-fun dc_65 () (_ BitVec 1))
(declare-fun dc_64 () (_ BitVec 1))
(declare-fun dc_63 () (_ BitVec 63))
(declare-fun dc_62 () (_ BitVec 64))
(declare-fun dc_61 () (_ BitVec 1))
(declare-fun dc_60 () (_ BitVec 62))
(declare-fun dc_59 () (_ BitVec 1))
(declare-fun dc_58 () (_ BitVec 1))
(declare-fun dc_57 () (_ BitVec 1))
(declare-fun dc_56 () (_ BitVec 63))
(declare-fun dc_55 () (_ BitVec 64))
(declare-fun dc_54 () (_ BitVec 1))
(declare-fun dc_53 () (_ BitVec 62))
(declare-fun dc_52 () (_ BitVec 1))
(declare-fun dc_51 () (_ BitVec 1))
(declare-fun dc_50 () (_ BitVec 1))
(declare-fun dc_49 () (_ BitVec 63))
(declare-fun dc_48 () (_ BitVec 64))
(declare-fun dc_47 () (_ BitVec 1))
(declare-fun dc_46 () (_ BitVec 62))
(declare-fun dc_45 () (_ BitVec 1))
(declare-fun dc_44 () (_ BitVec 1))
(declare-fun dc_43 () (_ BitVec 1))
(declare-fun dc_42 () (_ BitVec 63))
(declare-fun dc_41 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (= x7_3 (bvadd (bvadd f_0_low60_0_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_2 (bvadd (bvadd g_0_low60_0_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_0_1)) (bvsle f_0_low60_0_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_0_1)) (bvsle g_0_low60_0_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_3) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #x0000000000000001 #x0000000000000001)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_41 ((_ extract 63 1) x8_2)) (= x8_lo_1 ((_ extract 0 0) x8_2))))
(assert (= ne_1 (bvand x8_lo_1 #b1)))
(assert (= x10_1 (ite (= ne_1 #b1) x7_3 #x0000000000000000)))
(assert (and (= ge_1 ((_ extract 63 63) #x0000000000000001)) (= dc_42 ((_ extract 62 0) #x0000000000000001))))
(assert (= ge_2 (bvnot ge_1)))
(assert (= ge_3 (ite (= ne_1 #b1) ge_2 #b0)))
(assert (and (= dc_43 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_2 (ite (= ge_3 #b1) x3_neg_1 #x0000000000000001)))
(assert (and (= dc_44 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_2 (ite (= ge_3 #b1) x10_neg_1 x10_1)))
(assert (= x7_4 (ite (= ge_3 #b1) x8_2 x7_3)))
(assert (and (= dc_45 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2)))) (= x8_3 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2))))))
(assert (= x3_3 (bvadd x3_2 #x0000000000000002)))
(assert (and (= dc_46 ((_ extract 63 2) x8_3)) (= x8_lo_2 ((_ extract 1 0) x8_3))))
(assert (and (= x8_target_1 ((_ extract 1 1) x8_lo_2)) (= dc_47 ((_ extract 0 0) x8_lo_2))))
(assert (= ne_2 (bvand x8_target_1 #b1)))
(assert (and (= x8_4 ((_ sign_extend 1) ((_ extract 63 1) x8_3))) (= dc_48 ((_ zero_extend 63) ((_ extract 0 0) x8_3)))))
(assert true)
(assert (= x10_3 (ite (= ne_2 #b1) x7_4 #x0000000000000000)))
(assert (and (= ge_4 ((_ extract 63 63) x3_3)) (= dc_49 ((_ extract 62 0) x3_3))))
(assert (= ge_5 (bvnot ge_4)))
(assert (= ge_6 (ite (= ne_2 #b1) ge_5 #b0)))
(assert (and (= dc_50 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_4 (ite (= ge_6 #b1) x3_neg_2 x3_3)))
(assert (and (= dc_51 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_4 (ite (= ge_6 #b1) x10_neg_2 x10_3)))
(assert (= x7_5 (ite (= ge_6 #b1) x8_4 x7_4)))
(assert (and (= dc_52 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4)))) (= x8_5 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4))))))
(assert (= x3_5 (bvadd x3_4 #x0000000000000002)))
(assert (and (= dc_53 ((_ extract 63 2) x8_5)) (= x8_lo_3 ((_ extract 1 0) x8_5))))
(assert (and (= x8_target_2 ((_ extract 1 1) x8_lo_3)) (= dc_54 ((_ extract 0 0) x8_lo_3))))
(assert (= ne_3 (bvand x8_target_2 #b1)))
(assert (and (= x8_6 ((_ sign_extend 1) ((_ extract 63 1) x8_5))) (= dc_55 ((_ zero_extend 63) ((_ extract 0 0) x8_5)))))
(assert true)
(assert (= x10_5 (ite (= ne_3 #b1) x7_5 #x0000000000000000)))
(assert (and (= ge_7 ((_ extract 63 63) x3_5)) (= dc_56 ((_ extract 62 0) x3_5))))
(assert (= ge_8 (bvnot ge_7)))
(assert (= ge_9 (ite (= ne_3 #b1) ge_8 #b0)))
(assert (and (= dc_57 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_6 (ite (= ge_9 #b1) x3_neg_3 x3_5)))
(assert (and (= dc_58 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_6 (ite (= ge_9 #b1) x10_neg_3 x10_5)))
(assert (= x7_6 (ite (= ge_9 #b1) x8_6 x7_5)))
(assert (and (= dc_59 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6)))) (= x8_7 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6))))))
(assert (= x3_7 (bvadd x3_6 #x0000000000000002)))
(assert (and (= dc_60 ((_ extract 63 2) x8_7)) (= x8_lo_4 ((_ extract 1 0) x8_7))))
(assert (and (= x8_target_3 ((_ extract 1 1) x8_lo_4)) (= dc_61 ((_ extract 0 0) x8_lo_4))))
(assert (= ne_4 (bvand x8_target_3 #b1)))
(assert (and (= x8_8 ((_ sign_extend 1) ((_ extract 63 1) x8_7))) (= dc_62 ((_ zero_extend 63) ((_ extract 0 0) x8_7)))))
(assert true)
(assert (= x10_7 (ite (= ne_4 #b1) x7_6 #x0000000000000000)))
(assert (and (= ge_10 ((_ extract 63 63) x3_7)) (= dc_63 ((_ extract 62 0) x3_7))))
(assert (= ge_11 (bvnot ge_10)))
(assert (= ge_12 (ite (= ne_4 #b1) ge_11 #b0)))
(assert (and (= dc_64 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_7))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_4 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_7))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_8 (ite (= ge_12 #b1) x3_neg_4 x3_7)))
(assert (and (= dc_65 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_7))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_4 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_7))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_8 (ite (= ge_12 #b1) x10_neg_4 x10_7)))
(assert (= x7_7 (ite (= ge_12 #b1) x8_8 x7_6)))
(assert (and (= dc_66 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_8) ((_ zero_extend 1) x10_8)))) (= x8_9 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_8) ((_ zero_extend 1) x10_8))))))
(assert (= x3_9 (bvadd x3_8 #x0000000000000002)))
(assert (and (= dc_67 ((_ extract 63 2) x8_9)) (= x8_lo_5 ((_ extract 1 0) x8_9))))
(assert (and (= x8_target_4 ((_ extract 1 1) x8_lo_5)) (= dc_68 ((_ extract 0 0) x8_lo_5))))
(assert (= ne_5 (bvand x8_target_4 #b1)))
(assert (and (= x8_10 ((_ sign_extend 1) ((_ extract 63 1) x8_9))) (= dc_69 ((_ zero_extend 63) ((_ extract 0 0) x8_9)))))
(assert true)
(assert (= x10_9 (ite (= ne_5 #b1) x7_7 #x0000000000000000)))
(assert (and (= ge_13 ((_ extract 63 63) x3_9)) (= dc_70 ((_ extract 62 0) x3_9))))
(assert (= ge_14 (bvnot ge_13)))
(assert (= ge_15 (ite (= ne_5 #b1) ge_14 #b0)))
(assert (and (= dc_71 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_9))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_5 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_9))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_10 (ite (= ge_15 #b1) x3_neg_5 x3_9)))
(assert (and (= dc_72 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_9))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_5 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_9))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_10 (ite (= ge_15 #b1) x10_neg_5 x10_9)))
(assert (= x7_8 (ite (= ge_15 #b1) x8_10 x7_7)))
(assert (and (= dc_73 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_10) ((_ zero_extend 1) x10_10)))) (= x8_11 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_10) ((_ zero_extend 1) x10_10))))))
(assert (= x3_11 (bvadd x3_10 #x0000000000000002)))
(assert (and (= dc_74 ((_ extract 63 2) x8_11)) (= x8_lo_6 ((_ extract 1 0) x8_11))))
(assert (and (= x8_target_5 ((_ extract 1 1) x8_lo_6)) (= dc_75 ((_ extract 0 0) x8_lo_6))))
(assert (= ne_6 (bvand x8_target_5 #b1)))
(assert (and (= x8_12 ((_ sign_extend 1) ((_ extract 63 1) x8_11))) (= dc_76 ((_ zero_extend 63) ((_ extract 0 0) x8_11)))))
(assert true)
(assert (= x10_11 (ite (= ne_6 #b1) x7_8 #x0000000000000000)))
(assert (and (= ge_16 ((_ extract 63 63) x3_11)) (= dc_77 ((_ extract 62 0) x3_11))))
(assert (= ge_17 (bvnot ge_16)))
(assert (= ge_18 (ite (= ne_6 #b1) ge_17 #b0)))
(assert (and (= dc_78 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_11))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_6 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_11))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_12 (ite (= ge_18 #b1) x3_neg_6 x3_11)))
(assert (and (= dc_79 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_11))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_6 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_11))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_12 (ite (= ge_18 #b1) x10_neg_6 x10_11)))
(assert (= x7_9 (ite (= ge_18 #b1) x8_12 x7_8)))
(assert (and (= dc_80 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_12) ((_ zero_extend 1) x10_12)))) (= x8_13 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_12) ((_ zero_extend 1) x10_12))))))
(assert (= x3_13 (bvadd x3_12 #x0000000000000002)))
(assert (and (= dc_81 ((_ extract 63 2) x8_13)) (= x8_lo_7 ((_ extract 1 0) x8_13))))
(assert (and (= x8_target_6 ((_ extract 1 1) x8_lo_7)) (= dc_82 ((_ extract 0 0) x8_lo_7))))
(assert (= ne_7 (bvand x8_target_6 #b1)))
(assert (and (= x8_14 ((_ sign_extend 1) ((_ extract 63 1) x8_13))) (= dc_83 ((_ zero_extend 63) ((_ extract 0 0) x8_13)))))
(assert true)
(assert (= x10_13 (ite (= ne_7 #b1) x7_9 #x0000000000000000)))
(assert (and (= ge_19 ((_ extract 63 63) x3_13)) (= dc_84 ((_ extract 62 0) x3_13))))
(assert (= ge_20 (bvnot ge_19)))
(assert (= ge_21 (ite (= ne_7 #b1) ge_20 #b0)))
(assert (and (= dc_85 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_13))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_7 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_13))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_14 (ite (= ge_21 #b1) x3_neg_7 x3_13)))
(assert (and (= dc_86 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_13))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_7 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_13))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_14 (ite (= ge_21 #b1) x10_neg_7 x10_13)))
(assert (= x7_10 (ite (= ge_21 #b1) x8_14 x7_9)))
(assert (and (= dc_87 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_14) ((_ zero_extend 1) x10_14)))) (= x8_15 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_14) ((_ zero_extend 1) x10_14))))))
(assert (= x3_15 (bvadd x3_14 #x0000000000000002)))
(assert (and (= dc_88 ((_ extract 63 2) x8_15)) (= x8_lo_8 ((_ extract 1 0) x8_15))))
(assert (and (= x8_target_7 ((_ extract 1 1) x8_lo_8)) (= dc_89 ((_ extract 0 0) x8_lo_8))))
(assert (= ne_8 (bvand x8_target_7 #b1)))
(assert (and (= x8_16 ((_ sign_extend 1) ((_ extract 63 1) x8_15))) (= dc_90 ((_ zero_extend 63) ((_ extract 0 0) x8_15)))))
(assert true)
(assert (= x10_15 (ite (= ne_8 #b1) x7_10 #x0000000000000000)))
(assert (and (= ge_22 ((_ extract 63 63) x3_15)) (= dc_91 ((_ extract 62 0) x3_15))))
(assert (= ge_23 (bvnot ge_22)))
(assert (= ge_24 (ite (= ne_8 #b1) ge_23 #b0)))
(assert (and (= dc_92 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_15))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_8 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_15))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_16 (ite (= ge_24 #b1) x3_neg_8 x3_15)))
(assert (and (= dc_93 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_15))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_8 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_15))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_16 (ite (= ge_24 #b1) x10_neg_8 x10_15)))
(assert (= x7_11 (ite (= ge_24 #b1) x8_16 x7_10)))
(assert (and (= dc_94 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_16) ((_ zero_extend 1) x10_16)))) (= x8_17 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_16) ((_ zero_extend 1) x10_16))))))
(assert (= x3_17 (bvadd x3_16 #x0000000000000002)))
(assert (and (= dc_95 ((_ extract 63 2) x8_17)) (= x8_lo_9 ((_ extract 1 0) x8_17))))
(assert (and (= x8_target_8 ((_ extract 1 1) x8_lo_9)) (= dc_96 ((_ extract 0 0) x8_lo_9))))
(assert (= ne_9 (bvand x8_target_8 #b1)))
(assert (and (= x8_18 ((_ sign_extend 1) ((_ extract 63 1) x8_17))) (= dc_97 ((_ zero_extend 63) ((_ extract 0 0) x8_17)))))
(assert true)
(assert (= x10_17 (ite (= ne_9 #b1) x7_11 #x0000000000000000)))
(assert (and (= ge_25 ((_ extract 63 63) x3_17)) (= dc_98 ((_ extract 62 0) x3_17))))
(assert (= ge_26 (bvnot ge_25)))
(assert (= ge_27 (ite (= ne_9 #b1) ge_26 #b0)))
(assert (and (= dc_99 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_17))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_9 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_17))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_18 (ite (= ge_27 #b1) x3_neg_9 x3_17)))
(assert (and (= dc_100 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_17))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_9 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_17))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_18 (ite (= ge_27 #b1) x10_neg_9 x10_17)))
(assert (= x7_12 (ite (= ge_27 #b1) x8_18 x7_11)))
(assert (and (= dc_101 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_18) ((_ zero_extend 1) x10_18)))) (= x8_19 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_18) ((_ zero_extend 1) x10_18))))))
(assert (= x3_19 (bvadd x3_18 #x0000000000000002)))
(assert (and (= dc_102 ((_ extract 63 2) x8_19)) (= x8_lo_10 ((_ extract 1 0) x8_19))))
(assert (and (= x8_target_9 ((_ extract 1 1) x8_lo_10)) (= dc_103 ((_ extract 0 0) x8_lo_10))))
(assert (= ne_10 (bvand x8_target_9 #b1)))
(assert (and (= x8_20 ((_ sign_extend 1) ((_ extract 63 1) x8_19))) (= dc_104 ((_ zero_extend 63) ((_ extract 0 0) x8_19)))))
(assert true)
(assert (= x10_19 (ite (= ne_10 #b1) x7_12 #x0000000000000000)))
(assert (and (= ge_28 ((_ extract 63 63) x3_19)) (= dc_105 ((_ extract 62 0) x3_19))))
(assert (= ge_29 (bvnot ge_28)))
(assert (= ge_30 (ite (= ne_10 #b1) ge_29 #b0)))
(assert (and (= dc_106 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_19))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_10 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_19))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_20 (ite (= ge_30 #b1) x3_neg_10 x3_19)))
(assert (and (= dc_107 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_19))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_10 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_19))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_20 (ite (= ge_30 #b1) x10_neg_10 x10_19)))
(assert (= x7_13 (ite (= ge_30 #b1) x8_20 x7_12)))
(assert (and (= dc_108 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_20) ((_ zero_extend 1) x10_20)))) (= x8_21 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_20) ((_ zero_extend 1) x10_20))))))
(assert (= x3_21 (bvadd x3_20 #x0000000000000002)))
(assert (and (= dc_109 ((_ extract 63 2) x8_21)) (= x8_lo_11 ((_ extract 1 0) x8_21))))
(assert (and (= x8_target_10 ((_ extract 1 1) x8_lo_11)) (= dc_110 ((_ extract 0 0) x8_lo_11))))
(assert (= ne_11 (bvand x8_target_10 #b1)))
(assert (and (= x8_22 ((_ sign_extend 1) ((_ extract 63 1) x8_21))) (= dc_111 ((_ zero_extend 63) ((_ extract 0 0) x8_21)))))
(assert true)
(assert (= x10_21 (ite (= ne_11 #b1) x7_13 #x0000000000000000)))
(assert (and (= ge_31 ((_ extract 63 63) x3_21)) (= dc_112 ((_ extract 62 0) x3_21))))
(assert (= ge_32 (bvnot ge_31)))
(assert (= ge_33 (ite (= ne_11 #b1) ge_32 #b0)))
(assert (and (= dc_113 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_21))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_11 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_21))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_22 (ite (= ge_33 #b1) x3_neg_11 x3_21)))
(assert (and (= dc_114 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_21))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_11 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_21))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_22 (ite (= ge_33 #b1) x10_neg_11 x10_21)))
(assert (= x7_14 (ite (= ge_33 #b1) x8_22 x7_13)))
(assert (and (= dc_115 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_22) ((_ zero_extend 1) x10_22)))) (= x8_23 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_22) ((_ zero_extend 1) x10_22))))))
(assert (= x3_23 (bvadd x3_22 #x0000000000000002)))
(assert (and (= dc_116 ((_ extract 63 2) x8_23)) (= x8_lo_12 ((_ extract 1 0) x8_23))))
(assert (and (= x8_target_11 ((_ extract 1 1) x8_lo_12)) (= dc_117 ((_ extract 0 0) x8_lo_12))))
(assert (= ne_12 (bvand x8_target_11 #b1)))
(assert (and (= x8_24 ((_ sign_extend 1) ((_ extract 63 1) x8_23))) (= dc_118 ((_ zero_extend 63) ((_ extract 0 0) x8_23)))))
(assert true)
(assert (= x10_23 (ite (= ne_12 #b1) x7_14 #x0000000000000000)))
(assert (and (= ge_34 ((_ extract 63 63) x3_23)) (= dc_119 ((_ extract 62 0) x3_23))))
(assert (= ge_35 (bvnot ge_34)))
(assert (= ge_36 (ite (= ne_12 #b1) ge_35 #b0)))
(assert (and (= dc_120 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_23))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_12 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_23))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_24 (ite (= ge_36 #b1) x3_neg_12 x3_23)))
(assert (and (= dc_121 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_23))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_12 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_23))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_24 (ite (= ge_36 #b1) x10_neg_12 x10_23)))
(assert (= x7_15 (ite (= ge_36 #b1) x8_24 x7_14)))
(assert (and (= dc_122 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_24) ((_ zero_extend 1) x10_24)))) (= x8_25 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_24) ((_ zero_extend 1) x10_24))))))
(assert (= x3_25 (bvadd x3_24 #x0000000000000002)))
(assert (and (= dc_123 ((_ extract 63 2) x8_25)) (= x8_lo_13 ((_ extract 1 0) x8_25))))
(assert (and (= x8_target_12 ((_ extract 1 1) x8_lo_13)) (= dc_124 ((_ extract 0 0) x8_lo_13))))
(assert (= ne_13 (bvand x8_target_12 #b1)))
(assert (and (= x8_26 ((_ sign_extend 1) ((_ extract 63 1) x8_25))) (= dc_125 ((_ zero_extend 63) ((_ extract 0 0) x8_25)))))
(assert true)
(assert (= x10_25 (ite (= ne_13 #b1) x7_15 #x0000000000000000)))
(assert (and (= ge_37 ((_ extract 63 63) x3_25)) (= dc_126 ((_ extract 62 0) x3_25))))
(assert (= ge_38 (bvnot ge_37)))
(assert (= ge_39 (ite (= ne_13 #b1) ge_38 #b0)))
(assert (and (= dc_127 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_25))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_13 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_25))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_26 (ite (= ge_39 #b1) x3_neg_13 x3_25)))
(assert (and (= dc_128 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_25))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_13 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_25))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_26 (ite (= ge_39 #b1) x10_neg_13 x10_25)))
(assert (= x7_16 (ite (= ge_39 #b1) x8_26 x7_15)))
(assert (and (= dc_129 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_26) ((_ zero_extend 1) x10_26)))) (= x8_27 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_26) ((_ zero_extend 1) x10_26))))))
(assert (= x3_27 (bvadd x3_26 #x0000000000000002)))
(assert (and (= dc_130 ((_ extract 63 2) x8_27)) (= x8_lo_14 ((_ extract 1 0) x8_27))))
(assert (and (= x8_target_13 ((_ extract 1 1) x8_lo_14)) (= dc_131 ((_ extract 0 0) x8_lo_14))))
(assert (= ne_14 (bvand x8_target_13 #b1)))
(assert (and (= x8_28 ((_ sign_extend 1) ((_ extract 63 1) x8_27))) (= dc_132 ((_ zero_extend 63) ((_ extract 0 0) x8_27)))))
(assert true)
(assert (= x10_27 (ite (= ne_14 #b1) x7_16 #x0000000000000000)))
(assert (and (= ge_40 ((_ extract 63 63) x3_27)) (= dc_133 ((_ extract 62 0) x3_27))))
(assert (= ge_41 (bvnot ge_40)))
(assert (= ge_42 (ite (= ne_14 #b1) ge_41 #b0)))
(assert (and (= dc_134 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_27))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_14 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_27))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_28 (ite (= ge_42 #b1) x3_neg_14 x3_27)))
(assert (and (= dc_135 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_27))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_14 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_27))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_28 (ite (= ge_42 #b1) x10_neg_14 x10_27)))
(assert (= x7_17 (ite (= ge_42 #b1) x8_28 x7_16)))
(assert (and (= dc_136 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_28) ((_ zero_extend 1) x10_28)))) (= x8_29 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_28) ((_ zero_extend 1) x10_28))))))
(assert (= x3_29 (bvadd x3_28 #x0000000000000002)))
(assert (and (= dc_137 ((_ extract 63 2) x8_29)) (= x8_lo_15 ((_ extract 1 0) x8_29))))
(assert (and (= x8_target_14 ((_ extract 1 1) x8_lo_15)) (= dc_138 ((_ extract 0 0) x8_lo_15))))
(assert (= ne_15 (bvand x8_target_14 #b1)))
(assert (and (= x8_30 ((_ sign_extend 1) ((_ extract 63 1) x8_29))) (= dc_139 ((_ zero_extend 63) ((_ extract 0 0) x8_29)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_28) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_17 x7_16)) (= (bvmul x8_30 #x0000000000000002) x8_28)) (= x3_29 (bvadd #x0000000000000002 x3_27))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_28) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_27 #x0000000000000000)) (= x7_17 x7_16)) (= (bvmul x8_30 #x0000000000000002) (bvadd x8_28 x7_16))) (= x3_29 (bvadd #x0000000000000002 x3_27)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_28) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_27 #x0000000000000000)) (= x7_17 x8_28)) (= (bvmul x8_30 #x0000000000000002) (bvsub x8_28 x7_16))) (= x3_29 (bvsub #x0000000000000002 x3_27))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_992da5.smt2
Execution time of boolector: 1.1280 seconds
OUTPUT FROM boolector:
unsat

=== Cut #2 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #2
; Range assertion #26: or [and [smod (sub (uext x8_30 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_18 = x7_17, mul x8_32 2@64 = x8_30, x3_31 = add 2@64 x3_29], and [smod (sub (uext x8_30 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_29 <s 0@64, x7_18 = x7_17, mul x8_32 2@64 = add x8_30 x7_17, x3_31 = add 2@64 x3_29], and [smod (sub (uext x8_30 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_29 >=s 0@64, x7_18 = x8_30, mul x8_32 2@64 = sub x8_30 x7_17, x3_31 = sub 2@64 x3_29]]
; Range condition: ((x8_30@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_18 = x7_17 /\ x8_32 * 2 = x8_30 /\ x3_31 = 2 + x3_29 \/ ((x8_30@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_29 <s 0 /\ x7_18 = x7_17 /\ x8_32 * 2 = x8_30 + x7_17 /\ x3_31 = 2 + x3_29 \/ ((x8_30@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_29 >=s 0 /\ x7_18 = x8_30 /\ x8_32 * 2 = x8_30 - x7_17 /\ x3_31 = 2 - x3_29
; Output file: /tmp/outputqfbv_cf1c5e.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_15 () (_ BitVec 1))
(declare-fun x8_target_14 () (_ BitVec 1))
(declare-fun x8_target_13 () (_ BitVec 1))
(declare-fun x8_target_12 () (_ BitVec 1))
(declare-fun x8_target_11 () (_ BitVec 1))
(declare-fun x8_target_10 () (_ BitVec 1))
(declare-fun x8_target_9 () (_ BitVec 1))
(declare-fun x8_target_8 () (_ BitVec 1))
(declare-fun x8_target_7 () (_ BitVec 1))
(declare-fun x8_target_6 () (_ BitVec 1))
(declare-fun x8_target_5 () (_ BitVec 1))
(declare-fun x8_target_4 () (_ BitVec 1))
(declare-fun x8_target_3 () (_ BitVec 1))
(declare-fun x8_target_2 () (_ BitVec 1))
(declare-fun x8_target_1 () (_ BitVec 1))
(declare-fun x8_lo_16 () (_ BitVec 2))
(declare-fun x8_lo_15 () (_ BitVec 2))
(declare-fun x8_lo_14 () (_ BitVec 2))
(declare-fun x8_lo_13 () (_ BitVec 2))
(declare-fun x8_lo_12 () (_ BitVec 2))
(declare-fun x8_lo_11 () (_ BitVec 2))
(declare-fun x8_lo_10 () (_ BitVec 2))
(declare-fun x8_lo_9 () (_ BitVec 2))
(declare-fun x8_lo_8 () (_ BitVec 2))
(declare-fun x8_lo_7 () (_ BitVec 2))
(declare-fun x8_lo_6 () (_ BitVec 2))
(declare-fun x8_lo_5 () (_ BitVec 2))
(declare-fun x8_lo_4 () (_ BitVec 2))
(declare-fun x8_lo_3 () (_ BitVec 2))
(declare-fun x8_lo_2 () (_ BitVec 2))
(declare-fun x8_lo_1 () (_ BitVec 1))
(declare-fun x8_32 () (_ BitVec 64))
(declare-fun x8_31 () (_ BitVec 64))
(declare-fun x8_30 () (_ BitVec 64))
(declare-fun x8_29 () (_ BitVec 64))
(declare-fun x8_28 () (_ BitVec 64))
(declare-fun x8_27 () (_ BitVec 64))
(declare-fun x8_26 () (_ BitVec 64))
(declare-fun x8_25 () (_ BitVec 64))
(declare-fun x8_24 () (_ BitVec 64))
(declare-fun x8_23 () (_ BitVec 64))
(declare-fun x8_22 () (_ BitVec 64))
(declare-fun x8_21 () (_ BitVec 64))
(declare-fun x8_20 () (_ BitVec 64))
(declare-fun x8_19 () (_ BitVec 64))
(declare-fun x8_18 () (_ BitVec 64))
(declare-fun x8_17 () (_ BitVec 64))
(declare-fun x8_16 () (_ BitVec 64))
(declare-fun x8_15 () (_ BitVec 64))
(declare-fun x8_14 () (_ BitVec 64))
(declare-fun x8_13 () (_ BitVec 64))
(declare-fun x8_12 () (_ BitVec 64))
(declare-fun x8_11 () (_ BitVec 64))
(declare-fun x8_10 () (_ BitVec 64))
(declare-fun x8_9 () (_ BitVec 64))
(declare-fun x8_8 () (_ BitVec 64))
(declare-fun x8_7 () (_ BitVec 64))
(declare-fun x8_6 () (_ BitVec 64))
(declare-fun x8_5 () (_ BitVec 64))
(declare-fun x8_4 () (_ BitVec 64))
(declare-fun x8_3 () (_ BitVec 64))
(declare-fun x8_2 () (_ BitVec 64))
(declare-fun x7_18 () (_ BitVec 64))
(declare-fun x7_17 () (_ BitVec 64))
(declare-fun x7_16 () (_ BitVec 64))
(declare-fun x7_15 () (_ BitVec 64))
(declare-fun x7_14 () (_ BitVec 64))
(declare-fun x7_13 () (_ BitVec 64))
(declare-fun x7_12 () (_ BitVec 64))
(declare-fun x7_11 () (_ BitVec 64))
(declare-fun x7_10 () (_ BitVec 64))
(declare-fun x7_9 () (_ BitVec 64))
(declare-fun x7_8 () (_ BitVec 64))
(declare-fun x7_7 () (_ BitVec 64))
(declare-fun x7_6 () (_ BitVec 64))
(declare-fun x7_5 () (_ BitVec 64))
(declare-fun x7_4 () (_ BitVec 64))
(declare-fun x7_3 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_15 () (_ BitVec 64))
(declare-fun x3_neg_14 () (_ BitVec 64))
(declare-fun x3_neg_13 () (_ BitVec 64))
(declare-fun x3_neg_12 () (_ BitVec 64))
(declare-fun x3_neg_11 () (_ BitVec 64))
(declare-fun x3_neg_10 () (_ BitVec 64))
(declare-fun x3_neg_9 () (_ BitVec 64))
(declare-fun x3_neg_8 () (_ BitVec 64))
(declare-fun x3_neg_7 () (_ BitVec 64))
(declare-fun x3_neg_6 () (_ BitVec 64))
(declare-fun x3_neg_5 () (_ BitVec 64))
(declare-fun x3_neg_4 () (_ BitVec 64))
(declare-fun x3_neg_3 () (_ BitVec 64))
(declare-fun x3_neg_2 () (_ BitVec 64))
(declare-fun x3_neg_1 () (_ BitVec 64))
(declare-fun x3_31 () (_ BitVec 64))
(declare-fun x3_30 () (_ BitVec 64))
(declare-fun x3_29 () (_ BitVec 64))
(declare-fun x3_28 () (_ BitVec 64))
(declare-fun x3_27 () (_ BitVec 64))
(declare-fun x3_26 () (_ BitVec 64))
(declare-fun x3_25 () (_ BitVec 64))
(declare-fun x3_24 () (_ BitVec 64))
(declare-fun x3_23 () (_ BitVec 64))
(declare-fun x3_22 () (_ BitVec 64))
(declare-fun x3_21 () (_ BitVec 64))
(declare-fun x3_20 () (_ BitVec 64))
(declare-fun x3_19 () (_ BitVec 64))
(declare-fun x3_18 () (_ BitVec 64))
(declare-fun x3_17 () (_ BitVec 64))
(declare-fun x3_16 () (_ BitVec 64))
(declare-fun x3_15 () (_ BitVec 64))
(declare-fun x3_14 () (_ BitVec 64))
(declare-fun x3_13 () (_ BitVec 64))
(declare-fun x3_12 () (_ BitVec 64))
(declare-fun x3_11 () (_ BitVec 64))
(declare-fun x3_10 () (_ BitVec 64))
(declare-fun x3_9 () (_ BitVec 64))
(declare-fun x3_8 () (_ BitVec 64))
(declare-fun x3_7 () (_ BitVec 64))
(declare-fun x3_6 () (_ BitVec 64))
(declare-fun x3_5 () (_ BitVec 64))
(declare-fun x3_4 () (_ BitVec 64))
(declare-fun x3_3 () (_ BitVec 64))
(declare-fun x3_2 () (_ BitVec 64))
(declare-fun x10_neg_15 () (_ BitVec 64))
(declare-fun x10_neg_14 () (_ BitVec 64))
(declare-fun x10_neg_13 () (_ BitVec 64))
(declare-fun x10_neg_12 () (_ BitVec 64))
(declare-fun x10_neg_11 () (_ BitVec 64))
(declare-fun x10_neg_10 () (_ BitVec 64))
(declare-fun x10_neg_9 () (_ BitVec 64))
(declare-fun x10_neg_8 () (_ BitVec 64))
(declare-fun x10_neg_7 () (_ BitVec 64))
(declare-fun x10_neg_6 () (_ BitVec 64))
(declare-fun x10_neg_5 () (_ BitVec 64))
(declare-fun x10_neg_4 () (_ BitVec 64))
(declare-fun x10_neg_3 () (_ BitVec 64))
(declare-fun x10_neg_2 () (_ BitVec 64))
(declare-fun x10_neg_1 () (_ BitVec 64))
(declare-fun x10_30 () (_ BitVec 64))
(declare-fun x10_29 () (_ BitVec 64))
(declare-fun x10_28 () (_ BitVec 64))
(declare-fun x10_27 () (_ BitVec 64))
(declare-fun x10_26 () (_ BitVec 64))
(declare-fun x10_25 () (_ BitVec 64))
(declare-fun x10_24 () (_ BitVec 64))
(declare-fun x10_23 () (_ BitVec 64))
(declare-fun x10_22 () (_ BitVec 64))
(declare-fun x10_21 () (_ BitVec 64))
(declare-fun x10_20 () (_ BitVec 64))
(declare-fun x10_19 () (_ BitVec 64))
(declare-fun x10_18 () (_ BitVec 64))
(declare-fun x10_17 () (_ BitVec 64))
(declare-fun x10_16 () (_ BitVec 64))
(declare-fun x10_15 () (_ BitVec 64))
(declare-fun x10_14 () (_ BitVec 64))
(declare-fun x10_13 () (_ BitVec 64))
(declare-fun x10_12 () (_ BitVec 64))
(declare-fun x10_11 () (_ BitVec 64))
(declare-fun x10_10 () (_ BitVec 64))
(declare-fun x10_9 () (_ BitVec 64))
(declare-fun x10_8 () (_ BitVec 64))
(declare-fun x10_7 () (_ BitVec 64))
(declare-fun x10_6 () (_ BitVec 64))
(declare-fun x10_5 () (_ BitVec 64))
(declare-fun x10_4 () (_ BitVec 64))
(declare-fun x10_3 () (_ BitVec 64))
(declare-fun x10_2 () (_ BitVec 64))
(declare-fun x10_1 () (_ BitVec 64))
(declare-fun ne_16 () (_ BitVec 1))
(declare-fun ne_15 () (_ BitVec 1))
(declare-fun ne_14 () (_ BitVec 1))
(declare-fun ne_13 () (_ BitVec 1))
(declare-fun ne_12 () (_ BitVec 1))
(declare-fun ne_11 () (_ BitVec 1))
(declare-fun ne_10 () (_ BitVec 1))
(declare-fun ne_9 () (_ BitVec 1))
(declare-fun ne_8 () (_ BitVec 1))
(declare-fun ne_7 () (_ BitVec 1))
(declare-fun ne_6 () (_ BitVec 1))
(declare-fun ne_5 () (_ BitVec 1))
(declare-fun ne_4 () (_ BitVec 1))
(declare-fun ne_3 () (_ BitVec 1))
(declare-fun ne_2 () (_ BitVec 1))
(declare-fun ne_1 () (_ BitVec 1))
(declare-fun ge_45 () (_ BitVec 1))
(declare-fun ge_44 () (_ BitVec 1))
(declare-fun ge_43 () (_ BitVec 1))
(declare-fun ge_42 () (_ BitVec 1))
(declare-fun ge_41 () (_ BitVec 1))
(declare-fun ge_40 () (_ BitVec 1))
(declare-fun ge_39 () (_ BitVec 1))
(declare-fun ge_38 () (_ BitVec 1))
(declare-fun ge_37 () (_ BitVec 1))
(declare-fun ge_36 () (_ BitVec 1))
(declare-fun ge_35 () (_ BitVec 1))
(declare-fun ge_34 () (_ BitVec 1))
(declare-fun ge_33 () (_ BitVec 1))
(declare-fun ge_32 () (_ BitVec 1))
(declare-fun ge_31 () (_ BitVec 1))
(declare-fun ge_30 () (_ BitVec 1))
(declare-fun ge_29 () (_ BitVec 1))
(declare-fun ge_28 () (_ BitVec 1))
(declare-fun ge_27 () (_ BitVec 1))
(declare-fun ge_26 () (_ BitVec 1))
(declare-fun ge_25 () (_ BitVec 1))
(declare-fun ge_24 () (_ BitVec 1))
(declare-fun ge_23 () (_ BitVec 1))
(declare-fun ge_22 () (_ BitVec 1))
(declare-fun ge_21 () (_ BitVec 1))
(declare-fun ge_20 () (_ BitVec 1))
(declare-fun ge_19 () (_ BitVec 1))
(declare-fun ge_18 () (_ BitVec 1))
(declare-fun ge_17 () (_ BitVec 1))
(declare-fun ge_16 () (_ BitVec 1))
(declare-fun ge_15 () (_ BitVec 1))
(declare-fun ge_14 () (_ BitVec 1))
(declare-fun ge_13 () (_ BitVec 1))
(declare-fun ge_12 () (_ BitVec 1))
(declare-fun ge_11 () (_ BitVec 1))
(declare-fun ge_10 () (_ BitVec 1))
(declare-fun ge_9 () (_ BitVec 1))
(declare-fun ge_8 () (_ BitVec 1))
(declare-fun ge_7 () (_ BitVec 1))
(declare-fun ge_6 () (_ BitVec 1))
(declare-fun ge_5 () (_ BitVec 1))
(declare-fun ge_4 () (_ BitVec 1))
(declare-fun ge_3 () (_ BitVec 1))
(declare-fun ge_2 () (_ BitVec 1))
(declare-fun ge_1 () (_ BitVec 1))
(declare-fun g_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun dc_146 () (_ BitVec 64))
(declare-fun dc_145 () (_ BitVec 1))
(declare-fun dc_144 () (_ BitVec 62))
(declare-fun dc_143 () (_ BitVec 1))
(declare-fun dc_142 () (_ BitVec 1))
(declare-fun dc_141 () (_ BitVec 1))
(declare-fun dc_140 () (_ BitVec 63))
(declare-fun dc_139 () (_ BitVec 64))
(declare-fun dc_138 () (_ BitVec 1))
(declare-fun dc_137 () (_ BitVec 62))
(declare-fun dc_136 () (_ BitVec 1))
(declare-fun dc_135 () (_ BitVec 1))
(declare-fun dc_134 () (_ BitVec 1))
(declare-fun dc_133 () (_ BitVec 63))
(declare-fun dc_132 () (_ BitVec 64))
(declare-fun dc_131 () (_ BitVec 1))
(declare-fun dc_130 () (_ BitVec 62))
(declare-fun dc_129 () (_ BitVec 1))
(declare-fun dc_128 () (_ BitVec 1))
(declare-fun dc_127 () (_ BitVec 1))
(declare-fun dc_126 () (_ BitVec 63))
(declare-fun dc_125 () (_ BitVec 64))
(declare-fun dc_124 () (_ BitVec 1))
(declare-fun dc_123 () (_ BitVec 62))
(declare-fun dc_122 () (_ BitVec 1))
(declare-fun dc_121 () (_ BitVec 1))
(declare-fun dc_120 () (_ BitVec 1))
(declare-fun dc_119 () (_ BitVec 63))
(declare-fun dc_118 () (_ BitVec 64))
(declare-fun dc_117 () (_ BitVec 1))
(declare-fun dc_116 () (_ BitVec 62))
(declare-fun dc_115 () (_ BitVec 1))
(declare-fun dc_114 () (_ BitVec 1))
(declare-fun dc_113 () (_ BitVec 1))
(declare-fun dc_112 () (_ BitVec 63))
(declare-fun dc_111 () (_ BitVec 64))
(declare-fun dc_110 () (_ BitVec 1))
(declare-fun dc_109 () (_ BitVec 62))
(declare-fun dc_108 () (_ BitVec 1))
(declare-fun dc_107 () (_ BitVec 1))
(declare-fun dc_106 () (_ BitVec 1))
(declare-fun dc_105 () (_ BitVec 63))
(declare-fun dc_104 () (_ BitVec 64))
(declare-fun dc_103 () (_ BitVec 1))
(declare-fun dc_102 () (_ BitVec 62))
(declare-fun dc_101 () (_ BitVec 1))
(declare-fun dc_100 () (_ BitVec 1))
(declare-fun dc_99 () (_ BitVec 1))
(declare-fun dc_98 () (_ BitVec 63))
(declare-fun dc_97 () (_ BitVec 64))
(declare-fun dc_96 () (_ BitVec 1))
(declare-fun dc_95 () (_ BitVec 62))
(declare-fun dc_94 () (_ BitVec 1))
(declare-fun dc_93 () (_ BitVec 1))
(declare-fun dc_92 () (_ BitVec 1))
(declare-fun dc_91 () (_ BitVec 63))
(declare-fun dc_90 () (_ BitVec 64))
(declare-fun dc_89 () (_ BitVec 1))
(declare-fun dc_88 () (_ BitVec 62))
(declare-fun dc_87 () (_ BitVec 1))
(declare-fun dc_86 () (_ BitVec 1))
(declare-fun dc_85 () (_ BitVec 1))
(declare-fun dc_84 () (_ BitVec 63))
(declare-fun dc_83 () (_ BitVec 64))
(declare-fun dc_82 () (_ BitVec 1))
(declare-fun dc_81 () (_ BitVec 62))
(declare-fun dc_80 () (_ BitVec 1))
(declare-fun dc_79 () (_ BitVec 1))
(declare-fun dc_78 () (_ BitVec 1))
(declare-fun dc_77 () (_ BitVec 63))
(declare-fun dc_76 () (_ BitVec 64))
(declare-fun dc_75 () (_ BitVec 1))
(declare-fun dc_74 () (_ BitVec 62))
(declare-fun dc_73 () (_ BitVec 1))
(declare-fun dc_72 () (_ BitVec 1))
(declare-fun dc_71 () (_ BitVec 1))
(declare-fun dc_70 () (_ BitVec 63))
(declare-fun dc_69 () (_ BitVec 64))
(declare-fun dc_68 () (_ BitVec 1))
(declare-fun dc_67 () (_ BitVec 62))
(declare-fun dc_66 () (_ BitVec 1))
(declare-fun dc_65 () (_ BitVec 1))
(declare-fun dc_64 () (_ BitVec 1))
(declare-fun dc_63 () (_ BitVec 63))
(declare-fun dc_62 () (_ BitVec 64))
(declare-fun dc_61 () (_ BitVec 1))
(declare-fun dc_60 () (_ BitVec 62))
(declare-fun dc_59 () (_ BitVec 1))
(declare-fun dc_58 () (_ BitVec 1))
(declare-fun dc_57 () (_ BitVec 1))
(declare-fun dc_56 () (_ BitVec 63))
(declare-fun dc_55 () (_ BitVec 64))
(declare-fun dc_54 () (_ BitVec 1))
(declare-fun dc_53 () (_ BitVec 62))
(declare-fun dc_52 () (_ BitVec 1))
(declare-fun dc_51 () (_ BitVec 1))
(declare-fun dc_50 () (_ BitVec 1))
(declare-fun dc_49 () (_ BitVec 63))
(declare-fun dc_48 () (_ BitVec 64))
(declare-fun dc_47 () (_ BitVec 1))
(declare-fun dc_46 () (_ BitVec 62))
(declare-fun dc_45 () (_ BitVec 1))
(declare-fun dc_44 () (_ BitVec 1))
(declare-fun dc_43 () (_ BitVec 1))
(declare-fun dc_42 () (_ BitVec 63))
(declare-fun dc_41 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (= x7_3 (bvadd (bvadd f_0_low60_0_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_2 (bvadd (bvadd g_0_low60_0_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_0_1)) (bvsle f_0_low60_0_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_0_1)) (bvsle g_0_low60_0_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_3) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #x0000000000000001 #x0000000000000001)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_41 ((_ extract 63 1) x8_2)) (= x8_lo_1 ((_ extract 0 0) x8_2))))
(assert (= ne_1 (bvand x8_lo_1 #b1)))
(assert (= x10_1 (ite (= ne_1 #b1) x7_3 #x0000000000000000)))
(assert (and (= ge_1 ((_ extract 63 63) #x0000000000000001)) (= dc_42 ((_ extract 62 0) #x0000000000000001))))
(assert (= ge_2 (bvnot ge_1)))
(assert (= ge_3 (ite (= ne_1 #b1) ge_2 #b0)))
(assert (and (= dc_43 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_2 (ite (= ge_3 #b1) x3_neg_1 #x0000000000000001)))
(assert (and (= dc_44 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_2 (ite (= ge_3 #b1) x10_neg_1 x10_1)))
(assert (= x7_4 (ite (= ge_3 #b1) x8_2 x7_3)))
(assert (and (= dc_45 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2)))) (= x8_3 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2))))))
(assert (= x3_3 (bvadd x3_2 #x0000000000000002)))
(assert (and (= dc_46 ((_ extract 63 2) x8_3)) (= x8_lo_2 ((_ extract 1 0) x8_3))))
(assert (and (= x8_target_1 ((_ extract 1 1) x8_lo_2)) (= dc_47 ((_ extract 0 0) x8_lo_2))))
(assert (= ne_2 (bvand x8_target_1 #b1)))
(assert (and (= x8_4 ((_ sign_extend 1) ((_ extract 63 1) x8_3))) (= dc_48 ((_ zero_extend 63) ((_ extract 0 0) x8_3)))))
(assert true)
(assert (= x10_3 (ite (= ne_2 #b1) x7_4 #x0000000000000000)))
(assert (and (= ge_4 ((_ extract 63 63) x3_3)) (= dc_49 ((_ extract 62 0) x3_3))))
(assert (= ge_5 (bvnot ge_4)))
(assert (= ge_6 (ite (= ne_2 #b1) ge_5 #b0)))
(assert (and (= dc_50 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_4 (ite (= ge_6 #b1) x3_neg_2 x3_3)))
(assert (and (= dc_51 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_4 (ite (= ge_6 #b1) x10_neg_2 x10_3)))
(assert (= x7_5 (ite (= ge_6 #b1) x8_4 x7_4)))
(assert (and (= dc_52 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4)))) (= x8_5 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4))))))
(assert (= x3_5 (bvadd x3_4 #x0000000000000002)))
(assert (and (= dc_53 ((_ extract 63 2) x8_5)) (= x8_lo_3 ((_ extract 1 0) x8_5))))
(assert (and (= x8_target_2 ((_ extract 1 1) x8_lo_3)) (= dc_54 ((_ extract 0 0) x8_lo_3))))
(assert (= ne_3 (bvand x8_target_2 #b1)))
(assert (and (= x8_6 ((_ sign_extend 1) ((_ extract 63 1) x8_5))) (= dc_55 ((_ zero_extend 63) ((_ extract 0 0) x8_5)))))
(assert true)
(assert (= x10_5 (ite (= ne_3 #b1) x7_5 #x0000000000000000)))
(assert (and (= ge_7 ((_ extract 63 63) x3_5)) (= dc_56 ((_ extract 62 0) x3_5))))
(assert (= ge_8 (bvnot ge_7)))
(assert (= ge_9 (ite (= ne_3 #b1) ge_8 #b0)))
(assert (and (= dc_57 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_6 (ite (= ge_9 #b1) x3_neg_3 x3_5)))
(assert (and (= dc_58 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_6 (ite (= ge_9 #b1) x10_neg_3 x10_5)))
(assert (= x7_6 (ite (= ge_9 #b1) x8_6 x7_5)))
(assert (and (= dc_59 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6)))) (= x8_7 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6))))))
(assert (= x3_7 (bvadd x3_6 #x0000000000000002)))
(assert (and (= dc_60 ((_ extract 63 2) x8_7)) (= x8_lo_4 ((_ extract 1 0) x8_7))))
(assert (and (= x8_target_3 ((_ extract 1 1) x8_lo_4)) (= dc_61 ((_ extract 0 0) x8_lo_4))))
(assert (= ne_4 (bvand x8_target_3 #b1)))
(assert (and (= x8_8 ((_ sign_extend 1) ((_ extract 63 1) x8_7))) (= dc_62 ((_ zero_extend 63) ((_ extract 0 0) x8_7)))))
(assert true)
(assert (= x10_7 (ite (= ne_4 #b1) x7_6 #x0000000000000000)))
(assert (and (= ge_10 ((_ extract 63 63) x3_7)) (= dc_63 ((_ extract 62 0) x3_7))))
(assert (= ge_11 (bvnot ge_10)))
(assert (= ge_12 (ite (= ne_4 #b1) ge_11 #b0)))
(assert (and (= dc_64 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_7))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_4 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_7))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_8 (ite (= ge_12 #b1) x3_neg_4 x3_7)))
(assert (and (= dc_65 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_7))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_4 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_7))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_8 (ite (= ge_12 #b1) x10_neg_4 x10_7)))
(assert (= x7_7 (ite (= ge_12 #b1) x8_8 x7_6)))
(assert (and (= dc_66 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_8) ((_ zero_extend 1) x10_8)))) (= x8_9 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_8) ((_ zero_extend 1) x10_8))))))
(assert (= x3_9 (bvadd x3_8 #x0000000000000002)))
(assert (and (= dc_67 ((_ extract 63 2) x8_9)) (= x8_lo_5 ((_ extract 1 0) x8_9))))
(assert (and (= x8_target_4 ((_ extract 1 1) x8_lo_5)) (= dc_68 ((_ extract 0 0) x8_lo_5))))
(assert (= ne_5 (bvand x8_target_4 #b1)))
(assert (and (= x8_10 ((_ sign_extend 1) ((_ extract 63 1) x8_9))) (= dc_69 ((_ zero_extend 63) ((_ extract 0 0) x8_9)))))
(assert true)
(assert (= x10_9 (ite (= ne_5 #b1) x7_7 #x0000000000000000)))
(assert (and (= ge_13 ((_ extract 63 63) x3_9)) (= dc_70 ((_ extract 62 0) x3_9))))
(assert (= ge_14 (bvnot ge_13)))
(assert (= ge_15 (ite (= ne_5 #b1) ge_14 #b0)))
(assert (and (= dc_71 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_9))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_5 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_9))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_10 (ite (= ge_15 #b1) x3_neg_5 x3_9)))
(assert (and (= dc_72 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_9))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_5 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_9))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_10 (ite (= ge_15 #b1) x10_neg_5 x10_9)))
(assert (= x7_8 (ite (= ge_15 #b1) x8_10 x7_7)))
(assert (and (= dc_73 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_10) ((_ zero_extend 1) x10_10)))) (= x8_11 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_10) ((_ zero_extend 1) x10_10))))))
(assert (= x3_11 (bvadd x3_10 #x0000000000000002)))
(assert (and (= dc_74 ((_ extract 63 2) x8_11)) (= x8_lo_6 ((_ extract 1 0) x8_11))))
(assert (and (= x8_target_5 ((_ extract 1 1) x8_lo_6)) (= dc_75 ((_ extract 0 0) x8_lo_6))))
(assert (= ne_6 (bvand x8_target_5 #b1)))
(assert (and (= x8_12 ((_ sign_extend 1) ((_ extract 63 1) x8_11))) (= dc_76 ((_ zero_extend 63) ((_ extract 0 0) x8_11)))))
(assert true)
(assert (= x10_11 (ite (= ne_6 #b1) x7_8 #x0000000000000000)))
(assert (and (= ge_16 ((_ extract 63 63) x3_11)) (= dc_77 ((_ extract 62 0) x3_11))))
(assert (= ge_17 (bvnot ge_16)))
(assert (= ge_18 (ite (= ne_6 #b1) ge_17 #b0)))
(assert (and (= dc_78 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_11))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_6 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_11))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_12 (ite (= ge_18 #b1) x3_neg_6 x3_11)))
(assert (and (= dc_79 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_11))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_6 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_11))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_12 (ite (= ge_18 #b1) x10_neg_6 x10_11)))
(assert (= x7_9 (ite (= ge_18 #b1) x8_12 x7_8)))
(assert (and (= dc_80 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_12) ((_ zero_extend 1) x10_12)))) (= x8_13 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_12) ((_ zero_extend 1) x10_12))))))
(assert (= x3_13 (bvadd x3_12 #x0000000000000002)))
(assert (and (= dc_81 ((_ extract 63 2) x8_13)) (= x8_lo_7 ((_ extract 1 0) x8_13))))
(assert (and (= x8_target_6 ((_ extract 1 1) x8_lo_7)) (= dc_82 ((_ extract 0 0) x8_lo_7))))
(assert (= ne_7 (bvand x8_target_6 #b1)))
(assert (and (= x8_14 ((_ sign_extend 1) ((_ extract 63 1) x8_13))) (= dc_83 ((_ zero_extend 63) ((_ extract 0 0) x8_13)))))
(assert true)
(assert (= x10_13 (ite (= ne_7 #b1) x7_9 #x0000000000000000)))
(assert (and (= ge_19 ((_ extract 63 63) x3_13)) (= dc_84 ((_ extract 62 0) x3_13))))
(assert (= ge_20 (bvnot ge_19)))
(assert (= ge_21 (ite (= ne_7 #b1) ge_20 #b0)))
(assert (and (= dc_85 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_13))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_7 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_13))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_14 (ite (= ge_21 #b1) x3_neg_7 x3_13)))
(assert (and (= dc_86 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_13))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_7 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_13))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_14 (ite (= ge_21 #b1) x10_neg_7 x10_13)))
(assert (= x7_10 (ite (= ge_21 #b1) x8_14 x7_9)))
(assert (and (= dc_87 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_14) ((_ zero_extend 1) x10_14)))) (= x8_15 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_14) ((_ zero_extend 1) x10_14))))))
(assert (= x3_15 (bvadd x3_14 #x0000000000000002)))
(assert (and (= dc_88 ((_ extract 63 2) x8_15)) (= x8_lo_8 ((_ extract 1 0) x8_15))))
(assert (and (= x8_target_7 ((_ extract 1 1) x8_lo_8)) (= dc_89 ((_ extract 0 0) x8_lo_8))))
(assert (= ne_8 (bvand x8_target_7 #b1)))
(assert (and (= x8_16 ((_ sign_extend 1) ((_ extract 63 1) x8_15))) (= dc_90 ((_ zero_extend 63) ((_ extract 0 0) x8_15)))))
(assert true)
(assert (= x10_15 (ite (= ne_8 #b1) x7_10 #x0000000000000000)))
(assert (and (= ge_22 ((_ extract 63 63) x3_15)) (= dc_91 ((_ extract 62 0) x3_15))))
(assert (= ge_23 (bvnot ge_22)))
(assert (= ge_24 (ite (= ne_8 #b1) ge_23 #b0)))
(assert (and (= dc_92 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_15))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_8 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_15))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_16 (ite (= ge_24 #b1) x3_neg_8 x3_15)))
(assert (and (= dc_93 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_15))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_8 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_15))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_16 (ite (= ge_24 #b1) x10_neg_8 x10_15)))
(assert (= x7_11 (ite (= ge_24 #b1) x8_16 x7_10)))
(assert (and (= dc_94 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_16) ((_ zero_extend 1) x10_16)))) (= x8_17 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_16) ((_ zero_extend 1) x10_16))))))
(assert (= x3_17 (bvadd x3_16 #x0000000000000002)))
(assert (and (= dc_95 ((_ extract 63 2) x8_17)) (= x8_lo_9 ((_ extract 1 0) x8_17))))
(assert (and (= x8_target_8 ((_ extract 1 1) x8_lo_9)) (= dc_96 ((_ extract 0 0) x8_lo_9))))
(assert (= ne_9 (bvand x8_target_8 #b1)))
(assert (and (= x8_18 ((_ sign_extend 1) ((_ extract 63 1) x8_17))) (= dc_97 ((_ zero_extend 63) ((_ extract 0 0) x8_17)))))
(assert true)
(assert (= x10_17 (ite (= ne_9 #b1) x7_11 #x0000000000000000)))
(assert (and (= ge_25 ((_ extract 63 63) x3_17)) (= dc_98 ((_ extract 62 0) x3_17))))
(assert (= ge_26 (bvnot ge_25)))
(assert (= ge_27 (ite (= ne_9 #b1) ge_26 #b0)))
(assert (and (= dc_99 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_17))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_9 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_17))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_18 (ite (= ge_27 #b1) x3_neg_9 x3_17)))
(assert (and (= dc_100 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_17))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_9 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_17))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_18 (ite (= ge_27 #b1) x10_neg_9 x10_17)))
(assert (= x7_12 (ite (= ge_27 #b1) x8_18 x7_11)))
(assert (and (= dc_101 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_18) ((_ zero_extend 1) x10_18)))) (= x8_19 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_18) ((_ zero_extend 1) x10_18))))))
(assert (= x3_19 (bvadd x3_18 #x0000000000000002)))
(assert (and (= dc_102 ((_ extract 63 2) x8_19)) (= x8_lo_10 ((_ extract 1 0) x8_19))))
(assert (and (= x8_target_9 ((_ extract 1 1) x8_lo_10)) (= dc_103 ((_ extract 0 0) x8_lo_10))))
(assert (= ne_10 (bvand x8_target_9 #b1)))
(assert (and (= x8_20 ((_ sign_extend 1) ((_ extract 63 1) x8_19))) (= dc_104 ((_ zero_extend 63) ((_ extract 0 0) x8_19)))))
(assert true)
(assert (= x10_19 (ite (= ne_10 #b1) x7_12 #x0000000000000000)))
(assert (and (= ge_28 ((_ extract 63 63) x3_19)) (= dc_105 ((_ extract 62 0) x3_19))))
(assert (= ge_29 (bvnot ge_28)))
(assert (= ge_30 (ite (= ne_10 #b1) ge_29 #b0)))
(assert (and (= dc_106 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_19))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_10 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_19))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_20 (ite (= ge_30 #b1) x3_neg_10 x3_19)))
(assert (and (= dc_107 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_19))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_10 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_19))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_20 (ite (= ge_30 #b1) x10_neg_10 x10_19)))
(assert (= x7_13 (ite (= ge_30 #b1) x8_20 x7_12)))
(assert (and (= dc_108 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_20) ((_ zero_extend 1) x10_20)))) (= x8_21 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_20) ((_ zero_extend 1) x10_20))))))
(assert (= x3_21 (bvadd x3_20 #x0000000000000002)))
(assert (and (= dc_109 ((_ extract 63 2) x8_21)) (= x8_lo_11 ((_ extract 1 0) x8_21))))
(assert (and (= x8_target_10 ((_ extract 1 1) x8_lo_11)) (= dc_110 ((_ extract 0 0) x8_lo_11))))
(assert (= ne_11 (bvand x8_target_10 #b1)))
(assert (and (= x8_22 ((_ sign_extend 1) ((_ extract 63 1) x8_21))) (= dc_111 ((_ zero_extend 63) ((_ extract 0 0) x8_21)))))
(assert true)
(assert (= x10_21 (ite (= ne_11 #b1) x7_13 #x0000000000000000)))
(assert (and (= ge_31 ((_ extract 63 63) x3_21)) (= dc_112 ((_ extract 62 0) x3_21))))
(assert (= ge_32 (bvnot ge_31)))
(assert (= ge_33 (ite (= ne_11 #b1) ge_32 #b0)))
(assert (and (= dc_113 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_21))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_11 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_21))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_22 (ite (= ge_33 #b1) x3_neg_11 x3_21)))
(assert (and (= dc_114 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_21))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_11 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_21))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_22 (ite (= ge_33 #b1) x10_neg_11 x10_21)))
(assert (= x7_14 (ite (= ge_33 #b1) x8_22 x7_13)))
(assert (and (= dc_115 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_22) ((_ zero_extend 1) x10_22)))) (= x8_23 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_22) ((_ zero_extend 1) x10_22))))))
(assert (= x3_23 (bvadd x3_22 #x0000000000000002)))
(assert (and (= dc_116 ((_ extract 63 2) x8_23)) (= x8_lo_12 ((_ extract 1 0) x8_23))))
(assert (and (= x8_target_11 ((_ extract 1 1) x8_lo_12)) (= dc_117 ((_ extract 0 0) x8_lo_12))))
(assert (= ne_12 (bvand x8_target_11 #b1)))
(assert (and (= x8_24 ((_ sign_extend 1) ((_ extract 63 1) x8_23))) (= dc_118 ((_ zero_extend 63) ((_ extract 0 0) x8_23)))))
(assert true)
(assert (= x10_23 (ite (= ne_12 #b1) x7_14 #x0000000000000000)))
(assert (and (= ge_34 ((_ extract 63 63) x3_23)) (= dc_119 ((_ extract 62 0) x3_23))))
(assert (= ge_35 (bvnot ge_34)))
(assert (= ge_36 (ite (= ne_12 #b1) ge_35 #b0)))
(assert (and (= dc_120 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_23))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_12 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_23))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_24 (ite (= ge_36 #b1) x3_neg_12 x3_23)))
(assert (and (= dc_121 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_23))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_12 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_23))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_24 (ite (= ge_36 #b1) x10_neg_12 x10_23)))
(assert (= x7_15 (ite (= ge_36 #b1) x8_24 x7_14)))
(assert (and (= dc_122 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_24) ((_ zero_extend 1) x10_24)))) (= x8_25 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_24) ((_ zero_extend 1) x10_24))))))
(assert (= x3_25 (bvadd x3_24 #x0000000000000002)))
(assert (and (= dc_123 ((_ extract 63 2) x8_25)) (= x8_lo_13 ((_ extract 1 0) x8_25))))
(assert (and (= x8_target_12 ((_ extract 1 1) x8_lo_13)) (= dc_124 ((_ extract 0 0) x8_lo_13))))
(assert (= ne_13 (bvand x8_target_12 #b1)))
(assert (and (= x8_26 ((_ sign_extend 1) ((_ extract 63 1) x8_25))) (= dc_125 ((_ zero_extend 63) ((_ extract 0 0) x8_25)))))
(assert true)
(assert (= x10_25 (ite (= ne_13 #b1) x7_15 #x0000000000000000)))
(assert (and (= ge_37 ((_ extract 63 63) x3_25)) (= dc_126 ((_ extract 62 0) x3_25))))
(assert (= ge_38 (bvnot ge_37)))
(assert (= ge_39 (ite (= ne_13 #b1) ge_38 #b0)))
(assert (and (= dc_127 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_25))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_13 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_25))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_26 (ite (= ge_39 #b1) x3_neg_13 x3_25)))
(assert (and (= dc_128 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_25))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_13 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_25))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_26 (ite (= ge_39 #b1) x10_neg_13 x10_25)))
(assert (= x7_16 (ite (= ge_39 #b1) x8_26 x7_15)))
(assert (and (= dc_129 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_26) ((_ zero_extend 1) x10_26)))) (= x8_27 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_26) ((_ zero_extend 1) x10_26))))))
(assert (= x3_27 (bvadd x3_26 #x0000000000000002)))
(assert (and (= dc_130 ((_ extract 63 2) x8_27)) (= x8_lo_14 ((_ extract 1 0) x8_27))))
(assert (and (= x8_target_13 ((_ extract 1 1) x8_lo_14)) (= dc_131 ((_ extract 0 0) x8_lo_14))))
(assert (= ne_14 (bvand x8_target_13 #b1)))
(assert (and (= x8_28 ((_ sign_extend 1) ((_ extract 63 1) x8_27))) (= dc_132 ((_ zero_extend 63) ((_ extract 0 0) x8_27)))))
(assert true)
(assert (= x10_27 (ite (= ne_14 #b1) x7_16 #x0000000000000000)))
(assert (and (= ge_40 ((_ extract 63 63) x3_27)) (= dc_133 ((_ extract 62 0) x3_27))))
(assert (= ge_41 (bvnot ge_40)))
(assert (= ge_42 (ite (= ne_14 #b1) ge_41 #b0)))
(assert (and (= dc_134 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_27))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_14 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_27))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_28 (ite (= ge_42 #b1) x3_neg_14 x3_27)))
(assert (and (= dc_135 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_27))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_14 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_27))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_28 (ite (= ge_42 #b1) x10_neg_14 x10_27)))
(assert (= x7_17 (ite (= ge_42 #b1) x8_28 x7_16)))
(assert (and (= dc_136 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_28) ((_ zero_extend 1) x10_28)))) (= x8_29 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_28) ((_ zero_extend 1) x10_28))))))
(assert (= x3_29 (bvadd x3_28 #x0000000000000002)))
(assert (and (= dc_137 ((_ extract 63 2) x8_29)) (= x8_lo_15 ((_ extract 1 0) x8_29))))
(assert (and (= x8_target_14 ((_ extract 1 1) x8_lo_15)) (= dc_138 ((_ extract 0 0) x8_lo_15))))
(assert (= ne_15 (bvand x8_target_14 #b1)))
(assert (and (= x8_30 ((_ sign_extend 1) ((_ extract 63 1) x8_29))) (= dc_139 ((_ zero_extend 63) ((_ extract 0 0) x8_29)))))
(assert true)
(assert (= x10_29 (ite (= ne_15 #b1) x7_17 #x0000000000000000)))
(assert (and (= ge_43 ((_ extract 63 63) x3_29)) (= dc_140 ((_ extract 62 0) x3_29))))
(assert (= ge_44 (bvnot ge_43)))
(assert (= ge_45 (ite (= ne_15 #b1) ge_44 #b0)))
(assert (and (= dc_141 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_29))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_15 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_29))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_30 (ite (= ge_45 #b1) x3_neg_15 x3_29)))
(assert (and (= dc_142 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_29))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_15 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_29))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_30 (ite (= ge_45 #b1) x10_neg_15 x10_29)))
(assert (= x7_18 (ite (= ge_45 #b1) x8_30 x7_17)))
(assert (and (= dc_143 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_30) ((_ zero_extend 1) x10_30)))) (= x8_31 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_30) ((_ zero_extend 1) x10_30))))))
(assert (= x3_31 (bvadd x3_30 #x0000000000000002)))
(assert (and (= dc_144 ((_ extract 63 2) x8_31)) (= x8_lo_16 ((_ extract 1 0) x8_31))))
(assert (and (= x8_target_15 ((_ extract 1 1) x8_lo_16)) (= dc_145 ((_ extract 0 0) x8_lo_16))))
(assert (= ne_16 (bvand x8_target_15 #b1)))
(assert (and (= x8_32 ((_ sign_extend 1) ((_ extract 63 1) x8_31))) (= dc_146 ((_ zero_extend 63) ((_ extract 0 0) x8_31)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_30) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_18 x7_17)) (= (bvmul x8_32 #x0000000000000002) x8_30)) (= x3_31 (bvadd #x0000000000000002 x3_29))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_30) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_29 #x0000000000000000)) (= x7_18 x7_17)) (= (bvmul x8_32 #x0000000000000002) (bvadd x8_30 x7_17))) (= x3_31 (bvadd #x0000000000000002 x3_29)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_30) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_29 #x0000000000000000)) (= x7_18 x8_30)) (= (bvmul x8_32 #x0000000000000002) (bvsub x8_30 x7_17))) (= x3_31 (bvsub #x0000000000000002 x3_29))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_57b295.smt2
Execution time of boolector: 1.2987 seconds
OUTPUT FROM boolector:
unsat

=== Cut #2 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #2
; Range assertion #28: or [and [smod (sub (uext x8_34 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_20 = x7_19, mul x8_36 2@64 = x8_34, x3_35 = add 2@64 x3_33], and [smod (sub (uext x8_34 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_33 <s 0@64, x7_20 = x7_19, mul x8_36 2@64 = add x8_34 x7_19, x3_35 = add 2@64 x3_33], and [smod (sub (uext x8_34 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_33 >=s 0@64, x7_20 = x8_34, mul x8_36 2@64 = sub x8_34 x7_19, x3_35 = sub 2@64 x3_33]]
; Range condition: ((x8_34@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_20 = x7_19 /\ x8_36 * 2 = x8_34 /\ x3_35 = 2 + x3_33 \/ ((x8_34@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_33 <s 0 /\ x7_20 = x7_19 /\ x8_36 * 2 = x8_34 + x7_19 /\ x3_35 = 2 + x3_33 \/ ((x8_34@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_33 >=s 0 /\ x7_20 = x8_34 /\ x8_36 * 2 = x8_34 - x7_19 /\ x3_35 = 2 - x3_33
; Output file: /tmp/outputqfbv_81d872.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_17 () (_ BitVec 1))
(declare-fun x8_target_16 () (_ BitVec 1))
(declare-fun x8_target_15 () (_ BitVec 1))
(declare-fun x8_target_14 () (_ BitVec 1))
(declare-fun x8_target_13 () (_ BitVec 1))
(declare-fun x8_target_12 () (_ BitVec 1))
(declare-fun x8_target_11 () (_ BitVec 1))
(declare-fun x8_target_10 () (_ BitVec 1))
(declare-fun x8_target_9 () (_ BitVec 1))
(declare-fun x8_target_8 () (_ BitVec 1))
(declare-fun x8_target_7 () (_ BitVec 1))
(declare-fun x8_target_6 () (_ BitVec 1))
(declare-fun x8_target_5 () (_ BitVec 1))
(declare-fun x8_target_4 () (_ BitVec 1))
(declare-fun x8_target_3 () (_ BitVec 1))
(declare-fun x8_target_2 () (_ BitVec 1))
(declare-fun x8_target_1 () (_ BitVec 1))
(declare-fun x8_lo_18 () (_ BitVec 2))
(declare-fun x8_lo_17 () (_ BitVec 2))
(declare-fun x8_lo_16 () (_ BitVec 2))
(declare-fun x8_lo_15 () (_ BitVec 2))
(declare-fun x8_lo_14 () (_ BitVec 2))
(declare-fun x8_lo_13 () (_ BitVec 2))
(declare-fun x8_lo_12 () (_ BitVec 2))
(declare-fun x8_lo_11 () (_ BitVec 2))
(declare-fun x8_lo_10 () (_ BitVec 2))
(declare-fun x8_lo_9 () (_ BitVec 2))
(declare-fun x8_lo_8 () (_ BitVec 2))
(declare-fun x8_lo_7 () (_ BitVec 2))
(declare-fun x8_lo_6 () (_ BitVec 2))
(declare-fun x8_lo_5 () (_ BitVec 2))
(declare-fun x8_lo_4 () (_ BitVec 2))
(declare-fun x8_lo_3 () (_ BitVec 2))
(declare-fun x8_lo_2 () (_ BitVec 2))
(declare-fun x8_lo_1 () (_ BitVec 1))
(declare-fun x8_36 () (_ BitVec 64))
(declare-fun x8_35 () (_ BitVec 64))
(declare-fun x8_34 () (_ BitVec 64))
(declare-fun x8_33 () (_ BitVec 64))
(declare-fun x8_32 () (_ BitVec 64))
(declare-fun x8_31 () (_ BitVec 64))
(declare-fun x8_30 () (_ BitVec 64))
(declare-fun x8_29 () (_ BitVec 64))
(declare-fun x8_28 () (_ BitVec 64))
(declare-fun x8_27 () (_ BitVec 64))
(declare-fun x8_26 () (_ BitVec 64))
(declare-fun x8_25 () (_ BitVec 64))
(declare-fun x8_24 () (_ BitVec 64))
(declare-fun x8_23 () (_ BitVec 64))
(declare-fun x8_22 () (_ BitVec 64))
(declare-fun x8_21 () (_ BitVec 64))
(declare-fun x8_20 () (_ BitVec 64))
(declare-fun x8_19 () (_ BitVec 64))
(declare-fun x8_18 () (_ BitVec 64))
(declare-fun x8_17 () (_ BitVec 64))
(declare-fun x8_16 () (_ BitVec 64))
(declare-fun x8_15 () (_ BitVec 64))
(declare-fun x8_14 () (_ BitVec 64))
(declare-fun x8_13 () (_ BitVec 64))
(declare-fun x8_12 () (_ BitVec 64))
(declare-fun x8_11 () (_ BitVec 64))
(declare-fun x8_10 () (_ BitVec 64))
(declare-fun x8_9 () (_ BitVec 64))
(declare-fun x8_8 () (_ BitVec 64))
(declare-fun x8_7 () (_ BitVec 64))
(declare-fun x8_6 () (_ BitVec 64))
(declare-fun x8_5 () (_ BitVec 64))
(declare-fun x8_4 () (_ BitVec 64))
(declare-fun x8_3 () (_ BitVec 64))
(declare-fun x8_2 () (_ BitVec 64))
(declare-fun x7_20 () (_ BitVec 64))
(declare-fun x7_19 () (_ BitVec 64))
(declare-fun x7_18 () (_ BitVec 64))
(declare-fun x7_17 () (_ BitVec 64))
(declare-fun x7_16 () (_ BitVec 64))
(declare-fun x7_15 () (_ BitVec 64))
(declare-fun x7_14 () (_ BitVec 64))
(declare-fun x7_13 () (_ BitVec 64))
(declare-fun x7_12 () (_ BitVec 64))
(declare-fun x7_11 () (_ BitVec 64))
(declare-fun x7_10 () (_ BitVec 64))
(declare-fun x7_9 () (_ BitVec 64))
(declare-fun x7_8 () (_ BitVec 64))
(declare-fun x7_7 () (_ BitVec 64))
(declare-fun x7_6 () (_ BitVec 64))
(declare-fun x7_5 () (_ BitVec 64))
(declare-fun x7_4 () (_ BitVec 64))
(declare-fun x7_3 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_17 () (_ BitVec 64))
(declare-fun x3_neg_16 () (_ BitVec 64))
(declare-fun x3_neg_15 () (_ BitVec 64))
(declare-fun x3_neg_14 () (_ BitVec 64))
(declare-fun x3_neg_13 () (_ BitVec 64))
(declare-fun x3_neg_12 () (_ BitVec 64))
(declare-fun x3_neg_11 () (_ BitVec 64))
(declare-fun x3_neg_10 () (_ BitVec 64))
(declare-fun x3_neg_9 () (_ BitVec 64))
(declare-fun x3_neg_8 () (_ BitVec 64))
(declare-fun x3_neg_7 () (_ BitVec 64))
(declare-fun x3_neg_6 () (_ BitVec 64))
(declare-fun x3_neg_5 () (_ BitVec 64))
(declare-fun x3_neg_4 () (_ BitVec 64))
(declare-fun x3_neg_3 () (_ BitVec 64))
(declare-fun x3_neg_2 () (_ BitVec 64))
(declare-fun x3_neg_1 () (_ BitVec 64))
(declare-fun x3_35 () (_ BitVec 64))
(declare-fun x3_34 () (_ BitVec 64))
(declare-fun x3_33 () (_ BitVec 64))
(declare-fun x3_32 () (_ BitVec 64))
(declare-fun x3_31 () (_ BitVec 64))
(declare-fun x3_30 () (_ BitVec 64))
(declare-fun x3_29 () (_ BitVec 64))
(declare-fun x3_28 () (_ BitVec 64))
(declare-fun x3_27 () (_ BitVec 64))
(declare-fun x3_26 () (_ BitVec 64))
(declare-fun x3_25 () (_ BitVec 64))
(declare-fun x3_24 () (_ BitVec 64))
(declare-fun x3_23 () (_ BitVec 64))
(declare-fun x3_22 () (_ BitVec 64))
(declare-fun x3_21 () (_ BitVec 64))
(declare-fun x3_20 () (_ BitVec 64))
(declare-fun x3_19 () (_ BitVec 64))
(declare-fun x3_18 () (_ BitVec 64))
(declare-fun x3_17 () (_ BitVec 64))
(declare-fun x3_16 () (_ BitVec 64))
(declare-fun x3_15 () (_ BitVec 64))
(declare-fun x3_14 () (_ BitVec 64))
(declare-fun x3_13 () (_ BitVec 64))
(declare-fun x3_12 () (_ BitVec 64))
(declare-fun x3_11 () (_ BitVec 64))
(declare-fun x3_10 () (_ BitVec 64))
(declare-fun x3_9 () (_ BitVec 64))
(declare-fun x3_8 () (_ BitVec 64))
(declare-fun x3_7 () (_ BitVec 64))
(declare-fun x3_6 () (_ BitVec 64))
(declare-fun x3_5 () (_ BitVec 64))
(declare-fun x3_4 () (_ BitVec 64))
(declare-fun x3_3 () (_ BitVec 64))
(declare-fun x3_2 () (_ BitVec 64))
(declare-fun x10_neg_17 () (_ BitVec 64))
(declare-fun x10_neg_16 () (_ BitVec 64))
(declare-fun x10_neg_15 () (_ BitVec 64))
(declare-fun x10_neg_14 () (_ BitVec 64))
(declare-fun x10_neg_13 () (_ BitVec 64))
(declare-fun x10_neg_12 () (_ BitVec 64))
(declare-fun x10_neg_11 () (_ BitVec 64))
(declare-fun x10_neg_10 () (_ BitVec 64))
(declare-fun x10_neg_9 () (_ BitVec 64))
(declare-fun x10_neg_8 () (_ BitVec 64))
(declare-fun x10_neg_7 () (_ BitVec 64))
(declare-fun x10_neg_6 () (_ BitVec 64))
(declare-fun x10_neg_5 () (_ BitVec 64))
(declare-fun x10_neg_4 () (_ BitVec 64))
(declare-fun x10_neg_3 () (_ BitVec 64))
(declare-fun x10_neg_2 () (_ BitVec 64))
(declare-fun x10_neg_1 () (_ BitVec 64))
(declare-fun x10_34 () (_ BitVec 64))
(declare-fun x10_33 () (_ BitVec 64))
(declare-fun x10_32 () (_ BitVec 64))
(declare-fun x10_31 () (_ BitVec 64))
(declare-fun x10_30 () (_ BitVec 64))
(declare-fun x10_29 () (_ BitVec 64))
(declare-fun x10_28 () (_ BitVec 64))
(declare-fun x10_27 () (_ BitVec 64))
(declare-fun x10_26 () (_ BitVec 64))
(declare-fun x10_25 () (_ BitVec 64))
(declare-fun x10_24 () (_ BitVec 64))
(declare-fun x10_23 () (_ BitVec 64))
(declare-fun x10_22 () (_ BitVec 64))
(declare-fun x10_21 () (_ BitVec 64))
(declare-fun x10_20 () (_ BitVec 64))
(declare-fun x10_19 () (_ BitVec 64))
(declare-fun x10_18 () (_ BitVec 64))
(declare-fun x10_17 () (_ BitVec 64))
(declare-fun x10_16 () (_ BitVec 64))
(declare-fun x10_15 () (_ BitVec 64))
(declare-fun x10_14 () (_ BitVec 64))
(declare-fun x10_13 () (_ BitVec 64))
(declare-fun x10_12 () (_ BitVec 64))
(declare-fun x10_11 () (_ BitVec 64))
(declare-fun x10_10 () (_ BitVec 64))
(declare-fun x10_9 () (_ BitVec 64))
(declare-fun x10_8 () (_ BitVec 64))
(declare-fun x10_7 () (_ BitVec 64))
(declare-fun x10_6 () (_ BitVec 64))
(declare-fun x10_5 () (_ BitVec 64))
(declare-fun x10_4 () (_ BitVec 64))
(declare-fun x10_3 () (_ BitVec 64))
(declare-fun x10_2 () (_ BitVec 64))
(declare-fun x10_1 () (_ BitVec 64))
(declare-fun ne_18 () (_ BitVec 1))
(declare-fun ne_17 () (_ BitVec 1))
(declare-fun ne_16 () (_ BitVec 1))
(declare-fun ne_15 () (_ BitVec 1))
(declare-fun ne_14 () (_ BitVec 1))
(declare-fun ne_13 () (_ BitVec 1))
(declare-fun ne_12 () (_ BitVec 1))
(declare-fun ne_11 () (_ BitVec 1))
(declare-fun ne_10 () (_ BitVec 1))
(declare-fun ne_9 () (_ BitVec 1))
(declare-fun ne_8 () (_ BitVec 1))
(declare-fun ne_7 () (_ BitVec 1))
(declare-fun ne_6 () (_ BitVec 1))
(declare-fun ne_5 () (_ BitVec 1))
(declare-fun ne_4 () (_ BitVec 1))
(declare-fun ne_3 () (_ BitVec 1))
(declare-fun ne_2 () (_ BitVec 1))
(declare-fun ne_1 () (_ BitVec 1))
(declare-fun ge_51 () (_ BitVec 1))
(declare-fun ge_50 () (_ BitVec 1))
(declare-fun ge_49 () (_ BitVec 1))
(declare-fun ge_48 () (_ BitVec 1))
(declare-fun ge_47 () (_ BitVec 1))
(declare-fun ge_46 () (_ BitVec 1))
(declare-fun ge_45 () (_ BitVec 1))
(declare-fun ge_44 () (_ BitVec 1))
(declare-fun ge_43 () (_ BitVec 1))
(declare-fun ge_42 () (_ BitVec 1))
(declare-fun ge_41 () (_ BitVec 1))
(declare-fun ge_40 () (_ BitVec 1))
(declare-fun ge_39 () (_ BitVec 1))
(declare-fun ge_38 () (_ BitVec 1))
(declare-fun ge_37 () (_ BitVec 1))
(declare-fun ge_36 () (_ BitVec 1))
(declare-fun ge_35 () (_ BitVec 1))
(declare-fun ge_34 () (_ BitVec 1))
(declare-fun ge_33 () (_ BitVec 1))
(declare-fun ge_32 () (_ BitVec 1))
(declare-fun ge_31 () (_ BitVec 1))
(declare-fun ge_30 () (_ BitVec 1))
(declare-fun ge_29 () (_ BitVec 1))
(declare-fun ge_28 () (_ BitVec 1))
(declare-fun ge_27 () (_ BitVec 1))
(declare-fun ge_26 () (_ BitVec 1))
(declare-fun ge_25 () (_ BitVec 1))
(declare-fun ge_24 () (_ BitVec 1))
(declare-fun ge_23 () (_ BitVec 1))
(declare-fun ge_22 () (_ BitVec 1))
(declare-fun ge_21 () (_ BitVec 1))
(declare-fun ge_20 () (_ BitVec 1))
(declare-fun ge_19 () (_ BitVec 1))
(declare-fun ge_18 () (_ BitVec 1))
(declare-fun ge_17 () (_ BitVec 1))
(declare-fun ge_16 () (_ BitVec 1))
(declare-fun ge_15 () (_ BitVec 1))
(declare-fun ge_14 () (_ BitVec 1))
(declare-fun ge_13 () (_ BitVec 1))
(declare-fun ge_12 () (_ BitVec 1))
(declare-fun ge_11 () (_ BitVec 1))
(declare-fun ge_10 () (_ BitVec 1))
(declare-fun ge_9 () (_ BitVec 1))
(declare-fun ge_8 () (_ BitVec 1))
(declare-fun ge_7 () (_ BitVec 1))
(declare-fun ge_6 () (_ BitVec 1))
(declare-fun ge_5 () (_ BitVec 1))
(declare-fun ge_4 () (_ BitVec 1))
(declare-fun ge_3 () (_ BitVec 1))
(declare-fun ge_2 () (_ BitVec 1))
(declare-fun ge_1 () (_ BitVec 1))
(declare-fun g_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun dc_160 () (_ BitVec 64))
(declare-fun dc_159 () (_ BitVec 1))
(declare-fun dc_158 () (_ BitVec 62))
(declare-fun dc_157 () (_ BitVec 1))
(declare-fun dc_156 () (_ BitVec 1))
(declare-fun dc_155 () (_ BitVec 1))
(declare-fun dc_154 () (_ BitVec 63))
(declare-fun dc_153 () (_ BitVec 64))
(declare-fun dc_152 () (_ BitVec 1))
(declare-fun dc_151 () (_ BitVec 62))
(declare-fun dc_150 () (_ BitVec 1))
(declare-fun dc_149 () (_ BitVec 1))
(declare-fun dc_148 () (_ BitVec 1))
(declare-fun dc_147 () (_ BitVec 63))
(declare-fun dc_146 () (_ BitVec 64))
(declare-fun dc_145 () (_ BitVec 1))
(declare-fun dc_144 () (_ BitVec 62))
(declare-fun dc_143 () (_ BitVec 1))
(declare-fun dc_142 () (_ BitVec 1))
(declare-fun dc_141 () (_ BitVec 1))
(declare-fun dc_140 () (_ BitVec 63))
(declare-fun dc_139 () (_ BitVec 64))
(declare-fun dc_138 () (_ BitVec 1))
(declare-fun dc_137 () (_ BitVec 62))
(declare-fun dc_136 () (_ BitVec 1))
(declare-fun dc_135 () (_ BitVec 1))
(declare-fun dc_134 () (_ BitVec 1))
(declare-fun dc_133 () (_ BitVec 63))
(declare-fun dc_132 () (_ BitVec 64))
(declare-fun dc_131 () (_ BitVec 1))
(declare-fun dc_130 () (_ BitVec 62))
(declare-fun dc_129 () (_ BitVec 1))
(declare-fun dc_128 () (_ BitVec 1))
(declare-fun dc_127 () (_ BitVec 1))
(declare-fun dc_126 () (_ BitVec 63))
(declare-fun dc_125 () (_ BitVec 64))
(declare-fun dc_124 () (_ BitVec 1))
(declare-fun dc_123 () (_ BitVec 62))
(declare-fun dc_122 () (_ BitVec 1))
(declare-fun dc_121 () (_ BitVec 1))
(declare-fun dc_120 () (_ BitVec 1))
(declare-fun dc_119 () (_ BitVec 63))
(declare-fun dc_118 () (_ BitVec 64))
(declare-fun dc_117 () (_ BitVec 1))
(declare-fun dc_116 () (_ BitVec 62))
(declare-fun dc_115 () (_ BitVec 1))
(declare-fun dc_114 () (_ BitVec 1))
(declare-fun dc_113 () (_ BitVec 1))
(declare-fun dc_112 () (_ BitVec 63))
(declare-fun dc_111 () (_ BitVec 64))
(declare-fun dc_110 () (_ BitVec 1))
(declare-fun dc_109 () (_ BitVec 62))
(declare-fun dc_108 () (_ BitVec 1))
(declare-fun dc_107 () (_ BitVec 1))
(declare-fun dc_106 () (_ BitVec 1))
(declare-fun dc_105 () (_ BitVec 63))
(declare-fun dc_104 () (_ BitVec 64))
(declare-fun dc_103 () (_ BitVec 1))
(declare-fun dc_102 () (_ BitVec 62))
(declare-fun dc_101 () (_ BitVec 1))
(declare-fun dc_100 () (_ BitVec 1))
(declare-fun dc_99 () (_ BitVec 1))
(declare-fun dc_98 () (_ BitVec 63))
(declare-fun dc_97 () (_ BitVec 64))
(declare-fun dc_96 () (_ BitVec 1))
(declare-fun dc_95 () (_ BitVec 62))
(declare-fun dc_94 () (_ BitVec 1))
(declare-fun dc_93 () (_ BitVec 1))
(declare-fun dc_92 () (_ BitVec 1))
(declare-fun dc_91 () (_ BitVec 63))
(declare-fun dc_90 () (_ BitVec 64))
(declare-fun dc_89 () (_ BitVec 1))
(declare-fun dc_88 () (_ BitVec 62))
(declare-fun dc_87 () (_ BitVec 1))
(declare-fun dc_86 () (_ BitVec 1))
(declare-fun dc_85 () (_ BitVec 1))
(declare-fun dc_84 () (_ BitVec 63))
(declare-fun dc_83 () (_ BitVec 64))
(declare-fun dc_82 () (_ BitVec 1))
(declare-fun dc_81 () (_ BitVec 62))
(declare-fun dc_80 () (_ BitVec 1))
(declare-fun dc_79 () (_ BitVec 1))
(declare-fun dc_78 () (_ BitVec 1))
(declare-fun dc_77 () (_ BitVec 63))
(declare-fun dc_76 () (_ BitVec 64))
(declare-fun dc_75 () (_ BitVec 1))
(declare-fun dc_74 () (_ BitVec 62))
(declare-fun dc_73 () (_ BitVec 1))
(declare-fun dc_72 () (_ BitVec 1))
(declare-fun dc_71 () (_ BitVec 1))
(declare-fun dc_70 () (_ BitVec 63))
(declare-fun dc_69 () (_ BitVec 64))
(declare-fun dc_68 () (_ BitVec 1))
(declare-fun dc_67 () (_ BitVec 62))
(declare-fun dc_66 () (_ BitVec 1))
(declare-fun dc_65 () (_ BitVec 1))
(declare-fun dc_64 () (_ BitVec 1))
(declare-fun dc_63 () (_ BitVec 63))
(declare-fun dc_62 () (_ BitVec 64))
(declare-fun dc_61 () (_ BitVec 1))
(declare-fun dc_60 () (_ BitVec 62))
(declare-fun dc_59 () (_ BitVec 1))
(declare-fun dc_58 () (_ BitVec 1))
(declare-fun dc_57 () (_ BitVec 1))
(declare-fun dc_56 () (_ BitVec 63))
(declare-fun dc_55 () (_ BitVec 64))
(declare-fun dc_54 () (_ BitVec 1))
(declare-fun dc_53 () (_ BitVec 62))
(declare-fun dc_52 () (_ BitVec 1))
(declare-fun dc_51 () (_ BitVec 1))
(declare-fun dc_50 () (_ BitVec 1))
(declare-fun dc_49 () (_ BitVec 63))
(declare-fun dc_48 () (_ BitVec 64))
(declare-fun dc_47 () (_ BitVec 1))
(declare-fun dc_46 () (_ BitVec 62))
(declare-fun dc_45 () (_ BitVec 1))
(declare-fun dc_44 () (_ BitVec 1))
(declare-fun dc_43 () (_ BitVec 1))
(declare-fun dc_42 () (_ BitVec 63))
(declare-fun dc_41 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (= x7_3 (bvadd (bvadd f_0_low60_0_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_2 (bvadd (bvadd g_0_low60_0_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_0_1)) (bvsle f_0_low60_0_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_0_1)) (bvsle g_0_low60_0_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_3) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #x0000000000000001 #x0000000000000001)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_41 ((_ extract 63 1) x8_2)) (= x8_lo_1 ((_ extract 0 0) x8_2))))
(assert (= ne_1 (bvand x8_lo_1 #b1)))
(assert (= x10_1 (ite (= ne_1 #b1) x7_3 #x0000000000000000)))
(assert (and (= ge_1 ((_ extract 63 63) #x0000000000000001)) (= dc_42 ((_ extract 62 0) #x0000000000000001))))
(assert (= ge_2 (bvnot ge_1)))
(assert (= ge_3 (ite (= ne_1 #b1) ge_2 #b0)))
(assert (and (= dc_43 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_2 (ite (= ge_3 #b1) x3_neg_1 #x0000000000000001)))
(assert (and (= dc_44 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_2 (ite (= ge_3 #b1) x10_neg_1 x10_1)))
(assert (= x7_4 (ite (= ge_3 #b1) x8_2 x7_3)))
(assert (and (= dc_45 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2)))) (= x8_3 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2))))))
(assert (= x3_3 (bvadd x3_2 #x0000000000000002)))
(assert (and (= dc_46 ((_ extract 63 2) x8_3)) (= x8_lo_2 ((_ extract 1 0) x8_3))))
(assert (and (= x8_target_1 ((_ extract 1 1) x8_lo_2)) (= dc_47 ((_ extract 0 0) x8_lo_2))))
(assert (= ne_2 (bvand x8_target_1 #b1)))
(assert (and (= x8_4 ((_ sign_extend 1) ((_ extract 63 1) x8_3))) (= dc_48 ((_ zero_extend 63) ((_ extract 0 0) x8_3)))))
(assert true)
(assert (= x10_3 (ite (= ne_2 #b1) x7_4 #x0000000000000000)))
(assert (and (= ge_4 ((_ extract 63 63) x3_3)) (= dc_49 ((_ extract 62 0) x3_3))))
(assert (= ge_5 (bvnot ge_4)))
(assert (= ge_6 (ite (= ne_2 #b1) ge_5 #b0)))
(assert (and (= dc_50 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_4 (ite (= ge_6 #b1) x3_neg_2 x3_3)))
(assert (and (= dc_51 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_4 (ite (= ge_6 #b1) x10_neg_2 x10_3)))
(assert (= x7_5 (ite (= ge_6 #b1) x8_4 x7_4)))
(assert (and (= dc_52 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4)))) (= x8_5 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4))))))
(assert (= x3_5 (bvadd x3_4 #x0000000000000002)))
(assert (and (= dc_53 ((_ extract 63 2) x8_5)) (= x8_lo_3 ((_ extract 1 0) x8_5))))
(assert (and (= x8_target_2 ((_ extract 1 1) x8_lo_3)) (= dc_54 ((_ extract 0 0) x8_lo_3))))
(assert (= ne_3 (bvand x8_target_2 #b1)))
(assert (and (= x8_6 ((_ sign_extend 1) ((_ extract 63 1) x8_5))) (= dc_55 ((_ zero_extend 63) ((_ extract 0 0) x8_5)))))
(assert true)
(assert (= x10_5 (ite (= ne_3 #b1) x7_5 #x0000000000000000)))
(assert (and (= ge_7 ((_ extract 63 63) x3_5)) (= dc_56 ((_ extract 62 0) x3_5))))
(assert (= ge_8 (bvnot ge_7)))
(assert (= ge_9 (ite (= ne_3 #b1) ge_8 #b0)))
(assert (and (= dc_57 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_6 (ite (= ge_9 #b1) x3_neg_3 x3_5)))
(assert (and (= dc_58 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_6 (ite (= ge_9 #b1) x10_neg_3 x10_5)))
(assert (= x7_6 (ite (= ge_9 #b1) x8_6 x7_5)))
(assert (and (= dc_59 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6)))) (= x8_7 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6))))))
(assert (= x3_7 (bvadd x3_6 #x0000000000000002)))
(assert (and (= dc_60 ((_ extract 63 2) x8_7)) (= x8_lo_4 ((_ extract 1 0) x8_7))))
(assert (and (= x8_target_3 ((_ extract 1 1) x8_lo_4)) (= dc_61 ((_ extract 0 0) x8_lo_4))))
(assert (= ne_4 (bvand x8_target_3 #b1)))
(assert (and (= x8_8 ((_ sign_extend 1) ((_ extract 63 1) x8_7))) (= dc_62 ((_ zero_extend 63) ((_ extract 0 0) x8_7)))))
(assert true)
(assert (= x10_7 (ite (= ne_4 #b1) x7_6 #x0000000000000000)))
(assert (and (= ge_10 ((_ extract 63 63) x3_7)) (= dc_63 ((_ extract 62 0) x3_7))))
(assert (= ge_11 (bvnot ge_10)))
(assert (= ge_12 (ite (= ne_4 #b1) ge_11 #b0)))
(assert (and (= dc_64 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_7))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_4 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_7))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_8 (ite (= ge_12 #b1) x3_neg_4 x3_7)))
(assert (and (= dc_65 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_7))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_4 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_7))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_8 (ite (= ge_12 #b1) x10_neg_4 x10_7)))
(assert (= x7_7 (ite (= ge_12 #b1) x8_8 x7_6)))
(assert (and (= dc_66 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_8) ((_ zero_extend 1) x10_8)))) (= x8_9 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_8) ((_ zero_extend 1) x10_8))))))
(assert (= x3_9 (bvadd x3_8 #x0000000000000002)))
(assert (and (= dc_67 ((_ extract 63 2) x8_9)) (= x8_lo_5 ((_ extract 1 0) x8_9))))
(assert (and (= x8_target_4 ((_ extract 1 1) x8_lo_5)) (= dc_68 ((_ extract 0 0) x8_lo_5))))
(assert (= ne_5 (bvand x8_target_4 #b1)))
(assert (and (= x8_10 ((_ sign_extend 1) ((_ extract 63 1) x8_9))) (= dc_69 ((_ zero_extend 63) ((_ extract 0 0) x8_9)))))
(assert true)
(assert (= x10_9 (ite (= ne_5 #b1) x7_7 #x0000000000000000)))
(assert (and (= ge_13 ((_ extract 63 63) x3_9)) (= dc_70 ((_ extract 62 0) x3_9))))
(assert (= ge_14 (bvnot ge_13)))
(assert (= ge_15 (ite (= ne_5 #b1) ge_14 #b0)))
(assert (and (= dc_71 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_9))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_5 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_9))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_10 (ite (= ge_15 #b1) x3_neg_5 x3_9)))
(assert (and (= dc_72 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_9))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_5 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_9))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_10 (ite (= ge_15 #b1) x10_neg_5 x10_9)))
(assert (= x7_8 (ite (= ge_15 #b1) x8_10 x7_7)))
(assert (and (= dc_73 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_10) ((_ zero_extend 1) x10_10)))) (= x8_11 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_10) ((_ zero_extend 1) x10_10))))))
(assert (= x3_11 (bvadd x3_10 #x0000000000000002)))
(assert (and (= dc_74 ((_ extract 63 2) x8_11)) (= x8_lo_6 ((_ extract 1 0) x8_11))))
(assert (and (= x8_target_5 ((_ extract 1 1) x8_lo_6)) (= dc_75 ((_ extract 0 0) x8_lo_6))))
(assert (= ne_6 (bvand x8_target_5 #b1)))
(assert (and (= x8_12 ((_ sign_extend 1) ((_ extract 63 1) x8_11))) (= dc_76 ((_ zero_extend 63) ((_ extract 0 0) x8_11)))))
(assert true)
(assert (= x10_11 (ite (= ne_6 #b1) x7_8 #x0000000000000000)))
(assert (and (= ge_16 ((_ extract 63 63) x3_11)) (= dc_77 ((_ extract 62 0) x3_11))))
(assert (= ge_17 (bvnot ge_16)))
(assert (= ge_18 (ite (= ne_6 #b1) ge_17 #b0)))
(assert (and (= dc_78 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_11))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_6 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_11))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_12 (ite (= ge_18 #b1) x3_neg_6 x3_11)))
(assert (and (= dc_79 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_11))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_6 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_11))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_12 (ite (= ge_18 #b1) x10_neg_6 x10_11)))
(assert (= x7_9 (ite (= ge_18 #b1) x8_12 x7_8)))
(assert (and (= dc_80 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_12) ((_ zero_extend 1) x10_12)))) (= x8_13 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_12) ((_ zero_extend 1) x10_12))))))
(assert (= x3_13 (bvadd x3_12 #x0000000000000002)))
(assert (and (= dc_81 ((_ extract 63 2) x8_13)) (= x8_lo_7 ((_ extract 1 0) x8_13))))
(assert (and (= x8_target_6 ((_ extract 1 1) x8_lo_7)) (= dc_82 ((_ extract 0 0) x8_lo_7))))
(assert (= ne_7 (bvand x8_target_6 #b1)))
(assert (and (= x8_14 ((_ sign_extend 1) ((_ extract 63 1) x8_13))) (= dc_83 ((_ zero_extend 63) ((_ extract 0 0) x8_13)))))
(assert true)
(assert (= x10_13 (ite (= ne_7 #b1) x7_9 #x0000000000000000)))
(assert (and (= ge_19 ((_ extract 63 63) x3_13)) (= dc_84 ((_ extract 62 0) x3_13))))
(assert (= ge_20 (bvnot ge_19)))
(assert (= ge_21 (ite (= ne_7 #b1) ge_20 #b0)))
(assert (and (= dc_85 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_13))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_7 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_13))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_14 (ite (= ge_21 #b1) x3_neg_7 x3_13)))
(assert (and (= dc_86 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_13))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_7 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_13))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_14 (ite (= ge_21 #b1) x10_neg_7 x10_13)))
(assert (= x7_10 (ite (= ge_21 #b1) x8_14 x7_9)))
(assert (and (= dc_87 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_14) ((_ zero_extend 1) x10_14)))) (= x8_15 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_14) ((_ zero_extend 1) x10_14))))))
(assert (= x3_15 (bvadd x3_14 #x0000000000000002)))
(assert (and (= dc_88 ((_ extract 63 2) x8_15)) (= x8_lo_8 ((_ extract 1 0) x8_15))))
(assert (and (= x8_target_7 ((_ extract 1 1) x8_lo_8)) (= dc_89 ((_ extract 0 0) x8_lo_8))))
(assert (= ne_8 (bvand x8_target_7 #b1)))
(assert (and (= x8_16 ((_ sign_extend 1) ((_ extract 63 1) x8_15))) (= dc_90 ((_ zero_extend 63) ((_ extract 0 0) x8_15)))))
(assert true)
(assert (= x10_15 (ite (= ne_8 #b1) x7_10 #x0000000000000000)))
(assert (and (= ge_22 ((_ extract 63 63) x3_15)) (= dc_91 ((_ extract 62 0) x3_15))))
(assert (= ge_23 (bvnot ge_22)))
(assert (= ge_24 (ite (= ne_8 #b1) ge_23 #b0)))
(assert (and (= dc_92 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_15))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_8 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_15))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_16 (ite (= ge_24 #b1) x3_neg_8 x3_15)))
(assert (and (= dc_93 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_15))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_8 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_15))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_16 (ite (= ge_24 #b1) x10_neg_8 x10_15)))
(assert (= x7_11 (ite (= ge_24 #b1) x8_16 x7_10)))
(assert (and (= dc_94 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_16) ((_ zero_extend 1) x10_16)))) (= x8_17 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_16) ((_ zero_extend 1) x10_16))))))
(assert (= x3_17 (bvadd x3_16 #x0000000000000002)))
(assert (and (= dc_95 ((_ extract 63 2) x8_17)) (= x8_lo_9 ((_ extract 1 0) x8_17))))
(assert (and (= x8_target_8 ((_ extract 1 1) x8_lo_9)) (= dc_96 ((_ extract 0 0) x8_lo_9))))
(assert (= ne_9 (bvand x8_target_8 #b1)))
(assert (and (= x8_18 ((_ sign_extend 1) ((_ extract 63 1) x8_17))) (= dc_97 ((_ zero_extend 63) ((_ extract 0 0) x8_17)))))
(assert true)
(assert (= x10_17 (ite (= ne_9 #b1) x7_11 #x0000000000000000)))
(assert (and (= ge_25 ((_ extract 63 63) x3_17)) (= dc_98 ((_ extract 62 0) x3_17))))
(assert (= ge_26 (bvnot ge_25)))
(assert (= ge_27 (ite (= ne_9 #b1) ge_26 #b0)))
(assert (and (= dc_99 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_17))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_9 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_17))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_18 (ite (= ge_27 #b1) x3_neg_9 x3_17)))
(assert (and (= dc_100 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_17))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_9 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_17))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_18 (ite (= ge_27 #b1) x10_neg_9 x10_17)))
(assert (= x7_12 (ite (= ge_27 #b1) x8_18 x7_11)))
(assert (and (= dc_101 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_18) ((_ zero_extend 1) x10_18)))) (= x8_19 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_18) ((_ zero_extend 1) x10_18))))))
(assert (= x3_19 (bvadd x3_18 #x0000000000000002)))
(assert (and (= dc_102 ((_ extract 63 2) x8_19)) (= x8_lo_10 ((_ extract 1 0) x8_19))))
(assert (and (= x8_target_9 ((_ extract 1 1) x8_lo_10)) (= dc_103 ((_ extract 0 0) x8_lo_10))))
(assert (= ne_10 (bvand x8_target_9 #b1)))
(assert (and (= x8_20 ((_ sign_extend 1) ((_ extract 63 1) x8_19))) (= dc_104 ((_ zero_extend 63) ((_ extract 0 0) x8_19)))))
(assert true)
(assert (= x10_19 (ite (= ne_10 #b1) x7_12 #x0000000000000000)))
(assert (and (= ge_28 ((_ extract 63 63) x3_19)) (= dc_105 ((_ extract 62 0) x3_19))))
(assert (= ge_29 (bvnot ge_28)))
(assert (= ge_30 (ite (= ne_10 #b1) ge_29 #b0)))
(assert (and (= dc_106 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_19))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_10 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_19))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_20 (ite (= ge_30 #b1) x3_neg_10 x3_19)))
(assert (and (= dc_107 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_19))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_10 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_19))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_20 (ite (= ge_30 #b1) x10_neg_10 x10_19)))
(assert (= x7_13 (ite (= ge_30 #b1) x8_20 x7_12)))
(assert (and (= dc_108 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_20) ((_ zero_extend 1) x10_20)))) (= x8_21 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_20) ((_ zero_extend 1) x10_20))))))
(assert (= x3_21 (bvadd x3_20 #x0000000000000002)))
(assert (and (= dc_109 ((_ extract 63 2) x8_21)) (= x8_lo_11 ((_ extract 1 0) x8_21))))
(assert (and (= x8_target_10 ((_ extract 1 1) x8_lo_11)) (= dc_110 ((_ extract 0 0) x8_lo_11))))
(assert (= ne_11 (bvand x8_target_10 #b1)))
(assert (and (= x8_22 ((_ sign_extend 1) ((_ extract 63 1) x8_21))) (= dc_111 ((_ zero_extend 63) ((_ extract 0 0) x8_21)))))
(assert true)
(assert (= x10_21 (ite (= ne_11 #b1) x7_13 #x0000000000000000)))
(assert (and (= ge_31 ((_ extract 63 63) x3_21)) (= dc_112 ((_ extract 62 0) x3_21))))
(assert (= ge_32 (bvnot ge_31)))
(assert (= ge_33 (ite (= ne_11 #b1) ge_32 #b0)))
(assert (and (= dc_113 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_21))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_11 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_21))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_22 (ite (= ge_33 #b1) x3_neg_11 x3_21)))
(assert (and (= dc_114 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_21))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_11 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_21))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_22 (ite (= ge_33 #b1) x10_neg_11 x10_21)))
(assert (= x7_14 (ite (= ge_33 #b1) x8_22 x7_13)))
(assert (and (= dc_115 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_22) ((_ zero_extend 1) x10_22)))) (= x8_23 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_22) ((_ zero_extend 1) x10_22))))))
(assert (= x3_23 (bvadd x3_22 #x0000000000000002)))
(assert (and (= dc_116 ((_ extract 63 2) x8_23)) (= x8_lo_12 ((_ extract 1 0) x8_23))))
(assert (and (= x8_target_11 ((_ extract 1 1) x8_lo_12)) (= dc_117 ((_ extract 0 0) x8_lo_12))))
(assert (= ne_12 (bvand x8_target_11 #b1)))
(assert (and (= x8_24 ((_ sign_extend 1) ((_ extract 63 1) x8_23))) (= dc_118 ((_ zero_extend 63) ((_ extract 0 0) x8_23)))))
(assert true)
(assert (= x10_23 (ite (= ne_12 #b1) x7_14 #x0000000000000000)))
(assert (and (= ge_34 ((_ extract 63 63) x3_23)) (= dc_119 ((_ extract 62 0) x3_23))))
(assert (= ge_35 (bvnot ge_34)))
(assert (= ge_36 (ite (= ne_12 #b1) ge_35 #b0)))
(assert (and (= dc_120 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_23))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_12 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_23))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_24 (ite (= ge_36 #b1) x3_neg_12 x3_23)))
(assert (and (= dc_121 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_23))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_12 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_23))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_24 (ite (= ge_36 #b1) x10_neg_12 x10_23)))
(assert (= x7_15 (ite (= ge_36 #b1) x8_24 x7_14)))
(assert (and (= dc_122 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_24) ((_ zero_extend 1) x10_24)))) (= x8_25 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_24) ((_ zero_extend 1) x10_24))))))
(assert (= x3_25 (bvadd x3_24 #x0000000000000002)))
(assert (and (= dc_123 ((_ extract 63 2) x8_25)) (= x8_lo_13 ((_ extract 1 0) x8_25))))
(assert (and (= x8_target_12 ((_ extract 1 1) x8_lo_13)) (= dc_124 ((_ extract 0 0) x8_lo_13))))
(assert (= ne_13 (bvand x8_target_12 #b1)))
(assert (and (= x8_26 ((_ sign_extend 1) ((_ extract 63 1) x8_25))) (= dc_125 ((_ zero_extend 63) ((_ extract 0 0) x8_25)))))
(assert true)
(assert (= x10_25 (ite (= ne_13 #b1) x7_15 #x0000000000000000)))
(assert (and (= ge_37 ((_ extract 63 63) x3_25)) (= dc_126 ((_ extract 62 0) x3_25))))
(assert (= ge_38 (bvnot ge_37)))
(assert (= ge_39 (ite (= ne_13 #b1) ge_38 #b0)))
(assert (and (= dc_127 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_25))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_13 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_25))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_26 (ite (= ge_39 #b1) x3_neg_13 x3_25)))
(assert (and (= dc_128 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_25))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_13 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_25))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_26 (ite (= ge_39 #b1) x10_neg_13 x10_25)))
(assert (= x7_16 (ite (= ge_39 #b1) x8_26 x7_15)))
(assert (and (= dc_129 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_26) ((_ zero_extend 1) x10_26)))) (= x8_27 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_26) ((_ zero_extend 1) x10_26))))))
(assert (= x3_27 (bvadd x3_26 #x0000000000000002)))
(assert (and (= dc_130 ((_ extract 63 2) x8_27)) (= x8_lo_14 ((_ extract 1 0) x8_27))))
(assert (and (= x8_target_13 ((_ extract 1 1) x8_lo_14)) (= dc_131 ((_ extract 0 0) x8_lo_14))))
(assert (= ne_14 (bvand x8_target_13 #b1)))
(assert (and (= x8_28 ((_ sign_extend 1) ((_ extract 63 1) x8_27))) (= dc_132 ((_ zero_extend 63) ((_ extract 0 0) x8_27)))))
(assert true)
(assert (= x10_27 (ite (= ne_14 #b1) x7_16 #x0000000000000000)))
(assert (and (= ge_40 ((_ extract 63 63) x3_27)) (= dc_133 ((_ extract 62 0) x3_27))))
(assert (= ge_41 (bvnot ge_40)))
(assert (= ge_42 (ite (= ne_14 #b1) ge_41 #b0)))
(assert (and (= dc_134 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_27))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_14 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_27))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_28 (ite (= ge_42 #b1) x3_neg_14 x3_27)))
(assert (and (= dc_135 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_27))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_14 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_27))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_28 (ite (= ge_42 #b1) x10_neg_14 x10_27)))
(assert (= x7_17 (ite (= ge_42 #b1) x8_28 x7_16)))
(assert (and (= dc_136 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_28) ((_ zero_extend 1) x10_28)))) (= x8_29 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_28) ((_ zero_extend 1) x10_28))))))
(assert (= x3_29 (bvadd x3_28 #x0000000000000002)))
(assert (and (= dc_137 ((_ extract 63 2) x8_29)) (= x8_lo_15 ((_ extract 1 0) x8_29))))
(assert (and (= x8_target_14 ((_ extract 1 1) x8_lo_15)) (= dc_138 ((_ extract 0 0) x8_lo_15))))
(assert (= ne_15 (bvand x8_target_14 #b1)))
(assert (and (= x8_30 ((_ sign_extend 1) ((_ extract 63 1) x8_29))) (= dc_139 ((_ zero_extend 63) ((_ extract 0 0) x8_29)))))
(assert true)
(assert (= x10_29 (ite (= ne_15 #b1) x7_17 #x0000000000000000)))
(assert (and (= ge_43 ((_ extract 63 63) x3_29)) (= dc_140 ((_ extract 62 0) x3_29))))
(assert (= ge_44 (bvnot ge_43)))
(assert (= ge_45 (ite (= ne_15 #b1) ge_44 #b0)))
(assert (and (= dc_141 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_29))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_15 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_29))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_30 (ite (= ge_45 #b1) x3_neg_15 x3_29)))
(assert (and (= dc_142 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_29))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_15 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_29))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_30 (ite (= ge_45 #b1) x10_neg_15 x10_29)))
(assert (= x7_18 (ite (= ge_45 #b1) x8_30 x7_17)))
(assert (and (= dc_143 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_30) ((_ zero_extend 1) x10_30)))) (= x8_31 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_30) ((_ zero_extend 1) x10_30))))))
(assert (= x3_31 (bvadd x3_30 #x0000000000000002)))
(assert (and (= dc_144 ((_ extract 63 2) x8_31)) (= x8_lo_16 ((_ extract 1 0) x8_31))))
(assert (and (= x8_target_15 ((_ extract 1 1) x8_lo_16)) (= dc_145 ((_ extract 0 0) x8_lo_16))))
(assert (= ne_16 (bvand x8_target_15 #b1)))
(assert (and (= x8_32 ((_ sign_extend 1) ((_ extract 63 1) x8_31))) (= dc_146 ((_ zero_extend 63) ((_ extract 0 0) x8_31)))))
(assert true)
(assert (= x10_31 (ite (= ne_16 #b1) x7_18 #x0000000000000000)))
(assert (and (= ge_46 ((_ extract 63 63) x3_31)) (= dc_147 ((_ extract 62 0) x3_31))))
(assert (= ge_47 (bvnot ge_46)))
(assert (= ge_48 (ite (= ne_16 #b1) ge_47 #b0)))
(assert (and (= dc_148 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_31))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_16 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_31))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_32 (ite (= ge_48 #b1) x3_neg_16 x3_31)))
(assert (and (= dc_149 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_31))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_16 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_31))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_32 (ite (= ge_48 #b1) x10_neg_16 x10_31)))
(assert (= x7_19 (ite (= ge_48 #b1) x8_32 x7_18)))
(assert (and (= dc_150 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_32) ((_ zero_extend 1) x10_32)))) (= x8_33 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_32) ((_ zero_extend 1) x10_32))))))
(assert (= x3_33 (bvadd x3_32 #x0000000000000002)))
(assert (and (= dc_151 ((_ extract 63 2) x8_33)) (= x8_lo_17 ((_ extract 1 0) x8_33))))
(assert (and (= x8_target_16 ((_ extract 1 1) x8_lo_17)) (= dc_152 ((_ extract 0 0) x8_lo_17))))
(assert (= ne_17 (bvand x8_target_16 #b1)))
(assert (and (= x8_34 ((_ sign_extend 1) ((_ extract 63 1) x8_33))) (= dc_153 ((_ zero_extend 63) ((_ extract 0 0) x8_33)))))
(assert true)
(assert (= x10_33 (ite (= ne_17 #b1) x7_19 #x0000000000000000)))
(assert (and (= ge_49 ((_ extract 63 63) x3_33)) (= dc_154 ((_ extract 62 0) x3_33))))
(assert (= ge_50 (bvnot ge_49)))
(assert (= ge_51 (ite (= ne_17 #b1) ge_50 #b0)))
(assert (and (= dc_155 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_33))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_17 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_33))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_34 (ite (= ge_51 #b1) x3_neg_17 x3_33)))
(assert (and (= dc_156 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_33))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_17 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_33))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_34 (ite (= ge_51 #b1) x10_neg_17 x10_33)))
(assert (= x7_20 (ite (= ge_51 #b1) x8_34 x7_19)))
(assert (and (= dc_157 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_34) ((_ zero_extend 1) x10_34)))) (= x8_35 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_34) ((_ zero_extend 1) x10_34))))))
(assert (= x3_35 (bvadd x3_34 #x0000000000000002)))
(assert (and (= dc_158 ((_ extract 63 2) x8_35)) (= x8_lo_18 ((_ extract 1 0) x8_35))))
(assert (and (= x8_target_17 ((_ extract 1 1) x8_lo_18)) (= dc_159 ((_ extract 0 0) x8_lo_18))))
(assert (= ne_18 (bvand x8_target_17 #b1)))
(assert (and (= x8_36 ((_ sign_extend 1) ((_ extract 63 1) x8_35))) (= dc_160 ((_ zero_extend 63) ((_ extract 0 0) x8_35)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_34) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_20 x7_19)) (= (bvmul x8_36 #x0000000000000002) x8_34)) (= x3_35 (bvadd #x0000000000000002 x3_33))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_34) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_33 #x0000000000000000)) (= x7_20 x7_19)) (= (bvmul x8_36 #x0000000000000002) (bvadd x8_34 x7_19))) (= x3_35 (bvadd #x0000000000000002 x3_33)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_34) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_33 #x0000000000000000)) (= x7_20 x8_34)) (= (bvmul x8_36 #x0000000000000002) (bvsub x8_34 x7_19))) (= x3_35 (bvsub #x0000000000000002 x3_33))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_8f05f8.smt2
Execution time of boolector: 1.5838 seconds
OUTPUT FROM boolector:
unsat

=== Cut #2 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #2
; Range assertion #30: or [and [smod (sub (uext x8_38 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_22 = x7_21, mul x8_40 2@64 = x8_38, x3_39 = add 2@64 x3_37], and [smod (sub (uext x8_38 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_37 <s 0@64, x7_22 = x7_21, mul x8_40 2@64 = add x8_38 x7_21, x3_39 = add 2@64 x3_37], and [smod (sub (uext x8_38 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_37 >=s 0@64, x7_22 = x8_38, mul x8_40 2@64 = sub x8_38 x7_21, x3_39 = sub 2@64 x3_37]]
; Range condition: ((x8_38@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_22 = x7_21 /\ x8_40 * 2 = x8_38 /\ x3_39 = 2 + x3_37 \/ ((x8_38@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_37 <s 0 /\ x7_22 = x7_21 /\ x8_40 * 2 = x8_38 + x7_21 /\ x3_39 = 2 + x3_37 \/ ((x8_38@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_37 >=s 0 /\ x7_22 = x8_38 /\ x8_40 * 2 = x8_38 - x7_21 /\ x3_39 = 2 - x3_37
; Output file: /tmp/outputqfbv_e4a613.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_19 () (_ BitVec 1))
(declare-fun x8_target_18 () (_ BitVec 1))
(declare-fun x8_target_17 () (_ BitVec 1))
(declare-fun x8_target_16 () (_ BitVec 1))
(declare-fun x8_target_15 () (_ BitVec 1))
(declare-fun x8_target_14 () (_ BitVec 1))
(declare-fun x8_target_13 () (_ BitVec 1))
(declare-fun x8_target_12 () (_ BitVec 1))
(declare-fun x8_target_11 () (_ BitVec 1))
(declare-fun x8_target_10 () (_ BitVec 1))
(declare-fun x8_target_9 () (_ BitVec 1))
(declare-fun x8_target_8 () (_ BitVec 1))
(declare-fun x8_target_7 () (_ BitVec 1))
(declare-fun x8_target_6 () (_ BitVec 1))
(declare-fun x8_target_5 () (_ BitVec 1))
(declare-fun x8_target_4 () (_ BitVec 1))
(declare-fun x8_target_3 () (_ BitVec 1))
(declare-fun x8_target_2 () (_ BitVec 1))
(declare-fun x8_target_1 () (_ BitVec 1))
(declare-fun x8_lo_20 () (_ BitVec 2))
(declare-fun x8_lo_19 () (_ BitVec 2))
(declare-fun x8_lo_18 () (_ BitVec 2))
(declare-fun x8_lo_17 () (_ BitVec 2))
(declare-fun x8_lo_16 () (_ BitVec 2))
(declare-fun x8_lo_15 () (_ BitVec 2))
(declare-fun x8_lo_14 () (_ BitVec 2))
(declare-fun x8_lo_13 () (_ BitVec 2))
(declare-fun x8_lo_12 () (_ BitVec 2))
(declare-fun x8_lo_11 () (_ BitVec 2))
(declare-fun x8_lo_10 () (_ BitVec 2))
(declare-fun x8_lo_9 () (_ BitVec 2))
(declare-fun x8_lo_8 () (_ BitVec 2))
(declare-fun x8_lo_7 () (_ BitVec 2))
(declare-fun x8_lo_6 () (_ BitVec 2))
(declare-fun x8_lo_5 () (_ BitVec 2))
(declare-fun x8_lo_4 () (_ BitVec 2))
(declare-fun x8_lo_3 () (_ BitVec 2))
(declare-fun x8_lo_2 () (_ BitVec 2))
(declare-fun x8_lo_1 () (_ BitVec 1))
(declare-fun x8_40 () (_ BitVec 64))
(declare-fun x8_39 () (_ BitVec 64))
(declare-fun x8_38 () (_ BitVec 64))
(declare-fun x8_37 () (_ BitVec 64))
(declare-fun x8_36 () (_ BitVec 64))
(declare-fun x8_35 () (_ BitVec 64))
(declare-fun x8_34 () (_ BitVec 64))
(declare-fun x8_33 () (_ BitVec 64))
(declare-fun x8_32 () (_ BitVec 64))
(declare-fun x8_31 () (_ BitVec 64))
(declare-fun x8_30 () (_ BitVec 64))
(declare-fun x8_29 () (_ BitVec 64))
(declare-fun x8_28 () (_ BitVec 64))
(declare-fun x8_27 () (_ BitVec 64))
(declare-fun x8_26 () (_ BitVec 64))
(declare-fun x8_25 () (_ BitVec 64))
(declare-fun x8_24 () (_ BitVec 64))
(declare-fun x8_23 () (_ BitVec 64))
(declare-fun x8_22 () (_ BitVec 64))
(declare-fun x8_21 () (_ BitVec 64))
(declare-fun x8_20 () (_ BitVec 64))
(declare-fun x8_19 () (_ BitVec 64))
(declare-fun x8_18 () (_ BitVec 64))
(declare-fun x8_17 () (_ BitVec 64))
(declare-fun x8_16 () (_ BitVec 64))
(declare-fun x8_15 () (_ BitVec 64))
(declare-fun x8_14 () (_ BitVec 64))
(declare-fun x8_13 () (_ BitVec 64))
(declare-fun x8_12 () (_ BitVec 64))
(declare-fun x8_11 () (_ BitVec 64))
(declare-fun x8_10 () (_ BitVec 64))
(declare-fun x8_9 () (_ BitVec 64))
(declare-fun x8_8 () (_ BitVec 64))
(declare-fun x8_7 () (_ BitVec 64))
(declare-fun x8_6 () (_ BitVec 64))
(declare-fun x8_5 () (_ BitVec 64))
(declare-fun x8_4 () (_ BitVec 64))
(declare-fun x8_3 () (_ BitVec 64))
(declare-fun x8_2 () (_ BitVec 64))
(declare-fun x7_22 () (_ BitVec 64))
(declare-fun x7_21 () (_ BitVec 64))
(declare-fun x7_20 () (_ BitVec 64))
(declare-fun x7_19 () (_ BitVec 64))
(declare-fun x7_18 () (_ BitVec 64))
(declare-fun x7_17 () (_ BitVec 64))
(declare-fun x7_16 () (_ BitVec 64))
(declare-fun x7_15 () (_ BitVec 64))
(declare-fun x7_14 () (_ BitVec 64))
(declare-fun x7_13 () (_ BitVec 64))
(declare-fun x7_12 () (_ BitVec 64))
(declare-fun x7_11 () (_ BitVec 64))
(declare-fun x7_10 () (_ BitVec 64))
(declare-fun x7_9 () (_ BitVec 64))
(declare-fun x7_8 () (_ BitVec 64))
(declare-fun x7_7 () (_ BitVec 64))
(declare-fun x7_6 () (_ BitVec 64))
(declare-fun x7_5 () (_ BitVec 64))
(declare-fun x7_4 () (_ BitVec 64))
(declare-fun x7_3 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_19 () (_ BitVec 64))
(declare-fun x3_neg_18 () (_ BitVec 64))
(declare-fun x3_neg_17 () (_ BitVec 64))
(declare-fun x3_neg_16 () (_ BitVec 64))
(declare-fun x3_neg_15 () (_ BitVec 64))
(declare-fun x3_neg_14 () (_ BitVec 64))
(declare-fun x3_neg_13 () (_ BitVec 64))
(declare-fun x3_neg_12 () (_ BitVec 64))
(declare-fun x3_neg_11 () (_ BitVec 64))
(declare-fun x3_neg_10 () (_ BitVec 64))
(declare-fun x3_neg_9 () (_ BitVec 64))
(declare-fun x3_neg_8 () (_ BitVec 64))
(declare-fun x3_neg_7 () (_ BitVec 64))
(declare-fun x3_neg_6 () (_ BitVec 64))
(declare-fun x3_neg_5 () (_ BitVec 64))
(declare-fun x3_neg_4 () (_ BitVec 64))
(declare-fun x3_neg_3 () (_ BitVec 64))
(declare-fun x3_neg_2 () (_ BitVec 64))
(declare-fun x3_neg_1 () (_ BitVec 64))
(declare-fun x3_39 () (_ BitVec 64))
(declare-fun x3_38 () (_ BitVec 64))
(declare-fun x3_37 () (_ BitVec 64))
(declare-fun x3_36 () (_ BitVec 64))
(declare-fun x3_35 () (_ BitVec 64))
(declare-fun x3_34 () (_ BitVec 64))
(declare-fun x3_33 () (_ BitVec 64))
(declare-fun x3_32 () (_ BitVec 64))
(declare-fun x3_31 () (_ BitVec 64))
(declare-fun x3_30 () (_ BitVec 64))
(declare-fun x3_29 () (_ BitVec 64))
(declare-fun x3_28 () (_ BitVec 64))
(declare-fun x3_27 () (_ BitVec 64))
(declare-fun x3_26 () (_ BitVec 64))
(declare-fun x3_25 () (_ BitVec 64))
(declare-fun x3_24 () (_ BitVec 64))
(declare-fun x3_23 () (_ BitVec 64))
(declare-fun x3_22 () (_ BitVec 64))
(declare-fun x3_21 () (_ BitVec 64))
(declare-fun x3_20 () (_ BitVec 64))
(declare-fun x3_19 () (_ BitVec 64))
(declare-fun x3_18 () (_ BitVec 64))
(declare-fun x3_17 () (_ BitVec 64))
(declare-fun x3_16 () (_ BitVec 64))
(declare-fun x3_15 () (_ BitVec 64))
(declare-fun x3_14 () (_ BitVec 64))
(declare-fun x3_13 () (_ BitVec 64))
(declare-fun x3_12 () (_ BitVec 64))
(declare-fun x3_11 () (_ BitVec 64))
(declare-fun x3_10 () (_ BitVec 64))
(declare-fun x3_9 () (_ BitVec 64))
(declare-fun x3_8 () (_ BitVec 64))
(declare-fun x3_7 () (_ BitVec 64))
(declare-fun x3_6 () (_ BitVec 64))
(declare-fun x3_5 () (_ BitVec 64))
(declare-fun x3_4 () (_ BitVec 64))
(declare-fun x3_3 () (_ BitVec 64))
(declare-fun x3_2 () (_ BitVec 64))
(declare-fun x10_neg_19 () (_ BitVec 64))
(declare-fun x10_neg_18 () (_ BitVec 64))
(declare-fun x10_neg_17 () (_ BitVec 64))
(declare-fun x10_neg_16 () (_ BitVec 64))
(declare-fun x10_neg_15 () (_ BitVec 64))
(declare-fun x10_neg_14 () (_ BitVec 64))
(declare-fun x10_neg_13 () (_ BitVec 64))
(declare-fun x10_neg_12 () (_ BitVec 64))
(declare-fun x10_neg_11 () (_ BitVec 64))
(declare-fun x10_neg_10 () (_ BitVec 64))
(declare-fun x10_neg_9 () (_ BitVec 64))
(declare-fun x10_neg_8 () (_ BitVec 64))
(declare-fun x10_neg_7 () (_ BitVec 64))
(declare-fun x10_neg_6 () (_ BitVec 64))
(declare-fun x10_neg_5 () (_ BitVec 64))
(declare-fun x10_neg_4 () (_ BitVec 64))
(declare-fun x10_neg_3 () (_ BitVec 64))
(declare-fun x10_neg_2 () (_ BitVec 64))
(declare-fun x10_neg_1 () (_ BitVec 64))
(declare-fun x10_38 () (_ BitVec 64))
(declare-fun x10_37 () (_ BitVec 64))
(declare-fun x10_36 () (_ BitVec 64))
(declare-fun x10_35 () (_ BitVec 64))
(declare-fun x10_34 () (_ BitVec 64))
(declare-fun x10_33 () (_ BitVec 64))
(declare-fun x10_32 () (_ BitVec 64))
(declare-fun x10_31 () (_ BitVec 64))
(declare-fun x10_30 () (_ BitVec 64))
(declare-fun x10_29 () (_ BitVec 64))
(declare-fun x10_28 () (_ BitVec 64))
(declare-fun x10_27 () (_ BitVec 64))
(declare-fun x10_26 () (_ BitVec 64))
(declare-fun x10_25 () (_ BitVec 64))
(declare-fun x10_24 () (_ BitVec 64))
(declare-fun x10_23 () (_ BitVec 64))
(declare-fun x10_22 () (_ BitVec 64))
(declare-fun x10_21 () (_ BitVec 64))
(declare-fun x10_20 () (_ BitVec 64))
(declare-fun x10_19 () (_ BitVec 64))
(declare-fun x10_18 () (_ BitVec 64))
(declare-fun x10_17 () (_ BitVec 64))
(declare-fun x10_16 () (_ BitVec 64))
(declare-fun x10_15 () (_ BitVec 64))
(declare-fun x10_14 () (_ BitVec 64))
(declare-fun x10_13 () (_ BitVec 64))
(declare-fun x10_12 () (_ BitVec 64))
(declare-fun x10_11 () (_ BitVec 64))
(declare-fun x10_10 () (_ BitVec 64))
(declare-fun x10_9 () (_ BitVec 64))
(declare-fun x10_8 () (_ BitVec 64))
(declare-fun x10_7 () (_ BitVec 64))
(declare-fun x10_6 () (_ BitVec 64))
(declare-fun x10_5 () (_ BitVec 64))
(declare-fun x10_4 () (_ BitVec 64))
(declare-fun x10_3 () (_ BitVec 64))
(declare-fun x10_2 () (_ BitVec 64))
(declare-fun x10_1 () (_ BitVec 64))
(declare-fun ne_20 () (_ BitVec 1))
(declare-fun ne_19 () (_ BitVec 1))
(declare-fun ne_18 () (_ BitVec 1))
(declare-fun ne_17 () (_ BitVec 1))
(declare-fun ne_16 () (_ BitVec 1))
(declare-fun ne_15 () (_ BitVec 1))
(declare-fun ne_14 () (_ BitVec 1))
(declare-fun ne_13 () (_ BitVec 1))
(declare-fun ne_12 () (_ BitVec 1))
(declare-fun ne_11 () (_ BitVec 1))
(declare-fun ne_10 () (_ BitVec 1))
(declare-fun ne_9 () (_ BitVec 1))
(declare-fun ne_8 () (_ BitVec 1))
(declare-fun ne_7 () (_ BitVec 1))
(declare-fun ne_6 () (_ BitVec 1))
(declare-fun ne_5 () (_ BitVec 1))
(declare-fun ne_4 () (_ BitVec 1))
(declare-fun ne_3 () (_ BitVec 1))
(declare-fun ne_2 () (_ BitVec 1))
(declare-fun ne_1 () (_ BitVec 1))
(declare-fun ge_57 () (_ BitVec 1))
(declare-fun ge_56 () (_ BitVec 1))
(declare-fun ge_55 () (_ BitVec 1))
(declare-fun ge_54 () (_ BitVec 1))
(declare-fun ge_53 () (_ BitVec 1))
(declare-fun ge_52 () (_ BitVec 1))
(declare-fun ge_51 () (_ BitVec 1))
(declare-fun ge_50 () (_ BitVec 1))
(declare-fun ge_49 () (_ BitVec 1))
(declare-fun ge_48 () (_ BitVec 1))
(declare-fun ge_47 () (_ BitVec 1))
(declare-fun ge_46 () (_ BitVec 1))
(declare-fun ge_45 () (_ BitVec 1))
(declare-fun ge_44 () (_ BitVec 1))
(declare-fun ge_43 () (_ BitVec 1))
(declare-fun ge_42 () (_ BitVec 1))
(declare-fun ge_41 () (_ BitVec 1))
(declare-fun ge_40 () (_ BitVec 1))
(declare-fun ge_39 () (_ BitVec 1))
(declare-fun ge_38 () (_ BitVec 1))
(declare-fun ge_37 () (_ BitVec 1))
(declare-fun ge_36 () (_ BitVec 1))
(declare-fun ge_35 () (_ BitVec 1))
(declare-fun ge_34 () (_ BitVec 1))
(declare-fun ge_33 () (_ BitVec 1))
(declare-fun ge_32 () (_ BitVec 1))
(declare-fun ge_31 () (_ BitVec 1))
(declare-fun ge_30 () (_ BitVec 1))
(declare-fun ge_29 () (_ BitVec 1))
(declare-fun ge_28 () (_ BitVec 1))
(declare-fun ge_27 () (_ BitVec 1))
(declare-fun ge_26 () (_ BitVec 1))
(declare-fun ge_25 () (_ BitVec 1))
(declare-fun ge_24 () (_ BitVec 1))
(declare-fun ge_23 () (_ BitVec 1))
(declare-fun ge_22 () (_ BitVec 1))
(declare-fun ge_21 () (_ BitVec 1))
(declare-fun ge_20 () (_ BitVec 1))
(declare-fun ge_19 () (_ BitVec 1))
(declare-fun ge_18 () (_ BitVec 1))
(declare-fun ge_17 () (_ BitVec 1))
(declare-fun ge_16 () (_ BitVec 1))
(declare-fun ge_15 () (_ BitVec 1))
(declare-fun ge_14 () (_ BitVec 1))
(declare-fun ge_13 () (_ BitVec 1))
(declare-fun ge_12 () (_ BitVec 1))
(declare-fun ge_11 () (_ BitVec 1))
(declare-fun ge_10 () (_ BitVec 1))
(declare-fun ge_9 () (_ BitVec 1))
(declare-fun ge_8 () (_ BitVec 1))
(declare-fun ge_7 () (_ BitVec 1))
(declare-fun ge_6 () (_ BitVec 1))
(declare-fun ge_5 () (_ BitVec 1))
(declare-fun ge_4 () (_ BitVec 1))
(declare-fun ge_3 () (_ BitVec 1))
(declare-fun ge_2 () (_ BitVec 1))
(declare-fun ge_1 () (_ BitVec 1))
(declare-fun g_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun dc_174 () (_ BitVec 64))
(declare-fun dc_173 () (_ BitVec 1))
(declare-fun dc_172 () (_ BitVec 62))
(declare-fun dc_171 () (_ BitVec 1))
(declare-fun dc_170 () (_ BitVec 1))
(declare-fun dc_169 () (_ BitVec 1))
(declare-fun dc_168 () (_ BitVec 63))
(declare-fun dc_167 () (_ BitVec 64))
(declare-fun dc_166 () (_ BitVec 1))
(declare-fun dc_165 () (_ BitVec 62))
(declare-fun dc_164 () (_ BitVec 1))
(declare-fun dc_163 () (_ BitVec 1))
(declare-fun dc_162 () (_ BitVec 1))
(declare-fun dc_161 () (_ BitVec 63))
(declare-fun dc_160 () (_ BitVec 64))
(declare-fun dc_159 () (_ BitVec 1))
(declare-fun dc_158 () (_ BitVec 62))
(declare-fun dc_157 () (_ BitVec 1))
(declare-fun dc_156 () (_ BitVec 1))
(declare-fun dc_155 () (_ BitVec 1))
(declare-fun dc_154 () (_ BitVec 63))
(declare-fun dc_153 () (_ BitVec 64))
(declare-fun dc_152 () (_ BitVec 1))
(declare-fun dc_151 () (_ BitVec 62))
(declare-fun dc_150 () (_ BitVec 1))
(declare-fun dc_149 () (_ BitVec 1))
(declare-fun dc_148 () (_ BitVec 1))
(declare-fun dc_147 () (_ BitVec 63))
(declare-fun dc_146 () (_ BitVec 64))
(declare-fun dc_145 () (_ BitVec 1))
(declare-fun dc_144 () (_ BitVec 62))
(declare-fun dc_143 () (_ BitVec 1))
(declare-fun dc_142 () (_ BitVec 1))
(declare-fun dc_141 () (_ BitVec 1))
(declare-fun dc_140 () (_ BitVec 63))
(declare-fun dc_139 () (_ BitVec 64))
(declare-fun dc_138 () (_ BitVec 1))
(declare-fun dc_137 () (_ BitVec 62))
(declare-fun dc_136 () (_ BitVec 1))
(declare-fun dc_135 () (_ BitVec 1))
(declare-fun dc_134 () (_ BitVec 1))
(declare-fun dc_133 () (_ BitVec 63))
(declare-fun dc_132 () (_ BitVec 64))
(declare-fun dc_131 () (_ BitVec 1))
(declare-fun dc_130 () (_ BitVec 62))
(declare-fun dc_129 () (_ BitVec 1))
(declare-fun dc_128 () (_ BitVec 1))
(declare-fun dc_127 () (_ BitVec 1))
(declare-fun dc_126 () (_ BitVec 63))
(declare-fun dc_125 () (_ BitVec 64))
(declare-fun dc_124 () (_ BitVec 1))
(declare-fun dc_123 () (_ BitVec 62))
(declare-fun dc_122 () (_ BitVec 1))
(declare-fun dc_121 () (_ BitVec 1))
(declare-fun dc_120 () (_ BitVec 1))
(declare-fun dc_119 () (_ BitVec 63))
(declare-fun dc_118 () (_ BitVec 64))
(declare-fun dc_117 () (_ BitVec 1))
(declare-fun dc_116 () (_ BitVec 62))
(declare-fun dc_115 () (_ BitVec 1))
(declare-fun dc_114 () (_ BitVec 1))
(declare-fun dc_113 () (_ BitVec 1))
(declare-fun dc_112 () (_ BitVec 63))
(declare-fun dc_111 () (_ BitVec 64))
(declare-fun dc_110 () (_ BitVec 1))
(declare-fun dc_109 () (_ BitVec 62))
(declare-fun dc_108 () (_ BitVec 1))
(declare-fun dc_107 () (_ BitVec 1))
(declare-fun dc_106 () (_ BitVec 1))
(declare-fun dc_105 () (_ BitVec 63))
(declare-fun dc_104 () (_ BitVec 64))
(declare-fun dc_103 () (_ BitVec 1))
(declare-fun dc_102 () (_ BitVec 62))
(declare-fun dc_101 () (_ BitVec 1))
(declare-fun dc_100 () (_ BitVec 1))
(declare-fun dc_99 () (_ BitVec 1))
(declare-fun dc_98 () (_ BitVec 63))
(declare-fun dc_97 () (_ BitVec 64))
(declare-fun dc_96 () (_ BitVec 1))
(declare-fun dc_95 () (_ BitVec 62))
(declare-fun dc_94 () (_ BitVec 1))
(declare-fun dc_93 () (_ BitVec 1))
(declare-fun dc_92 () (_ BitVec 1))
(declare-fun dc_91 () (_ BitVec 63))
(declare-fun dc_90 () (_ BitVec 64))
(declare-fun dc_89 () (_ BitVec 1))
(declare-fun dc_88 () (_ BitVec 62))
(declare-fun dc_87 () (_ BitVec 1))
(declare-fun dc_86 () (_ BitVec 1))
(declare-fun dc_85 () (_ BitVec 1))
(declare-fun dc_84 () (_ BitVec 63))
(declare-fun dc_83 () (_ BitVec 64))
(declare-fun dc_82 () (_ BitVec 1))
(declare-fun dc_81 () (_ BitVec 62))
(declare-fun dc_80 () (_ BitVec 1))
(declare-fun dc_79 () (_ BitVec 1))
(declare-fun dc_78 () (_ BitVec 1))
(declare-fun dc_77 () (_ BitVec 63))
(declare-fun dc_76 () (_ BitVec 64))
(declare-fun dc_75 () (_ BitVec 1))
(declare-fun dc_74 () (_ BitVec 62))
(declare-fun dc_73 () (_ BitVec 1))
(declare-fun dc_72 () (_ BitVec 1))
(declare-fun dc_71 () (_ BitVec 1))
(declare-fun dc_70 () (_ BitVec 63))
(declare-fun dc_69 () (_ BitVec 64))
(declare-fun dc_68 () (_ BitVec 1))
(declare-fun dc_67 () (_ BitVec 62))
(declare-fun dc_66 () (_ BitVec 1))
(declare-fun dc_65 () (_ BitVec 1))
(declare-fun dc_64 () (_ BitVec 1))
(declare-fun dc_63 () (_ BitVec 63))
(declare-fun dc_62 () (_ BitVec 64))
(declare-fun dc_61 () (_ BitVec 1))
(declare-fun dc_60 () (_ BitVec 62))
(declare-fun dc_59 () (_ BitVec 1))
(declare-fun dc_58 () (_ BitVec 1))
(declare-fun dc_57 () (_ BitVec 1))
(declare-fun dc_56 () (_ BitVec 63))
(declare-fun dc_55 () (_ BitVec 64))
(declare-fun dc_54 () (_ BitVec 1))
(declare-fun dc_53 () (_ BitVec 62))
(declare-fun dc_52 () (_ BitVec 1))
(declare-fun dc_51 () (_ BitVec 1))
(declare-fun dc_50 () (_ BitVec 1))
(declare-fun dc_49 () (_ BitVec 63))
(declare-fun dc_48 () (_ BitVec 64))
(declare-fun dc_47 () (_ BitVec 1))
(declare-fun dc_46 () (_ BitVec 62))
(declare-fun dc_45 () (_ BitVec 1))
(declare-fun dc_44 () (_ BitVec 1))
(declare-fun dc_43 () (_ BitVec 1))
(declare-fun dc_42 () (_ BitVec 63))
(declare-fun dc_41 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (= x7_3 (bvadd (bvadd f_0_low60_0_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_2 (bvadd (bvadd g_0_low60_0_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_0_1)) (bvsle f_0_low60_0_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_0_1)) (bvsle g_0_low60_0_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_3) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #x0000000000000001 #x0000000000000001)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_41 ((_ extract 63 1) x8_2)) (= x8_lo_1 ((_ extract 0 0) x8_2))))
(assert (= ne_1 (bvand x8_lo_1 #b1)))
(assert (= x10_1 (ite (= ne_1 #b1) x7_3 #x0000000000000000)))
(assert (and (= ge_1 ((_ extract 63 63) #x0000000000000001)) (= dc_42 ((_ extract 62 0) #x0000000000000001))))
(assert (= ge_2 (bvnot ge_1)))
(assert (= ge_3 (ite (= ne_1 #b1) ge_2 #b0)))
(assert (and (= dc_43 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_2 (ite (= ge_3 #b1) x3_neg_1 #x0000000000000001)))
(assert (and (= dc_44 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_2 (ite (= ge_3 #b1) x10_neg_1 x10_1)))
(assert (= x7_4 (ite (= ge_3 #b1) x8_2 x7_3)))
(assert (and (= dc_45 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2)))) (= x8_3 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2))))))
(assert (= x3_3 (bvadd x3_2 #x0000000000000002)))
(assert (and (= dc_46 ((_ extract 63 2) x8_3)) (= x8_lo_2 ((_ extract 1 0) x8_3))))
(assert (and (= x8_target_1 ((_ extract 1 1) x8_lo_2)) (= dc_47 ((_ extract 0 0) x8_lo_2))))
(assert (= ne_2 (bvand x8_target_1 #b1)))
(assert (and (= x8_4 ((_ sign_extend 1) ((_ extract 63 1) x8_3))) (= dc_48 ((_ zero_extend 63) ((_ extract 0 0) x8_3)))))
(assert true)
(assert (= x10_3 (ite (= ne_2 #b1) x7_4 #x0000000000000000)))
(assert (and (= ge_4 ((_ extract 63 63) x3_3)) (= dc_49 ((_ extract 62 0) x3_3))))
(assert (= ge_5 (bvnot ge_4)))
(assert (= ge_6 (ite (= ne_2 #b1) ge_5 #b0)))
(assert (and (= dc_50 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_4 (ite (= ge_6 #b1) x3_neg_2 x3_3)))
(assert (and (= dc_51 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_4 (ite (= ge_6 #b1) x10_neg_2 x10_3)))
(assert (= x7_5 (ite (= ge_6 #b1) x8_4 x7_4)))
(assert (and (= dc_52 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4)))) (= x8_5 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4))))))
(assert (= x3_5 (bvadd x3_4 #x0000000000000002)))
(assert (and (= dc_53 ((_ extract 63 2) x8_5)) (= x8_lo_3 ((_ extract 1 0) x8_5))))
(assert (and (= x8_target_2 ((_ extract 1 1) x8_lo_3)) (= dc_54 ((_ extract 0 0) x8_lo_3))))
(assert (= ne_3 (bvand x8_target_2 #b1)))
(assert (and (= x8_6 ((_ sign_extend 1) ((_ extract 63 1) x8_5))) (= dc_55 ((_ zero_extend 63) ((_ extract 0 0) x8_5)))))
(assert true)
(assert (= x10_5 (ite (= ne_3 #b1) x7_5 #x0000000000000000)))
(assert (and (= ge_7 ((_ extract 63 63) x3_5)) (= dc_56 ((_ extract 62 0) x3_5))))
(assert (= ge_8 (bvnot ge_7)))
(assert (= ge_9 (ite (= ne_3 #b1) ge_8 #b0)))
(assert (and (= dc_57 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_6 (ite (= ge_9 #b1) x3_neg_3 x3_5)))
(assert (and (= dc_58 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_6 (ite (= ge_9 #b1) x10_neg_3 x10_5)))
(assert (= x7_6 (ite (= ge_9 #b1) x8_6 x7_5)))
(assert (and (= dc_59 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6)))) (= x8_7 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6))))))
(assert (= x3_7 (bvadd x3_6 #x0000000000000002)))
(assert (and (= dc_60 ((_ extract 63 2) x8_7)) (= x8_lo_4 ((_ extract 1 0) x8_7))))
(assert (and (= x8_target_3 ((_ extract 1 1) x8_lo_4)) (= dc_61 ((_ extract 0 0) x8_lo_4))))
(assert (= ne_4 (bvand x8_target_3 #b1)))
(assert (and (= x8_8 ((_ sign_extend 1) ((_ extract 63 1) x8_7))) (= dc_62 ((_ zero_extend 63) ((_ extract 0 0) x8_7)))))
(assert true)
(assert (= x10_7 (ite (= ne_4 #b1) x7_6 #x0000000000000000)))
(assert (and (= ge_10 ((_ extract 63 63) x3_7)) (= dc_63 ((_ extract 62 0) x3_7))))
(assert (= ge_11 (bvnot ge_10)))
(assert (= ge_12 (ite (= ne_4 #b1) ge_11 #b0)))
(assert (and (= dc_64 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_7))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_4 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_7))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_8 (ite (= ge_12 #b1) x3_neg_4 x3_7)))
(assert (and (= dc_65 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_7))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_4 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_7))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_8 (ite (= ge_12 #b1) x10_neg_4 x10_7)))
(assert (= x7_7 (ite (= ge_12 #b1) x8_8 x7_6)))
(assert (and (= dc_66 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_8) ((_ zero_extend 1) x10_8)))) (= x8_9 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_8) ((_ zero_extend 1) x10_8))))))
(assert (= x3_9 (bvadd x3_8 #x0000000000000002)))
(assert (and (= dc_67 ((_ extract 63 2) x8_9)) (= x8_lo_5 ((_ extract 1 0) x8_9))))
(assert (and (= x8_target_4 ((_ extract 1 1) x8_lo_5)) (= dc_68 ((_ extract 0 0) x8_lo_5))))
(assert (= ne_5 (bvand x8_target_4 #b1)))
(assert (and (= x8_10 ((_ sign_extend 1) ((_ extract 63 1) x8_9))) (= dc_69 ((_ zero_extend 63) ((_ extract 0 0) x8_9)))))
(assert true)
(assert (= x10_9 (ite (= ne_5 #b1) x7_7 #x0000000000000000)))
(assert (and (= ge_13 ((_ extract 63 63) x3_9)) (= dc_70 ((_ extract 62 0) x3_9))))
(assert (= ge_14 (bvnot ge_13)))
(assert (= ge_15 (ite (= ne_5 #b1) ge_14 #b0)))
(assert (and (= dc_71 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_9))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_5 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_9))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_10 (ite (= ge_15 #b1) x3_neg_5 x3_9)))
(assert (and (= dc_72 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_9))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_5 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_9))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_10 (ite (= ge_15 #b1) x10_neg_5 x10_9)))
(assert (= x7_8 (ite (= ge_15 #b1) x8_10 x7_7)))
(assert (and (= dc_73 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_10) ((_ zero_extend 1) x10_10)))) (= x8_11 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_10) ((_ zero_extend 1) x10_10))))))
(assert (= x3_11 (bvadd x3_10 #x0000000000000002)))
(assert (and (= dc_74 ((_ extract 63 2) x8_11)) (= x8_lo_6 ((_ extract 1 0) x8_11))))
(assert (and (= x8_target_5 ((_ extract 1 1) x8_lo_6)) (= dc_75 ((_ extract 0 0) x8_lo_6))))
(assert (= ne_6 (bvand x8_target_5 #b1)))
(assert (and (= x8_12 ((_ sign_extend 1) ((_ extract 63 1) x8_11))) (= dc_76 ((_ zero_extend 63) ((_ extract 0 0) x8_11)))))
(assert true)
(assert (= x10_11 (ite (= ne_6 #b1) x7_8 #x0000000000000000)))
(assert (and (= ge_16 ((_ extract 63 63) x3_11)) (= dc_77 ((_ extract 62 0) x3_11))))
(assert (= ge_17 (bvnot ge_16)))
(assert (= ge_18 (ite (= ne_6 #b1) ge_17 #b0)))
(assert (and (= dc_78 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_11))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_6 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_11))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_12 (ite (= ge_18 #b1) x3_neg_6 x3_11)))
(assert (and (= dc_79 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_11))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_6 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_11))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_12 (ite (= ge_18 #b1) x10_neg_6 x10_11)))
(assert (= x7_9 (ite (= ge_18 #b1) x8_12 x7_8)))
(assert (and (= dc_80 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_12) ((_ zero_extend 1) x10_12)))) (= x8_13 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_12) ((_ zero_extend 1) x10_12))))))
(assert (= x3_13 (bvadd x3_12 #x0000000000000002)))
(assert (and (= dc_81 ((_ extract 63 2) x8_13)) (= x8_lo_7 ((_ extract 1 0) x8_13))))
(assert (and (= x8_target_6 ((_ extract 1 1) x8_lo_7)) (= dc_82 ((_ extract 0 0) x8_lo_7))))
(assert (= ne_7 (bvand x8_target_6 #b1)))
(assert (and (= x8_14 ((_ sign_extend 1) ((_ extract 63 1) x8_13))) (= dc_83 ((_ zero_extend 63) ((_ extract 0 0) x8_13)))))
(assert true)
(assert (= x10_13 (ite (= ne_7 #b1) x7_9 #x0000000000000000)))
(assert (and (= ge_19 ((_ extract 63 63) x3_13)) (= dc_84 ((_ extract 62 0) x3_13))))
(assert (= ge_20 (bvnot ge_19)))
(assert (= ge_21 (ite (= ne_7 #b1) ge_20 #b0)))
(assert (and (= dc_85 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_13))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_7 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_13))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_14 (ite (= ge_21 #b1) x3_neg_7 x3_13)))
(assert (and (= dc_86 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_13))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_7 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_13))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_14 (ite (= ge_21 #b1) x10_neg_7 x10_13)))
(assert (= x7_10 (ite (= ge_21 #b1) x8_14 x7_9)))
(assert (and (= dc_87 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_14) ((_ zero_extend 1) x10_14)))) (= x8_15 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_14) ((_ zero_extend 1) x10_14))))))
(assert (= x3_15 (bvadd x3_14 #x0000000000000002)))
(assert (and (= dc_88 ((_ extract 63 2) x8_15)) (= x8_lo_8 ((_ extract 1 0) x8_15))))
(assert (and (= x8_target_7 ((_ extract 1 1) x8_lo_8)) (= dc_89 ((_ extract 0 0) x8_lo_8))))
(assert (= ne_8 (bvand x8_target_7 #b1)))
(assert (and (= x8_16 ((_ sign_extend 1) ((_ extract 63 1) x8_15))) (= dc_90 ((_ zero_extend 63) ((_ extract 0 0) x8_15)))))
(assert true)
(assert (= x10_15 (ite (= ne_8 #b1) x7_10 #x0000000000000000)))
(assert (and (= ge_22 ((_ extract 63 63) x3_15)) (= dc_91 ((_ extract 62 0) x3_15))))
(assert (= ge_23 (bvnot ge_22)))
(assert (= ge_24 (ite (= ne_8 #b1) ge_23 #b0)))
(assert (and (= dc_92 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_15))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_8 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_15))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_16 (ite (= ge_24 #b1) x3_neg_8 x3_15)))
(assert (and (= dc_93 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_15))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_8 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_15))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_16 (ite (= ge_24 #b1) x10_neg_8 x10_15)))
(assert (= x7_11 (ite (= ge_24 #b1) x8_16 x7_10)))
(assert (and (= dc_94 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_16) ((_ zero_extend 1) x10_16)))) (= x8_17 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_16) ((_ zero_extend 1) x10_16))))))
(assert (= x3_17 (bvadd x3_16 #x0000000000000002)))
(assert (and (= dc_95 ((_ extract 63 2) x8_17)) (= x8_lo_9 ((_ extract 1 0) x8_17))))
(assert (and (= x8_target_8 ((_ extract 1 1) x8_lo_9)) (= dc_96 ((_ extract 0 0) x8_lo_9))))
(assert (= ne_9 (bvand x8_target_8 #b1)))
(assert (and (= x8_18 ((_ sign_extend 1) ((_ extract 63 1) x8_17))) (= dc_97 ((_ zero_extend 63) ((_ extract 0 0) x8_17)))))
(assert true)
(assert (= x10_17 (ite (= ne_9 #b1) x7_11 #x0000000000000000)))
(assert (and (= ge_25 ((_ extract 63 63) x3_17)) (= dc_98 ((_ extract 62 0) x3_17))))
(assert (= ge_26 (bvnot ge_25)))
(assert (= ge_27 (ite (= ne_9 #b1) ge_26 #b0)))
(assert (and (= dc_99 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_17))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_9 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_17))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_18 (ite (= ge_27 #b1) x3_neg_9 x3_17)))
(assert (and (= dc_100 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_17))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_9 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_17))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_18 (ite (= ge_27 #b1) x10_neg_9 x10_17)))
(assert (= x7_12 (ite (= ge_27 #b1) x8_18 x7_11)))
(assert (and (= dc_101 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_18) ((_ zero_extend 1) x10_18)))) (= x8_19 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_18) ((_ zero_extend 1) x10_18))))))
(assert (= x3_19 (bvadd x3_18 #x0000000000000002)))
(assert (and (= dc_102 ((_ extract 63 2) x8_19)) (= x8_lo_10 ((_ extract 1 0) x8_19))))
(assert (and (= x8_target_9 ((_ extract 1 1) x8_lo_10)) (= dc_103 ((_ extract 0 0) x8_lo_10))))
(assert (= ne_10 (bvand x8_target_9 #b1)))
(assert (and (= x8_20 ((_ sign_extend 1) ((_ extract 63 1) x8_19))) (= dc_104 ((_ zero_extend 63) ((_ extract 0 0) x8_19)))))
(assert true)
(assert (= x10_19 (ite (= ne_10 #b1) x7_12 #x0000000000000000)))
(assert (and (= ge_28 ((_ extract 63 63) x3_19)) (= dc_105 ((_ extract 62 0) x3_19))))
(assert (= ge_29 (bvnot ge_28)))
(assert (= ge_30 (ite (= ne_10 #b1) ge_29 #b0)))
(assert (and (= dc_106 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_19))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_10 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_19))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_20 (ite (= ge_30 #b1) x3_neg_10 x3_19)))
(assert (and (= dc_107 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_19))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_10 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_19))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_20 (ite (= ge_30 #b1) x10_neg_10 x10_19)))
(assert (= x7_13 (ite (= ge_30 #b1) x8_20 x7_12)))
(assert (and (= dc_108 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_20) ((_ zero_extend 1) x10_20)))) (= x8_21 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_20) ((_ zero_extend 1) x10_20))))))
(assert (= x3_21 (bvadd x3_20 #x0000000000000002)))
(assert (and (= dc_109 ((_ extract 63 2) x8_21)) (= x8_lo_11 ((_ extract 1 0) x8_21))))
(assert (and (= x8_target_10 ((_ extract 1 1) x8_lo_11)) (= dc_110 ((_ extract 0 0) x8_lo_11))))
(assert (= ne_11 (bvand x8_target_10 #b1)))
(assert (and (= x8_22 ((_ sign_extend 1) ((_ extract 63 1) x8_21))) (= dc_111 ((_ zero_extend 63) ((_ extract 0 0) x8_21)))))
(assert true)
(assert (= x10_21 (ite (= ne_11 #b1) x7_13 #x0000000000000000)))
(assert (and (= ge_31 ((_ extract 63 63) x3_21)) (= dc_112 ((_ extract 62 0) x3_21))))
(assert (= ge_32 (bvnot ge_31)))
(assert (= ge_33 (ite (= ne_11 #b1) ge_32 #b0)))
(assert (and (= dc_113 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_21))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_11 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_21))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_22 (ite (= ge_33 #b1) x3_neg_11 x3_21)))
(assert (and (= dc_114 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_21))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_11 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_21))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_22 (ite (= ge_33 #b1) x10_neg_11 x10_21)))
(assert (= x7_14 (ite (= ge_33 #b1) x8_22 x7_13)))
(assert (and (= dc_115 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_22) ((_ zero_extend 1) x10_22)))) (= x8_23 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_22) ((_ zero_extend 1) x10_22))))))
(assert (= x3_23 (bvadd x3_22 #x0000000000000002)))
(assert (and (= dc_116 ((_ extract 63 2) x8_23)) (= x8_lo_12 ((_ extract 1 0) x8_23))))
(assert (and (= x8_target_11 ((_ extract 1 1) x8_lo_12)) (= dc_117 ((_ extract 0 0) x8_lo_12))))
(assert (= ne_12 (bvand x8_target_11 #b1)))
(assert (and (= x8_24 ((_ sign_extend 1) ((_ extract 63 1) x8_23))) (= dc_118 ((_ zero_extend 63) ((_ extract 0 0) x8_23)))))
(assert true)
(assert (= x10_23 (ite (= ne_12 #b1) x7_14 #x0000000000000000)))
(assert (and (= ge_34 ((_ extract 63 63) x3_23)) (= dc_119 ((_ extract 62 0) x3_23))))
(assert (= ge_35 (bvnot ge_34)))
(assert (= ge_36 (ite (= ne_12 #b1) ge_35 #b0)))
(assert (and (= dc_120 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_23))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_12 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_23))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_24 (ite (= ge_36 #b1) x3_neg_12 x3_23)))
(assert (and (= dc_121 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_23))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_12 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_23))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_24 (ite (= ge_36 #b1) x10_neg_12 x10_23)))
(assert (= x7_15 (ite (= ge_36 #b1) x8_24 x7_14)))
(assert (and (= dc_122 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_24) ((_ zero_extend 1) x10_24)))) (= x8_25 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_24) ((_ zero_extend 1) x10_24))))))
(assert (= x3_25 (bvadd x3_24 #x0000000000000002)))
(assert (and (= dc_123 ((_ extract 63 2) x8_25)) (= x8_lo_13 ((_ extract 1 0) x8_25))))
(assert (and (= x8_target_12 ((_ extract 1 1) x8_lo_13)) (= dc_124 ((_ extract 0 0) x8_lo_13))))
(assert (= ne_13 (bvand x8_target_12 #b1)))
(assert (and (= x8_26 ((_ sign_extend 1) ((_ extract 63 1) x8_25))) (= dc_125 ((_ zero_extend 63) ((_ extract 0 0) x8_25)))))
(assert true)
(assert (= x10_25 (ite (= ne_13 #b1) x7_15 #x0000000000000000)))
(assert (and (= ge_37 ((_ extract 63 63) x3_25)) (= dc_126 ((_ extract 62 0) x3_25))))
(assert (= ge_38 (bvnot ge_37)))
(assert (= ge_39 (ite (= ne_13 #b1) ge_38 #b0)))
(assert (and (= dc_127 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_25))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_13 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_25))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_26 (ite (= ge_39 #b1) x3_neg_13 x3_25)))
(assert (and (= dc_128 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_25))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_13 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_25))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_26 (ite (= ge_39 #b1) x10_neg_13 x10_25)))
(assert (= x7_16 (ite (= ge_39 #b1) x8_26 x7_15)))
(assert (and (= dc_129 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_26) ((_ zero_extend 1) x10_26)))) (= x8_27 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_26) ((_ zero_extend 1) x10_26))))))
(assert (= x3_27 (bvadd x3_26 #x0000000000000002)))
(assert (and (= dc_130 ((_ extract 63 2) x8_27)) (= x8_lo_14 ((_ extract 1 0) x8_27))))
(assert (and (= x8_target_13 ((_ extract 1 1) x8_lo_14)) (= dc_131 ((_ extract 0 0) x8_lo_14))))
(assert (= ne_14 (bvand x8_target_13 #b1)))
(assert (and (= x8_28 ((_ sign_extend 1) ((_ extract 63 1) x8_27))) (= dc_132 ((_ zero_extend 63) ((_ extract 0 0) x8_27)))))
(assert true)
(assert (= x10_27 (ite (= ne_14 #b1) x7_16 #x0000000000000000)))
(assert (and (= ge_40 ((_ extract 63 63) x3_27)) (= dc_133 ((_ extract 62 0) x3_27))))
(assert (= ge_41 (bvnot ge_40)))
(assert (= ge_42 (ite (= ne_14 #b1) ge_41 #b0)))
(assert (and (= dc_134 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_27))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_14 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_27))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_28 (ite (= ge_42 #b1) x3_neg_14 x3_27)))
(assert (and (= dc_135 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_27))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_14 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_27))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_28 (ite (= ge_42 #b1) x10_neg_14 x10_27)))
(assert (= x7_17 (ite (= ge_42 #b1) x8_28 x7_16)))
(assert (and (= dc_136 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_28) ((_ zero_extend 1) x10_28)))) (= x8_29 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_28) ((_ zero_extend 1) x10_28))))))
(assert (= x3_29 (bvadd x3_28 #x0000000000000002)))
(assert (and (= dc_137 ((_ extract 63 2) x8_29)) (= x8_lo_15 ((_ extract 1 0) x8_29))))
(assert (and (= x8_target_14 ((_ extract 1 1) x8_lo_15)) (= dc_138 ((_ extract 0 0) x8_lo_15))))
(assert (= ne_15 (bvand x8_target_14 #b1)))
(assert (and (= x8_30 ((_ sign_extend 1) ((_ extract 63 1) x8_29))) (= dc_139 ((_ zero_extend 63) ((_ extract 0 0) x8_29)))))
(assert true)
(assert (= x10_29 (ite (= ne_15 #b1) x7_17 #x0000000000000000)))
(assert (and (= ge_43 ((_ extract 63 63) x3_29)) (= dc_140 ((_ extract 62 0) x3_29))))
(assert (= ge_44 (bvnot ge_43)))
(assert (= ge_45 (ite (= ne_15 #b1) ge_44 #b0)))
(assert (and (= dc_141 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_29))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_15 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_29))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_30 (ite (= ge_45 #b1) x3_neg_15 x3_29)))
(assert (and (= dc_142 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_29))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_15 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_29))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_30 (ite (= ge_45 #b1) x10_neg_15 x10_29)))
(assert (= x7_18 (ite (= ge_45 #b1) x8_30 x7_17)))
(assert (and (= dc_143 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_30) ((_ zero_extend 1) x10_30)))) (= x8_31 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_30) ((_ zero_extend 1) x10_30))))))
(assert (= x3_31 (bvadd x3_30 #x0000000000000002)))
(assert (and (= dc_144 ((_ extract 63 2) x8_31)) (= x8_lo_16 ((_ extract 1 0) x8_31))))
(assert (and (= x8_target_15 ((_ extract 1 1) x8_lo_16)) (= dc_145 ((_ extract 0 0) x8_lo_16))))
(assert (= ne_16 (bvand x8_target_15 #b1)))
(assert (and (= x8_32 ((_ sign_extend 1) ((_ extract 63 1) x8_31))) (= dc_146 ((_ zero_extend 63) ((_ extract 0 0) x8_31)))))
(assert true)
(assert (= x10_31 (ite (= ne_16 #b1) x7_18 #x0000000000000000)))
(assert (and (= ge_46 ((_ extract 63 63) x3_31)) (= dc_147 ((_ extract 62 0) x3_31))))
(assert (= ge_47 (bvnot ge_46)))
(assert (= ge_48 (ite (= ne_16 #b1) ge_47 #b0)))
(assert (and (= dc_148 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_31))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_16 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_31))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_32 (ite (= ge_48 #b1) x3_neg_16 x3_31)))
(assert (and (= dc_149 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_31))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_16 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_31))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_32 (ite (= ge_48 #b1) x10_neg_16 x10_31)))
(assert (= x7_19 (ite (= ge_48 #b1) x8_32 x7_18)))
(assert (and (= dc_150 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_32) ((_ zero_extend 1) x10_32)))) (= x8_33 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_32) ((_ zero_extend 1) x10_32))))))
(assert (= x3_33 (bvadd x3_32 #x0000000000000002)))
(assert (and (= dc_151 ((_ extract 63 2) x8_33)) (= x8_lo_17 ((_ extract 1 0) x8_33))))
(assert (and (= x8_target_16 ((_ extract 1 1) x8_lo_17)) (= dc_152 ((_ extract 0 0) x8_lo_17))))
(assert (= ne_17 (bvand x8_target_16 #b1)))
(assert (and (= x8_34 ((_ sign_extend 1) ((_ extract 63 1) x8_33))) (= dc_153 ((_ zero_extend 63) ((_ extract 0 0) x8_33)))))
(assert true)
(assert (= x10_33 (ite (= ne_17 #b1) x7_19 #x0000000000000000)))
(assert (and (= ge_49 ((_ extract 63 63) x3_33)) (= dc_154 ((_ extract 62 0) x3_33))))
(assert (= ge_50 (bvnot ge_49)))
(assert (= ge_51 (ite (= ne_17 #b1) ge_50 #b0)))
(assert (and (= dc_155 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_33))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_17 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_33))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_34 (ite (= ge_51 #b1) x3_neg_17 x3_33)))
(assert (and (= dc_156 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_33))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_17 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_33))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_34 (ite (= ge_51 #b1) x10_neg_17 x10_33)))
(assert (= x7_20 (ite (= ge_51 #b1) x8_34 x7_19)))
(assert (and (= dc_157 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_34) ((_ zero_extend 1) x10_34)))) (= x8_35 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_34) ((_ zero_extend 1) x10_34))))))
(assert (= x3_35 (bvadd x3_34 #x0000000000000002)))
(assert (and (= dc_158 ((_ extract 63 2) x8_35)) (= x8_lo_18 ((_ extract 1 0) x8_35))))
(assert (and (= x8_target_17 ((_ extract 1 1) x8_lo_18)) (= dc_159 ((_ extract 0 0) x8_lo_18))))
(assert (= ne_18 (bvand x8_target_17 #b1)))
(assert (and (= x8_36 ((_ sign_extend 1) ((_ extract 63 1) x8_35))) (= dc_160 ((_ zero_extend 63) ((_ extract 0 0) x8_35)))))
(assert true)
(assert (= x10_35 (ite (= ne_18 #b1) x7_20 #x0000000000000000)))
(assert (and (= ge_52 ((_ extract 63 63) x3_35)) (= dc_161 ((_ extract 62 0) x3_35))))
(assert (= ge_53 (bvnot ge_52)))
(assert (= ge_54 (ite (= ne_18 #b1) ge_53 #b0)))
(assert (and (= dc_162 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_35))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_18 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_35))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_36 (ite (= ge_54 #b1) x3_neg_18 x3_35)))
(assert (and (= dc_163 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_35))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_18 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_35))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_36 (ite (= ge_54 #b1) x10_neg_18 x10_35)))
(assert (= x7_21 (ite (= ge_54 #b1) x8_36 x7_20)))
(assert (and (= dc_164 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_36) ((_ zero_extend 1) x10_36)))) (= x8_37 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_36) ((_ zero_extend 1) x10_36))))))
(assert (= x3_37 (bvadd x3_36 #x0000000000000002)))
(assert (and (= dc_165 ((_ extract 63 2) x8_37)) (= x8_lo_19 ((_ extract 1 0) x8_37))))
(assert (and (= x8_target_18 ((_ extract 1 1) x8_lo_19)) (= dc_166 ((_ extract 0 0) x8_lo_19))))
(assert (= ne_19 (bvand x8_target_18 #b1)))
(assert (and (= x8_38 ((_ sign_extend 1) ((_ extract 63 1) x8_37))) (= dc_167 ((_ zero_extend 63) ((_ extract 0 0) x8_37)))))
(assert true)
(assert (= x10_37 (ite (= ne_19 #b1) x7_21 #x0000000000000000)))
(assert (and (= ge_55 ((_ extract 63 63) x3_37)) (= dc_168 ((_ extract 62 0) x3_37))))
(assert (= ge_56 (bvnot ge_55)))
(assert (= ge_57 (ite (= ne_19 #b1) ge_56 #b0)))
(assert (and (= dc_169 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_37))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_19 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_37))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_38 (ite (= ge_57 #b1) x3_neg_19 x3_37)))
(assert (and (= dc_170 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_37))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_19 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_37))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_38 (ite (= ge_57 #b1) x10_neg_19 x10_37)))
(assert (= x7_22 (ite (= ge_57 #b1) x8_38 x7_21)))
(assert (and (= dc_171 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_38) ((_ zero_extend 1) x10_38)))) (= x8_39 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_38) ((_ zero_extend 1) x10_38))))))
(assert (= x3_39 (bvadd x3_38 #x0000000000000002)))
(assert (and (= dc_172 ((_ extract 63 2) x8_39)) (= x8_lo_20 ((_ extract 1 0) x8_39))))
(assert (and (= x8_target_19 ((_ extract 1 1) x8_lo_20)) (= dc_173 ((_ extract 0 0) x8_lo_20))))
(assert (= ne_20 (bvand x8_target_19 #b1)))
(assert (and (= x8_40 ((_ sign_extend 1) ((_ extract 63 1) x8_39))) (= dc_174 ((_ zero_extend 63) ((_ extract 0 0) x8_39)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_38) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_22 x7_21)) (= (bvmul x8_40 #x0000000000000002) x8_38)) (= x3_39 (bvadd #x0000000000000002 x3_37))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_38) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_37 #x0000000000000000)) (= x7_22 x7_21)) (= (bvmul x8_40 #x0000000000000002) (bvadd x8_38 x7_21))) (= x3_39 (bvadd #x0000000000000002 x3_37)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_38) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_37 #x0000000000000000)) (= x7_22 x8_38)) (= (bvmul x8_40 #x0000000000000002) (bvsub x8_38 x7_21))) (= x3_39 (bvsub #x0000000000000002 x3_37))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_5585e9.smt2
Execution time of boolector: 1.3762 seconds
OUTPUT FROM boolector:
unsat

=== Cut #3 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #3
; Range assertion #32: x11_5 = u_0_20_2
; Range condition: x11_5 = u_0_20_2
; Output file: /tmp/outputqfbv_720c39.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_42 () (_ BitVec 64))
(declare-fun x7_23 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x14_3 () (_ BitVec 64))
(declare-fun x14_2 () (_ BitVec 64))
(declare-fun x14_1 () (_ BitVec 64))
(declare-fun x13_5 () (_ BitVec 64))
(declare-fun x13_4 () (_ BitVec 64))
(declare-fun x13_3 () (_ BitVec 64))
(declare-fun x13_2 () (_ BitVec 64))
(declare-fun x13_1 () (_ BitVec 64))
(declare-fun x12_3 () (_ BitVec 64))
(declare-fun x12_2 () (_ BitVec 64))
(declare-fun x12_1 () (_ BitVec 64))
(declare-fun x11_5 () (_ BitVec 64))
(declare-fun x11_4 () (_ BitVec 64))
(declare-fun x11_3 () (_ BitVec 64))
(declare-fun x11_2 () (_ BitVec 64))
(declare-fun x11_1 () (_ BitVec 64))
(declare-fun v_0_20_2 () (_ BitVec 64))
(declare-fun u_0_20_2 () (_ BitVec 64))
(declare-fun s_0_20_2 () (_ BitVec 64))
(declare-fun r_0_20_2 () (_ BitVec 64))
(declare-fun g_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun dcH_2 () (_ BitVec 64))
(declare-fun dcH_1 () (_ BitVec 64))
(declare-fun dc_183 () (_ BitVec 64))
(declare-fun dc_182 () (_ BitVec 64))
(declare-fun dc_181 () (_ BitVec 64))
(declare-fun dc_180 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_23 (bvadd (bvadd f_0_low60_0_low20_20_1 (bvmul u_0_20_2 #x0000000000200000)) (bvmul v_0_20_2 #x0000040000000000))) (= x8_42 (bvadd (bvadd g_0_low60_0_low20_20_1 (bvmul r_0_20_2 #x0000000000200000)) (bvmul s_0_20_2 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_20_1)) (bvsle f_0_low60_0_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_20_1)) (bvsle g_0_low60_0_low20_20_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) f_0_low60_20_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (bvsle #xFFFFFFFFFFF00000 u_0_20_2)) (bvsle u_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 v_0_20_2)) (bvsle v_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 r_0_20_2)) (bvsle r_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 s_0_20_2)) (bvsle s_0_20_2 #x00000000000FFFFF)) (bvsle (bvadd u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvsub u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvadd r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvsub r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (= x6_2 #x0000020000100000)))
(assert (= x12_1 (bvadd x7_23 x6_2)))
(assert (= x12_2 x12_1))
(assert (and (= x12_3 ((_ sign_extend 42) ((_ extract 63 42) x12_2))) (= dc_180 ((_ zero_extend 22) ((_ extract 41 0) x12_2)))))
(assert (= x11_1 (bvadd x7_23 #x0000000000100000)))
(assert (and (= dcH_1 ((_ sign_extend 42) ((_ extract 63 42) x11_1))) (= x11_2 ((_ zero_extend 22) ((_ extract 41 0) x11_1)))))
(assert (= x11_3 (bvshl x11_2 #x0000000000000016)))
(assert (= x11_4 x11_3))
(assert (and (= x11_5 ((_ sign_extend 43) ((_ extract 63 43) x11_4))) (= dc_181 ((_ zero_extend 21) ((_ extract 42 0) x11_4)))))
(assert (= x14_1 (bvadd x8_42 x6_2)))
(assert (= x14_2 x14_1))
(assert (and (= x14_3 ((_ sign_extend 42) ((_ extract 63 42) x14_2))) (= dc_182 ((_ zero_extend 22) ((_ extract 41 0) x14_2)))))
(assert (= x13_1 (bvadd x8_42 #x0000000000100000)))
(assert (and (= dcH_2 ((_ sign_extend 42) ((_ extract 63 42) x13_1))) (= x13_2 ((_ zero_extend 22) ((_ extract 41 0) x13_1)))))
(assert (= x13_3 (bvshl x13_2 #x0000000000000016)))
(assert (= x13_4 x13_3))
(assert (and (= x13_5 ((_ sign_extend 43) ((_ extract 63 43) x13_4))) (= dc_183 ((_ zero_extend 21) ((_ extract 42 0) x13_4)))))
(assert (not (= x11_5 u_0_20_2)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_ec4b0b.smt2
Execution time of boolector: 0.0073 seconds
OUTPUT FROM boolector:
unsat

=== Cut #3 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #3
; Range assertion #33: x12_3 = v_0_20_2
; Range condition: x12_3 = v_0_20_2
; Output file: /tmp/outputqfbv_31d8ab.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_42 () (_ BitVec 64))
(declare-fun x7_23 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x14_3 () (_ BitVec 64))
(declare-fun x14_2 () (_ BitVec 64))
(declare-fun x14_1 () (_ BitVec 64))
(declare-fun x13_5 () (_ BitVec 64))
(declare-fun x13_4 () (_ BitVec 64))
(declare-fun x13_3 () (_ BitVec 64))
(declare-fun x13_2 () (_ BitVec 64))
(declare-fun x13_1 () (_ BitVec 64))
(declare-fun x12_3 () (_ BitVec 64))
(declare-fun x12_2 () (_ BitVec 64))
(declare-fun x12_1 () (_ BitVec 64))
(declare-fun x11_5 () (_ BitVec 64))
(declare-fun x11_4 () (_ BitVec 64))
(declare-fun x11_3 () (_ BitVec 64))
(declare-fun x11_2 () (_ BitVec 64))
(declare-fun x11_1 () (_ BitVec 64))
(declare-fun v_0_20_2 () (_ BitVec 64))
(declare-fun u_0_20_2 () (_ BitVec 64))
(declare-fun s_0_20_2 () (_ BitVec 64))
(declare-fun r_0_20_2 () (_ BitVec 64))
(declare-fun g_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun dcH_2 () (_ BitVec 64))
(declare-fun dcH_1 () (_ BitVec 64))
(declare-fun dc_183 () (_ BitVec 64))
(declare-fun dc_182 () (_ BitVec 64))
(declare-fun dc_181 () (_ BitVec 64))
(declare-fun dc_180 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_23 (bvadd (bvadd f_0_low60_0_low20_20_1 (bvmul u_0_20_2 #x0000000000200000)) (bvmul v_0_20_2 #x0000040000000000))) (= x8_42 (bvadd (bvadd g_0_low60_0_low20_20_1 (bvmul r_0_20_2 #x0000000000200000)) (bvmul s_0_20_2 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_20_1)) (bvsle f_0_low60_0_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_20_1)) (bvsle g_0_low60_0_low20_20_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) f_0_low60_20_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (bvsle #xFFFFFFFFFFF00000 u_0_20_2)) (bvsle u_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 v_0_20_2)) (bvsle v_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 r_0_20_2)) (bvsle r_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 s_0_20_2)) (bvsle s_0_20_2 #x00000000000FFFFF)) (bvsle (bvadd u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvsub u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvadd r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvsub r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (= x6_2 #x0000020000100000)))
(assert (= x12_1 (bvadd x7_23 x6_2)))
(assert (= x12_2 x12_1))
(assert (and (= x12_3 ((_ sign_extend 42) ((_ extract 63 42) x12_2))) (= dc_180 ((_ zero_extend 22) ((_ extract 41 0) x12_2)))))
(assert (= x11_1 (bvadd x7_23 #x0000000000100000)))
(assert (and (= dcH_1 ((_ sign_extend 42) ((_ extract 63 42) x11_1))) (= x11_2 ((_ zero_extend 22) ((_ extract 41 0) x11_1)))))
(assert (= x11_3 (bvshl x11_2 #x0000000000000016)))
(assert (= x11_4 x11_3))
(assert (and (= x11_5 ((_ sign_extend 43) ((_ extract 63 43) x11_4))) (= dc_181 ((_ zero_extend 21) ((_ extract 42 0) x11_4)))))
(assert (= x14_1 (bvadd x8_42 x6_2)))
(assert (= x14_2 x14_1))
(assert (and (= x14_3 ((_ sign_extend 42) ((_ extract 63 42) x14_2))) (= dc_182 ((_ zero_extend 22) ((_ extract 41 0) x14_2)))))
(assert (= x13_1 (bvadd x8_42 #x0000000000100000)))
(assert (and (= dcH_2 ((_ sign_extend 42) ((_ extract 63 42) x13_1))) (= x13_2 ((_ zero_extend 22) ((_ extract 41 0) x13_1)))))
(assert (= x13_3 (bvshl x13_2 #x0000000000000016)))
(assert (= x13_4 x13_3))
(assert (and (= x13_5 ((_ sign_extend 43) ((_ extract 63 43) x13_4))) (= dc_183 ((_ zero_extend 21) ((_ extract 42 0) x13_4)))))
(assert true)
(assert (not (= x12_3 v_0_20_2)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_6d8583.smt2
Execution time of boolector: 0.0102 seconds
OUTPUT FROM boolector:
unsat

=== Cut #3 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #3
; Range assertion #34: x13_5 = r_0_20_2
; Range condition: x13_5 = r_0_20_2
; Output file: /tmp/outputqfbv_d41e43.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_42 () (_ BitVec 64))
(declare-fun x7_23 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x14_3 () (_ BitVec 64))
(declare-fun x14_2 () (_ BitVec 64))
(declare-fun x14_1 () (_ BitVec 64))
(declare-fun x13_5 () (_ BitVec 64))
(declare-fun x13_4 () (_ BitVec 64))
(declare-fun x13_3 () (_ BitVec 64))
(declare-fun x13_2 () (_ BitVec 64))
(declare-fun x13_1 () (_ BitVec 64))
(declare-fun x12_3 () (_ BitVec 64))
(declare-fun x12_2 () (_ BitVec 64))
(declare-fun x12_1 () (_ BitVec 64))
(declare-fun x11_5 () (_ BitVec 64))
(declare-fun x11_4 () (_ BitVec 64))
(declare-fun x11_3 () (_ BitVec 64))
(declare-fun x11_2 () (_ BitVec 64))
(declare-fun x11_1 () (_ BitVec 64))
(declare-fun v_0_20_2 () (_ BitVec 64))
(declare-fun u_0_20_2 () (_ BitVec 64))
(declare-fun s_0_20_2 () (_ BitVec 64))
(declare-fun r_0_20_2 () (_ BitVec 64))
(declare-fun g_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun dcH_2 () (_ BitVec 64))
(declare-fun dcH_1 () (_ BitVec 64))
(declare-fun dc_183 () (_ BitVec 64))
(declare-fun dc_182 () (_ BitVec 64))
(declare-fun dc_181 () (_ BitVec 64))
(declare-fun dc_180 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_23 (bvadd (bvadd f_0_low60_0_low20_20_1 (bvmul u_0_20_2 #x0000000000200000)) (bvmul v_0_20_2 #x0000040000000000))) (= x8_42 (bvadd (bvadd g_0_low60_0_low20_20_1 (bvmul r_0_20_2 #x0000000000200000)) (bvmul s_0_20_2 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_20_1)) (bvsle f_0_low60_0_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_20_1)) (bvsle g_0_low60_0_low20_20_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) f_0_low60_20_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (bvsle #xFFFFFFFFFFF00000 u_0_20_2)) (bvsle u_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 v_0_20_2)) (bvsle v_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 r_0_20_2)) (bvsle r_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 s_0_20_2)) (bvsle s_0_20_2 #x00000000000FFFFF)) (bvsle (bvadd u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvsub u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvadd r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvsub r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (= x6_2 #x0000020000100000)))
(assert (= x12_1 (bvadd x7_23 x6_2)))
(assert (= x12_2 x12_1))
(assert (and (= x12_3 ((_ sign_extend 42) ((_ extract 63 42) x12_2))) (= dc_180 ((_ zero_extend 22) ((_ extract 41 0) x12_2)))))
(assert (= x11_1 (bvadd x7_23 #x0000000000100000)))
(assert (and (= dcH_1 ((_ sign_extend 42) ((_ extract 63 42) x11_1))) (= x11_2 ((_ zero_extend 22) ((_ extract 41 0) x11_1)))))
(assert (= x11_3 (bvshl x11_2 #x0000000000000016)))
(assert (= x11_4 x11_3))
(assert (and (= x11_5 ((_ sign_extend 43) ((_ extract 63 43) x11_4))) (= dc_181 ((_ zero_extend 21) ((_ extract 42 0) x11_4)))))
(assert (= x14_1 (bvadd x8_42 x6_2)))
(assert (= x14_2 x14_1))
(assert (and (= x14_3 ((_ sign_extend 42) ((_ extract 63 42) x14_2))) (= dc_182 ((_ zero_extend 22) ((_ extract 41 0) x14_2)))))
(assert (= x13_1 (bvadd x8_42 #x0000000000100000)))
(assert (and (= dcH_2 ((_ sign_extend 42) ((_ extract 63 42) x13_1))) (= x13_2 ((_ zero_extend 22) ((_ extract 41 0) x13_1)))))
(assert (= x13_3 (bvshl x13_2 #x0000000000000016)))
(assert (= x13_4 x13_3))
(assert (and (= x13_5 ((_ sign_extend 43) ((_ extract 63 43) x13_4))) (= dc_183 ((_ zero_extend 21) ((_ extract 42 0) x13_4)))))
(assert true)
(assert true)
(assert (not (= x13_5 r_0_20_2)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_ef6bb3.smt2
Execution time of boolector: 0.0073 seconds
OUTPUT FROM boolector:
unsat

=== Cut #3 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #3
; Range assertion #35: x14_3 = s_0_20_2
; Range condition: x14_3 = s_0_20_2
; Output file: /tmp/outputqfbv_da2ed6.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_42 () (_ BitVec 64))
(declare-fun x7_23 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x14_3 () (_ BitVec 64))
(declare-fun x14_2 () (_ BitVec 64))
(declare-fun x14_1 () (_ BitVec 64))
(declare-fun x13_5 () (_ BitVec 64))
(declare-fun x13_4 () (_ BitVec 64))
(declare-fun x13_3 () (_ BitVec 64))
(declare-fun x13_2 () (_ BitVec 64))
(declare-fun x13_1 () (_ BitVec 64))
(declare-fun x12_3 () (_ BitVec 64))
(declare-fun x12_2 () (_ BitVec 64))
(declare-fun x12_1 () (_ BitVec 64))
(declare-fun x11_5 () (_ BitVec 64))
(declare-fun x11_4 () (_ BitVec 64))
(declare-fun x11_3 () (_ BitVec 64))
(declare-fun x11_2 () (_ BitVec 64))
(declare-fun x11_1 () (_ BitVec 64))
(declare-fun v_0_20_2 () (_ BitVec 64))
(declare-fun u_0_20_2 () (_ BitVec 64))
(declare-fun s_0_20_2 () (_ BitVec 64))
(declare-fun r_0_20_2 () (_ BitVec 64))
(declare-fun g_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun dcH_2 () (_ BitVec 64))
(declare-fun dcH_1 () (_ BitVec 64))
(declare-fun dc_183 () (_ BitVec 64))
(declare-fun dc_182 () (_ BitVec 64))
(declare-fun dc_181 () (_ BitVec 64))
(declare-fun dc_180 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_23 (bvadd (bvadd f_0_low60_0_low20_20_1 (bvmul u_0_20_2 #x0000000000200000)) (bvmul v_0_20_2 #x0000040000000000))) (= x8_42 (bvadd (bvadd g_0_low60_0_low20_20_1 (bvmul r_0_20_2 #x0000000000200000)) (bvmul s_0_20_2 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_20_1)) (bvsle f_0_low60_0_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_20_1)) (bvsle g_0_low60_0_low20_20_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) f_0_low60_20_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (bvsle #xFFFFFFFFFFF00000 u_0_20_2)) (bvsle u_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 v_0_20_2)) (bvsle v_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 r_0_20_2)) (bvsle r_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 s_0_20_2)) (bvsle s_0_20_2 #x00000000000FFFFF)) (bvsle (bvadd u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvsub u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvadd r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvsub r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (= x6_2 #x0000020000100000)))
(assert (= x12_1 (bvadd x7_23 x6_2)))
(assert (= x12_2 x12_1))
(assert (and (= x12_3 ((_ sign_extend 42) ((_ extract 63 42) x12_2))) (= dc_180 ((_ zero_extend 22) ((_ extract 41 0) x12_2)))))
(assert (= x11_1 (bvadd x7_23 #x0000000000100000)))
(assert (and (= dcH_1 ((_ sign_extend 42) ((_ extract 63 42) x11_1))) (= x11_2 ((_ zero_extend 22) ((_ extract 41 0) x11_1)))))
(assert (= x11_3 (bvshl x11_2 #x0000000000000016)))
(assert (= x11_4 x11_3))
(assert (and (= x11_5 ((_ sign_extend 43) ((_ extract 63 43) x11_4))) (= dc_181 ((_ zero_extend 21) ((_ extract 42 0) x11_4)))))
(assert (= x14_1 (bvadd x8_42 x6_2)))
(assert (= x14_2 x14_1))
(assert (and (= x14_3 ((_ sign_extend 42) ((_ extract 63 42) x14_2))) (= dc_182 ((_ zero_extend 22) ((_ extract 41 0) x14_2)))))
(assert (= x13_1 (bvadd x8_42 #x0000000000100000)))
(assert (and (= dcH_2 ((_ sign_extend 42) ((_ extract 63 42) x13_1))) (= x13_2 ((_ zero_extend 22) ((_ extract 41 0) x13_1)))))
(assert (= x13_3 (bvshl x13_2 #x0000000000000016)))
(assert (= x13_4 x13_3))
(assert (and (= x13_5 ((_ sign_extend 43) ((_ extract 63 43) x13_4))) (= dc_183 ((_ zero_extend 21) ((_ extract 42 0) x13_4)))))
(assert true)
(assert true)
(assert true)
(assert (not (= x14_3 s_0_20_2)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_778e62.smt2
Execution time of boolector: 0.0105 seconds
OUTPUT FROM boolector:
unsat

=== Cut #4 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #4
; Range assertion #38: smod (sub (uext x9_3 1) (uext (mul (-1)@64 f_0_low60_20_1) 1)) (uext 17592186044416@64 1) = 0@65
; Range condition: ((x9_3@e1) - ((-1 * f_0_low60_20_1)@e1)) smod (17592186044416@e1) = 0
; Output file: /tmp/outputqfbv_df384c.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x9_3 () (_ BitVec 64))
(declare-fun x9_2 () (_ BitVec 64))
(declare-fun x9_1 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x2_7 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x14_3 () (_ BitVec 64))
(declare-fun x13_5 () (_ BitVec 64))
(declare-fun x12_3 () (_ BitVec 64))
(declare-fun x11_5 () (_ BitVec 64))
(declare-fun x10_42 () (_ BitVec 64))
(declare-fun x10_41 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun tmp_2 () (_ BitVec 64))
(declare-fun tmp_1 () (_ BitVec 64))
(declare-fun g_0_low60_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_20_1 () (_ BitVec 64))
(declare-fun dcH_6 () (_ BitVec 64))
(declare-fun dcH_5 () (_ BitVec 64))
(declare-fun dcH_4 () (_ BitVec 64))
(declare-fun dcH_3 () (_ BitVec 64))
(declare-fun dc_187 () (_ BitVec 64))
(declare-fun dc_186 () (_ BitVec 1))
(declare-fun dc_185 () (_ BitVec 64))
(declare-fun dc_184 () (_ BitVec 1))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) f_0_low60_20_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (bvsle #xFFFFFFFFFFF00000 x11_5)) (bvsle x11_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x12_3)) (bvsle x12_3 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x13_5)) (bvsle x13_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x14_3)) (bvsle x14_3 #x00000000000FFFFF)) (bvsle (bvadd x11_5 x12_3) #x0000000000100000)) (bvsle (bvsub x11_5 x12_3) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 x11_5) x12_3) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 x11_5) x12_3) #x0000000000100000)) (bvsle (bvadd x13_5 x14_3) #x0000000000100000)) (bvsle (bvsub x13_5 x14_3) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 x13_5) x14_3) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 x13_5) x14_3) #x0000000000100000)) (= x6_2 #x0000020000100000)))
(assert (and (= dcH_3 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x11_5) ((_ sign_extend 64) x1_2)))) (= x9_1 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x11_5) ((_ sign_extend 64) x1_2))))))
(assert (and (= dcH_4 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x12_3)))) (= tmp_1 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x12_3))))))
(assert (and (= dc_184 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x9_1) ((_ zero_extend 1) tmp_1)))) (= x9_2 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x9_1) ((_ zero_extend 1) tmp_1))))))
(assert true)
(assert (and (= x9_2 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) f_0_low60_20_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x9_2) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x9_3 ((_ zero_extend 20) ((_ extract 63 20) x9_2))) (= dc_185 ((_ zero_extend 44) ((_ extract 19 0) x9_2)))))
(assert (and (= dcH_5 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x13_5) ((_ sign_extend 64) x1_2)))) (= x10_41 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x13_5) ((_ sign_extend 64) x1_2))))))
(assert (and (= dcH_6 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x14_3)))) (= tmp_2 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x14_3))))))
(assert (and (= dc_186 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x10_41) ((_ zero_extend 1) tmp_2)))) (= x10_42 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x10_41) ((_ zero_extend 1) tmp_2))))))
(assert true)
(assert (and (= x10_42 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) g_0_low60_20_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x10_42) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x2_7 ((_ zero_extend 20) ((_ extract 63 20) x10_42))) (= dc_187 ((_ zero_extend 44) ((_ extract 19 0) x10_42)))))
(assert (not (= (bvsmod (bvsub ((_ zero_extend 1) x9_3) ((_ zero_extend 1) (bvmul #xFFFFFFFFFFFFFFFF f_0_low60_20_1))) ((_ zero_extend 1) #x0000100000000000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_299e1b.smt2
Execution time of boolector: 0.1225 seconds
OUTPUT FROM boolector:
unsat

=== Cut #4 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #4
; Range assertion #39: smod (sub (uext x2_7 1) (uext (mul (-1)@64 g_0_low60_20_1) 1)) (uext 17592186044416@64 1) = 0@65
; Range condition: ((x2_7@e1) - ((-1 * g_0_low60_20_1)@e1)) smod (17592186044416@e1) = 0
; Output file: /tmp/outputqfbv_8dba2f.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x9_3 () (_ BitVec 64))
(declare-fun x9_2 () (_ BitVec 64))
(declare-fun x9_1 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x2_7 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x14_3 () (_ BitVec 64))
(declare-fun x13_5 () (_ BitVec 64))
(declare-fun x12_3 () (_ BitVec 64))
(declare-fun x11_5 () (_ BitVec 64))
(declare-fun x10_42 () (_ BitVec 64))
(declare-fun x10_41 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun tmp_2 () (_ BitVec 64))
(declare-fun tmp_1 () (_ BitVec 64))
(declare-fun g_0_low60_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_20_1 () (_ BitVec 64))
(declare-fun dcH_6 () (_ BitVec 64))
(declare-fun dcH_5 () (_ BitVec 64))
(declare-fun dcH_4 () (_ BitVec 64))
(declare-fun dcH_3 () (_ BitVec 64))
(declare-fun dc_187 () (_ BitVec 64))
(declare-fun dc_186 () (_ BitVec 1))
(declare-fun dc_185 () (_ BitVec 64))
(declare-fun dc_184 () (_ BitVec 1))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) f_0_low60_20_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (bvsle #xFFFFFFFFFFF00000 x11_5)) (bvsle x11_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x12_3)) (bvsle x12_3 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x13_5)) (bvsle x13_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x14_3)) (bvsle x14_3 #x00000000000FFFFF)) (bvsle (bvadd x11_5 x12_3) #x0000000000100000)) (bvsle (bvsub x11_5 x12_3) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 x11_5) x12_3) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 x11_5) x12_3) #x0000000000100000)) (bvsle (bvadd x13_5 x14_3) #x0000000000100000)) (bvsle (bvsub x13_5 x14_3) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 x13_5) x14_3) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 x13_5) x14_3) #x0000000000100000)) (= x6_2 #x0000020000100000)))
(assert (and (= dcH_3 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x11_5) ((_ sign_extend 64) x1_2)))) (= x9_1 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x11_5) ((_ sign_extend 64) x1_2))))))
(assert (and (= dcH_4 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x12_3)))) (= tmp_1 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x12_3))))))
(assert (and (= dc_184 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x9_1) ((_ zero_extend 1) tmp_1)))) (= x9_2 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x9_1) ((_ zero_extend 1) tmp_1))))))
(assert true)
(assert (and (= x9_2 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) f_0_low60_20_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x9_2) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x9_3 ((_ zero_extend 20) ((_ extract 63 20) x9_2))) (= dc_185 ((_ zero_extend 44) ((_ extract 19 0) x9_2)))))
(assert (and (= dcH_5 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x13_5) ((_ sign_extend 64) x1_2)))) (= x10_41 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x13_5) ((_ sign_extend 64) x1_2))))))
(assert (and (= dcH_6 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x14_3)))) (= tmp_2 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x14_3))))))
(assert (and (= dc_186 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x10_41) ((_ zero_extend 1) tmp_2)))) (= x10_42 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x10_41) ((_ zero_extend 1) tmp_2))))))
(assert true)
(assert (and (= x10_42 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) g_0_low60_20_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x10_42) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x2_7 ((_ zero_extend 20) ((_ extract 63 20) x10_42))) (= dc_187 ((_ zero_extend 44) ((_ extract 19 0) x10_42)))))
(assert true)
(assert (not (= (bvsmod (bvsub ((_ zero_extend 1) x2_7) ((_ zero_extend 1) (bvmul #xFFFFFFFFFFFFFFFF g_0_low60_20_1))) ((_ zero_extend 1) #x0000100000000000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_e785a6.smt2
Execution time of boolector: 0.1224 seconds
OUTPUT FROM boolector:
unsat

=== Cut #6 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #6
; Range assertion #40: or [and [smod (sub (uext x8_44 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_26 = x7_25, mul x8_46 2@64 = x8_44, x3_43 = add 2@64 x3_41], and [smod (sub (uext x8_44 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_41 <s 0@64, x7_26 = x7_25, mul x8_46 2@64 = add x8_44 x7_25, x3_43 = add 2@64 x3_41], and [smod (sub (uext x8_44 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_41 >=s 0@64, x7_26 = x8_44, mul x8_46 2@64 = sub x8_44 x7_25, x3_43 = sub 2@64 x3_41]]
; Range condition: ((x8_44@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_26 = x7_25 /\ x8_46 * 2 = x8_44 /\ x3_43 = 2 + x3_41 \/ ((x8_44@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_41 <s 0 /\ x7_26 = x7_25 /\ x8_46 * 2 = x8_44 + x7_25 /\ x3_43 = 2 + x3_41 \/ ((x8_44@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_41 >=s 0 /\ x7_26 = x8_44 /\ x8_46 * 2 = x8_44 - x7_25 /\ x3_43 = 2 - x3_41
; Output file: /tmp/outputqfbv_3c2ab7.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_20 () (_ BitVec 1))
(declare-fun x8_lo_22 () (_ BitVec 2))
(declare-fun x8_lo_21 () (_ BitVec 1))
(declare-fun x8_46 () (_ BitVec 64))
(declare-fun x8_45 () (_ BitVec 64))
(declare-fun x8_44 () (_ BitVec 64))
(declare-fun x7_26 () (_ BitVec 64))
(declare-fun x7_25 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_21 () (_ BitVec 64))
(declare-fun x3_43 () (_ BitVec 64))
(declare-fun x3_42 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x10_neg_21 () (_ BitVec 64))
(declare-fun x10_44 () (_ BitVec 64))
(declare-fun x10_43 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun ne_22 () (_ BitVec 1))
(declare-fun ne_21 () (_ BitVec 1))
(declare-fun ge_63 () (_ BitVec 1))
(declare-fun ge_62 () (_ BitVec 1))
(declare-fun ge_61 () (_ BitVec 1))
(declare-fun dc_195 () (_ BitVec 64))
(declare-fun dc_194 () (_ BitVec 1))
(declare-fun dc_193 () (_ BitVec 62))
(declare-fun dc_192 () (_ BitVec 1))
(declare-fun dc_191 () (_ BitVec 1))
(declare-fun dc_190 () (_ BitVec 1))
(declare-fun dc_189 () (_ BitVec 63))
(declare-fun dc_188 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_25 (bvadd (bvadd neg_f_0_low60_20_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_44 (bvadd (bvadd neg_g_0_low60_20_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_0_1)) (bvsle neg_f_0_low60_20_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_0_1)) (bvsle neg_g_0_low60_20_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_25) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_188 ((_ extract 63 1) x8_44)) (= x8_lo_21 ((_ extract 0 0) x8_44))))
(assert (= ne_21 (bvand x8_lo_21 #b1)))
(assert (= x10_43 (ite (= ne_21 #b1) x7_25 #x0000000000000000)))
(assert (and (= ge_61 ((_ extract 63 63) x3_41)) (= dc_189 ((_ extract 62 0) x3_41))))
(assert (= ge_62 (bvnot ge_61)))
(assert (= ge_63 (ite (= ne_21 #b1) ge_62 #b0)))
(assert (and (= dc_190 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_42 (ite (= ge_63 #b1) x3_neg_21 x3_41)))
(assert (and (= dc_191 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_44 (ite (= ge_63 #b1) x10_neg_21 x10_43)))
(assert (= x7_26 (ite (= ge_63 #b1) x8_44 x7_25)))
(assert (and (= dc_192 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44)))) (= x8_45 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44))))))
(assert (= x3_43 (bvadd x3_42 #x0000000000000002)))
(assert (and (= dc_193 ((_ extract 63 2) x8_45)) (= x8_lo_22 ((_ extract 1 0) x8_45))))
(assert (and (= x8_target_20 ((_ extract 1 1) x8_lo_22)) (= dc_194 ((_ extract 0 0) x8_lo_22))))
(assert (= ne_22 (bvand x8_target_20 #b1)))
(assert (and (= x8_46 ((_ sign_extend 1) ((_ extract 63 1) x8_45))) (= dc_195 ((_ zero_extend 63) ((_ extract 0 0) x8_45)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_44) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_26 x7_25)) (= (bvmul x8_46 #x0000000000000002) x8_44)) (= x3_43 (bvadd #x0000000000000002 x3_41))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_44) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_41 #x0000000000000000)) (= x7_26 x7_25)) (= (bvmul x8_46 #x0000000000000002) (bvadd x8_44 x7_25))) (= x3_43 (bvadd #x0000000000000002 x3_41)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_44) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_41 #x0000000000000000)) (= x7_26 x8_44)) (= (bvmul x8_46 #x0000000000000002) (bvsub x8_44 x7_25))) (= x3_43 (bvsub #x0000000000000002 x3_41))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_b3d374.smt2
Execution time of boolector: 0.0165 seconds
OUTPUT FROM boolector:
unsat

=== Cut #6 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #6
; Range assertion #41: or [and [smod (sub (uext x8_46 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_27 = x7_26, mul x8_48 2@64 = x8_46, x3_45 = add 2@64 x3_43], and [smod (sub (uext x8_46 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_43 <s 0@64, x7_27 = x7_26, mul x8_48 2@64 = add x8_46 x7_26, x3_45 = add 2@64 x3_43], and [smod (sub (uext x8_46 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_43 >=s 0@64, x7_27 = x8_46, mul x8_48 2@64 = sub x8_46 x7_26, x3_45 = sub 2@64 x3_43]]
; Range condition: ((x8_46@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_27 = x7_26 /\ x8_48 * 2 = x8_46 /\ x3_45 = 2 + x3_43 \/ ((x8_46@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_43 <s 0 /\ x7_27 = x7_26 /\ x8_48 * 2 = x8_46 + x7_26 /\ x3_45 = 2 + x3_43 \/ ((x8_46@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_43 >=s 0 /\ x7_27 = x8_46 /\ x8_48 * 2 = x8_46 - x7_26 /\ x3_45 = 2 - x3_43
; Output file: /tmp/outputqfbv_e3fe37.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_21 () (_ BitVec 1))
(declare-fun x8_target_20 () (_ BitVec 1))
(declare-fun x8_lo_23 () (_ BitVec 2))
(declare-fun x8_lo_22 () (_ BitVec 2))
(declare-fun x8_lo_21 () (_ BitVec 1))
(declare-fun x8_48 () (_ BitVec 64))
(declare-fun x8_47 () (_ BitVec 64))
(declare-fun x8_46 () (_ BitVec 64))
(declare-fun x8_45 () (_ BitVec 64))
(declare-fun x8_44 () (_ BitVec 64))
(declare-fun x7_27 () (_ BitVec 64))
(declare-fun x7_26 () (_ BitVec 64))
(declare-fun x7_25 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_22 () (_ BitVec 64))
(declare-fun x3_neg_21 () (_ BitVec 64))
(declare-fun x3_45 () (_ BitVec 64))
(declare-fun x3_44 () (_ BitVec 64))
(declare-fun x3_43 () (_ BitVec 64))
(declare-fun x3_42 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x10_neg_22 () (_ BitVec 64))
(declare-fun x10_neg_21 () (_ BitVec 64))
(declare-fun x10_46 () (_ BitVec 64))
(declare-fun x10_45 () (_ BitVec 64))
(declare-fun x10_44 () (_ BitVec 64))
(declare-fun x10_43 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun ne_23 () (_ BitVec 1))
(declare-fun ne_22 () (_ BitVec 1))
(declare-fun ne_21 () (_ BitVec 1))
(declare-fun ge_66 () (_ BitVec 1))
(declare-fun ge_65 () (_ BitVec 1))
(declare-fun ge_64 () (_ BitVec 1))
(declare-fun ge_63 () (_ BitVec 1))
(declare-fun ge_62 () (_ BitVec 1))
(declare-fun ge_61 () (_ BitVec 1))
(declare-fun dc_202 () (_ BitVec 64))
(declare-fun dc_201 () (_ BitVec 1))
(declare-fun dc_200 () (_ BitVec 62))
(declare-fun dc_199 () (_ BitVec 1))
(declare-fun dc_198 () (_ BitVec 1))
(declare-fun dc_197 () (_ BitVec 1))
(declare-fun dc_196 () (_ BitVec 63))
(declare-fun dc_195 () (_ BitVec 64))
(declare-fun dc_194 () (_ BitVec 1))
(declare-fun dc_193 () (_ BitVec 62))
(declare-fun dc_192 () (_ BitVec 1))
(declare-fun dc_191 () (_ BitVec 1))
(declare-fun dc_190 () (_ BitVec 1))
(declare-fun dc_189 () (_ BitVec 63))
(declare-fun dc_188 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_25 (bvadd (bvadd neg_f_0_low60_20_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_44 (bvadd (bvadd neg_g_0_low60_20_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_0_1)) (bvsle neg_f_0_low60_20_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_0_1)) (bvsle neg_g_0_low60_20_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_25) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_188 ((_ extract 63 1) x8_44)) (= x8_lo_21 ((_ extract 0 0) x8_44))))
(assert (= ne_21 (bvand x8_lo_21 #b1)))
(assert (= x10_43 (ite (= ne_21 #b1) x7_25 #x0000000000000000)))
(assert (and (= ge_61 ((_ extract 63 63) x3_41)) (= dc_189 ((_ extract 62 0) x3_41))))
(assert (= ge_62 (bvnot ge_61)))
(assert (= ge_63 (ite (= ne_21 #b1) ge_62 #b0)))
(assert (and (= dc_190 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_42 (ite (= ge_63 #b1) x3_neg_21 x3_41)))
(assert (and (= dc_191 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_44 (ite (= ge_63 #b1) x10_neg_21 x10_43)))
(assert (= x7_26 (ite (= ge_63 #b1) x8_44 x7_25)))
(assert (and (= dc_192 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44)))) (= x8_45 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44))))))
(assert (= x3_43 (bvadd x3_42 #x0000000000000002)))
(assert (and (= dc_193 ((_ extract 63 2) x8_45)) (= x8_lo_22 ((_ extract 1 0) x8_45))))
(assert (and (= x8_target_20 ((_ extract 1 1) x8_lo_22)) (= dc_194 ((_ extract 0 0) x8_lo_22))))
(assert (= ne_22 (bvand x8_target_20 #b1)))
(assert (and (= x8_46 ((_ sign_extend 1) ((_ extract 63 1) x8_45))) (= dc_195 ((_ zero_extend 63) ((_ extract 0 0) x8_45)))))
(assert true)
(assert (= x10_45 (ite (= ne_22 #b1) x7_26 #x0000000000000000)))
(assert (and (= ge_64 ((_ extract 63 63) x3_43)) (= dc_196 ((_ extract 62 0) x3_43))))
(assert (= ge_65 (bvnot ge_64)))
(assert (= ge_66 (ite (= ne_22 #b1) ge_65 #b0)))
(assert (and (= dc_197 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_44 (ite (= ge_66 #b1) x3_neg_22 x3_43)))
(assert (and (= dc_198 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_46 (ite (= ge_66 #b1) x10_neg_22 x10_45)))
(assert (= x7_27 (ite (= ge_66 #b1) x8_46 x7_26)))
(assert (and (= dc_199 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46)))) (= x8_47 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46))))))
(assert (= x3_45 (bvadd x3_44 #x0000000000000002)))
(assert (and (= dc_200 ((_ extract 63 2) x8_47)) (= x8_lo_23 ((_ extract 1 0) x8_47))))
(assert (and (= x8_target_21 ((_ extract 1 1) x8_lo_23)) (= dc_201 ((_ extract 0 0) x8_lo_23))))
(assert (= ne_23 (bvand x8_target_21 #b1)))
(assert (and (= x8_48 ((_ sign_extend 1) ((_ extract 63 1) x8_47))) (= dc_202 ((_ zero_extend 63) ((_ extract 0 0) x8_47)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_46) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_27 x7_26)) (= (bvmul x8_48 #x0000000000000002) x8_46)) (= x3_45 (bvadd #x0000000000000002 x3_43))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_46) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_43 #x0000000000000000)) (= x7_27 x7_26)) (= (bvmul x8_48 #x0000000000000002) (bvadd x8_46 x7_26))) (= x3_45 (bvadd #x0000000000000002 x3_43)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_46) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_43 #x0000000000000000)) (= x7_27 x8_46)) (= (bvmul x8_48 #x0000000000000002) (bvsub x8_46 x7_26))) (= x3_45 (bvsub #x0000000000000002 x3_43))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_920d69.smt2
Execution time of boolector: 0.0722 seconds
OUTPUT FROM boolector:
unsat

=== Cut #2 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #2
; Range assertion #31: or [and [smod (sub (uext x8_40 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_23 = x7_22, mul x8_42 2@64 = x8_40, x3_41 = add 2@64 x3_39], and [smod (sub (uext x8_40 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_39 <s 0@64, x7_23 = x7_22, mul x8_42 2@64 = add x8_40 x7_22, x3_41 = add 2@64 x3_39], and [smod (sub (uext x8_40 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_39 >=s 0@64, x7_23 = x8_40, mul x8_42 2@64 = sub x8_40 x7_22, x3_41 = sub 2@64 x3_39]]
; Range condition: ((x8_40@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_23 = x7_22 /\ x8_42 * 2 = x8_40 /\ x3_41 = 2 + x3_39 \/ ((x8_40@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_39 <s 0 /\ x7_23 = x7_22 /\ x8_42 * 2 = x8_40 + x7_22 /\ x3_41 = 2 + x3_39 \/ ((x8_40@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_39 >=s 0 /\ x7_23 = x8_40 /\ x8_42 * 2 = x8_40 - x7_22 /\ x3_41 = 2 - x3_39
; Output file: /tmp/outputqfbv_abd08d.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_19 () (_ BitVec 1))
(declare-fun x8_target_18 () (_ BitVec 1))
(declare-fun x8_target_17 () (_ BitVec 1))
(declare-fun x8_target_16 () (_ BitVec 1))
(declare-fun x8_target_15 () (_ BitVec 1))
(declare-fun x8_target_14 () (_ BitVec 1))
(declare-fun x8_target_13 () (_ BitVec 1))
(declare-fun x8_target_12 () (_ BitVec 1))
(declare-fun x8_target_11 () (_ BitVec 1))
(declare-fun x8_target_10 () (_ BitVec 1))
(declare-fun x8_target_9 () (_ BitVec 1))
(declare-fun x8_target_8 () (_ BitVec 1))
(declare-fun x8_target_7 () (_ BitVec 1))
(declare-fun x8_target_6 () (_ BitVec 1))
(declare-fun x8_target_5 () (_ BitVec 1))
(declare-fun x8_target_4 () (_ BitVec 1))
(declare-fun x8_target_3 () (_ BitVec 1))
(declare-fun x8_target_2 () (_ BitVec 1))
(declare-fun x8_target_1 () (_ BitVec 1))
(declare-fun x8_lo_20 () (_ BitVec 2))
(declare-fun x8_lo_19 () (_ BitVec 2))
(declare-fun x8_lo_18 () (_ BitVec 2))
(declare-fun x8_lo_17 () (_ BitVec 2))
(declare-fun x8_lo_16 () (_ BitVec 2))
(declare-fun x8_lo_15 () (_ BitVec 2))
(declare-fun x8_lo_14 () (_ BitVec 2))
(declare-fun x8_lo_13 () (_ BitVec 2))
(declare-fun x8_lo_12 () (_ BitVec 2))
(declare-fun x8_lo_11 () (_ BitVec 2))
(declare-fun x8_lo_10 () (_ BitVec 2))
(declare-fun x8_lo_9 () (_ BitVec 2))
(declare-fun x8_lo_8 () (_ BitVec 2))
(declare-fun x8_lo_7 () (_ BitVec 2))
(declare-fun x8_lo_6 () (_ BitVec 2))
(declare-fun x8_lo_5 () (_ BitVec 2))
(declare-fun x8_lo_4 () (_ BitVec 2))
(declare-fun x8_lo_3 () (_ BitVec 2))
(declare-fun x8_lo_2 () (_ BitVec 2))
(declare-fun x8_lo_1 () (_ BitVec 1))
(declare-fun x8_42 () (_ BitVec 64))
(declare-fun x8_41 () (_ BitVec 64))
(declare-fun x8_40 () (_ BitVec 64))
(declare-fun x8_39 () (_ BitVec 64))
(declare-fun x8_38 () (_ BitVec 64))
(declare-fun x8_37 () (_ BitVec 64))
(declare-fun x8_36 () (_ BitVec 64))
(declare-fun x8_35 () (_ BitVec 64))
(declare-fun x8_34 () (_ BitVec 64))
(declare-fun x8_33 () (_ BitVec 64))
(declare-fun x8_32 () (_ BitVec 64))
(declare-fun x8_31 () (_ BitVec 64))
(declare-fun x8_30 () (_ BitVec 64))
(declare-fun x8_29 () (_ BitVec 64))
(declare-fun x8_28 () (_ BitVec 64))
(declare-fun x8_27 () (_ BitVec 64))
(declare-fun x8_26 () (_ BitVec 64))
(declare-fun x8_25 () (_ BitVec 64))
(declare-fun x8_24 () (_ BitVec 64))
(declare-fun x8_23 () (_ BitVec 64))
(declare-fun x8_22 () (_ BitVec 64))
(declare-fun x8_21 () (_ BitVec 64))
(declare-fun x8_20 () (_ BitVec 64))
(declare-fun x8_19 () (_ BitVec 64))
(declare-fun x8_18 () (_ BitVec 64))
(declare-fun x8_17 () (_ BitVec 64))
(declare-fun x8_16 () (_ BitVec 64))
(declare-fun x8_15 () (_ BitVec 64))
(declare-fun x8_14 () (_ BitVec 64))
(declare-fun x8_13 () (_ BitVec 64))
(declare-fun x8_12 () (_ BitVec 64))
(declare-fun x8_11 () (_ BitVec 64))
(declare-fun x8_10 () (_ BitVec 64))
(declare-fun x8_9 () (_ BitVec 64))
(declare-fun x8_8 () (_ BitVec 64))
(declare-fun x8_7 () (_ BitVec 64))
(declare-fun x8_6 () (_ BitVec 64))
(declare-fun x8_5 () (_ BitVec 64))
(declare-fun x8_4 () (_ BitVec 64))
(declare-fun x8_3 () (_ BitVec 64))
(declare-fun x8_2 () (_ BitVec 64))
(declare-fun x7_23 () (_ BitVec 64))
(declare-fun x7_22 () (_ BitVec 64))
(declare-fun x7_21 () (_ BitVec 64))
(declare-fun x7_20 () (_ BitVec 64))
(declare-fun x7_19 () (_ BitVec 64))
(declare-fun x7_18 () (_ BitVec 64))
(declare-fun x7_17 () (_ BitVec 64))
(declare-fun x7_16 () (_ BitVec 64))
(declare-fun x7_15 () (_ BitVec 64))
(declare-fun x7_14 () (_ BitVec 64))
(declare-fun x7_13 () (_ BitVec 64))
(declare-fun x7_12 () (_ BitVec 64))
(declare-fun x7_11 () (_ BitVec 64))
(declare-fun x7_10 () (_ BitVec 64))
(declare-fun x7_9 () (_ BitVec 64))
(declare-fun x7_8 () (_ BitVec 64))
(declare-fun x7_7 () (_ BitVec 64))
(declare-fun x7_6 () (_ BitVec 64))
(declare-fun x7_5 () (_ BitVec 64))
(declare-fun x7_4 () (_ BitVec 64))
(declare-fun x7_3 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_20 () (_ BitVec 64))
(declare-fun x3_neg_19 () (_ BitVec 64))
(declare-fun x3_neg_18 () (_ BitVec 64))
(declare-fun x3_neg_17 () (_ BitVec 64))
(declare-fun x3_neg_16 () (_ BitVec 64))
(declare-fun x3_neg_15 () (_ BitVec 64))
(declare-fun x3_neg_14 () (_ BitVec 64))
(declare-fun x3_neg_13 () (_ BitVec 64))
(declare-fun x3_neg_12 () (_ BitVec 64))
(declare-fun x3_neg_11 () (_ BitVec 64))
(declare-fun x3_neg_10 () (_ BitVec 64))
(declare-fun x3_neg_9 () (_ BitVec 64))
(declare-fun x3_neg_8 () (_ BitVec 64))
(declare-fun x3_neg_7 () (_ BitVec 64))
(declare-fun x3_neg_6 () (_ BitVec 64))
(declare-fun x3_neg_5 () (_ BitVec 64))
(declare-fun x3_neg_4 () (_ BitVec 64))
(declare-fun x3_neg_3 () (_ BitVec 64))
(declare-fun x3_neg_2 () (_ BitVec 64))
(declare-fun x3_neg_1 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x3_40 () (_ BitVec 64))
(declare-fun x3_39 () (_ BitVec 64))
(declare-fun x3_38 () (_ BitVec 64))
(declare-fun x3_37 () (_ BitVec 64))
(declare-fun x3_36 () (_ BitVec 64))
(declare-fun x3_35 () (_ BitVec 64))
(declare-fun x3_34 () (_ BitVec 64))
(declare-fun x3_33 () (_ BitVec 64))
(declare-fun x3_32 () (_ BitVec 64))
(declare-fun x3_31 () (_ BitVec 64))
(declare-fun x3_30 () (_ BitVec 64))
(declare-fun x3_29 () (_ BitVec 64))
(declare-fun x3_28 () (_ BitVec 64))
(declare-fun x3_27 () (_ BitVec 64))
(declare-fun x3_26 () (_ BitVec 64))
(declare-fun x3_25 () (_ BitVec 64))
(declare-fun x3_24 () (_ BitVec 64))
(declare-fun x3_23 () (_ BitVec 64))
(declare-fun x3_22 () (_ BitVec 64))
(declare-fun x3_21 () (_ BitVec 64))
(declare-fun x3_20 () (_ BitVec 64))
(declare-fun x3_19 () (_ BitVec 64))
(declare-fun x3_18 () (_ BitVec 64))
(declare-fun x3_17 () (_ BitVec 64))
(declare-fun x3_16 () (_ BitVec 64))
(declare-fun x3_15 () (_ BitVec 64))
(declare-fun x3_14 () (_ BitVec 64))
(declare-fun x3_13 () (_ BitVec 64))
(declare-fun x3_12 () (_ BitVec 64))
(declare-fun x3_11 () (_ BitVec 64))
(declare-fun x3_10 () (_ BitVec 64))
(declare-fun x3_9 () (_ BitVec 64))
(declare-fun x3_8 () (_ BitVec 64))
(declare-fun x3_7 () (_ BitVec 64))
(declare-fun x3_6 () (_ BitVec 64))
(declare-fun x3_5 () (_ BitVec 64))
(declare-fun x3_4 () (_ BitVec 64))
(declare-fun x3_3 () (_ BitVec 64))
(declare-fun x3_2 () (_ BitVec 64))
(declare-fun x10_neg_20 () (_ BitVec 64))
(declare-fun x10_neg_19 () (_ BitVec 64))
(declare-fun x10_neg_18 () (_ BitVec 64))
(declare-fun x10_neg_17 () (_ BitVec 64))
(declare-fun x10_neg_16 () (_ BitVec 64))
(declare-fun x10_neg_15 () (_ BitVec 64))
(declare-fun x10_neg_14 () (_ BitVec 64))
(declare-fun x10_neg_13 () (_ BitVec 64))
(declare-fun x10_neg_12 () (_ BitVec 64))
(declare-fun x10_neg_11 () (_ BitVec 64))
(declare-fun x10_neg_10 () (_ BitVec 64))
(declare-fun x10_neg_9 () (_ BitVec 64))
(declare-fun x10_neg_8 () (_ BitVec 64))
(declare-fun x10_neg_7 () (_ BitVec 64))
(declare-fun x10_neg_6 () (_ BitVec 64))
(declare-fun x10_neg_5 () (_ BitVec 64))
(declare-fun x10_neg_4 () (_ BitVec 64))
(declare-fun x10_neg_3 () (_ BitVec 64))
(declare-fun x10_neg_2 () (_ BitVec 64))
(declare-fun x10_neg_1 () (_ BitVec 64))
(declare-fun x10_40 () (_ BitVec 64))
(declare-fun x10_39 () (_ BitVec 64))
(declare-fun x10_38 () (_ BitVec 64))
(declare-fun x10_37 () (_ BitVec 64))
(declare-fun x10_36 () (_ BitVec 64))
(declare-fun x10_35 () (_ BitVec 64))
(declare-fun x10_34 () (_ BitVec 64))
(declare-fun x10_33 () (_ BitVec 64))
(declare-fun x10_32 () (_ BitVec 64))
(declare-fun x10_31 () (_ BitVec 64))
(declare-fun x10_30 () (_ BitVec 64))
(declare-fun x10_29 () (_ BitVec 64))
(declare-fun x10_28 () (_ BitVec 64))
(declare-fun x10_27 () (_ BitVec 64))
(declare-fun x10_26 () (_ BitVec 64))
(declare-fun x10_25 () (_ BitVec 64))
(declare-fun x10_24 () (_ BitVec 64))
(declare-fun x10_23 () (_ BitVec 64))
(declare-fun x10_22 () (_ BitVec 64))
(declare-fun x10_21 () (_ BitVec 64))
(declare-fun x10_20 () (_ BitVec 64))
(declare-fun x10_19 () (_ BitVec 64))
(declare-fun x10_18 () (_ BitVec 64))
(declare-fun x10_17 () (_ BitVec 64))
(declare-fun x10_16 () (_ BitVec 64))
(declare-fun x10_15 () (_ BitVec 64))
(declare-fun x10_14 () (_ BitVec 64))
(declare-fun x10_13 () (_ BitVec 64))
(declare-fun x10_12 () (_ BitVec 64))
(declare-fun x10_11 () (_ BitVec 64))
(declare-fun x10_10 () (_ BitVec 64))
(declare-fun x10_9 () (_ BitVec 64))
(declare-fun x10_8 () (_ BitVec 64))
(declare-fun x10_7 () (_ BitVec 64))
(declare-fun x10_6 () (_ BitVec 64))
(declare-fun x10_5 () (_ BitVec 64))
(declare-fun x10_4 () (_ BitVec 64))
(declare-fun x10_3 () (_ BitVec 64))
(declare-fun x10_2 () (_ BitVec 64))
(declare-fun x10_1 () (_ BitVec 64))
(declare-fun ne_20 () (_ BitVec 1))
(declare-fun ne_19 () (_ BitVec 1))
(declare-fun ne_18 () (_ BitVec 1))
(declare-fun ne_17 () (_ BitVec 1))
(declare-fun ne_16 () (_ BitVec 1))
(declare-fun ne_15 () (_ BitVec 1))
(declare-fun ne_14 () (_ BitVec 1))
(declare-fun ne_13 () (_ BitVec 1))
(declare-fun ne_12 () (_ BitVec 1))
(declare-fun ne_11 () (_ BitVec 1))
(declare-fun ne_10 () (_ BitVec 1))
(declare-fun ne_9 () (_ BitVec 1))
(declare-fun ne_8 () (_ BitVec 1))
(declare-fun ne_7 () (_ BitVec 1))
(declare-fun ne_6 () (_ BitVec 1))
(declare-fun ne_5 () (_ BitVec 1))
(declare-fun ne_4 () (_ BitVec 1))
(declare-fun ne_3 () (_ BitVec 1))
(declare-fun ne_2 () (_ BitVec 1))
(declare-fun ne_1 () (_ BitVec 1))
(declare-fun ge_60 () (_ BitVec 1))
(declare-fun ge_59 () (_ BitVec 1))
(declare-fun ge_58 () (_ BitVec 1))
(declare-fun ge_57 () (_ BitVec 1))
(declare-fun ge_56 () (_ BitVec 1))
(declare-fun ge_55 () (_ BitVec 1))
(declare-fun ge_54 () (_ BitVec 1))
(declare-fun ge_53 () (_ BitVec 1))
(declare-fun ge_52 () (_ BitVec 1))
(declare-fun ge_51 () (_ BitVec 1))
(declare-fun ge_50 () (_ BitVec 1))
(declare-fun ge_49 () (_ BitVec 1))
(declare-fun ge_48 () (_ BitVec 1))
(declare-fun ge_47 () (_ BitVec 1))
(declare-fun ge_46 () (_ BitVec 1))
(declare-fun ge_45 () (_ BitVec 1))
(declare-fun ge_44 () (_ BitVec 1))
(declare-fun ge_43 () (_ BitVec 1))
(declare-fun ge_42 () (_ BitVec 1))
(declare-fun ge_41 () (_ BitVec 1))
(declare-fun ge_40 () (_ BitVec 1))
(declare-fun ge_39 () (_ BitVec 1))
(declare-fun ge_38 () (_ BitVec 1))
(declare-fun ge_37 () (_ BitVec 1))
(declare-fun ge_36 () (_ BitVec 1))
(declare-fun ge_35 () (_ BitVec 1))
(declare-fun ge_34 () (_ BitVec 1))
(declare-fun ge_33 () (_ BitVec 1))
(declare-fun ge_32 () (_ BitVec 1))
(declare-fun ge_31 () (_ BitVec 1))
(declare-fun ge_30 () (_ BitVec 1))
(declare-fun ge_29 () (_ BitVec 1))
(declare-fun ge_28 () (_ BitVec 1))
(declare-fun ge_27 () (_ BitVec 1))
(declare-fun ge_26 () (_ BitVec 1))
(declare-fun ge_25 () (_ BitVec 1))
(declare-fun ge_24 () (_ BitVec 1))
(declare-fun ge_23 () (_ BitVec 1))
(declare-fun ge_22 () (_ BitVec 1))
(declare-fun ge_21 () (_ BitVec 1))
(declare-fun ge_20 () (_ BitVec 1))
(declare-fun ge_19 () (_ BitVec 1))
(declare-fun ge_18 () (_ BitVec 1))
(declare-fun ge_17 () (_ BitVec 1))
(declare-fun ge_16 () (_ BitVec 1))
(declare-fun ge_15 () (_ BitVec 1))
(declare-fun ge_14 () (_ BitVec 1))
(declare-fun ge_13 () (_ BitVec 1))
(declare-fun ge_12 () (_ BitVec 1))
(declare-fun ge_11 () (_ BitVec 1))
(declare-fun ge_10 () (_ BitVec 1))
(declare-fun ge_9 () (_ BitVec 1))
(declare-fun ge_8 () (_ BitVec 1))
(declare-fun ge_7 () (_ BitVec 1))
(declare-fun ge_6 () (_ BitVec 1))
(declare-fun ge_5 () (_ BitVec 1))
(declare-fun ge_4 () (_ BitVec 1))
(declare-fun ge_3 () (_ BitVec 1))
(declare-fun ge_2 () (_ BitVec 1))
(declare-fun ge_1 () (_ BitVec 1))
(declare-fun g_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun dc_179 () (_ BitVec 64))
(declare-fun dc_178 () (_ BitVec 1))
(declare-fun dc_177 () (_ BitVec 1))
(declare-fun dc_176 () (_ BitVec 1))
(declare-fun dc_175 () (_ BitVec 63))
(declare-fun dc_174 () (_ BitVec 64))
(declare-fun dc_173 () (_ BitVec 1))
(declare-fun dc_172 () (_ BitVec 62))
(declare-fun dc_171 () (_ BitVec 1))
(declare-fun dc_170 () (_ BitVec 1))
(declare-fun dc_169 () (_ BitVec 1))
(declare-fun dc_168 () (_ BitVec 63))
(declare-fun dc_167 () (_ BitVec 64))
(declare-fun dc_166 () (_ BitVec 1))
(declare-fun dc_165 () (_ BitVec 62))
(declare-fun dc_164 () (_ BitVec 1))
(declare-fun dc_163 () (_ BitVec 1))
(declare-fun dc_162 () (_ BitVec 1))
(declare-fun dc_161 () (_ BitVec 63))
(declare-fun dc_160 () (_ BitVec 64))
(declare-fun dc_159 () (_ BitVec 1))
(declare-fun dc_158 () (_ BitVec 62))
(declare-fun dc_157 () (_ BitVec 1))
(declare-fun dc_156 () (_ BitVec 1))
(declare-fun dc_155 () (_ BitVec 1))
(declare-fun dc_154 () (_ BitVec 63))
(declare-fun dc_153 () (_ BitVec 64))
(declare-fun dc_152 () (_ BitVec 1))
(declare-fun dc_151 () (_ BitVec 62))
(declare-fun dc_150 () (_ BitVec 1))
(declare-fun dc_149 () (_ BitVec 1))
(declare-fun dc_148 () (_ BitVec 1))
(declare-fun dc_147 () (_ BitVec 63))
(declare-fun dc_146 () (_ BitVec 64))
(declare-fun dc_145 () (_ BitVec 1))
(declare-fun dc_144 () (_ BitVec 62))
(declare-fun dc_143 () (_ BitVec 1))
(declare-fun dc_142 () (_ BitVec 1))
(declare-fun dc_141 () (_ BitVec 1))
(declare-fun dc_140 () (_ BitVec 63))
(declare-fun dc_139 () (_ BitVec 64))
(declare-fun dc_138 () (_ BitVec 1))
(declare-fun dc_137 () (_ BitVec 62))
(declare-fun dc_136 () (_ BitVec 1))
(declare-fun dc_135 () (_ BitVec 1))
(declare-fun dc_134 () (_ BitVec 1))
(declare-fun dc_133 () (_ BitVec 63))
(declare-fun dc_132 () (_ BitVec 64))
(declare-fun dc_131 () (_ BitVec 1))
(declare-fun dc_130 () (_ BitVec 62))
(declare-fun dc_129 () (_ BitVec 1))
(declare-fun dc_128 () (_ BitVec 1))
(declare-fun dc_127 () (_ BitVec 1))
(declare-fun dc_126 () (_ BitVec 63))
(declare-fun dc_125 () (_ BitVec 64))
(declare-fun dc_124 () (_ BitVec 1))
(declare-fun dc_123 () (_ BitVec 62))
(declare-fun dc_122 () (_ BitVec 1))
(declare-fun dc_121 () (_ BitVec 1))
(declare-fun dc_120 () (_ BitVec 1))
(declare-fun dc_119 () (_ BitVec 63))
(declare-fun dc_118 () (_ BitVec 64))
(declare-fun dc_117 () (_ BitVec 1))
(declare-fun dc_116 () (_ BitVec 62))
(declare-fun dc_115 () (_ BitVec 1))
(declare-fun dc_114 () (_ BitVec 1))
(declare-fun dc_113 () (_ BitVec 1))
(declare-fun dc_112 () (_ BitVec 63))
(declare-fun dc_111 () (_ BitVec 64))
(declare-fun dc_110 () (_ BitVec 1))
(declare-fun dc_109 () (_ BitVec 62))
(declare-fun dc_108 () (_ BitVec 1))
(declare-fun dc_107 () (_ BitVec 1))
(declare-fun dc_106 () (_ BitVec 1))
(declare-fun dc_105 () (_ BitVec 63))
(declare-fun dc_104 () (_ BitVec 64))
(declare-fun dc_103 () (_ BitVec 1))
(declare-fun dc_102 () (_ BitVec 62))
(declare-fun dc_101 () (_ BitVec 1))
(declare-fun dc_100 () (_ BitVec 1))
(declare-fun dc_99 () (_ BitVec 1))
(declare-fun dc_98 () (_ BitVec 63))
(declare-fun dc_97 () (_ BitVec 64))
(declare-fun dc_96 () (_ BitVec 1))
(declare-fun dc_95 () (_ BitVec 62))
(declare-fun dc_94 () (_ BitVec 1))
(declare-fun dc_93 () (_ BitVec 1))
(declare-fun dc_92 () (_ BitVec 1))
(declare-fun dc_91 () (_ BitVec 63))
(declare-fun dc_90 () (_ BitVec 64))
(declare-fun dc_89 () (_ BitVec 1))
(declare-fun dc_88 () (_ BitVec 62))
(declare-fun dc_87 () (_ BitVec 1))
(declare-fun dc_86 () (_ BitVec 1))
(declare-fun dc_85 () (_ BitVec 1))
(declare-fun dc_84 () (_ BitVec 63))
(declare-fun dc_83 () (_ BitVec 64))
(declare-fun dc_82 () (_ BitVec 1))
(declare-fun dc_81 () (_ BitVec 62))
(declare-fun dc_80 () (_ BitVec 1))
(declare-fun dc_79 () (_ BitVec 1))
(declare-fun dc_78 () (_ BitVec 1))
(declare-fun dc_77 () (_ BitVec 63))
(declare-fun dc_76 () (_ BitVec 64))
(declare-fun dc_75 () (_ BitVec 1))
(declare-fun dc_74 () (_ BitVec 62))
(declare-fun dc_73 () (_ BitVec 1))
(declare-fun dc_72 () (_ BitVec 1))
(declare-fun dc_71 () (_ BitVec 1))
(declare-fun dc_70 () (_ BitVec 63))
(declare-fun dc_69 () (_ BitVec 64))
(declare-fun dc_68 () (_ BitVec 1))
(declare-fun dc_67 () (_ BitVec 62))
(declare-fun dc_66 () (_ BitVec 1))
(declare-fun dc_65 () (_ BitVec 1))
(declare-fun dc_64 () (_ BitVec 1))
(declare-fun dc_63 () (_ BitVec 63))
(declare-fun dc_62 () (_ BitVec 64))
(declare-fun dc_61 () (_ BitVec 1))
(declare-fun dc_60 () (_ BitVec 62))
(declare-fun dc_59 () (_ BitVec 1))
(declare-fun dc_58 () (_ BitVec 1))
(declare-fun dc_57 () (_ BitVec 1))
(declare-fun dc_56 () (_ BitVec 63))
(declare-fun dc_55 () (_ BitVec 64))
(declare-fun dc_54 () (_ BitVec 1))
(declare-fun dc_53 () (_ BitVec 62))
(declare-fun dc_52 () (_ BitVec 1))
(declare-fun dc_51 () (_ BitVec 1))
(declare-fun dc_50 () (_ BitVec 1))
(declare-fun dc_49 () (_ BitVec 63))
(declare-fun dc_48 () (_ BitVec 64))
(declare-fun dc_47 () (_ BitVec 1))
(declare-fun dc_46 () (_ BitVec 62))
(declare-fun dc_45 () (_ BitVec 1))
(declare-fun dc_44 () (_ BitVec 1))
(declare-fun dc_43 () (_ BitVec 1))
(declare-fun dc_42 () (_ BitVec 63))
(declare-fun dc_41 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (= x7_3 (bvadd (bvadd f_0_low60_0_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_2 (bvadd (bvadd g_0_low60_0_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_0_1)) (bvsle f_0_low60_0_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_0_1)) (bvsle g_0_low60_0_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_3) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #x0000000000000001 #x0000000000000001)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_41 ((_ extract 63 1) x8_2)) (= x8_lo_1 ((_ extract 0 0) x8_2))))
(assert (= ne_1 (bvand x8_lo_1 #b1)))
(assert (= x10_1 (ite (= ne_1 #b1) x7_3 #x0000000000000000)))
(assert (and (= ge_1 ((_ extract 63 63) #x0000000000000001)) (= dc_42 ((_ extract 62 0) #x0000000000000001))))
(assert (= ge_2 (bvnot ge_1)))
(assert (= ge_3 (ite (= ne_1 #b1) ge_2 #b0)))
(assert (and (= dc_43 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_2 (ite (= ge_3 #b1) x3_neg_1 #x0000000000000001)))
(assert (and (= dc_44 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_2 (ite (= ge_3 #b1) x10_neg_1 x10_1)))
(assert (= x7_4 (ite (= ge_3 #b1) x8_2 x7_3)))
(assert (and (= dc_45 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2)))) (= x8_3 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2))))))
(assert (= x3_3 (bvadd x3_2 #x0000000000000002)))
(assert (and (= dc_46 ((_ extract 63 2) x8_3)) (= x8_lo_2 ((_ extract 1 0) x8_3))))
(assert (and (= x8_target_1 ((_ extract 1 1) x8_lo_2)) (= dc_47 ((_ extract 0 0) x8_lo_2))))
(assert (= ne_2 (bvand x8_target_1 #b1)))
(assert (and (= x8_4 ((_ sign_extend 1) ((_ extract 63 1) x8_3))) (= dc_48 ((_ zero_extend 63) ((_ extract 0 0) x8_3)))))
(assert true)
(assert (= x10_3 (ite (= ne_2 #b1) x7_4 #x0000000000000000)))
(assert (and (= ge_4 ((_ extract 63 63) x3_3)) (= dc_49 ((_ extract 62 0) x3_3))))
(assert (= ge_5 (bvnot ge_4)))
(assert (= ge_6 (ite (= ne_2 #b1) ge_5 #b0)))
(assert (and (= dc_50 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_4 (ite (= ge_6 #b1) x3_neg_2 x3_3)))
(assert (and (= dc_51 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_4 (ite (= ge_6 #b1) x10_neg_2 x10_3)))
(assert (= x7_5 (ite (= ge_6 #b1) x8_4 x7_4)))
(assert (and (= dc_52 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4)))) (= x8_5 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4))))))
(assert (= x3_5 (bvadd x3_4 #x0000000000000002)))
(assert (and (= dc_53 ((_ extract 63 2) x8_5)) (= x8_lo_3 ((_ extract 1 0) x8_5))))
(assert (and (= x8_target_2 ((_ extract 1 1) x8_lo_3)) (= dc_54 ((_ extract 0 0) x8_lo_3))))
(assert (= ne_3 (bvand x8_target_2 #b1)))
(assert (and (= x8_6 ((_ sign_extend 1) ((_ extract 63 1) x8_5))) (= dc_55 ((_ zero_extend 63) ((_ extract 0 0) x8_5)))))
(assert true)
(assert (= x10_5 (ite (= ne_3 #b1) x7_5 #x0000000000000000)))
(assert (and (= ge_7 ((_ extract 63 63) x3_5)) (= dc_56 ((_ extract 62 0) x3_5))))
(assert (= ge_8 (bvnot ge_7)))
(assert (= ge_9 (ite (= ne_3 #b1) ge_8 #b0)))
(assert (and (= dc_57 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_6 (ite (= ge_9 #b1) x3_neg_3 x3_5)))
(assert (and (= dc_58 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_6 (ite (= ge_9 #b1) x10_neg_3 x10_5)))
(assert (= x7_6 (ite (= ge_9 #b1) x8_6 x7_5)))
(assert (and (= dc_59 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6)))) (= x8_7 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6))))))
(assert (= x3_7 (bvadd x3_6 #x0000000000000002)))
(assert (and (= dc_60 ((_ extract 63 2) x8_7)) (= x8_lo_4 ((_ extract 1 0) x8_7))))
(assert (and (= x8_target_3 ((_ extract 1 1) x8_lo_4)) (= dc_61 ((_ extract 0 0) x8_lo_4))))
(assert (= ne_4 (bvand x8_target_3 #b1)))
(assert (and (= x8_8 ((_ sign_extend 1) ((_ extract 63 1) x8_7))) (= dc_62 ((_ zero_extend 63) ((_ extract 0 0) x8_7)))))
(assert true)
(assert (= x10_7 (ite (= ne_4 #b1) x7_6 #x0000000000000000)))
(assert (and (= ge_10 ((_ extract 63 63) x3_7)) (= dc_63 ((_ extract 62 0) x3_7))))
(assert (= ge_11 (bvnot ge_10)))
(assert (= ge_12 (ite (= ne_4 #b1) ge_11 #b0)))
(assert (and (= dc_64 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_7))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_4 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_7))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_8 (ite (= ge_12 #b1) x3_neg_4 x3_7)))
(assert (and (= dc_65 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_7))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_4 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_7))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_8 (ite (= ge_12 #b1) x10_neg_4 x10_7)))
(assert (= x7_7 (ite (= ge_12 #b1) x8_8 x7_6)))
(assert (and (= dc_66 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_8) ((_ zero_extend 1) x10_8)))) (= x8_9 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_8) ((_ zero_extend 1) x10_8))))))
(assert (= x3_9 (bvadd x3_8 #x0000000000000002)))
(assert (and (= dc_67 ((_ extract 63 2) x8_9)) (= x8_lo_5 ((_ extract 1 0) x8_9))))
(assert (and (= x8_target_4 ((_ extract 1 1) x8_lo_5)) (= dc_68 ((_ extract 0 0) x8_lo_5))))
(assert (= ne_5 (bvand x8_target_4 #b1)))
(assert (and (= x8_10 ((_ sign_extend 1) ((_ extract 63 1) x8_9))) (= dc_69 ((_ zero_extend 63) ((_ extract 0 0) x8_9)))))
(assert true)
(assert (= x10_9 (ite (= ne_5 #b1) x7_7 #x0000000000000000)))
(assert (and (= ge_13 ((_ extract 63 63) x3_9)) (= dc_70 ((_ extract 62 0) x3_9))))
(assert (= ge_14 (bvnot ge_13)))
(assert (= ge_15 (ite (= ne_5 #b1) ge_14 #b0)))
(assert (and (= dc_71 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_9))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_5 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_9))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_10 (ite (= ge_15 #b1) x3_neg_5 x3_9)))
(assert (and (= dc_72 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_9))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_5 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_9))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_10 (ite (= ge_15 #b1) x10_neg_5 x10_9)))
(assert (= x7_8 (ite (= ge_15 #b1) x8_10 x7_7)))
(assert (and (= dc_73 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_10) ((_ zero_extend 1) x10_10)))) (= x8_11 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_10) ((_ zero_extend 1) x10_10))))))
(assert (= x3_11 (bvadd x3_10 #x0000000000000002)))
(assert (and (= dc_74 ((_ extract 63 2) x8_11)) (= x8_lo_6 ((_ extract 1 0) x8_11))))
(assert (and (= x8_target_5 ((_ extract 1 1) x8_lo_6)) (= dc_75 ((_ extract 0 0) x8_lo_6))))
(assert (= ne_6 (bvand x8_target_5 #b1)))
(assert (and (= x8_12 ((_ sign_extend 1) ((_ extract 63 1) x8_11))) (= dc_76 ((_ zero_extend 63) ((_ extract 0 0) x8_11)))))
(assert true)
(assert (= x10_11 (ite (= ne_6 #b1) x7_8 #x0000000000000000)))
(assert (and (= ge_16 ((_ extract 63 63) x3_11)) (= dc_77 ((_ extract 62 0) x3_11))))
(assert (= ge_17 (bvnot ge_16)))
(assert (= ge_18 (ite (= ne_6 #b1) ge_17 #b0)))
(assert (and (= dc_78 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_11))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_6 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_11))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_12 (ite (= ge_18 #b1) x3_neg_6 x3_11)))
(assert (and (= dc_79 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_11))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_6 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_11))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_12 (ite (= ge_18 #b1) x10_neg_6 x10_11)))
(assert (= x7_9 (ite (= ge_18 #b1) x8_12 x7_8)))
(assert (and (= dc_80 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_12) ((_ zero_extend 1) x10_12)))) (= x8_13 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_12) ((_ zero_extend 1) x10_12))))))
(assert (= x3_13 (bvadd x3_12 #x0000000000000002)))
(assert (and (= dc_81 ((_ extract 63 2) x8_13)) (= x8_lo_7 ((_ extract 1 0) x8_13))))
(assert (and (= x8_target_6 ((_ extract 1 1) x8_lo_7)) (= dc_82 ((_ extract 0 0) x8_lo_7))))
(assert (= ne_7 (bvand x8_target_6 #b1)))
(assert (and (= x8_14 ((_ sign_extend 1) ((_ extract 63 1) x8_13))) (= dc_83 ((_ zero_extend 63) ((_ extract 0 0) x8_13)))))
(assert true)
(assert (= x10_13 (ite (= ne_7 #b1) x7_9 #x0000000000000000)))
(assert (and (= ge_19 ((_ extract 63 63) x3_13)) (= dc_84 ((_ extract 62 0) x3_13))))
(assert (= ge_20 (bvnot ge_19)))
(assert (= ge_21 (ite (= ne_7 #b1) ge_20 #b0)))
(assert (and (= dc_85 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_13))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_7 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_13))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_14 (ite (= ge_21 #b1) x3_neg_7 x3_13)))
(assert (and (= dc_86 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_13))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_7 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_13))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_14 (ite (= ge_21 #b1) x10_neg_7 x10_13)))
(assert (= x7_10 (ite (= ge_21 #b1) x8_14 x7_9)))
(assert (and (= dc_87 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_14) ((_ zero_extend 1) x10_14)))) (= x8_15 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_14) ((_ zero_extend 1) x10_14))))))
(assert (= x3_15 (bvadd x3_14 #x0000000000000002)))
(assert (and (= dc_88 ((_ extract 63 2) x8_15)) (= x8_lo_8 ((_ extract 1 0) x8_15))))
(assert (and (= x8_target_7 ((_ extract 1 1) x8_lo_8)) (= dc_89 ((_ extract 0 0) x8_lo_8))))
(assert (= ne_8 (bvand x8_target_7 #b1)))
(assert (and (= x8_16 ((_ sign_extend 1) ((_ extract 63 1) x8_15))) (= dc_90 ((_ zero_extend 63) ((_ extract 0 0) x8_15)))))
(assert true)
(assert (= x10_15 (ite (= ne_8 #b1) x7_10 #x0000000000000000)))
(assert (and (= ge_22 ((_ extract 63 63) x3_15)) (= dc_91 ((_ extract 62 0) x3_15))))
(assert (= ge_23 (bvnot ge_22)))
(assert (= ge_24 (ite (= ne_8 #b1) ge_23 #b0)))
(assert (and (= dc_92 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_15))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_8 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_15))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_16 (ite (= ge_24 #b1) x3_neg_8 x3_15)))
(assert (and (= dc_93 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_15))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_8 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_15))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_16 (ite (= ge_24 #b1) x10_neg_8 x10_15)))
(assert (= x7_11 (ite (= ge_24 #b1) x8_16 x7_10)))
(assert (and (= dc_94 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_16) ((_ zero_extend 1) x10_16)))) (= x8_17 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_16) ((_ zero_extend 1) x10_16))))))
(assert (= x3_17 (bvadd x3_16 #x0000000000000002)))
(assert (and (= dc_95 ((_ extract 63 2) x8_17)) (= x8_lo_9 ((_ extract 1 0) x8_17))))
(assert (and (= x8_target_8 ((_ extract 1 1) x8_lo_9)) (= dc_96 ((_ extract 0 0) x8_lo_9))))
(assert (= ne_9 (bvand x8_target_8 #b1)))
(assert (and (= x8_18 ((_ sign_extend 1) ((_ extract 63 1) x8_17))) (= dc_97 ((_ zero_extend 63) ((_ extract 0 0) x8_17)))))
(assert true)
(assert (= x10_17 (ite (= ne_9 #b1) x7_11 #x0000000000000000)))
(assert (and (= ge_25 ((_ extract 63 63) x3_17)) (= dc_98 ((_ extract 62 0) x3_17))))
(assert (= ge_26 (bvnot ge_25)))
(assert (= ge_27 (ite (= ne_9 #b1) ge_26 #b0)))
(assert (and (= dc_99 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_17))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_9 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_17))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_18 (ite (= ge_27 #b1) x3_neg_9 x3_17)))
(assert (and (= dc_100 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_17))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_9 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_17))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_18 (ite (= ge_27 #b1) x10_neg_9 x10_17)))
(assert (= x7_12 (ite (= ge_27 #b1) x8_18 x7_11)))
(assert (and (= dc_101 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_18) ((_ zero_extend 1) x10_18)))) (= x8_19 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_18) ((_ zero_extend 1) x10_18))))))
(assert (= x3_19 (bvadd x3_18 #x0000000000000002)))
(assert (and (= dc_102 ((_ extract 63 2) x8_19)) (= x8_lo_10 ((_ extract 1 0) x8_19))))
(assert (and (= x8_target_9 ((_ extract 1 1) x8_lo_10)) (= dc_103 ((_ extract 0 0) x8_lo_10))))
(assert (= ne_10 (bvand x8_target_9 #b1)))
(assert (and (= x8_20 ((_ sign_extend 1) ((_ extract 63 1) x8_19))) (= dc_104 ((_ zero_extend 63) ((_ extract 0 0) x8_19)))))
(assert true)
(assert (= x10_19 (ite (= ne_10 #b1) x7_12 #x0000000000000000)))
(assert (and (= ge_28 ((_ extract 63 63) x3_19)) (= dc_105 ((_ extract 62 0) x3_19))))
(assert (= ge_29 (bvnot ge_28)))
(assert (= ge_30 (ite (= ne_10 #b1) ge_29 #b0)))
(assert (and (= dc_106 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_19))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_10 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_19))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_20 (ite (= ge_30 #b1) x3_neg_10 x3_19)))
(assert (and (= dc_107 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_19))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_10 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_19))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_20 (ite (= ge_30 #b1) x10_neg_10 x10_19)))
(assert (= x7_13 (ite (= ge_30 #b1) x8_20 x7_12)))
(assert (and (= dc_108 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_20) ((_ zero_extend 1) x10_20)))) (= x8_21 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_20) ((_ zero_extend 1) x10_20))))))
(assert (= x3_21 (bvadd x3_20 #x0000000000000002)))
(assert (and (= dc_109 ((_ extract 63 2) x8_21)) (= x8_lo_11 ((_ extract 1 0) x8_21))))
(assert (and (= x8_target_10 ((_ extract 1 1) x8_lo_11)) (= dc_110 ((_ extract 0 0) x8_lo_11))))
(assert (= ne_11 (bvand x8_target_10 #b1)))
(assert (and (= x8_22 ((_ sign_extend 1) ((_ extract 63 1) x8_21))) (= dc_111 ((_ zero_extend 63) ((_ extract 0 0) x8_21)))))
(assert true)
(assert (= x10_21 (ite (= ne_11 #b1) x7_13 #x0000000000000000)))
(assert (and (= ge_31 ((_ extract 63 63) x3_21)) (= dc_112 ((_ extract 62 0) x3_21))))
(assert (= ge_32 (bvnot ge_31)))
(assert (= ge_33 (ite (= ne_11 #b1) ge_32 #b0)))
(assert (and (= dc_113 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_21))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_11 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_21))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_22 (ite (= ge_33 #b1) x3_neg_11 x3_21)))
(assert (and (= dc_114 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_21))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_11 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_21))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_22 (ite (= ge_33 #b1) x10_neg_11 x10_21)))
(assert (= x7_14 (ite (= ge_33 #b1) x8_22 x7_13)))
(assert (and (= dc_115 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_22) ((_ zero_extend 1) x10_22)))) (= x8_23 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_22) ((_ zero_extend 1) x10_22))))))
(assert (= x3_23 (bvadd x3_22 #x0000000000000002)))
(assert (and (= dc_116 ((_ extract 63 2) x8_23)) (= x8_lo_12 ((_ extract 1 0) x8_23))))
(assert (and (= x8_target_11 ((_ extract 1 1) x8_lo_12)) (= dc_117 ((_ extract 0 0) x8_lo_12))))
(assert (= ne_12 (bvand x8_target_11 #b1)))
(assert (and (= x8_24 ((_ sign_extend 1) ((_ extract 63 1) x8_23))) (= dc_118 ((_ zero_extend 63) ((_ extract 0 0) x8_23)))))
(assert true)
(assert (= x10_23 (ite (= ne_12 #b1) x7_14 #x0000000000000000)))
(assert (and (= ge_34 ((_ extract 63 63) x3_23)) (= dc_119 ((_ extract 62 0) x3_23))))
(assert (= ge_35 (bvnot ge_34)))
(assert (= ge_36 (ite (= ne_12 #b1) ge_35 #b0)))
(assert (and (= dc_120 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_23))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_12 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_23))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_24 (ite (= ge_36 #b1) x3_neg_12 x3_23)))
(assert (and (= dc_121 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_23))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_12 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_23))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_24 (ite (= ge_36 #b1) x10_neg_12 x10_23)))
(assert (= x7_15 (ite (= ge_36 #b1) x8_24 x7_14)))
(assert (and (= dc_122 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_24) ((_ zero_extend 1) x10_24)))) (= x8_25 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_24) ((_ zero_extend 1) x10_24))))))
(assert (= x3_25 (bvadd x3_24 #x0000000000000002)))
(assert (and (= dc_123 ((_ extract 63 2) x8_25)) (= x8_lo_13 ((_ extract 1 0) x8_25))))
(assert (and (= x8_target_12 ((_ extract 1 1) x8_lo_13)) (= dc_124 ((_ extract 0 0) x8_lo_13))))
(assert (= ne_13 (bvand x8_target_12 #b1)))
(assert (and (= x8_26 ((_ sign_extend 1) ((_ extract 63 1) x8_25))) (= dc_125 ((_ zero_extend 63) ((_ extract 0 0) x8_25)))))
(assert true)
(assert (= x10_25 (ite (= ne_13 #b1) x7_15 #x0000000000000000)))
(assert (and (= ge_37 ((_ extract 63 63) x3_25)) (= dc_126 ((_ extract 62 0) x3_25))))
(assert (= ge_38 (bvnot ge_37)))
(assert (= ge_39 (ite (= ne_13 #b1) ge_38 #b0)))
(assert (and (= dc_127 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_25))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_13 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_25))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_26 (ite (= ge_39 #b1) x3_neg_13 x3_25)))
(assert (and (= dc_128 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_25))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_13 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_25))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_26 (ite (= ge_39 #b1) x10_neg_13 x10_25)))
(assert (= x7_16 (ite (= ge_39 #b1) x8_26 x7_15)))
(assert (and (= dc_129 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_26) ((_ zero_extend 1) x10_26)))) (= x8_27 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_26) ((_ zero_extend 1) x10_26))))))
(assert (= x3_27 (bvadd x3_26 #x0000000000000002)))
(assert (and (= dc_130 ((_ extract 63 2) x8_27)) (= x8_lo_14 ((_ extract 1 0) x8_27))))
(assert (and (= x8_target_13 ((_ extract 1 1) x8_lo_14)) (= dc_131 ((_ extract 0 0) x8_lo_14))))
(assert (= ne_14 (bvand x8_target_13 #b1)))
(assert (and (= x8_28 ((_ sign_extend 1) ((_ extract 63 1) x8_27))) (= dc_132 ((_ zero_extend 63) ((_ extract 0 0) x8_27)))))
(assert true)
(assert (= x10_27 (ite (= ne_14 #b1) x7_16 #x0000000000000000)))
(assert (and (= ge_40 ((_ extract 63 63) x3_27)) (= dc_133 ((_ extract 62 0) x3_27))))
(assert (= ge_41 (bvnot ge_40)))
(assert (= ge_42 (ite (= ne_14 #b1) ge_41 #b0)))
(assert (and (= dc_134 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_27))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_14 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_27))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_28 (ite (= ge_42 #b1) x3_neg_14 x3_27)))
(assert (and (= dc_135 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_27))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_14 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_27))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_28 (ite (= ge_42 #b1) x10_neg_14 x10_27)))
(assert (= x7_17 (ite (= ge_42 #b1) x8_28 x7_16)))
(assert (and (= dc_136 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_28) ((_ zero_extend 1) x10_28)))) (= x8_29 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_28) ((_ zero_extend 1) x10_28))))))
(assert (= x3_29 (bvadd x3_28 #x0000000000000002)))
(assert (and (= dc_137 ((_ extract 63 2) x8_29)) (= x8_lo_15 ((_ extract 1 0) x8_29))))
(assert (and (= x8_target_14 ((_ extract 1 1) x8_lo_15)) (= dc_138 ((_ extract 0 0) x8_lo_15))))
(assert (= ne_15 (bvand x8_target_14 #b1)))
(assert (and (= x8_30 ((_ sign_extend 1) ((_ extract 63 1) x8_29))) (= dc_139 ((_ zero_extend 63) ((_ extract 0 0) x8_29)))))
(assert true)
(assert (= x10_29 (ite (= ne_15 #b1) x7_17 #x0000000000000000)))
(assert (and (= ge_43 ((_ extract 63 63) x3_29)) (= dc_140 ((_ extract 62 0) x3_29))))
(assert (= ge_44 (bvnot ge_43)))
(assert (= ge_45 (ite (= ne_15 #b1) ge_44 #b0)))
(assert (and (= dc_141 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_29))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_15 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_29))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_30 (ite (= ge_45 #b1) x3_neg_15 x3_29)))
(assert (and (= dc_142 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_29))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_15 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_29))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_30 (ite (= ge_45 #b1) x10_neg_15 x10_29)))
(assert (= x7_18 (ite (= ge_45 #b1) x8_30 x7_17)))
(assert (and (= dc_143 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_30) ((_ zero_extend 1) x10_30)))) (= x8_31 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_30) ((_ zero_extend 1) x10_30))))))
(assert (= x3_31 (bvadd x3_30 #x0000000000000002)))
(assert (and (= dc_144 ((_ extract 63 2) x8_31)) (= x8_lo_16 ((_ extract 1 0) x8_31))))
(assert (and (= x8_target_15 ((_ extract 1 1) x8_lo_16)) (= dc_145 ((_ extract 0 0) x8_lo_16))))
(assert (= ne_16 (bvand x8_target_15 #b1)))
(assert (and (= x8_32 ((_ sign_extend 1) ((_ extract 63 1) x8_31))) (= dc_146 ((_ zero_extend 63) ((_ extract 0 0) x8_31)))))
(assert true)
(assert (= x10_31 (ite (= ne_16 #b1) x7_18 #x0000000000000000)))
(assert (and (= ge_46 ((_ extract 63 63) x3_31)) (= dc_147 ((_ extract 62 0) x3_31))))
(assert (= ge_47 (bvnot ge_46)))
(assert (= ge_48 (ite (= ne_16 #b1) ge_47 #b0)))
(assert (and (= dc_148 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_31))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_16 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_31))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_32 (ite (= ge_48 #b1) x3_neg_16 x3_31)))
(assert (and (= dc_149 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_31))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_16 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_31))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_32 (ite (= ge_48 #b1) x10_neg_16 x10_31)))
(assert (= x7_19 (ite (= ge_48 #b1) x8_32 x7_18)))
(assert (and (= dc_150 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_32) ((_ zero_extend 1) x10_32)))) (= x8_33 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_32) ((_ zero_extend 1) x10_32))))))
(assert (= x3_33 (bvadd x3_32 #x0000000000000002)))
(assert (and (= dc_151 ((_ extract 63 2) x8_33)) (= x8_lo_17 ((_ extract 1 0) x8_33))))
(assert (and (= x8_target_16 ((_ extract 1 1) x8_lo_17)) (= dc_152 ((_ extract 0 0) x8_lo_17))))
(assert (= ne_17 (bvand x8_target_16 #b1)))
(assert (and (= x8_34 ((_ sign_extend 1) ((_ extract 63 1) x8_33))) (= dc_153 ((_ zero_extend 63) ((_ extract 0 0) x8_33)))))
(assert true)
(assert (= x10_33 (ite (= ne_17 #b1) x7_19 #x0000000000000000)))
(assert (and (= ge_49 ((_ extract 63 63) x3_33)) (= dc_154 ((_ extract 62 0) x3_33))))
(assert (= ge_50 (bvnot ge_49)))
(assert (= ge_51 (ite (= ne_17 #b1) ge_50 #b0)))
(assert (and (= dc_155 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_33))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_17 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_33))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_34 (ite (= ge_51 #b1) x3_neg_17 x3_33)))
(assert (and (= dc_156 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_33))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_17 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_33))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_34 (ite (= ge_51 #b1) x10_neg_17 x10_33)))
(assert (= x7_20 (ite (= ge_51 #b1) x8_34 x7_19)))
(assert (and (= dc_157 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_34) ((_ zero_extend 1) x10_34)))) (= x8_35 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_34) ((_ zero_extend 1) x10_34))))))
(assert (= x3_35 (bvadd x3_34 #x0000000000000002)))
(assert (and (= dc_158 ((_ extract 63 2) x8_35)) (= x8_lo_18 ((_ extract 1 0) x8_35))))
(assert (and (= x8_target_17 ((_ extract 1 1) x8_lo_18)) (= dc_159 ((_ extract 0 0) x8_lo_18))))
(assert (= ne_18 (bvand x8_target_17 #b1)))
(assert (and (= x8_36 ((_ sign_extend 1) ((_ extract 63 1) x8_35))) (= dc_160 ((_ zero_extend 63) ((_ extract 0 0) x8_35)))))
(assert true)
(assert (= x10_35 (ite (= ne_18 #b1) x7_20 #x0000000000000000)))
(assert (and (= ge_52 ((_ extract 63 63) x3_35)) (= dc_161 ((_ extract 62 0) x3_35))))
(assert (= ge_53 (bvnot ge_52)))
(assert (= ge_54 (ite (= ne_18 #b1) ge_53 #b0)))
(assert (and (= dc_162 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_35))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_18 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_35))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_36 (ite (= ge_54 #b1) x3_neg_18 x3_35)))
(assert (and (= dc_163 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_35))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_18 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_35))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_36 (ite (= ge_54 #b1) x10_neg_18 x10_35)))
(assert (= x7_21 (ite (= ge_54 #b1) x8_36 x7_20)))
(assert (and (= dc_164 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_36) ((_ zero_extend 1) x10_36)))) (= x8_37 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_36) ((_ zero_extend 1) x10_36))))))
(assert (= x3_37 (bvadd x3_36 #x0000000000000002)))
(assert (and (= dc_165 ((_ extract 63 2) x8_37)) (= x8_lo_19 ((_ extract 1 0) x8_37))))
(assert (and (= x8_target_18 ((_ extract 1 1) x8_lo_19)) (= dc_166 ((_ extract 0 0) x8_lo_19))))
(assert (= ne_19 (bvand x8_target_18 #b1)))
(assert (and (= x8_38 ((_ sign_extend 1) ((_ extract 63 1) x8_37))) (= dc_167 ((_ zero_extend 63) ((_ extract 0 0) x8_37)))))
(assert true)
(assert (= x10_37 (ite (= ne_19 #b1) x7_21 #x0000000000000000)))
(assert (and (= ge_55 ((_ extract 63 63) x3_37)) (= dc_168 ((_ extract 62 0) x3_37))))
(assert (= ge_56 (bvnot ge_55)))
(assert (= ge_57 (ite (= ne_19 #b1) ge_56 #b0)))
(assert (and (= dc_169 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_37))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_19 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_37))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_38 (ite (= ge_57 #b1) x3_neg_19 x3_37)))
(assert (and (= dc_170 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_37))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_19 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_37))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_38 (ite (= ge_57 #b1) x10_neg_19 x10_37)))
(assert (= x7_22 (ite (= ge_57 #b1) x8_38 x7_21)))
(assert (and (= dc_171 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_38) ((_ zero_extend 1) x10_38)))) (= x8_39 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_38) ((_ zero_extend 1) x10_38))))))
(assert (= x3_39 (bvadd x3_38 #x0000000000000002)))
(assert (and (= dc_172 ((_ extract 63 2) x8_39)) (= x8_lo_20 ((_ extract 1 0) x8_39))))
(assert (and (= x8_target_19 ((_ extract 1 1) x8_lo_20)) (= dc_173 ((_ extract 0 0) x8_lo_20))))
(assert (= ne_20 (bvand x8_target_19 #b1)))
(assert (and (= x8_40 ((_ sign_extend 1) ((_ extract 63 1) x8_39))) (= dc_174 ((_ zero_extend 63) ((_ extract 0 0) x8_39)))))
(assert true)
(assert (= x10_39 (ite (= ne_20 #b1) x7_22 #x0000000000000000)))
(assert (and (= ge_58 ((_ extract 63 63) x3_39)) (= dc_175 ((_ extract 62 0) x3_39))))
(assert (= ge_59 (bvnot ge_58)))
(assert (= ge_60 (ite (= ne_20 #b1) ge_59 #b0)))
(assert (and (= dc_176 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_39))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_20 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_39))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_40 (ite (= ge_60 #b1) x3_neg_20 x3_39)))
(assert (and (= dc_177 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_39))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_20 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_39))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_40 (ite (= ge_60 #b1) x10_neg_20 x10_39)))
(assert (= x7_23 (ite (= ge_60 #b1) x8_40 x7_22)))
(assert (and (= dc_178 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_40) ((_ zero_extend 1) x10_40)))) (= x8_41 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_40) ((_ zero_extend 1) x10_40))))))
(assert (= x3_41 (bvadd x3_40 #x0000000000000002)))
(assert (and (= x8_42 ((_ sign_extend 1) ((_ extract 63 1) x8_41))) (= dc_179 ((_ zero_extend 63) ((_ extract 0 0) x8_41)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_40) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_23 x7_22)) (= (bvmul x8_42 #x0000000000000002) x8_40)) (= x3_41 (bvadd #x0000000000000002 x3_39))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_40) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_39 #x0000000000000000)) (= x7_23 x7_22)) (= (bvmul x8_42 #x0000000000000002) (bvadd x8_40 x7_22))) (= x3_41 (bvadd #x0000000000000002 x3_39)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_40) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_39 #x0000000000000000)) (= x7_23 x8_40)) (= (bvmul x8_42 #x0000000000000002) (bvsub x8_40 x7_22))) (= x3_41 (bvsub #x0000000000000002 x3_39))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_b33099.smt2
Execution time of boolector: 0.7348 seconds
OUTPUT FROM boolector:
unsat

=== Cut #2 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #2
; Range assertion #29: or [and [smod (sub (uext x8_36 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_21 = x7_20, mul x8_38 2@64 = x8_36, x3_37 = add 2@64 x3_35], and [smod (sub (uext x8_36 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_35 <s 0@64, x7_21 = x7_20, mul x8_38 2@64 = add x8_36 x7_20, x3_37 = add 2@64 x3_35], and [smod (sub (uext x8_36 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_35 >=s 0@64, x7_21 = x8_36, mul x8_38 2@64 = sub x8_36 x7_20, x3_37 = sub 2@64 x3_35]]
; Range condition: ((x8_36@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_21 = x7_20 /\ x8_38 * 2 = x8_36 /\ x3_37 = 2 + x3_35 \/ ((x8_36@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_35 <s 0 /\ x7_21 = x7_20 /\ x8_38 * 2 = x8_36 + x7_20 /\ x3_37 = 2 + x3_35 \/ ((x8_36@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_35 >=s 0 /\ x7_21 = x8_36 /\ x8_38 * 2 = x8_36 - x7_20 /\ x3_37 = 2 - x3_35
; Output file: /tmp/outputqfbv_2ec774.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_18 () (_ BitVec 1))
(declare-fun x8_target_17 () (_ BitVec 1))
(declare-fun x8_target_16 () (_ BitVec 1))
(declare-fun x8_target_15 () (_ BitVec 1))
(declare-fun x8_target_14 () (_ BitVec 1))
(declare-fun x8_target_13 () (_ BitVec 1))
(declare-fun x8_target_12 () (_ BitVec 1))
(declare-fun x8_target_11 () (_ BitVec 1))
(declare-fun x8_target_10 () (_ BitVec 1))
(declare-fun x8_target_9 () (_ BitVec 1))
(declare-fun x8_target_8 () (_ BitVec 1))
(declare-fun x8_target_7 () (_ BitVec 1))
(declare-fun x8_target_6 () (_ BitVec 1))
(declare-fun x8_target_5 () (_ BitVec 1))
(declare-fun x8_target_4 () (_ BitVec 1))
(declare-fun x8_target_3 () (_ BitVec 1))
(declare-fun x8_target_2 () (_ BitVec 1))
(declare-fun x8_target_1 () (_ BitVec 1))
(declare-fun x8_lo_19 () (_ BitVec 2))
(declare-fun x8_lo_18 () (_ BitVec 2))
(declare-fun x8_lo_17 () (_ BitVec 2))
(declare-fun x8_lo_16 () (_ BitVec 2))
(declare-fun x8_lo_15 () (_ BitVec 2))
(declare-fun x8_lo_14 () (_ BitVec 2))
(declare-fun x8_lo_13 () (_ BitVec 2))
(declare-fun x8_lo_12 () (_ BitVec 2))
(declare-fun x8_lo_11 () (_ BitVec 2))
(declare-fun x8_lo_10 () (_ BitVec 2))
(declare-fun x8_lo_9 () (_ BitVec 2))
(declare-fun x8_lo_8 () (_ BitVec 2))
(declare-fun x8_lo_7 () (_ BitVec 2))
(declare-fun x8_lo_6 () (_ BitVec 2))
(declare-fun x8_lo_5 () (_ BitVec 2))
(declare-fun x8_lo_4 () (_ BitVec 2))
(declare-fun x8_lo_3 () (_ BitVec 2))
(declare-fun x8_lo_2 () (_ BitVec 2))
(declare-fun x8_lo_1 () (_ BitVec 1))
(declare-fun x8_38 () (_ BitVec 64))
(declare-fun x8_37 () (_ BitVec 64))
(declare-fun x8_36 () (_ BitVec 64))
(declare-fun x8_35 () (_ BitVec 64))
(declare-fun x8_34 () (_ BitVec 64))
(declare-fun x8_33 () (_ BitVec 64))
(declare-fun x8_32 () (_ BitVec 64))
(declare-fun x8_31 () (_ BitVec 64))
(declare-fun x8_30 () (_ BitVec 64))
(declare-fun x8_29 () (_ BitVec 64))
(declare-fun x8_28 () (_ BitVec 64))
(declare-fun x8_27 () (_ BitVec 64))
(declare-fun x8_26 () (_ BitVec 64))
(declare-fun x8_25 () (_ BitVec 64))
(declare-fun x8_24 () (_ BitVec 64))
(declare-fun x8_23 () (_ BitVec 64))
(declare-fun x8_22 () (_ BitVec 64))
(declare-fun x8_21 () (_ BitVec 64))
(declare-fun x8_20 () (_ BitVec 64))
(declare-fun x8_19 () (_ BitVec 64))
(declare-fun x8_18 () (_ BitVec 64))
(declare-fun x8_17 () (_ BitVec 64))
(declare-fun x8_16 () (_ BitVec 64))
(declare-fun x8_15 () (_ BitVec 64))
(declare-fun x8_14 () (_ BitVec 64))
(declare-fun x8_13 () (_ BitVec 64))
(declare-fun x8_12 () (_ BitVec 64))
(declare-fun x8_11 () (_ BitVec 64))
(declare-fun x8_10 () (_ BitVec 64))
(declare-fun x8_9 () (_ BitVec 64))
(declare-fun x8_8 () (_ BitVec 64))
(declare-fun x8_7 () (_ BitVec 64))
(declare-fun x8_6 () (_ BitVec 64))
(declare-fun x8_5 () (_ BitVec 64))
(declare-fun x8_4 () (_ BitVec 64))
(declare-fun x8_3 () (_ BitVec 64))
(declare-fun x8_2 () (_ BitVec 64))
(declare-fun x7_21 () (_ BitVec 64))
(declare-fun x7_20 () (_ BitVec 64))
(declare-fun x7_19 () (_ BitVec 64))
(declare-fun x7_18 () (_ BitVec 64))
(declare-fun x7_17 () (_ BitVec 64))
(declare-fun x7_16 () (_ BitVec 64))
(declare-fun x7_15 () (_ BitVec 64))
(declare-fun x7_14 () (_ BitVec 64))
(declare-fun x7_13 () (_ BitVec 64))
(declare-fun x7_12 () (_ BitVec 64))
(declare-fun x7_11 () (_ BitVec 64))
(declare-fun x7_10 () (_ BitVec 64))
(declare-fun x7_9 () (_ BitVec 64))
(declare-fun x7_8 () (_ BitVec 64))
(declare-fun x7_7 () (_ BitVec 64))
(declare-fun x7_6 () (_ BitVec 64))
(declare-fun x7_5 () (_ BitVec 64))
(declare-fun x7_4 () (_ BitVec 64))
(declare-fun x7_3 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_18 () (_ BitVec 64))
(declare-fun x3_neg_17 () (_ BitVec 64))
(declare-fun x3_neg_16 () (_ BitVec 64))
(declare-fun x3_neg_15 () (_ BitVec 64))
(declare-fun x3_neg_14 () (_ BitVec 64))
(declare-fun x3_neg_13 () (_ BitVec 64))
(declare-fun x3_neg_12 () (_ BitVec 64))
(declare-fun x3_neg_11 () (_ BitVec 64))
(declare-fun x3_neg_10 () (_ BitVec 64))
(declare-fun x3_neg_9 () (_ BitVec 64))
(declare-fun x3_neg_8 () (_ BitVec 64))
(declare-fun x3_neg_7 () (_ BitVec 64))
(declare-fun x3_neg_6 () (_ BitVec 64))
(declare-fun x3_neg_5 () (_ BitVec 64))
(declare-fun x3_neg_4 () (_ BitVec 64))
(declare-fun x3_neg_3 () (_ BitVec 64))
(declare-fun x3_neg_2 () (_ BitVec 64))
(declare-fun x3_neg_1 () (_ BitVec 64))
(declare-fun x3_37 () (_ BitVec 64))
(declare-fun x3_36 () (_ BitVec 64))
(declare-fun x3_35 () (_ BitVec 64))
(declare-fun x3_34 () (_ BitVec 64))
(declare-fun x3_33 () (_ BitVec 64))
(declare-fun x3_32 () (_ BitVec 64))
(declare-fun x3_31 () (_ BitVec 64))
(declare-fun x3_30 () (_ BitVec 64))
(declare-fun x3_29 () (_ BitVec 64))
(declare-fun x3_28 () (_ BitVec 64))
(declare-fun x3_27 () (_ BitVec 64))
(declare-fun x3_26 () (_ BitVec 64))
(declare-fun x3_25 () (_ BitVec 64))
(declare-fun x3_24 () (_ BitVec 64))
(declare-fun x3_23 () (_ BitVec 64))
(declare-fun x3_22 () (_ BitVec 64))
(declare-fun x3_21 () (_ BitVec 64))
(declare-fun x3_20 () (_ BitVec 64))
(declare-fun x3_19 () (_ BitVec 64))
(declare-fun x3_18 () (_ BitVec 64))
(declare-fun x3_17 () (_ BitVec 64))
(declare-fun x3_16 () (_ BitVec 64))
(declare-fun x3_15 () (_ BitVec 64))
(declare-fun x3_14 () (_ BitVec 64))
(declare-fun x3_13 () (_ BitVec 64))
(declare-fun x3_12 () (_ BitVec 64))
(declare-fun x3_11 () (_ BitVec 64))
(declare-fun x3_10 () (_ BitVec 64))
(declare-fun x3_9 () (_ BitVec 64))
(declare-fun x3_8 () (_ BitVec 64))
(declare-fun x3_7 () (_ BitVec 64))
(declare-fun x3_6 () (_ BitVec 64))
(declare-fun x3_5 () (_ BitVec 64))
(declare-fun x3_4 () (_ BitVec 64))
(declare-fun x3_3 () (_ BitVec 64))
(declare-fun x3_2 () (_ BitVec 64))
(declare-fun x10_neg_18 () (_ BitVec 64))
(declare-fun x10_neg_17 () (_ BitVec 64))
(declare-fun x10_neg_16 () (_ BitVec 64))
(declare-fun x10_neg_15 () (_ BitVec 64))
(declare-fun x10_neg_14 () (_ BitVec 64))
(declare-fun x10_neg_13 () (_ BitVec 64))
(declare-fun x10_neg_12 () (_ BitVec 64))
(declare-fun x10_neg_11 () (_ BitVec 64))
(declare-fun x10_neg_10 () (_ BitVec 64))
(declare-fun x10_neg_9 () (_ BitVec 64))
(declare-fun x10_neg_8 () (_ BitVec 64))
(declare-fun x10_neg_7 () (_ BitVec 64))
(declare-fun x10_neg_6 () (_ BitVec 64))
(declare-fun x10_neg_5 () (_ BitVec 64))
(declare-fun x10_neg_4 () (_ BitVec 64))
(declare-fun x10_neg_3 () (_ BitVec 64))
(declare-fun x10_neg_2 () (_ BitVec 64))
(declare-fun x10_neg_1 () (_ BitVec 64))
(declare-fun x10_36 () (_ BitVec 64))
(declare-fun x10_35 () (_ BitVec 64))
(declare-fun x10_34 () (_ BitVec 64))
(declare-fun x10_33 () (_ BitVec 64))
(declare-fun x10_32 () (_ BitVec 64))
(declare-fun x10_31 () (_ BitVec 64))
(declare-fun x10_30 () (_ BitVec 64))
(declare-fun x10_29 () (_ BitVec 64))
(declare-fun x10_28 () (_ BitVec 64))
(declare-fun x10_27 () (_ BitVec 64))
(declare-fun x10_26 () (_ BitVec 64))
(declare-fun x10_25 () (_ BitVec 64))
(declare-fun x10_24 () (_ BitVec 64))
(declare-fun x10_23 () (_ BitVec 64))
(declare-fun x10_22 () (_ BitVec 64))
(declare-fun x10_21 () (_ BitVec 64))
(declare-fun x10_20 () (_ BitVec 64))
(declare-fun x10_19 () (_ BitVec 64))
(declare-fun x10_18 () (_ BitVec 64))
(declare-fun x10_17 () (_ BitVec 64))
(declare-fun x10_16 () (_ BitVec 64))
(declare-fun x10_15 () (_ BitVec 64))
(declare-fun x10_14 () (_ BitVec 64))
(declare-fun x10_13 () (_ BitVec 64))
(declare-fun x10_12 () (_ BitVec 64))
(declare-fun x10_11 () (_ BitVec 64))
(declare-fun x10_10 () (_ BitVec 64))
(declare-fun x10_9 () (_ BitVec 64))
(declare-fun x10_8 () (_ BitVec 64))
(declare-fun x10_7 () (_ BitVec 64))
(declare-fun x10_6 () (_ BitVec 64))
(declare-fun x10_5 () (_ BitVec 64))
(declare-fun x10_4 () (_ BitVec 64))
(declare-fun x10_3 () (_ BitVec 64))
(declare-fun x10_2 () (_ BitVec 64))
(declare-fun x10_1 () (_ BitVec 64))
(declare-fun ne_19 () (_ BitVec 1))
(declare-fun ne_18 () (_ BitVec 1))
(declare-fun ne_17 () (_ BitVec 1))
(declare-fun ne_16 () (_ BitVec 1))
(declare-fun ne_15 () (_ BitVec 1))
(declare-fun ne_14 () (_ BitVec 1))
(declare-fun ne_13 () (_ BitVec 1))
(declare-fun ne_12 () (_ BitVec 1))
(declare-fun ne_11 () (_ BitVec 1))
(declare-fun ne_10 () (_ BitVec 1))
(declare-fun ne_9 () (_ BitVec 1))
(declare-fun ne_8 () (_ BitVec 1))
(declare-fun ne_7 () (_ BitVec 1))
(declare-fun ne_6 () (_ BitVec 1))
(declare-fun ne_5 () (_ BitVec 1))
(declare-fun ne_4 () (_ BitVec 1))
(declare-fun ne_3 () (_ BitVec 1))
(declare-fun ne_2 () (_ BitVec 1))
(declare-fun ne_1 () (_ BitVec 1))
(declare-fun ge_54 () (_ BitVec 1))
(declare-fun ge_53 () (_ BitVec 1))
(declare-fun ge_52 () (_ BitVec 1))
(declare-fun ge_51 () (_ BitVec 1))
(declare-fun ge_50 () (_ BitVec 1))
(declare-fun ge_49 () (_ BitVec 1))
(declare-fun ge_48 () (_ BitVec 1))
(declare-fun ge_47 () (_ BitVec 1))
(declare-fun ge_46 () (_ BitVec 1))
(declare-fun ge_45 () (_ BitVec 1))
(declare-fun ge_44 () (_ BitVec 1))
(declare-fun ge_43 () (_ BitVec 1))
(declare-fun ge_42 () (_ BitVec 1))
(declare-fun ge_41 () (_ BitVec 1))
(declare-fun ge_40 () (_ BitVec 1))
(declare-fun ge_39 () (_ BitVec 1))
(declare-fun ge_38 () (_ BitVec 1))
(declare-fun ge_37 () (_ BitVec 1))
(declare-fun ge_36 () (_ BitVec 1))
(declare-fun ge_35 () (_ BitVec 1))
(declare-fun ge_34 () (_ BitVec 1))
(declare-fun ge_33 () (_ BitVec 1))
(declare-fun ge_32 () (_ BitVec 1))
(declare-fun ge_31 () (_ BitVec 1))
(declare-fun ge_30 () (_ BitVec 1))
(declare-fun ge_29 () (_ BitVec 1))
(declare-fun ge_28 () (_ BitVec 1))
(declare-fun ge_27 () (_ BitVec 1))
(declare-fun ge_26 () (_ BitVec 1))
(declare-fun ge_25 () (_ BitVec 1))
(declare-fun ge_24 () (_ BitVec 1))
(declare-fun ge_23 () (_ BitVec 1))
(declare-fun ge_22 () (_ BitVec 1))
(declare-fun ge_21 () (_ BitVec 1))
(declare-fun ge_20 () (_ BitVec 1))
(declare-fun ge_19 () (_ BitVec 1))
(declare-fun ge_18 () (_ BitVec 1))
(declare-fun ge_17 () (_ BitVec 1))
(declare-fun ge_16 () (_ BitVec 1))
(declare-fun ge_15 () (_ BitVec 1))
(declare-fun ge_14 () (_ BitVec 1))
(declare-fun ge_13 () (_ BitVec 1))
(declare-fun ge_12 () (_ BitVec 1))
(declare-fun ge_11 () (_ BitVec 1))
(declare-fun ge_10 () (_ BitVec 1))
(declare-fun ge_9 () (_ BitVec 1))
(declare-fun ge_8 () (_ BitVec 1))
(declare-fun ge_7 () (_ BitVec 1))
(declare-fun ge_6 () (_ BitVec 1))
(declare-fun ge_5 () (_ BitVec 1))
(declare-fun ge_4 () (_ BitVec 1))
(declare-fun ge_3 () (_ BitVec 1))
(declare-fun ge_2 () (_ BitVec 1))
(declare-fun ge_1 () (_ BitVec 1))
(declare-fun g_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun dc_167 () (_ BitVec 64))
(declare-fun dc_166 () (_ BitVec 1))
(declare-fun dc_165 () (_ BitVec 62))
(declare-fun dc_164 () (_ BitVec 1))
(declare-fun dc_163 () (_ BitVec 1))
(declare-fun dc_162 () (_ BitVec 1))
(declare-fun dc_161 () (_ BitVec 63))
(declare-fun dc_160 () (_ BitVec 64))
(declare-fun dc_159 () (_ BitVec 1))
(declare-fun dc_158 () (_ BitVec 62))
(declare-fun dc_157 () (_ BitVec 1))
(declare-fun dc_156 () (_ BitVec 1))
(declare-fun dc_155 () (_ BitVec 1))
(declare-fun dc_154 () (_ BitVec 63))
(declare-fun dc_153 () (_ BitVec 64))
(declare-fun dc_152 () (_ BitVec 1))
(declare-fun dc_151 () (_ BitVec 62))
(declare-fun dc_150 () (_ BitVec 1))
(declare-fun dc_149 () (_ BitVec 1))
(declare-fun dc_148 () (_ BitVec 1))
(declare-fun dc_147 () (_ BitVec 63))
(declare-fun dc_146 () (_ BitVec 64))
(declare-fun dc_145 () (_ BitVec 1))
(declare-fun dc_144 () (_ BitVec 62))
(declare-fun dc_143 () (_ BitVec 1))
(declare-fun dc_142 () (_ BitVec 1))
(declare-fun dc_141 () (_ BitVec 1))
(declare-fun dc_140 () (_ BitVec 63))
(declare-fun dc_139 () (_ BitVec 64))
(declare-fun dc_138 () (_ BitVec 1))
(declare-fun dc_137 () (_ BitVec 62))
(declare-fun dc_136 () (_ BitVec 1))
(declare-fun dc_135 () (_ BitVec 1))
(declare-fun dc_134 () (_ BitVec 1))
(declare-fun dc_133 () (_ BitVec 63))
(declare-fun dc_132 () (_ BitVec 64))
(declare-fun dc_131 () (_ BitVec 1))
(declare-fun dc_130 () (_ BitVec 62))
(declare-fun dc_129 () (_ BitVec 1))
(declare-fun dc_128 () (_ BitVec 1))
(declare-fun dc_127 () (_ BitVec 1))
(declare-fun dc_126 () (_ BitVec 63))
(declare-fun dc_125 () (_ BitVec 64))
(declare-fun dc_124 () (_ BitVec 1))
(declare-fun dc_123 () (_ BitVec 62))
(declare-fun dc_122 () (_ BitVec 1))
(declare-fun dc_121 () (_ BitVec 1))
(declare-fun dc_120 () (_ BitVec 1))
(declare-fun dc_119 () (_ BitVec 63))
(declare-fun dc_118 () (_ BitVec 64))
(declare-fun dc_117 () (_ BitVec 1))
(declare-fun dc_116 () (_ BitVec 62))
(declare-fun dc_115 () (_ BitVec 1))
(declare-fun dc_114 () (_ BitVec 1))
(declare-fun dc_113 () (_ BitVec 1))
(declare-fun dc_112 () (_ BitVec 63))
(declare-fun dc_111 () (_ BitVec 64))
(declare-fun dc_110 () (_ BitVec 1))
(declare-fun dc_109 () (_ BitVec 62))
(declare-fun dc_108 () (_ BitVec 1))
(declare-fun dc_107 () (_ BitVec 1))
(declare-fun dc_106 () (_ BitVec 1))
(declare-fun dc_105 () (_ BitVec 63))
(declare-fun dc_104 () (_ BitVec 64))
(declare-fun dc_103 () (_ BitVec 1))
(declare-fun dc_102 () (_ BitVec 62))
(declare-fun dc_101 () (_ BitVec 1))
(declare-fun dc_100 () (_ BitVec 1))
(declare-fun dc_99 () (_ BitVec 1))
(declare-fun dc_98 () (_ BitVec 63))
(declare-fun dc_97 () (_ BitVec 64))
(declare-fun dc_96 () (_ BitVec 1))
(declare-fun dc_95 () (_ BitVec 62))
(declare-fun dc_94 () (_ BitVec 1))
(declare-fun dc_93 () (_ BitVec 1))
(declare-fun dc_92 () (_ BitVec 1))
(declare-fun dc_91 () (_ BitVec 63))
(declare-fun dc_90 () (_ BitVec 64))
(declare-fun dc_89 () (_ BitVec 1))
(declare-fun dc_88 () (_ BitVec 62))
(declare-fun dc_87 () (_ BitVec 1))
(declare-fun dc_86 () (_ BitVec 1))
(declare-fun dc_85 () (_ BitVec 1))
(declare-fun dc_84 () (_ BitVec 63))
(declare-fun dc_83 () (_ BitVec 64))
(declare-fun dc_82 () (_ BitVec 1))
(declare-fun dc_81 () (_ BitVec 62))
(declare-fun dc_80 () (_ BitVec 1))
(declare-fun dc_79 () (_ BitVec 1))
(declare-fun dc_78 () (_ BitVec 1))
(declare-fun dc_77 () (_ BitVec 63))
(declare-fun dc_76 () (_ BitVec 64))
(declare-fun dc_75 () (_ BitVec 1))
(declare-fun dc_74 () (_ BitVec 62))
(declare-fun dc_73 () (_ BitVec 1))
(declare-fun dc_72 () (_ BitVec 1))
(declare-fun dc_71 () (_ BitVec 1))
(declare-fun dc_70 () (_ BitVec 63))
(declare-fun dc_69 () (_ BitVec 64))
(declare-fun dc_68 () (_ BitVec 1))
(declare-fun dc_67 () (_ BitVec 62))
(declare-fun dc_66 () (_ BitVec 1))
(declare-fun dc_65 () (_ BitVec 1))
(declare-fun dc_64 () (_ BitVec 1))
(declare-fun dc_63 () (_ BitVec 63))
(declare-fun dc_62 () (_ BitVec 64))
(declare-fun dc_61 () (_ BitVec 1))
(declare-fun dc_60 () (_ BitVec 62))
(declare-fun dc_59 () (_ BitVec 1))
(declare-fun dc_58 () (_ BitVec 1))
(declare-fun dc_57 () (_ BitVec 1))
(declare-fun dc_56 () (_ BitVec 63))
(declare-fun dc_55 () (_ BitVec 64))
(declare-fun dc_54 () (_ BitVec 1))
(declare-fun dc_53 () (_ BitVec 62))
(declare-fun dc_52 () (_ BitVec 1))
(declare-fun dc_51 () (_ BitVec 1))
(declare-fun dc_50 () (_ BitVec 1))
(declare-fun dc_49 () (_ BitVec 63))
(declare-fun dc_48 () (_ BitVec 64))
(declare-fun dc_47 () (_ BitVec 1))
(declare-fun dc_46 () (_ BitVec 62))
(declare-fun dc_45 () (_ BitVec 1))
(declare-fun dc_44 () (_ BitVec 1))
(declare-fun dc_43 () (_ BitVec 1))
(declare-fun dc_42 () (_ BitVec 63))
(declare-fun dc_41 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (= x7_3 (bvadd (bvadd f_0_low60_0_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_2 (bvadd (bvadd g_0_low60_0_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_0_1)) (bvsle f_0_low60_0_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_0_1)) (bvsle g_0_low60_0_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_3) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #x0000000000000001 #x0000000000000001)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_41 ((_ extract 63 1) x8_2)) (= x8_lo_1 ((_ extract 0 0) x8_2))))
(assert (= ne_1 (bvand x8_lo_1 #b1)))
(assert (= x10_1 (ite (= ne_1 #b1) x7_3 #x0000000000000000)))
(assert (and (= ge_1 ((_ extract 63 63) #x0000000000000001)) (= dc_42 ((_ extract 62 0) #x0000000000000001))))
(assert (= ge_2 (bvnot ge_1)))
(assert (= ge_3 (ite (= ne_1 #b1) ge_2 #b0)))
(assert (and (= dc_43 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_2 (ite (= ge_3 #b1) x3_neg_1 #x0000000000000001)))
(assert (and (= dc_44 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_2 (ite (= ge_3 #b1) x10_neg_1 x10_1)))
(assert (= x7_4 (ite (= ge_3 #b1) x8_2 x7_3)))
(assert (and (= dc_45 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2)))) (= x8_3 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2))))))
(assert (= x3_3 (bvadd x3_2 #x0000000000000002)))
(assert (and (= dc_46 ((_ extract 63 2) x8_3)) (= x8_lo_2 ((_ extract 1 0) x8_3))))
(assert (and (= x8_target_1 ((_ extract 1 1) x8_lo_2)) (= dc_47 ((_ extract 0 0) x8_lo_2))))
(assert (= ne_2 (bvand x8_target_1 #b1)))
(assert (and (= x8_4 ((_ sign_extend 1) ((_ extract 63 1) x8_3))) (= dc_48 ((_ zero_extend 63) ((_ extract 0 0) x8_3)))))
(assert true)
(assert (= x10_3 (ite (= ne_2 #b1) x7_4 #x0000000000000000)))
(assert (and (= ge_4 ((_ extract 63 63) x3_3)) (= dc_49 ((_ extract 62 0) x3_3))))
(assert (= ge_5 (bvnot ge_4)))
(assert (= ge_6 (ite (= ne_2 #b1) ge_5 #b0)))
(assert (and (= dc_50 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_4 (ite (= ge_6 #b1) x3_neg_2 x3_3)))
(assert (and (= dc_51 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_4 (ite (= ge_6 #b1) x10_neg_2 x10_3)))
(assert (= x7_5 (ite (= ge_6 #b1) x8_4 x7_4)))
(assert (and (= dc_52 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4)))) (= x8_5 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4))))))
(assert (= x3_5 (bvadd x3_4 #x0000000000000002)))
(assert (and (= dc_53 ((_ extract 63 2) x8_5)) (= x8_lo_3 ((_ extract 1 0) x8_5))))
(assert (and (= x8_target_2 ((_ extract 1 1) x8_lo_3)) (= dc_54 ((_ extract 0 0) x8_lo_3))))
(assert (= ne_3 (bvand x8_target_2 #b1)))
(assert (and (= x8_6 ((_ sign_extend 1) ((_ extract 63 1) x8_5))) (= dc_55 ((_ zero_extend 63) ((_ extract 0 0) x8_5)))))
(assert true)
(assert (= x10_5 (ite (= ne_3 #b1) x7_5 #x0000000000000000)))
(assert (and (= ge_7 ((_ extract 63 63) x3_5)) (= dc_56 ((_ extract 62 0) x3_5))))
(assert (= ge_8 (bvnot ge_7)))
(assert (= ge_9 (ite (= ne_3 #b1) ge_8 #b0)))
(assert (and (= dc_57 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_6 (ite (= ge_9 #b1) x3_neg_3 x3_5)))
(assert (and (= dc_58 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_6 (ite (= ge_9 #b1) x10_neg_3 x10_5)))
(assert (= x7_6 (ite (= ge_9 #b1) x8_6 x7_5)))
(assert (and (= dc_59 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6)))) (= x8_7 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6))))))
(assert (= x3_7 (bvadd x3_6 #x0000000000000002)))
(assert (and (= dc_60 ((_ extract 63 2) x8_7)) (= x8_lo_4 ((_ extract 1 0) x8_7))))
(assert (and (= x8_target_3 ((_ extract 1 1) x8_lo_4)) (= dc_61 ((_ extract 0 0) x8_lo_4))))
(assert (= ne_4 (bvand x8_target_3 #b1)))
(assert (and (= x8_8 ((_ sign_extend 1) ((_ extract 63 1) x8_7))) (= dc_62 ((_ zero_extend 63) ((_ extract 0 0) x8_7)))))
(assert true)
(assert (= x10_7 (ite (= ne_4 #b1) x7_6 #x0000000000000000)))
(assert (and (= ge_10 ((_ extract 63 63) x3_7)) (= dc_63 ((_ extract 62 0) x3_7))))
(assert (= ge_11 (bvnot ge_10)))
(assert (= ge_12 (ite (= ne_4 #b1) ge_11 #b0)))
(assert (and (= dc_64 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_7))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_4 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_7))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_8 (ite (= ge_12 #b1) x3_neg_4 x3_7)))
(assert (and (= dc_65 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_7))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_4 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_7))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_8 (ite (= ge_12 #b1) x10_neg_4 x10_7)))
(assert (= x7_7 (ite (= ge_12 #b1) x8_8 x7_6)))
(assert (and (= dc_66 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_8) ((_ zero_extend 1) x10_8)))) (= x8_9 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_8) ((_ zero_extend 1) x10_8))))))
(assert (= x3_9 (bvadd x3_8 #x0000000000000002)))
(assert (and (= dc_67 ((_ extract 63 2) x8_9)) (= x8_lo_5 ((_ extract 1 0) x8_9))))
(assert (and (= x8_target_4 ((_ extract 1 1) x8_lo_5)) (= dc_68 ((_ extract 0 0) x8_lo_5))))
(assert (= ne_5 (bvand x8_target_4 #b1)))
(assert (and (= x8_10 ((_ sign_extend 1) ((_ extract 63 1) x8_9))) (= dc_69 ((_ zero_extend 63) ((_ extract 0 0) x8_9)))))
(assert true)
(assert (= x10_9 (ite (= ne_5 #b1) x7_7 #x0000000000000000)))
(assert (and (= ge_13 ((_ extract 63 63) x3_9)) (= dc_70 ((_ extract 62 0) x3_9))))
(assert (= ge_14 (bvnot ge_13)))
(assert (= ge_15 (ite (= ne_5 #b1) ge_14 #b0)))
(assert (and (= dc_71 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_9))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_5 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_9))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_10 (ite (= ge_15 #b1) x3_neg_5 x3_9)))
(assert (and (= dc_72 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_9))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_5 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_9))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_10 (ite (= ge_15 #b1) x10_neg_5 x10_9)))
(assert (= x7_8 (ite (= ge_15 #b1) x8_10 x7_7)))
(assert (and (= dc_73 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_10) ((_ zero_extend 1) x10_10)))) (= x8_11 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_10) ((_ zero_extend 1) x10_10))))))
(assert (= x3_11 (bvadd x3_10 #x0000000000000002)))
(assert (and (= dc_74 ((_ extract 63 2) x8_11)) (= x8_lo_6 ((_ extract 1 0) x8_11))))
(assert (and (= x8_target_5 ((_ extract 1 1) x8_lo_6)) (= dc_75 ((_ extract 0 0) x8_lo_6))))
(assert (= ne_6 (bvand x8_target_5 #b1)))
(assert (and (= x8_12 ((_ sign_extend 1) ((_ extract 63 1) x8_11))) (= dc_76 ((_ zero_extend 63) ((_ extract 0 0) x8_11)))))
(assert true)
(assert (= x10_11 (ite (= ne_6 #b1) x7_8 #x0000000000000000)))
(assert (and (= ge_16 ((_ extract 63 63) x3_11)) (= dc_77 ((_ extract 62 0) x3_11))))
(assert (= ge_17 (bvnot ge_16)))
(assert (= ge_18 (ite (= ne_6 #b1) ge_17 #b0)))
(assert (and (= dc_78 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_11))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_6 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_11))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_12 (ite (= ge_18 #b1) x3_neg_6 x3_11)))
(assert (and (= dc_79 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_11))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_6 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_11))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_12 (ite (= ge_18 #b1) x10_neg_6 x10_11)))
(assert (= x7_9 (ite (= ge_18 #b1) x8_12 x7_8)))
(assert (and (= dc_80 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_12) ((_ zero_extend 1) x10_12)))) (= x8_13 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_12) ((_ zero_extend 1) x10_12))))))
(assert (= x3_13 (bvadd x3_12 #x0000000000000002)))
(assert (and (= dc_81 ((_ extract 63 2) x8_13)) (= x8_lo_7 ((_ extract 1 0) x8_13))))
(assert (and (= x8_target_6 ((_ extract 1 1) x8_lo_7)) (= dc_82 ((_ extract 0 0) x8_lo_7))))
(assert (= ne_7 (bvand x8_target_6 #b1)))
(assert (and (= x8_14 ((_ sign_extend 1) ((_ extract 63 1) x8_13))) (= dc_83 ((_ zero_extend 63) ((_ extract 0 0) x8_13)))))
(assert true)
(assert (= x10_13 (ite (= ne_7 #b1) x7_9 #x0000000000000000)))
(assert (and (= ge_19 ((_ extract 63 63) x3_13)) (= dc_84 ((_ extract 62 0) x3_13))))
(assert (= ge_20 (bvnot ge_19)))
(assert (= ge_21 (ite (= ne_7 #b1) ge_20 #b0)))
(assert (and (= dc_85 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_13))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_7 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_13))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_14 (ite (= ge_21 #b1) x3_neg_7 x3_13)))
(assert (and (= dc_86 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_13))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_7 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_13))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_14 (ite (= ge_21 #b1) x10_neg_7 x10_13)))
(assert (= x7_10 (ite (= ge_21 #b1) x8_14 x7_9)))
(assert (and (= dc_87 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_14) ((_ zero_extend 1) x10_14)))) (= x8_15 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_14) ((_ zero_extend 1) x10_14))))))
(assert (= x3_15 (bvadd x3_14 #x0000000000000002)))
(assert (and (= dc_88 ((_ extract 63 2) x8_15)) (= x8_lo_8 ((_ extract 1 0) x8_15))))
(assert (and (= x8_target_7 ((_ extract 1 1) x8_lo_8)) (= dc_89 ((_ extract 0 0) x8_lo_8))))
(assert (= ne_8 (bvand x8_target_7 #b1)))
(assert (and (= x8_16 ((_ sign_extend 1) ((_ extract 63 1) x8_15))) (= dc_90 ((_ zero_extend 63) ((_ extract 0 0) x8_15)))))
(assert true)
(assert (= x10_15 (ite (= ne_8 #b1) x7_10 #x0000000000000000)))
(assert (and (= ge_22 ((_ extract 63 63) x3_15)) (= dc_91 ((_ extract 62 0) x3_15))))
(assert (= ge_23 (bvnot ge_22)))
(assert (= ge_24 (ite (= ne_8 #b1) ge_23 #b0)))
(assert (and (= dc_92 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_15))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_8 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_15))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_16 (ite (= ge_24 #b1) x3_neg_8 x3_15)))
(assert (and (= dc_93 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_15))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_8 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_15))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_16 (ite (= ge_24 #b1) x10_neg_8 x10_15)))
(assert (= x7_11 (ite (= ge_24 #b1) x8_16 x7_10)))
(assert (and (= dc_94 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_16) ((_ zero_extend 1) x10_16)))) (= x8_17 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_16) ((_ zero_extend 1) x10_16))))))
(assert (= x3_17 (bvadd x3_16 #x0000000000000002)))
(assert (and (= dc_95 ((_ extract 63 2) x8_17)) (= x8_lo_9 ((_ extract 1 0) x8_17))))
(assert (and (= x8_target_8 ((_ extract 1 1) x8_lo_9)) (= dc_96 ((_ extract 0 0) x8_lo_9))))
(assert (= ne_9 (bvand x8_target_8 #b1)))
(assert (and (= x8_18 ((_ sign_extend 1) ((_ extract 63 1) x8_17))) (= dc_97 ((_ zero_extend 63) ((_ extract 0 0) x8_17)))))
(assert true)
(assert (= x10_17 (ite (= ne_9 #b1) x7_11 #x0000000000000000)))
(assert (and (= ge_25 ((_ extract 63 63) x3_17)) (= dc_98 ((_ extract 62 0) x3_17))))
(assert (= ge_26 (bvnot ge_25)))
(assert (= ge_27 (ite (= ne_9 #b1) ge_26 #b0)))
(assert (and (= dc_99 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_17))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_9 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_17))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_18 (ite (= ge_27 #b1) x3_neg_9 x3_17)))
(assert (and (= dc_100 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_17))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_9 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_17))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_18 (ite (= ge_27 #b1) x10_neg_9 x10_17)))
(assert (= x7_12 (ite (= ge_27 #b1) x8_18 x7_11)))
(assert (and (= dc_101 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_18) ((_ zero_extend 1) x10_18)))) (= x8_19 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_18) ((_ zero_extend 1) x10_18))))))
(assert (= x3_19 (bvadd x3_18 #x0000000000000002)))
(assert (and (= dc_102 ((_ extract 63 2) x8_19)) (= x8_lo_10 ((_ extract 1 0) x8_19))))
(assert (and (= x8_target_9 ((_ extract 1 1) x8_lo_10)) (= dc_103 ((_ extract 0 0) x8_lo_10))))
(assert (= ne_10 (bvand x8_target_9 #b1)))
(assert (and (= x8_20 ((_ sign_extend 1) ((_ extract 63 1) x8_19))) (= dc_104 ((_ zero_extend 63) ((_ extract 0 0) x8_19)))))
(assert true)
(assert (= x10_19 (ite (= ne_10 #b1) x7_12 #x0000000000000000)))
(assert (and (= ge_28 ((_ extract 63 63) x3_19)) (= dc_105 ((_ extract 62 0) x3_19))))
(assert (= ge_29 (bvnot ge_28)))
(assert (= ge_30 (ite (= ne_10 #b1) ge_29 #b0)))
(assert (and (= dc_106 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_19))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_10 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_19))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_20 (ite (= ge_30 #b1) x3_neg_10 x3_19)))
(assert (and (= dc_107 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_19))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_10 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_19))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_20 (ite (= ge_30 #b1) x10_neg_10 x10_19)))
(assert (= x7_13 (ite (= ge_30 #b1) x8_20 x7_12)))
(assert (and (= dc_108 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_20) ((_ zero_extend 1) x10_20)))) (= x8_21 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_20) ((_ zero_extend 1) x10_20))))))
(assert (= x3_21 (bvadd x3_20 #x0000000000000002)))
(assert (and (= dc_109 ((_ extract 63 2) x8_21)) (= x8_lo_11 ((_ extract 1 0) x8_21))))
(assert (and (= x8_target_10 ((_ extract 1 1) x8_lo_11)) (= dc_110 ((_ extract 0 0) x8_lo_11))))
(assert (= ne_11 (bvand x8_target_10 #b1)))
(assert (and (= x8_22 ((_ sign_extend 1) ((_ extract 63 1) x8_21))) (= dc_111 ((_ zero_extend 63) ((_ extract 0 0) x8_21)))))
(assert true)
(assert (= x10_21 (ite (= ne_11 #b1) x7_13 #x0000000000000000)))
(assert (and (= ge_31 ((_ extract 63 63) x3_21)) (= dc_112 ((_ extract 62 0) x3_21))))
(assert (= ge_32 (bvnot ge_31)))
(assert (= ge_33 (ite (= ne_11 #b1) ge_32 #b0)))
(assert (and (= dc_113 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_21))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_11 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_21))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_22 (ite (= ge_33 #b1) x3_neg_11 x3_21)))
(assert (and (= dc_114 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_21))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_11 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_21))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_22 (ite (= ge_33 #b1) x10_neg_11 x10_21)))
(assert (= x7_14 (ite (= ge_33 #b1) x8_22 x7_13)))
(assert (and (= dc_115 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_22) ((_ zero_extend 1) x10_22)))) (= x8_23 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_22) ((_ zero_extend 1) x10_22))))))
(assert (= x3_23 (bvadd x3_22 #x0000000000000002)))
(assert (and (= dc_116 ((_ extract 63 2) x8_23)) (= x8_lo_12 ((_ extract 1 0) x8_23))))
(assert (and (= x8_target_11 ((_ extract 1 1) x8_lo_12)) (= dc_117 ((_ extract 0 0) x8_lo_12))))
(assert (= ne_12 (bvand x8_target_11 #b1)))
(assert (and (= x8_24 ((_ sign_extend 1) ((_ extract 63 1) x8_23))) (= dc_118 ((_ zero_extend 63) ((_ extract 0 0) x8_23)))))
(assert true)
(assert (= x10_23 (ite (= ne_12 #b1) x7_14 #x0000000000000000)))
(assert (and (= ge_34 ((_ extract 63 63) x3_23)) (= dc_119 ((_ extract 62 0) x3_23))))
(assert (= ge_35 (bvnot ge_34)))
(assert (= ge_36 (ite (= ne_12 #b1) ge_35 #b0)))
(assert (and (= dc_120 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_23))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_12 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_23))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_24 (ite (= ge_36 #b1) x3_neg_12 x3_23)))
(assert (and (= dc_121 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_23))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_12 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_23))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_24 (ite (= ge_36 #b1) x10_neg_12 x10_23)))
(assert (= x7_15 (ite (= ge_36 #b1) x8_24 x7_14)))
(assert (and (= dc_122 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_24) ((_ zero_extend 1) x10_24)))) (= x8_25 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_24) ((_ zero_extend 1) x10_24))))))
(assert (= x3_25 (bvadd x3_24 #x0000000000000002)))
(assert (and (= dc_123 ((_ extract 63 2) x8_25)) (= x8_lo_13 ((_ extract 1 0) x8_25))))
(assert (and (= x8_target_12 ((_ extract 1 1) x8_lo_13)) (= dc_124 ((_ extract 0 0) x8_lo_13))))
(assert (= ne_13 (bvand x8_target_12 #b1)))
(assert (and (= x8_26 ((_ sign_extend 1) ((_ extract 63 1) x8_25))) (= dc_125 ((_ zero_extend 63) ((_ extract 0 0) x8_25)))))
(assert true)
(assert (= x10_25 (ite (= ne_13 #b1) x7_15 #x0000000000000000)))
(assert (and (= ge_37 ((_ extract 63 63) x3_25)) (= dc_126 ((_ extract 62 0) x3_25))))
(assert (= ge_38 (bvnot ge_37)))
(assert (= ge_39 (ite (= ne_13 #b1) ge_38 #b0)))
(assert (and (= dc_127 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_25))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_13 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_25))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_26 (ite (= ge_39 #b1) x3_neg_13 x3_25)))
(assert (and (= dc_128 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_25))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_13 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_25))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_26 (ite (= ge_39 #b1) x10_neg_13 x10_25)))
(assert (= x7_16 (ite (= ge_39 #b1) x8_26 x7_15)))
(assert (and (= dc_129 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_26) ((_ zero_extend 1) x10_26)))) (= x8_27 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_26) ((_ zero_extend 1) x10_26))))))
(assert (= x3_27 (bvadd x3_26 #x0000000000000002)))
(assert (and (= dc_130 ((_ extract 63 2) x8_27)) (= x8_lo_14 ((_ extract 1 0) x8_27))))
(assert (and (= x8_target_13 ((_ extract 1 1) x8_lo_14)) (= dc_131 ((_ extract 0 0) x8_lo_14))))
(assert (= ne_14 (bvand x8_target_13 #b1)))
(assert (and (= x8_28 ((_ sign_extend 1) ((_ extract 63 1) x8_27))) (= dc_132 ((_ zero_extend 63) ((_ extract 0 0) x8_27)))))
(assert true)
(assert (= x10_27 (ite (= ne_14 #b1) x7_16 #x0000000000000000)))
(assert (and (= ge_40 ((_ extract 63 63) x3_27)) (= dc_133 ((_ extract 62 0) x3_27))))
(assert (= ge_41 (bvnot ge_40)))
(assert (= ge_42 (ite (= ne_14 #b1) ge_41 #b0)))
(assert (and (= dc_134 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_27))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_14 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_27))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_28 (ite (= ge_42 #b1) x3_neg_14 x3_27)))
(assert (and (= dc_135 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_27))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_14 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_27))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_28 (ite (= ge_42 #b1) x10_neg_14 x10_27)))
(assert (= x7_17 (ite (= ge_42 #b1) x8_28 x7_16)))
(assert (and (= dc_136 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_28) ((_ zero_extend 1) x10_28)))) (= x8_29 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_28) ((_ zero_extend 1) x10_28))))))
(assert (= x3_29 (bvadd x3_28 #x0000000000000002)))
(assert (and (= dc_137 ((_ extract 63 2) x8_29)) (= x8_lo_15 ((_ extract 1 0) x8_29))))
(assert (and (= x8_target_14 ((_ extract 1 1) x8_lo_15)) (= dc_138 ((_ extract 0 0) x8_lo_15))))
(assert (= ne_15 (bvand x8_target_14 #b1)))
(assert (and (= x8_30 ((_ sign_extend 1) ((_ extract 63 1) x8_29))) (= dc_139 ((_ zero_extend 63) ((_ extract 0 0) x8_29)))))
(assert true)
(assert (= x10_29 (ite (= ne_15 #b1) x7_17 #x0000000000000000)))
(assert (and (= ge_43 ((_ extract 63 63) x3_29)) (= dc_140 ((_ extract 62 0) x3_29))))
(assert (= ge_44 (bvnot ge_43)))
(assert (= ge_45 (ite (= ne_15 #b1) ge_44 #b0)))
(assert (and (= dc_141 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_29))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_15 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_29))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_30 (ite (= ge_45 #b1) x3_neg_15 x3_29)))
(assert (and (= dc_142 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_29))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_15 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_29))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_30 (ite (= ge_45 #b1) x10_neg_15 x10_29)))
(assert (= x7_18 (ite (= ge_45 #b1) x8_30 x7_17)))
(assert (and (= dc_143 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_30) ((_ zero_extend 1) x10_30)))) (= x8_31 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_30) ((_ zero_extend 1) x10_30))))))
(assert (= x3_31 (bvadd x3_30 #x0000000000000002)))
(assert (and (= dc_144 ((_ extract 63 2) x8_31)) (= x8_lo_16 ((_ extract 1 0) x8_31))))
(assert (and (= x8_target_15 ((_ extract 1 1) x8_lo_16)) (= dc_145 ((_ extract 0 0) x8_lo_16))))
(assert (= ne_16 (bvand x8_target_15 #b1)))
(assert (and (= x8_32 ((_ sign_extend 1) ((_ extract 63 1) x8_31))) (= dc_146 ((_ zero_extend 63) ((_ extract 0 0) x8_31)))))
(assert true)
(assert (= x10_31 (ite (= ne_16 #b1) x7_18 #x0000000000000000)))
(assert (and (= ge_46 ((_ extract 63 63) x3_31)) (= dc_147 ((_ extract 62 0) x3_31))))
(assert (= ge_47 (bvnot ge_46)))
(assert (= ge_48 (ite (= ne_16 #b1) ge_47 #b0)))
(assert (and (= dc_148 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_31))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_16 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_31))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_32 (ite (= ge_48 #b1) x3_neg_16 x3_31)))
(assert (and (= dc_149 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_31))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_16 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_31))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_32 (ite (= ge_48 #b1) x10_neg_16 x10_31)))
(assert (= x7_19 (ite (= ge_48 #b1) x8_32 x7_18)))
(assert (and (= dc_150 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_32) ((_ zero_extend 1) x10_32)))) (= x8_33 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_32) ((_ zero_extend 1) x10_32))))))
(assert (= x3_33 (bvadd x3_32 #x0000000000000002)))
(assert (and (= dc_151 ((_ extract 63 2) x8_33)) (= x8_lo_17 ((_ extract 1 0) x8_33))))
(assert (and (= x8_target_16 ((_ extract 1 1) x8_lo_17)) (= dc_152 ((_ extract 0 0) x8_lo_17))))
(assert (= ne_17 (bvand x8_target_16 #b1)))
(assert (and (= x8_34 ((_ sign_extend 1) ((_ extract 63 1) x8_33))) (= dc_153 ((_ zero_extend 63) ((_ extract 0 0) x8_33)))))
(assert true)
(assert (= x10_33 (ite (= ne_17 #b1) x7_19 #x0000000000000000)))
(assert (and (= ge_49 ((_ extract 63 63) x3_33)) (= dc_154 ((_ extract 62 0) x3_33))))
(assert (= ge_50 (bvnot ge_49)))
(assert (= ge_51 (ite (= ne_17 #b1) ge_50 #b0)))
(assert (and (= dc_155 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_33))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_17 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_33))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_34 (ite (= ge_51 #b1) x3_neg_17 x3_33)))
(assert (and (= dc_156 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_33))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_17 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_33))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_34 (ite (= ge_51 #b1) x10_neg_17 x10_33)))
(assert (= x7_20 (ite (= ge_51 #b1) x8_34 x7_19)))
(assert (and (= dc_157 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_34) ((_ zero_extend 1) x10_34)))) (= x8_35 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_34) ((_ zero_extend 1) x10_34))))))
(assert (= x3_35 (bvadd x3_34 #x0000000000000002)))
(assert (and (= dc_158 ((_ extract 63 2) x8_35)) (= x8_lo_18 ((_ extract 1 0) x8_35))))
(assert (and (= x8_target_17 ((_ extract 1 1) x8_lo_18)) (= dc_159 ((_ extract 0 0) x8_lo_18))))
(assert (= ne_18 (bvand x8_target_17 #b1)))
(assert (and (= x8_36 ((_ sign_extend 1) ((_ extract 63 1) x8_35))) (= dc_160 ((_ zero_extend 63) ((_ extract 0 0) x8_35)))))
(assert true)
(assert (= x10_35 (ite (= ne_18 #b1) x7_20 #x0000000000000000)))
(assert (and (= ge_52 ((_ extract 63 63) x3_35)) (= dc_161 ((_ extract 62 0) x3_35))))
(assert (= ge_53 (bvnot ge_52)))
(assert (= ge_54 (ite (= ne_18 #b1) ge_53 #b0)))
(assert (and (= dc_162 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_35))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_18 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_35))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_36 (ite (= ge_54 #b1) x3_neg_18 x3_35)))
(assert (and (= dc_163 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_35))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_18 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_35))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_36 (ite (= ge_54 #b1) x10_neg_18 x10_35)))
(assert (= x7_21 (ite (= ge_54 #b1) x8_36 x7_20)))
(assert (and (= dc_164 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_36) ((_ zero_extend 1) x10_36)))) (= x8_37 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_36) ((_ zero_extend 1) x10_36))))))
(assert (= x3_37 (bvadd x3_36 #x0000000000000002)))
(assert (and (= dc_165 ((_ extract 63 2) x8_37)) (= x8_lo_19 ((_ extract 1 0) x8_37))))
(assert (and (= x8_target_18 ((_ extract 1 1) x8_lo_19)) (= dc_166 ((_ extract 0 0) x8_lo_19))))
(assert (= ne_19 (bvand x8_target_18 #b1)))
(assert (and (= x8_38 ((_ sign_extend 1) ((_ extract 63 1) x8_37))) (= dc_167 ((_ zero_extend 63) ((_ extract 0 0) x8_37)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_36) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_21 x7_20)) (= (bvmul x8_38 #x0000000000000002) x8_36)) (= x3_37 (bvadd #x0000000000000002 x3_35))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_36) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_35 #x0000000000000000)) (= x7_21 x7_20)) (= (bvmul x8_38 #x0000000000000002) (bvadd x8_36 x7_20))) (= x3_37 (bvadd #x0000000000000002 x3_35)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_36) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_35 #x0000000000000000)) (= x7_21 x8_36)) (= (bvmul x8_38 #x0000000000000002) (bvsub x8_36 x7_20))) (= x3_37 (bvsub #x0000000000000002 x3_35))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_68e3f3.smt2
Execution time of boolector: 2.2681 seconds
OUTPUT FROM boolector:
unsat

=== Cut #6 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #6
; Range assertion #43: or [and [smod (sub (uext x8_50 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_29 = x7_28, mul x8_52 2@64 = x8_50, x3_49 = add 2@64 x3_47], and [smod (sub (uext x8_50 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_47 <s 0@64, x7_29 = x7_28, mul x8_52 2@64 = add x8_50 x7_28, x3_49 = add 2@64 x3_47], and [smod (sub (uext x8_50 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_47 >=s 0@64, x7_29 = x8_50, mul x8_52 2@64 = sub x8_50 x7_28, x3_49 = sub 2@64 x3_47]]
; Range condition: ((x8_50@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_29 = x7_28 /\ x8_52 * 2 = x8_50 /\ x3_49 = 2 + x3_47 \/ ((x8_50@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_47 <s 0 /\ x7_29 = x7_28 /\ x8_52 * 2 = x8_50 + x7_28 /\ x3_49 = 2 + x3_47 \/ ((x8_50@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_47 >=s 0 /\ x7_29 = x8_50 /\ x8_52 * 2 = x8_50 - x7_28 /\ x3_49 = 2 - x3_47
; Output file: /tmp/outputqfbv_0710ff.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_23 () (_ BitVec 1))
(declare-fun x8_target_22 () (_ BitVec 1))
(declare-fun x8_target_21 () (_ BitVec 1))
(declare-fun x8_target_20 () (_ BitVec 1))
(declare-fun x8_lo_25 () (_ BitVec 2))
(declare-fun x8_lo_24 () (_ BitVec 2))
(declare-fun x8_lo_23 () (_ BitVec 2))
(declare-fun x8_lo_22 () (_ BitVec 2))
(declare-fun x8_lo_21 () (_ BitVec 1))
(declare-fun x8_52 () (_ BitVec 64))
(declare-fun x8_51 () (_ BitVec 64))
(declare-fun x8_50 () (_ BitVec 64))
(declare-fun x8_49 () (_ BitVec 64))
(declare-fun x8_48 () (_ BitVec 64))
(declare-fun x8_47 () (_ BitVec 64))
(declare-fun x8_46 () (_ BitVec 64))
(declare-fun x8_45 () (_ BitVec 64))
(declare-fun x8_44 () (_ BitVec 64))
(declare-fun x7_29 () (_ BitVec 64))
(declare-fun x7_28 () (_ BitVec 64))
(declare-fun x7_27 () (_ BitVec 64))
(declare-fun x7_26 () (_ BitVec 64))
(declare-fun x7_25 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_24 () (_ BitVec 64))
(declare-fun x3_neg_23 () (_ BitVec 64))
(declare-fun x3_neg_22 () (_ BitVec 64))
(declare-fun x3_neg_21 () (_ BitVec 64))
(declare-fun x3_49 () (_ BitVec 64))
(declare-fun x3_48 () (_ BitVec 64))
(declare-fun x3_47 () (_ BitVec 64))
(declare-fun x3_46 () (_ BitVec 64))
(declare-fun x3_45 () (_ BitVec 64))
(declare-fun x3_44 () (_ BitVec 64))
(declare-fun x3_43 () (_ BitVec 64))
(declare-fun x3_42 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x10_neg_24 () (_ BitVec 64))
(declare-fun x10_neg_23 () (_ BitVec 64))
(declare-fun x10_neg_22 () (_ BitVec 64))
(declare-fun x10_neg_21 () (_ BitVec 64))
(declare-fun x10_50 () (_ BitVec 64))
(declare-fun x10_49 () (_ BitVec 64))
(declare-fun x10_48 () (_ BitVec 64))
(declare-fun x10_47 () (_ BitVec 64))
(declare-fun x10_46 () (_ BitVec 64))
(declare-fun x10_45 () (_ BitVec 64))
(declare-fun x10_44 () (_ BitVec 64))
(declare-fun x10_43 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun ne_25 () (_ BitVec 1))
(declare-fun ne_24 () (_ BitVec 1))
(declare-fun ne_23 () (_ BitVec 1))
(declare-fun ne_22 () (_ BitVec 1))
(declare-fun ne_21 () (_ BitVec 1))
(declare-fun ge_72 () (_ BitVec 1))
(declare-fun ge_71 () (_ BitVec 1))
(declare-fun ge_70 () (_ BitVec 1))
(declare-fun ge_69 () (_ BitVec 1))
(declare-fun ge_68 () (_ BitVec 1))
(declare-fun ge_67 () (_ BitVec 1))
(declare-fun ge_66 () (_ BitVec 1))
(declare-fun ge_65 () (_ BitVec 1))
(declare-fun ge_64 () (_ BitVec 1))
(declare-fun ge_63 () (_ BitVec 1))
(declare-fun ge_62 () (_ BitVec 1))
(declare-fun ge_61 () (_ BitVec 1))
(declare-fun dc_216 () (_ BitVec 64))
(declare-fun dc_215 () (_ BitVec 1))
(declare-fun dc_214 () (_ BitVec 62))
(declare-fun dc_213 () (_ BitVec 1))
(declare-fun dc_212 () (_ BitVec 1))
(declare-fun dc_211 () (_ BitVec 1))
(declare-fun dc_210 () (_ BitVec 63))
(declare-fun dc_209 () (_ BitVec 64))
(declare-fun dc_208 () (_ BitVec 1))
(declare-fun dc_207 () (_ BitVec 62))
(declare-fun dc_206 () (_ BitVec 1))
(declare-fun dc_205 () (_ BitVec 1))
(declare-fun dc_204 () (_ BitVec 1))
(declare-fun dc_203 () (_ BitVec 63))
(declare-fun dc_202 () (_ BitVec 64))
(declare-fun dc_201 () (_ BitVec 1))
(declare-fun dc_200 () (_ BitVec 62))
(declare-fun dc_199 () (_ BitVec 1))
(declare-fun dc_198 () (_ BitVec 1))
(declare-fun dc_197 () (_ BitVec 1))
(declare-fun dc_196 () (_ BitVec 63))
(declare-fun dc_195 () (_ BitVec 64))
(declare-fun dc_194 () (_ BitVec 1))
(declare-fun dc_193 () (_ BitVec 62))
(declare-fun dc_192 () (_ BitVec 1))
(declare-fun dc_191 () (_ BitVec 1))
(declare-fun dc_190 () (_ BitVec 1))
(declare-fun dc_189 () (_ BitVec 63))
(declare-fun dc_188 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_25 (bvadd (bvadd neg_f_0_low60_20_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_44 (bvadd (bvadd neg_g_0_low60_20_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_0_1)) (bvsle neg_f_0_low60_20_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_0_1)) (bvsle neg_g_0_low60_20_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_25) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_188 ((_ extract 63 1) x8_44)) (= x8_lo_21 ((_ extract 0 0) x8_44))))
(assert (= ne_21 (bvand x8_lo_21 #b1)))
(assert (= x10_43 (ite (= ne_21 #b1) x7_25 #x0000000000000000)))
(assert (and (= ge_61 ((_ extract 63 63) x3_41)) (= dc_189 ((_ extract 62 0) x3_41))))
(assert (= ge_62 (bvnot ge_61)))
(assert (= ge_63 (ite (= ne_21 #b1) ge_62 #b0)))
(assert (and (= dc_190 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_42 (ite (= ge_63 #b1) x3_neg_21 x3_41)))
(assert (and (= dc_191 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_44 (ite (= ge_63 #b1) x10_neg_21 x10_43)))
(assert (= x7_26 (ite (= ge_63 #b1) x8_44 x7_25)))
(assert (and (= dc_192 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44)))) (= x8_45 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44))))))
(assert (= x3_43 (bvadd x3_42 #x0000000000000002)))
(assert (and (= dc_193 ((_ extract 63 2) x8_45)) (= x8_lo_22 ((_ extract 1 0) x8_45))))
(assert (and (= x8_target_20 ((_ extract 1 1) x8_lo_22)) (= dc_194 ((_ extract 0 0) x8_lo_22))))
(assert (= ne_22 (bvand x8_target_20 #b1)))
(assert (and (= x8_46 ((_ sign_extend 1) ((_ extract 63 1) x8_45))) (= dc_195 ((_ zero_extend 63) ((_ extract 0 0) x8_45)))))
(assert true)
(assert (= x10_45 (ite (= ne_22 #b1) x7_26 #x0000000000000000)))
(assert (and (= ge_64 ((_ extract 63 63) x3_43)) (= dc_196 ((_ extract 62 0) x3_43))))
(assert (= ge_65 (bvnot ge_64)))
(assert (= ge_66 (ite (= ne_22 #b1) ge_65 #b0)))
(assert (and (= dc_197 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_44 (ite (= ge_66 #b1) x3_neg_22 x3_43)))
(assert (and (= dc_198 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_46 (ite (= ge_66 #b1) x10_neg_22 x10_45)))
(assert (= x7_27 (ite (= ge_66 #b1) x8_46 x7_26)))
(assert (and (= dc_199 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46)))) (= x8_47 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46))))))
(assert (= x3_45 (bvadd x3_44 #x0000000000000002)))
(assert (and (= dc_200 ((_ extract 63 2) x8_47)) (= x8_lo_23 ((_ extract 1 0) x8_47))))
(assert (and (= x8_target_21 ((_ extract 1 1) x8_lo_23)) (= dc_201 ((_ extract 0 0) x8_lo_23))))
(assert (= ne_23 (bvand x8_target_21 #b1)))
(assert (and (= x8_48 ((_ sign_extend 1) ((_ extract 63 1) x8_47))) (= dc_202 ((_ zero_extend 63) ((_ extract 0 0) x8_47)))))
(assert true)
(assert (= x10_47 (ite (= ne_23 #b1) x7_27 #x0000000000000000)))
(assert (and (= ge_67 ((_ extract 63 63) x3_45)) (= dc_203 ((_ extract 62 0) x3_45))))
(assert (= ge_68 (bvnot ge_67)))
(assert (= ge_69 (ite (= ne_23 #b1) ge_68 #b0)))
(assert (and (= dc_204 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_46 (ite (= ge_69 #b1) x3_neg_23 x3_45)))
(assert (and (= dc_205 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_48 (ite (= ge_69 #b1) x10_neg_23 x10_47)))
(assert (= x7_28 (ite (= ge_69 #b1) x8_48 x7_27)))
(assert (and (= dc_206 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48)))) (= x8_49 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48))))))
(assert (= x3_47 (bvadd x3_46 #x0000000000000002)))
(assert (and (= dc_207 ((_ extract 63 2) x8_49)) (= x8_lo_24 ((_ extract 1 0) x8_49))))
(assert (and (= x8_target_22 ((_ extract 1 1) x8_lo_24)) (= dc_208 ((_ extract 0 0) x8_lo_24))))
(assert (= ne_24 (bvand x8_target_22 #b1)))
(assert (and (= x8_50 ((_ sign_extend 1) ((_ extract 63 1) x8_49))) (= dc_209 ((_ zero_extend 63) ((_ extract 0 0) x8_49)))))
(assert true)
(assert (= x10_49 (ite (= ne_24 #b1) x7_28 #x0000000000000000)))
(assert (and (= ge_70 ((_ extract 63 63) x3_47)) (= dc_210 ((_ extract 62 0) x3_47))))
(assert (= ge_71 (bvnot ge_70)))
(assert (= ge_72 (ite (= ne_24 #b1) ge_71 #b0)))
(assert (and (= dc_211 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_47))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_24 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_47))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_48 (ite (= ge_72 #b1) x3_neg_24 x3_47)))
(assert (and (= dc_212 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_49))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_24 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_49))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_50 (ite (= ge_72 #b1) x10_neg_24 x10_49)))
(assert (= x7_29 (ite (= ge_72 #b1) x8_50 x7_28)))
(assert (and (= dc_213 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_50) ((_ zero_extend 1) x10_50)))) (= x8_51 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_50) ((_ zero_extend 1) x10_50))))))
(assert (= x3_49 (bvadd x3_48 #x0000000000000002)))
(assert (and (= dc_214 ((_ extract 63 2) x8_51)) (= x8_lo_25 ((_ extract 1 0) x8_51))))
(assert (and (= x8_target_23 ((_ extract 1 1) x8_lo_25)) (= dc_215 ((_ extract 0 0) x8_lo_25))))
(assert (= ne_25 (bvand x8_target_23 #b1)))
(assert (and (= x8_52 ((_ sign_extend 1) ((_ extract 63 1) x8_51))) (= dc_216 ((_ zero_extend 63) ((_ extract 0 0) x8_51)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_50) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_29 x7_28)) (= (bvmul x8_52 #x0000000000000002) x8_50)) (= x3_49 (bvadd #x0000000000000002 x3_47))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_50) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_47 #x0000000000000000)) (= x7_29 x7_28)) (= (bvmul x8_52 #x0000000000000002) (bvadd x8_50 x7_28))) (= x3_49 (bvadd #x0000000000000002 x3_47)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_50) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_47 #x0000000000000000)) (= x7_29 x8_50)) (= (bvmul x8_52 #x0000000000000002) (bvsub x8_50 x7_28))) (= x3_49 (bvsub #x0000000000000002 x3_47))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_5ad39b.smt2
Execution time of boolector: 0.1946 seconds
OUTPUT FROM boolector:
unsat

=== Cut #6 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #6
; Range assertion #42: or [and [smod (sub (uext x8_48 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_28 = x7_27, mul x8_50 2@64 = x8_48, x3_47 = add 2@64 x3_45], and [smod (sub (uext x8_48 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_45 <s 0@64, x7_28 = x7_27, mul x8_50 2@64 = add x8_48 x7_27, x3_47 = add 2@64 x3_45], and [smod (sub (uext x8_48 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_45 >=s 0@64, x7_28 = x8_48, mul x8_50 2@64 = sub x8_48 x7_27, x3_47 = sub 2@64 x3_45]]
; Range condition: ((x8_48@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_28 = x7_27 /\ x8_50 * 2 = x8_48 /\ x3_47 = 2 + x3_45 \/ ((x8_48@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_45 <s 0 /\ x7_28 = x7_27 /\ x8_50 * 2 = x8_48 + x7_27 /\ x3_47 = 2 + x3_45 \/ ((x8_48@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_45 >=s 0 /\ x7_28 = x8_48 /\ x8_50 * 2 = x8_48 - x7_27 /\ x3_47 = 2 - x3_45
; Output file: /tmp/outputqfbv_e5daa3.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_22 () (_ BitVec 1))
(declare-fun x8_target_21 () (_ BitVec 1))
(declare-fun x8_target_20 () (_ BitVec 1))
(declare-fun x8_lo_24 () (_ BitVec 2))
(declare-fun x8_lo_23 () (_ BitVec 2))
(declare-fun x8_lo_22 () (_ BitVec 2))
(declare-fun x8_lo_21 () (_ BitVec 1))
(declare-fun x8_50 () (_ BitVec 64))
(declare-fun x8_49 () (_ BitVec 64))
(declare-fun x8_48 () (_ BitVec 64))
(declare-fun x8_47 () (_ BitVec 64))
(declare-fun x8_46 () (_ BitVec 64))
(declare-fun x8_45 () (_ BitVec 64))
(declare-fun x8_44 () (_ BitVec 64))
(declare-fun x7_28 () (_ BitVec 64))
(declare-fun x7_27 () (_ BitVec 64))
(declare-fun x7_26 () (_ BitVec 64))
(declare-fun x7_25 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_23 () (_ BitVec 64))
(declare-fun x3_neg_22 () (_ BitVec 64))
(declare-fun x3_neg_21 () (_ BitVec 64))
(declare-fun x3_47 () (_ BitVec 64))
(declare-fun x3_46 () (_ BitVec 64))
(declare-fun x3_45 () (_ BitVec 64))
(declare-fun x3_44 () (_ BitVec 64))
(declare-fun x3_43 () (_ BitVec 64))
(declare-fun x3_42 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x10_neg_23 () (_ BitVec 64))
(declare-fun x10_neg_22 () (_ BitVec 64))
(declare-fun x10_neg_21 () (_ BitVec 64))
(declare-fun x10_48 () (_ BitVec 64))
(declare-fun x10_47 () (_ BitVec 64))
(declare-fun x10_46 () (_ BitVec 64))
(declare-fun x10_45 () (_ BitVec 64))
(declare-fun x10_44 () (_ BitVec 64))
(declare-fun x10_43 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun ne_24 () (_ BitVec 1))
(declare-fun ne_23 () (_ BitVec 1))
(declare-fun ne_22 () (_ BitVec 1))
(declare-fun ne_21 () (_ BitVec 1))
(declare-fun ge_69 () (_ BitVec 1))
(declare-fun ge_68 () (_ BitVec 1))
(declare-fun ge_67 () (_ BitVec 1))
(declare-fun ge_66 () (_ BitVec 1))
(declare-fun ge_65 () (_ BitVec 1))
(declare-fun ge_64 () (_ BitVec 1))
(declare-fun ge_63 () (_ BitVec 1))
(declare-fun ge_62 () (_ BitVec 1))
(declare-fun ge_61 () (_ BitVec 1))
(declare-fun dc_209 () (_ BitVec 64))
(declare-fun dc_208 () (_ BitVec 1))
(declare-fun dc_207 () (_ BitVec 62))
(declare-fun dc_206 () (_ BitVec 1))
(declare-fun dc_205 () (_ BitVec 1))
(declare-fun dc_204 () (_ BitVec 1))
(declare-fun dc_203 () (_ BitVec 63))
(declare-fun dc_202 () (_ BitVec 64))
(declare-fun dc_201 () (_ BitVec 1))
(declare-fun dc_200 () (_ BitVec 62))
(declare-fun dc_199 () (_ BitVec 1))
(declare-fun dc_198 () (_ BitVec 1))
(declare-fun dc_197 () (_ BitVec 1))
(declare-fun dc_196 () (_ BitVec 63))
(declare-fun dc_195 () (_ BitVec 64))
(declare-fun dc_194 () (_ BitVec 1))
(declare-fun dc_193 () (_ BitVec 62))
(declare-fun dc_192 () (_ BitVec 1))
(declare-fun dc_191 () (_ BitVec 1))
(declare-fun dc_190 () (_ BitVec 1))
(declare-fun dc_189 () (_ BitVec 63))
(declare-fun dc_188 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_25 (bvadd (bvadd neg_f_0_low60_20_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_44 (bvadd (bvadd neg_g_0_low60_20_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_0_1)) (bvsle neg_f_0_low60_20_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_0_1)) (bvsle neg_g_0_low60_20_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_25) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_188 ((_ extract 63 1) x8_44)) (= x8_lo_21 ((_ extract 0 0) x8_44))))
(assert (= ne_21 (bvand x8_lo_21 #b1)))
(assert (= x10_43 (ite (= ne_21 #b1) x7_25 #x0000000000000000)))
(assert (and (= ge_61 ((_ extract 63 63) x3_41)) (= dc_189 ((_ extract 62 0) x3_41))))
(assert (= ge_62 (bvnot ge_61)))
(assert (= ge_63 (ite (= ne_21 #b1) ge_62 #b0)))
(assert (and (= dc_190 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_42 (ite (= ge_63 #b1) x3_neg_21 x3_41)))
(assert (and (= dc_191 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_44 (ite (= ge_63 #b1) x10_neg_21 x10_43)))
(assert (= x7_26 (ite (= ge_63 #b1) x8_44 x7_25)))
(assert (and (= dc_192 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44)))) (= x8_45 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44))))))
(assert (= x3_43 (bvadd x3_42 #x0000000000000002)))
(assert (and (= dc_193 ((_ extract 63 2) x8_45)) (= x8_lo_22 ((_ extract 1 0) x8_45))))
(assert (and (= x8_target_20 ((_ extract 1 1) x8_lo_22)) (= dc_194 ((_ extract 0 0) x8_lo_22))))
(assert (= ne_22 (bvand x8_target_20 #b1)))
(assert (and (= x8_46 ((_ sign_extend 1) ((_ extract 63 1) x8_45))) (= dc_195 ((_ zero_extend 63) ((_ extract 0 0) x8_45)))))
(assert true)
(assert (= x10_45 (ite (= ne_22 #b1) x7_26 #x0000000000000000)))
(assert (and (= ge_64 ((_ extract 63 63) x3_43)) (= dc_196 ((_ extract 62 0) x3_43))))
(assert (= ge_65 (bvnot ge_64)))
(assert (= ge_66 (ite (= ne_22 #b1) ge_65 #b0)))
(assert (and (= dc_197 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_44 (ite (= ge_66 #b1) x3_neg_22 x3_43)))
(assert (and (= dc_198 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_46 (ite (= ge_66 #b1) x10_neg_22 x10_45)))
(assert (= x7_27 (ite (= ge_66 #b1) x8_46 x7_26)))
(assert (and (= dc_199 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46)))) (= x8_47 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46))))))
(assert (= x3_45 (bvadd x3_44 #x0000000000000002)))
(assert (and (= dc_200 ((_ extract 63 2) x8_47)) (= x8_lo_23 ((_ extract 1 0) x8_47))))
(assert (and (= x8_target_21 ((_ extract 1 1) x8_lo_23)) (= dc_201 ((_ extract 0 0) x8_lo_23))))
(assert (= ne_23 (bvand x8_target_21 #b1)))
(assert (and (= x8_48 ((_ sign_extend 1) ((_ extract 63 1) x8_47))) (= dc_202 ((_ zero_extend 63) ((_ extract 0 0) x8_47)))))
(assert true)
(assert (= x10_47 (ite (= ne_23 #b1) x7_27 #x0000000000000000)))
(assert (and (= ge_67 ((_ extract 63 63) x3_45)) (= dc_203 ((_ extract 62 0) x3_45))))
(assert (= ge_68 (bvnot ge_67)))
(assert (= ge_69 (ite (= ne_23 #b1) ge_68 #b0)))
(assert (and (= dc_204 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_46 (ite (= ge_69 #b1) x3_neg_23 x3_45)))
(assert (and (= dc_205 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_48 (ite (= ge_69 #b1) x10_neg_23 x10_47)))
(assert (= x7_28 (ite (= ge_69 #b1) x8_48 x7_27)))
(assert (and (= dc_206 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48)))) (= x8_49 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48))))))
(assert (= x3_47 (bvadd x3_46 #x0000000000000002)))
(assert (and (= dc_207 ((_ extract 63 2) x8_49)) (= x8_lo_24 ((_ extract 1 0) x8_49))))
(assert (and (= x8_target_22 ((_ extract 1 1) x8_lo_24)) (= dc_208 ((_ extract 0 0) x8_lo_24))))
(assert (= ne_24 (bvand x8_target_22 #b1)))
(assert (and (= x8_50 ((_ sign_extend 1) ((_ extract 63 1) x8_49))) (= dc_209 ((_ zero_extend 63) ((_ extract 0 0) x8_49)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_48) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_28 x7_27)) (= (bvmul x8_50 #x0000000000000002) x8_48)) (= x3_47 (bvadd #x0000000000000002 x3_45))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_48) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_45 #x0000000000000000)) (= x7_28 x7_27)) (= (bvmul x8_50 #x0000000000000002) (bvadd x8_48 x7_27))) (= x3_47 (bvadd #x0000000000000002 x3_45)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_48) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_45 #x0000000000000000)) (= x7_28 x8_48)) (= (bvmul x8_50 #x0000000000000002) (bvsub x8_48 x7_27))) (= x3_47 (bvsub #x0000000000000002 x3_45))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_3329ea.smt2
Execution time of boolector: 0.2400 seconds
OUTPUT FROM boolector:
unsat

=== Cut #2 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #2
; Range assertion #27: or [and [smod (sub (uext x8_32 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_19 = x7_18, mul x8_34 2@64 = x8_32, x3_33 = add 2@64 x3_31], and [smod (sub (uext x8_32 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_31 <s 0@64, x7_19 = x7_18, mul x8_34 2@64 = add x8_32 x7_18, x3_33 = add 2@64 x3_31], and [smod (sub (uext x8_32 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_31 >=s 0@64, x7_19 = x8_32, mul x8_34 2@64 = sub x8_32 x7_18, x3_33 = sub 2@64 x3_31]]
; Range condition: ((x8_32@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_19 = x7_18 /\ x8_34 * 2 = x8_32 /\ x3_33 = 2 + x3_31 \/ ((x8_32@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_31 <s 0 /\ x7_19 = x7_18 /\ x8_34 * 2 = x8_32 + x7_18 /\ x3_33 = 2 + x3_31 \/ ((x8_32@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_31 >=s 0 /\ x7_19 = x8_32 /\ x8_34 * 2 = x8_32 - x7_18 /\ x3_33 = 2 - x3_31
; Output file: /tmp/outputqfbv_248d84.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_16 () (_ BitVec 1))
(declare-fun x8_target_15 () (_ BitVec 1))
(declare-fun x8_target_14 () (_ BitVec 1))
(declare-fun x8_target_13 () (_ BitVec 1))
(declare-fun x8_target_12 () (_ BitVec 1))
(declare-fun x8_target_11 () (_ BitVec 1))
(declare-fun x8_target_10 () (_ BitVec 1))
(declare-fun x8_target_9 () (_ BitVec 1))
(declare-fun x8_target_8 () (_ BitVec 1))
(declare-fun x8_target_7 () (_ BitVec 1))
(declare-fun x8_target_6 () (_ BitVec 1))
(declare-fun x8_target_5 () (_ BitVec 1))
(declare-fun x8_target_4 () (_ BitVec 1))
(declare-fun x8_target_3 () (_ BitVec 1))
(declare-fun x8_target_2 () (_ BitVec 1))
(declare-fun x8_target_1 () (_ BitVec 1))
(declare-fun x8_lo_17 () (_ BitVec 2))
(declare-fun x8_lo_16 () (_ BitVec 2))
(declare-fun x8_lo_15 () (_ BitVec 2))
(declare-fun x8_lo_14 () (_ BitVec 2))
(declare-fun x8_lo_13 () (_ BitVec 2))
(declare-fun x8_lo_12 () (_ BitVec 2))
(declare-fun x8_lo_11 () (_ BitVec 2))
(declare-fun x8_lo_10 () (_ BitVec 2))
(declare-fun x8_lo_9 () (_ BitVec 2))
(declare-fun x8_lo_8 () (_ BitVec 2))
(declare-fun x8_lo_7 () (_ BitVec 2))
(declare-fun x8_lo_6 () (_ BitVec 2))
(declare-fun x8_lo_5 () (_ BitVec 2))
(declare-fun x8_lo_4 () (_ BitVec 2))
(declare-fun x8_lo_3 () (_ BitVec 2))
(declare-fun x8_lo_2 () (_ BitVec 2))
(declare-fun x8_lo_1 () (_ BitVec 1))
(declare-fun x8_34 () (_ BitVec 64))
(declare-fun x8_33 () (_ BitVec 64))
(declare-fun x8_32 () (_ BitVec 64))
(declare-fun x8_31 () (_ BitVec 64))
(declare-fun x8_30 () (_ BitVec 64))
(declare-fun x8_29 () (_ BitVec 64))
(declare-fun x8_28 () (_ BitVec 64))
(declare-fun x8_27 () (_ BitVec 64))
(declare-fun x8_26 () (_ BitVec 64))
(declare-fun x8_25 () (_ BitVec 64))
(declare-fun x8_24 () (_ BitVec 64))
(declare-fun x8_23 () (_ BitVec 64))
(declare-fun x8_22 () (_ BitVec 64))
(declare-fun x8_21 () (_ BitVec 64))
(declare-fun x8_20 () (_ BitVec 64))
(declare-fun x8_19 () (_ BitVec 64))
(declare-fun x8_18 () (_ BitVec 64))
(declare-fun x8_17 () (_ BitVec 64))
(declare-fun x8_16 () (_ BitVec 64))
(declare-fun x8_15 () (_ BitVec 64))
(declare-fun x8_14 () (_ BitVec 64))
(declare-fun x8_13 () (_ BitVec 64))
(declare-fun x8_12 () (_ BitVec 64))
(declare-fun x8_11 () (_ BitVec 64))
(declare-fun x8_10 () (_ BitVec 64))
(declare-fun x8_9 () (_ BitVec 64))
(declare-fun x8_8 () (_ BitVec 64))
(declare-fun x8_7 () (_ BitVec 64))
(declare-fun x8_6 () (_ BitVec 64))
(declare-fun x8_5 () (_ BitVec 64))
(declare-fun x8_4 () (_ BitVec 64))
(declare-fun x8_3 () (_ BitVec 64))
(declare-fun x8_2 () (_ BitVec 64))
(declare-fun x7_19 () (_ BitVec 64))
(declare-fun x7_18 () (_ BitVec 64))
(declare-fun x7_17 () (_ BitVec 64))
(declare-fun x7_16 () (_ BitVec 64))
(declare-fun x7_15 () (_ BitVec 64))
(declare-fun x7_14 () (_ BitVec 64))
(declare-fun x7_13 () (_ BitVec 64))
(declare-fun x7_12 () (_ BitVec 64))
(declare-fun x7_11 () (_ BitVec 64))
(declare-fun x7_10 () (_ BitVec 64))
(declare-fun x7_9 () (_ BitVec 64))
(declare-fun x7_8 () (_ BitVec 64))
(declare-fun x7_7 () (_ BitVec 64))
(declare-fun x7_6 () (_ BitVec 64))
(declare-fun x7_5 () (_ BitVec 64))
(declare-fun x7_4 () (_ BitVec 64))
(declare-fun x7_3 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_16 () (_ BitVec 64))
(declare-fun x3_neg_15 () (_ BitVec 64))
(declare-fun x3_neg_14 () (_ BitVec 64))
(declare-fun x3_neg_13 () (_ BitVec 64))
(declare-fun x3_neg_12 () (_ BitVec 64))
(declare-fun x3_neg_11 () (_ BitVec 64))
(declare-fun x3_neg_10 () (_ BitVec 64))
(declare-fun x3_neg_9 () (_ BitVec 64))
(declare-fun x3_neg_8 () (_ BitVec 64))
(declare-fun x3_neg_7 () (_ BitVec 64))
(declare-fun x3_neg_6 () (_ BitVec 64))
(declare-fun x3_neg_5 () (_ BitVec 64))
(declare-fun x3_neg_4 () (_ BitVec 64))
(declare-fun x3_neg_3 () (_ BitVec 64))
(declare-fun x3_neg_2 () (_ BitVec 64))
(declare-fun x3_neg_1 () (_ BitVec 64))
(declare-fun x3_33 () (_ BitVec 64))
(declare-fun x3_32 () (_ BitVec 64))
(declare-fun x3_31 () (_ BitVec 64))
(declare-fun x3_30 () (_ BitVec 64))
(declare-fun x3_29 () (_ BitVec 64))
(declare-fun x3_28 () (_ BitVec 64))
(declare-fun x3_27 () (_ BitVec 64))
(declare-fun x3_26 () (_ BitVec 64))
(declare-fun x3_25 () (_ BitVec 64))
(declare-fun x3_24 () (_ BitVec 64))
(declare-fun x3_23 () (_ BitVec 64))
(declare-fun x3_22 () (_ BitVec 64))
(declare-fun x3_21 () (_ BitVec 64))
(declare-fun x3_20 () (_ BitVec 64))
(declare-fun x3_19 () (_ BitVec 64))
(declare-fun x3_18 () (_ BitVec 64))
(declare-fun x3_17 () (_ BitVec 64))
(declare-fun x3_16 () (_ BitVec 64))
(declare-fun x3_15 () (_ BitVec 64))
(declare-fun x3_14 () (_ BitVec 64))
(declare-fun x3_13 () (_ BitVec 64))
(declare-fun x3_12 () (_ BitVec 64))
(declare-fun x3_11 () (_ BitVec 64))
(declare-fun x3_10 () (_ BitVec 64))
(declare-fun x3_9 () (_ BitVec 64))
(declare-fun x3_8 () (_ BitVec 64))
(declare-fun x3_7 () (_ BitVec 64))
(declare-fun x3_6 () (_ BitVec 64))
(declare-fun x3_5 () (_ BitVec 64))
(declare-fun x3_4 () (_ BitVec 64))
(declare-fun x3_3 () (_ BitVec 64))
(declare-fun x3_2 () (_ BitVec 64))
(declare-fun x10_neg_16 () (_ BitVec 64))
(declare-fun x10_neg_15 () (_ BitVec 64))
(declare-fun x10_neg_14 () (_ BitVec 64))
(declare-fun x10_neg_13 () (_ BitVec 64))
(declare-fun x10_neg_12 () (_ BitVec 64))
(declare-fun x10_neg_11 () (_ BitVec 64))
(declare-fun x10_neg_10 () (_ BitVec 64))
(declare-fun x10_neg_9 () (_ BitVec 64))
(declare-fun x10_neg_8 () (_ BitVec 64))
(declare-fun x10_neg_7 () (_ BitVec 64))
(declare-fun x10_neg_6 () (_ BitVec 64))
(declare-fun x10_neg_5 () (_ BitVec 64))
(declare-fun x10_neg_4 () (_ BitVec 64))
(declare-fun x10_neg_3 () (_ BitVec 64))
(declare-fun x10_neg_2 () (_ BitVec 64))
(declare-fun x10_neg_1 () (_ BitVec 64))
(declare-fun x10_32 () (_ BitVec 64))
(declare-fun x10_31 () (_ BitVec 64))
(declare-fun x10_30 () (_ BitVec 64))
(declare-fun x10_29 () (_ BitVec 64))
(declare-fun x10_28 () (_ BitVec 64))
(declare-fun x10_27 () (_ BitVec 64))
(declare-fun x10_26 () (_ BitVec 64))
(declare-fun x10_25 () (_ BitVec 64))
(declare-fun x10_24 () (_ BitVec 64))
(declare-fun x10_23 () (_ BitVec 64))
(declare-fun x10_22 () (_ BitVec 64))
(declare-fun x10_21 () (_ BitVec 64))
(declare-fun x10_20 () (_ BitVec 64))
(declare-fun x10_19 () (_ BitVec 64))
(declare-fun x10_18 () (_ BitVec 64))
(declare-fun x10_17 () (_ BitVec 64))
(declare-fun x10_16 () (_ BitVec 64))
(declare-fun x10_15 () (_ BitVec 64))
(declare-fun x10_14 () (_ BitVec 64))
(declare-fun x10_13 () (_ BitVec 64))
(declare-fun x10_12 () (_ BitVec 64))
(declare-fun x10_11 () (_ BitVec 64))
(declare-fun x10_10 () (_ BitVec 64))
(declare-fun x10_9 () (_ BitVec 64))
(declare-fun x10_8 () (_ BitVec 64))
(declare-fun x10_7 () (_ BitVec 64))
(declare-fun x10_6 () (_ BitVec 64))
(declare-fun x10_5 () (_ BitVec 64))
(declare-fun x10_4 () (_ BitVec 64))
(declare-fun x10_3 () (_ BitVec 64))
(declare-fun x10_2 () (_ BitVec 64))
(declare-fun x10_1 () (_ BitVec 64))
(declare-fun ne_17 () (_ BitVec 1))
(declare-fun ne_16 () (_ BitVec 1))
(declare-fun ne_15 () (_ BitVec 1))
(declare-fun ne_14 () (_ BitVec 1))
(declare-fun ne_13 () (_ BitVec 1))
(declare-fun ne_12 () (_ BitVec 1))
(declare-fun ne_11 () (_ BitVec 1))
(declare-fun ne_10 () (_ BitVec 1))
(declare-fun ne_9 () (_ BitVec 1))
(declare-fun ne_8 () (_ BitVec 1))
(declare-fun ne_7 () (_ BitVec 1))
(declare-fun ne_6 () (_ BitVec 1))
(declare-fun ne_5 () (_ BitVec 1))
(declare-fun ne_4 () (_ BitVec 1))
(declare-fun ne_3 () (_ BitVec 1))
(declare-fun ne_2 () (_ BitVec 1))
(declare-fun ne_1 () (_ BitVec 1))
(declare-fun ge_48 () (_ BitVec 1))
(declare-fun ge_47 () (_ BitVec 1))
(declare-fun ge_46 () (_ BitVec 1))
(declare-fun ge_45 () (_ BitVec 1))
(declare-fun ge_44 () (_ BitVec 1))
(declare-fun ge_43 () (_ BitVec 1))
(declare-fun ge_42 () (_ BitVec 1))
(declare-fun ge_41 () (_ BitVec 1))
(declare-fun ge_40 () (_ BitVec 1))
(declare-fun ge_39 () (_ BitVec 1))
(declare-fun ge_38 () (_ BitVec 1))
(declare-fun ge_37 () (_ BitVec 1))
(declare-fun ge_36 () (_ BitVec 1))
(declare-fun ge_35 () (_ BitVec 1))
(declare-fun ge_34 () (_ BitVec 1))
(declare-fun ge_33 () (_ BitVec 1))
(declare-fun ge_32 () (_ BitVec 1))
(declare-fun ge_31 () (_ BitVec 1))
(declare-fun ge_30 () (_ BitVec 1))
(declare-fun ge_29 () (_ BitVec 1))
(declare-fun ge_28 () (_ BitVec 1))
(declare-fun ge_27 () (_ BitVec 1))
(declare-fun ge_26 () (_ BitVec 1))
(declare-fun ge_25 () (_ BitVec 1))
(declare-fun ge_24 () (_ BitVec 1))
(declare-fun ge_23 () (_ BitVec 1))
(declare-fun ge_22 () (_ BitVec 1))
(declare-fun ge_21 () (_ BitVec 1))
(declare-fun ge_20 () (_ BitVec 1))
(declare-fun ge_19 () (_ BitVec 1))
(declare-fun ge_18 () (_ BitVec 1))
(declare-fun ge_17 () (_ BitVec 1))
(declare-fun ge_16 () (_ BitVec 1))
(declare-fun ge_15 () (_ BitVec 1))
(declare-fun ge_14 () (_ BitVec 1))
(declare-fun ge_13 () (_ BitVec 1))
(declare-fun ge_12 () (_ BitVec 1))
(declare-fun ge_11 () (_ BitVec 1))
(declare-fun ge_10 () (_ BitVec 1))
(declare-fun ge_9 () (_ BitVec 1))
(declare-fun ge_8 () (_ BitVec 1))
(declare-fun ge_7 () (_ BitVec 1))
(declare-fun ge_6 () (_ BitVec 1))
(declare-fun ge_5 () (_ BitVec 1))
(declare-fun ge_4 () (_ BitVec 1))
(declare-fun ge_3 () (_ BitVec 1))
(declare-fun ge_2 () (_ BitVec 1))
(declare-fun ge_1 () (_ BitVec 1))
(declare-fun g_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun dc_153 () (_ BitVec 64))
(declare-fun dc_152 () (_ BitVec 1))
(declare-fun dc_151 () (_ BitVec 62))
(declare-fun dc_150 () (_ BitVec 1))
(declare-fun dc_149 () (_ BitVec 1))
(declare-fun dc_148 () (_ BitVec 1))
(declare-fun dc_147 () (_ BitVec 63))
(declare-fun dc_146 () (_ BitVec 64))
(declare-fun dc_145 () (_ BitVec 1))
(declare-fun dc_144 () (_ BitVec 62))
(declare-fun dc_143 () (_ BitVec 1))
(declare-fun dc_142 () (_ BitVec 1))
(declare-fun dc_141 () (_ BitVec 1))
(declare-fun dc_140 () (_ BitVec 63))
(declare-fun dc_139 () (_ BitVec 64))
(declare-fun dc_138 () (_ BitVec 1))
(declare-fun dc_137 () (_ BitVec 62))
(declare-fun dc_136 () (_ BitVec 1))
(declare-fun dc_135 () (_ BitVec 1))
(declare-fun dc_134 () (_ BitVec 1))
(declare-fun dc_133 () (_ BitVec 63))
(declare-fun dc_132 () (_ BitVec 64))
(declare-fun dc_131 () (_ BitVec 1))
(declare-fun dc_130 () (_ BitVec 62))
(declare-fun dc_129 () (_ BitVec 1))
(declare-fun dc_128 () (_ BitVec 1))
(declare-fun dc_127 () (_ BitVec 1))
(declare-fun dc_126 () (_ BitVec 63))
(declare-fun dc_125 () (_ BitVec 64))
(declare-fun dc_124 () (_ BitVec 1))
(declare-fun dc_123 () (_ BitVec 62))
(declare-fun dc_122 () (_ BitVec 1))
(declare-fun dc_121 () (_ BitVec 1))
(declare-fun dc_120 () (_ BitVec 1))
(declare-fun dc_119 () (_ BitVec 63))
(declare-fun dc_118 () (_ BitVec 64))
(declare-fun dc_117 () (_ BitVec 1))
(declare-fun dc_116 () (_ BitVec 62))
(declare-fun dc_115 () (_ BitVec 1))
(declare-fun dc_114 () (_ BitVec 1))
(declare-fun dc_113 () (_ BitVec 1))
(declare-fun dc_112 () (_ BitVec 63))
(declare-fun dc_111 () (_ BitVec 64))
(declare-fun dc_110 () (_ BitVec 1))
(declare-fun dc_109 () (_ BitVec 62))
(declare-fun dc_108 () (_ BitVec 1))
(declare-fun dc_107 () (_ BitVec 1))
(declare-fun dc_106 () (_ BitVec 1))
(declare-fun dc_105 () (_ BitVec 63))
(declare-fun dc_104 () (_ BitVec 64))
(declare-fun dc_103 () (_ BitVec 1))
(declare-fun dc_102 () (_ BitVec 62))
(declare-fun dc_101 () (_ BitVec 1))
(declare-fun dc_100 () (_ BitVec 1))
(declare-fun dc_99 () (_ BitVec 1))
(declare-fun dc_98 () (_ BitVec 63))
(declare-fun dc_97 () (_ BitVec 64))
(declare-fun dc_96 () (_ BitVec 1))
(declare-fun dc_95 () (_ BitVec 62))
(declare-fun dc_94 () (_ BitVec 1))
(declare-fun dc_93 () (_ BitVec 1))
(declare-fun dc_92 () (_ BitVec 1))
(declare-fun dc_91 () (_ BitVec 63))
(declare-fun dc_90 () (_ BitVec 64))
(declare-fun dc_89 () (_ BitVec 1))
(declare-fun dc_88 () (_ BitVec 62))
(declare-fun dc_87 () (_ BitVec 1))
(declare-fun dc_86 () (_ BitVec 1))
(declare-fun dc_85 () (_ BitVec 1))
(declare-fun dc_84 () (_ BitVec 63))
(declare-fun dc_83 () (_ BitVec 64))
(declare-fun dc_82 () (_ BitVec 1))
(declare-fun dc_81 () (_ BitVec 62))
(declare-fun dc_80 () (_ BitVec 1))
(declare-fun dc_79 () (_ BitVec 1))
(declare-fun dc_78 () (_ BitVec 1))
(declare-fun dc_77 () (_ BitVec 63))
(declare-fun dc_76 () (_ BitVec 64))
(declare-fun dc_75 () (_ BitVec 1))
(declare-fun dc_74 () (_ BitVec 62))
(declare-fun dc_73 () (_ BitVec 1))
(declare-fun dc_72 () (_ BitVec 1))
(declare-fun dc_71 () (_ BitVec 1))
(declare-fun dc_70 () (_ BitVec 63))
(declare-fun dc_69 () (_ BitVec 64))
(declare-fun dc_68 () (_ BitVec 1))
(declare-fun dc_67 () (_ BitVec 62))
(declare-fun dc_66 () (_ BitVec 1))
(declare-fun dc_65 () (_ BitVec 1))
(declare-fun dc_64 () (_ BitVec 1))
(declare-fun dc_63 () (_ BitVec 63))
(declare-fun dc_62 () (_ BitVec 64))
(declare-fun dc_61 () (_ BitVec 1))
(declare-fun dc_60 () (_ BitVec 62))
(declare-fun dc_59 () (_ BitVec 1))
(declare-fun dc_58 () (_ BitVec 1))
(declare-fun dc_57 () (_ BitVec 1))
(declare-fun dc_56 () (_ BitVec 63))
(declare-fun dc_55 () (_ BitVec 64))
(declare-fun dc_54 () (_ BitVec 1))
(declare-fun dc_53 () (_ BitVec 62))
(declare-fun dc_52 () (_ BitVec 1))
(declare-fun dc_51 () (_ BitVec 1))
(declare-fun dc_50 () (_ BitVec 1))
(declare-fun dc_49 () (_ BitVec 63))
(declare-fun dc_48 () (_ BitVec 64))
(declare-fun dc_47 () (_ BitVec 1))
(declare-fun dc_46 () (_ BitVec 62))
(declare-fun dc_45 () (_ BitVec 1))
(declare-fun dc_44 () (_ BitVec 1))
(declare-fun dc_43 () (_ BitVec 1))
(declare-fun dc_42 () (_ BitVec 63))
(declare-fun dc_41 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (= x7_3 (bvadd (bvadd f_0_low60_0_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_2 (bvadd (bvadd g_0_low60_0_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_0_1)) (bvsle f_0_low60_0_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_0_1)) (bvsle g_0_low60_0_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_3) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #x0000000000000001 #x0000000000000001)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_41 ((_ extract 63 1) x8_2)) (= x8_lo_1 ((_ extract 0 0) x8_2))))
(assert (= ne_1 (bvand x8_lo_1 #b1)))
(assert (= x10_1 (ite (= ne_1 #b1) x7_3 #x0000000000000000)))
(assert (and (= ge_1 ((_ extract 63 63) #x0000000000000001)) (= dc_42 ((_ extract 62 0) #x0000000000000001))))
(assert (= ge_2 (bvnot ge_1)))
(assert (= ge_3 (ite (= ne_1 #b1) ge_2 #b0)))
(assert (and (= dc_43 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot #x0000000000000001))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_2 (ite (= ge_3 #b1) x3_neg_1 #x0000000000000001)))
(assert (and (= dc_44 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_1 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_1))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_2 (ite (= ge_3 #b1) x10_neg_1 x10_1)))
(assert (= x7_4 (ite (= ge_3 #b1) x8_2 x7_3)))
(assert (and (= dc_45 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2)))) (= x8_3 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_2) ((_ zero_extend 1) x10_2))))))
(assert (= x3_3 (bvadd x3_2 #x0000000000000002)))
(assert (and (= dc_46 ((_ extract 63 2) x8_3)) (= x8_lo_2 ((_ extract 1 0) x8_3))))
(assert (and (= x8_target_1 ((_ extract 1 1) x8_lo_2)) (= dc_47 ((_ extract 0 0) x8_lo_2))))
(assert (= ne_2 (bvand x8_target_1 #b1)))
(assert (and (= x8_4 ((_ sign_extend 1) ((_ extract 63 1) x8_3))) (= dc_48 ((_ zero_extend 63) ((_ extract 0 0) x8_3)))))
(assert true)
(assert (= x10_3 (ite (= ne_2 #b1) x7_4 #x0000000000000000)))
(assert (and (= ge_4 ((_ extract 63 63) x3_3)) (= dc_49 ((_ extract 62 0) x3_3))))
(assert (= ge_5 (bvnot ge_4)))
(assert (= ge_6 (ite (= ne_2 #b1) ge_5 #b0)))
(assert (and (= dc_50 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_4 (ite (= ge_6 #b1) x3_neg_2 x3_3)))
(assert (and (= dc_51 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_2 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_3))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_4 (ite (= ge_6 #b1) x10_neg_2 x10_3)))
(assert (= x7_5 (ite (= ge_6 #b1) x8_4 x7_4)))
(assert (and (= dc_52 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4)))) (= x8_5 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_4) ((_ zero_extend 1) x10_4))))))
(assert (= x3_5 (bvadd x3_4 #x0000000000000002)))
(assert (and (= dc_53 ((_ extract 63 2) x8_5)) (= x8_lo_3 ((_ extract 1 0) x8_5))))
(assert (and (= x8_target_2 ((_ extract 1 1) x8_lo_3)) (= dc_54 ((_ extract 0 0) x8_lo_3))))
(assert (= ne_3 (bvand x8_target_2 #b1)))
(assert (and (= x8_6 ((_ sign_extend 1) ((_ extract 63 1) x8_5))) (= dc_55 ((_ zero_extend 63) ((_ extract 0 0) x8_5)))))
(assert true)
(assert (= x10_5 (ite (= ne_3 #b1) x7_5 #x0000000000000000)))
(assert (and (= ge_7 ((_ extract 63 63) x3_5)) (= dc_56 ((_ extract 62 0) x3_5))))
(assert (= ge_8 (bvnot ge_7)))
(assert (= ge_9 (ite (= ne_3 #b1) ge_8 #b0)))
(assert (and (= dc_57 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_6 (ite (= ge_9 #b1) x3_neg_3 x3_5)))
(assert (and (= dc_58 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_3 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_5))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_6 (ite (= ge_9 #b1) x10_neg_3 x10_5)))
(assert (= x7_6 (ite (= ge_9 #b1) x8_6 x7_5)))
(assert (and (= dc_59 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6)))) (= x8_7 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_6) ((_ zero_extend 1) x10_6))))))
(assert (= x3_7 (bvadd x3_6 #x0000000000000002)))
(assert (and (= dc_60 ((_ extract 63 2) x8_7)) (= x8_lo_4 ((_ extract 1 0) x8_7))))
(assert (and (= x8_target_3 ((_ extract 1 1) x8_lo_4)) (= dc_61 ((_ extract 0 0) x8_lo_4))))
(assert (= ne_4 (bvand x8_target_3 #b1)))
(assert (and (= x8_8 ((_ sign_extend 1) ((_ extract 63 1) x8_7))) (= dc_62 ((_ zero_extend 63) ((_ extract 0 0) x8_7)))))
(assert true)
(assert (= x10_7 (ite (= ne_4 #b1) x7_6 #x0000000000000000)))
(assert (and (= ge_10 ((_ extract 63 63) x3_7)) (= dc_63 ((_ extract 62 0) x3_7))))
(assert (= ge_11 (bvnot ge_10)))
(assert (= ge_12 (ite (= ne_4 #b1) ge_11 #b0)))
(assert (and (= dc_64 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_7))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_4 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_7))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_8 (ite (= ge_12 #b1) x3_neg_4 x3_7)))
(assert (and (= dc_65 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_7))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_4 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_7))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_8 (ite (= ge_12 #b1) x10_neg_4 x10_7)))
(assert (= x7_7 (ite (= ge_12 #b1) x8_8 x7_6)))
(assert (and (= dc_66 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_8) ((_ zero_extend 1) x10_8)))) (= x8_9 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_8) ((_ zero_extend 1) x10_8))))))
(assert (= x3_9 (bvadd x3_8 #x0000000000000002)))
(assert (and (= dc_67 ((_ extract 63 2) x8_9)) (= x8_lo_5 ((_ extract 1 0) x8_9))))
(assert (and (= x8_target_4 ((_ extract 1 1) x8_lo_5)) (= dc_68 ((_ extract 0 0) x8_lo_5))))
(assert (= ne_5 (bvand x8_target_4 #b1)))
(assert (and (= x8_10 ((_ sign_extend 1) ((_ extract 63 1) x8_9))) (= dc_69 ((_ zero_extend 63) ((_ extract 0 0) x8_9)))))
(assert true)
(assert (= x10_9 (ite (= ne_5 #b1) x7_7 #x0000000000000000)))
(assert (and (= ge_13 ((_ extract 63 63) x3_9)) (= dc_70 ((_ extract 62 0) x3_9))))
(assert (= ge_14 (bvnot ge_13)))
(assert (= ge_15 (ite (= ne_5 #b1) ge_14 #b0)))
(assert (and (= dc_71 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_9))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_5 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_9))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_10 (ite (= ge_15 #b1) x3_neg_5 x3_9)))
(assert (and (= dc_72 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_9))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_5 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_9))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_10 (ite (= ge_15 #b1) x10_neg_5 x10_9)))
(assert (= x7_8 (ite (= ge_15 #b1) x8_10 x7_7)))
(assert (and (= dc_73 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_10) ((_ zero_extend 1) x10_10)))) (= x8_11 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_10) ((_ zero_extend 1) x10_10))))))
(assert (= x3_11 (bvadd x3_10 #x0000000000000002)))
(assert (and (= dc_74 ((_ extract 63 2) x8_11)) (= x8_lo_6 ((_ extract 1 0) x8_11))))
(assert (and (= x8_target_5 ((_ extract 1 1) x8_lo_6)) (= dc_75 ((_ extract 0 0) x8_lo_6))))
(assert (= ne_6 (bvand x8_target_5 #b1)))
(assert (and (= x8_12 ((_ sign_extend 1) ((_ extract 63 1) x8_11))) (= dc_76 ((_ zero_extend 63) ((_ extract 0 0) x8_11)))))
(assert true)
(assert (= x10_11 (ite (= ne_6 #b1) x7_8 #x0000000000000000)))
(assert (and (= ge_16 ((_ extract 63 63) x3_11)) (= dc_77 ((_ extract 62 0) x3_11))))
(assert (= ge_17 (bvnot ge_16)))
(assert (= ge_18 (ite (= ne_6 #b1) ge_17 #b0)))
(assert (and (= dc_78 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_11))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_6 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_11))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_12 (ite (= ge_18 #b1) x3_neg_6 x3_11)))
(assert (and (= dc_79 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_11))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_6 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_11))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_12 (ite (= ge_18 #b1) x10_neg_6 x10_11)))
(assert (= x7_9 (ite (= ge_18 #b1) x8_12 x7_8)))
(assert (and (= dc_80 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_12) ((_ zero_extend 1) x10_12)))) (= x8_13 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_12) ((_ zero_extend 1) x10_12))))))
(assert (= x3_13 (bvadd x3_12 #x0000000000000002)))
(assert (and (= dc_81 ((_ extract 63 2) x8_13)) (= x8_lo_7 ((_ extract 1 0) x8_13))))
(assert (and (= x8_target_6 ((_ extract 1 1) x8_lo_7)) (= dc_82 ((_ extract 0 0) x8_lo_7))))
(assert (= ne_7 (bvand x8_target_6 #b1)))
(assert (and (= x8_14 ((_ sign_extend 1) ((_ extract 63 1) x8_13))) (= dc_83 ((_ zero_extend 63) ((_ extract 0 0) x8_13)))))
(assert true)
(assert (= x10_13 (ite (= ne_7 #b1) x7_9 #x0000000000000000)))
(assert (and (= ge_19 ((_ extract 63 63) x3_13)) (= dc_84 ((_ extract 62 0) x3_13))))
(assert (= ge_20 (bvnot ge_19)))
(assert (= ge_21 (ite (= ne_7 #b1) ge_20 #b0)))
(assert (and (= dc_85 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_13))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_7 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_13))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_14 (ite (= ge_21 #b1) x3_neg_7 x3_13)))
(assert (and (= dc_86 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_13))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_7 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_13))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_14 (ite (= ge_21 #b1) x10_neg_7 x10_13)))
(assert (= x7_10 (ite (= ge_21 #b1) x8_14 x7_9)))
(assert (and (= dc_87 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_14) ((_ zero_extend 1) x10_14)))) (= x8_15 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_14) ((_ zero_extend 1) x10_14))))))
(assert (= x3_15 (bvadd x3_14 #x0000000000000002)))
(assert (and (= dc_88 ((_ extract 63 2) x8_15)) (= x8_lo_8 ((_ extract 1 0) x8_15))))
(assert (and (= x8_target_7 ((_ extract 1 1) x8_lo_8)) (= dc_89 ((_ extract 0 0) x8_lo_8))))
(assert (= ne_8 (bvand x8_target_7 #b1)))
(assert (and (= x8_16 ((_ sign_extend 1) ((_ extract 63 1) x8_15))) (= dc_90 ((_ zero_extend 63) ((_ extract 0 0) x8_15)))))
(assert true)
(assert (= x10_15 (ite (= ne_8 #b1) x7_10 #x0000000000000000)))
(assert (and (= ge_22 ((_ extract 63 63) x3_15)) (= dc_91 ((_ extract 62 0) x3_15))))
(assert (= ge_23 (bvnot ge_22)))
(assert (= ge_24 (ite (= ne_8 #b1) ge_23 #b0)))
(assert (and (= dc_92 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_15))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_8 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_15))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_16 (ite (= ge_24 #b1) x3_neg_8 x3_15)))
(assert (and (= dc_93 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_15))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_8 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_15))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_16 (ite (= ge_24 #b1) x10_neg_8 x10_15)))
(assert (= x7_11 (ite (= ge_24 #b1) x8_16 x7_10)))
(assert (and (= dc_94 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_16) ((_ zero_extend 1) x10_16)))) (= x8_17 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_16) ((_ zero_extend 1) x10_16))))))
(assert (= x3_17 (bvadd x3_16 #x0000000000000002)))
(assert (and (= dc_95 ((_ extract 63 2) x8_17)) (= x8_lo_9 ((_ extract 1 0) x8_17))))
(assert (and (= x8_target_8 ((_ extract 1 1) x8_lo_9)) (= dc_96 ((_ extract 0 0) x8_lo_9))))
(assert (= ne_9 (bvand x8_target_8 #b1)))
(assert (and (= x8_18 ((_ sign_extend 1) ((_ extract 63 1) x8_17))) (= dc_97 ((_ zero_extend 63) ((_ extract 0 0) x8_17)))))
(assert true)
(assert (= x10_17 (ite (= ne_9 #b1) x7_11 #x0000000000000000)))
(assert (and (= ge_25 ((_ extract 63 63) x3_17)) (= dc_98 ((_ extract 62 0) x3_17))))
(assert (= ge_26 (bvnot ge_25)))
(assert (= ge_27 (ite (= ne_9 #b1) ge_26 #b0)))
(assert (and (= dc_99 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_17))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_9 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_17))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_18 (ite (= ge_27 #b1) x3_neg_9 x3_17)))
(assert (and (= dc_100 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_17))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_9 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_17))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_18 (ite (= ge_27 #b1) x10_neg_9 x10_17)))
(assert (= x7_12 (ite (= ge_27 #b1) x8_18 x7_11)))
(assert (and (= dc_101 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_18) ((_ zero_extend 1) x10_18)))) (= x8_19 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_18) ((_ zero_extend 1) x10_18))))))
(assert (= x3_19 (bvadd x3_18 #x0000000000000002)))
(assert (and (= dc_102 ((_ extract 63 2) x8_19)) (= x8_lo_10 ((_ extract 1 0) x8_19))))
(assert (and (= x8_target_9 ((_ extract 1 1) x8_lo_10)) (= dc_103 ((_ extract 0 0) x8_lo_10))))
(assert (= ne_10 (bvand x8_target_9 #b1)))
(assert (and (= x8_20 ((_ sign_extend 1) ((_ extract 63 1) x8_19))) (= dc_104 ((_ zero_extend 63) ((_ extract 0 0) x8_19)))))
(assert true)
(assert (= x10_19 (ite (= ne_10 #b1) x7_12 #x0000000000000000)))
(assert (and (= ge_28 ((_ extract 63 63) x3_19)) (= dc_105 ((_ extract 62 0) x3_19))))
(assert (= ge_29 (bvnot ge_28)))
(assert (= ge_30 (ite (= ne_10 #b1) ge_29 #b0)))
(assert (and (= dc_106 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_19))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_10 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_19))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_20 (ite (= ge_30 #b1) x3_neg_10 x3_19)))
(assert (and (= dc_107 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_19))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_10 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_19))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_20 (ite (= ge_30 #b1) x10_neg_10 x10_19)))
(assert (= x7_13 (ite (= ge_30 #b1) x8_20 x7_12)))
(assert (and (= dc_108 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_20) ((_ zero_extend 1) x10_20)))) (= x8_21 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_20) ((_ zero_extend 1) x10_20))))))
(assert (= x3_21 (bvadd x3_20 #x0000000000000002)))
(assert (and (= dc_109 ((_ extract 63 2) x8_21)) (= x8_lo_11 ((_ extract 1 0) x8_21))))
(assert (and (= x8_target_10 ((_ extract 1 1) x8_lo_11)) (= dc_110 ((_ extract 0 0) x8_lo_11))))
(assert (= ne_11 (bvand x8_target_10 #b1)))
(assert (and (= x8_22 ((_ sign_extend 1) ((_ extract 63 1) x8_21))) (= dc_111 ((_ zero_extend 63) ((_ extract 0 0) x8_21)))))
(assert true)
(assert (= x10_21 (ite (= ne_11 #b1) x7_13 #x0000000000000000)))
(assert (and (= ge_31 ((_ extract 63 63) x3_21)) (= dc_112 ((_ extract 62 0) x3_21))))
(assert (= ge_32 (bvnot ge_31)))
(assert (= ge_33 (ite (= ne_11 #b1) ge_32 #b0)))
(assert (and (= dc_113 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_21))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_11 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_21))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_22 (ite (= ge_33 #b1) x3_neg_11 x3_21)))
(assert (and (= dc_114 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_21))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_11 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_21))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_22 (ite (= ge_33 #b1) x10_neg_11 x10_21)))
(assert (= x7_14 (ite (= ge_33 #b1) x8_22 x7_13)))
(assert (and (= dc_115 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_22) ((_ zero_extend 1) x10_22)))) (= x8_23 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_22) ((_ zero_extend 1) x10_22))))))
(assert (= x3_23 (bvadd x3_22 #x0000000000000002)))
(assert (and (= dc_116 ((_ extract 63 2) x8_23)) (= x8_lo_12 ((_ extract 1 0) x8_23))))
(assert (and (= x8_target_11 ((_ extract 1 1) x8_lo_12)) (= dc_117 ((_ extract 0 0) x8_lo_12))))
(assert (= ne_12 (bvand x8_target_11 #b1)))
(assert (and (= x8_24 ((_ sign_extend 1) ((_ extract 63 1) x8_23))) (= dc_118 ((_ zero_extend 63) ((_ extract 0 0) x8_23)))))
(assert true)
(assert (= x10_23 (ite (= ne_12 #b1) x7_14 #x0000000000000000)))
(assert (and (= ge_34 ((_ extract 63 63) x3_23)) (= dc_119 ((_ extract 62 0) x3_23))))
(assert (= ge_35 (bvnot ge_34)))
(assert (= ge_36 (ite (= ne_12 #b1) ge_35 #b0)))
(assert (and (= dc_120 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_23))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_12 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_23))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_24 (ite (= ge_36 #b1) x3_neg_12 x3_23)))
(assert (and (= dc_121 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_23))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_12 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_23))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_24 (ite (= ge_36 #b1) x10_neg_12 x10_23)))
(assert (= x7_15 (ite (= ge_36 #b1) x8_24 x7_14)))
(assert (and (= dc_122 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_24) ((_ zero_extend 1) x10_24)))) (= x8_25 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_24) ((_ zero_extend 1) x10_24))))))
(assert (= x3_25 (bvadd x3_24 #x0000000000000002)))
(assert (and (= dc_123 ((_ extract 63 2) x8_25)) (= x8_lo_13 ((_ extract 1 0) x8_25))))
(assert (and (= x8_target_12 ((_ extract 1 1) x8_lo_13)) (= dc_124 ((_ extract 0 0) x8_lo_13))))
(assert (= ne_13 (bvand x8_target_12 #b1)))
(assert (and (= x8_26 ((_ sign_extend 1) ((_ extract 63 1) x8_25))) (= dc_125 ((_ zero_extend 63) ((_ extract 0 0) x8_25)))))
(assert true)
(assert (= x10_25 (ite (= ne_13 #b1) x7_15 #x0000000000000000)))
(assert (and (= ge_37 ((_ extract 63 63) x3_25)) (= dc_126 ((_ extract 62 0) x3_25))))
(assert (= ge_38 (bvnot ge_37)))
(assert (= ge_39 (ite (= ne_13 #b1) ge_38 #b0)))
(assert (and (= dc_127 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_25))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_13 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_25))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_26 (ite (= ge_39 #b1) x3_neg_13 x3_25)))
(assert (and (= dc_128 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_25))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_13 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_25))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_26 (ite (= ge_39 #b1) x10_neg_13 x10_25)))
(assert (= x7_16 (ite (= ge_39 #b1) x8_26 x7_15)))
(assert (and (= dc_129 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_26) ((_ zero_extend 1) x10_26)))) (= x8_27 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_26) ((_ zero_extend 1) x10_26))))))
(assert (= x3_27 (bvadd x3_26 #x0000000000000002)))
(assert (and (= dc_130 ((_ extract 63 2) x8_27)) (= x8_lo_14 ((_ extract 1 0) x8_27))))
(assert (and (= x8_target_13 ((_ extract 1 1) x8_lo_14)) (= dc_131 ((_ extract 0 0) x8_lo_14))))
(assert (= ne_14 (bvand x8_target_13 #b1)))
(assert (and (= x8_28 ((_ sign_extend 1) ((_ extract 63 1) x8_27))) (= dc_132 ((_ zero_extend 63) ((_ extract 0 0) x8_27)))))
(assert true)
(assert (= x10_27 (ite (= ne_14 #b1) x7_16 #x0000000000000000)))
(assert (and (= ge_40 ((_ extract 63 63) x3_27)) (= dc_133 ((_ extract 62 0) x3_27))))
(assert (= ge_41 (bvnot ge_40)))
(assert (= ge_42 (ite (= ne_14 #b1) ge_41 #b0)))
(assert (and (= dc_134 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_27))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_14 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_27))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_28 (ite (= ge_42 #b1) x3_neg_14 x3_27)))
(assert (and (= dc_135 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_27))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_14 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_27))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_28 (ite (= ge_42 #b1) x10_neg_14 x10_27)))
(assert (= x7_17 (ite (= ge_42 #b1) x8_28 x7_16)))
(assert (and (= dc_136 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_28) ((_ zero_extend 1) x10_28)))) (= x8_29 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_28) ((_ zero_extend 1) x10_28))))))
(assert (= x3_29 (bvadd x3_28 #x0000000000000002)))
(assert (and (= dc_137 ((_ extract 63 2) x8_29)) (= x8_lo_15 ((_ extract 1 0) x8_29))))
(assert (and (= x8_target_14 ((_ extract 1 1) x8_lo_15)) (= dc_138 ((_ extract 0 0) x8_lo_15))))
(assert (= ne_15 (bvand x8_target_14 #b1)))
(assert (and (= x8_30 ((_ sign_extend 1) ((_ extract 63 1) x8_29))) (= dc_139 ((_ zero_extend 63) ((_ extract 0 0) x8_29)))))
(assert true)
(assert (= x10_29 (ite (= ne_15 #b1) x7_17 #x0000000000000000)))
(assert (and (= ge_43 ((_ extract 63 63) x3_29)) (= dc_140 ((_ extract 62 0) x3_29))))
(assert (= ge_44 (bvnot ge_43)))
(assert (= ge_45 (ite (= ne_15 #b1) ge_44 #b0)))
(assert (and (= dc_141 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_29))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_15 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_29))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_30 (ite (= ge_45 #b1) x3_neg_15 x3_29)))
(assert (and (= dc_142 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_29))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_15 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_29))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_30 (ite (= ge_45 #b1) x10_neg_15 x10_29)))
(assert (= x7_18 (ite (= ge_45 #b1) x8_30 x7_17)))
(assert (and (= dc_143 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_30) ((_ zero_extend 1) x10_30)))) (= x8_31 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_30) ((_ zero_extend 1) x10_30))))))
(assert (= x3_31 (bvadd x3_30 #x0000000000000002)))
(assert (and (= dc_144 ((_ extract 63 2) x8_31)) (= x8_lo_16 ((_ extract 1 0) x8_31))))
(assert (and (= x8_target_15 ((_ extract 1 1) x8_lo_16)) (= dc_145 ((_ extract 0 0) x8_lo_16))))
(assert (= ne_16 (bvand x8_target_15 #b1)))
(assert (and (= x8_32 ((_ sign_extend 1) ((_ extract 63 1) x8_31))) (= dc_146 ((_ zero_extend 63) ((_ extract 0 0) x8_31)))))
(assert true)
(assert (= x10_31 (ite (= ne_16 #b1) x7_18 #x0000000000000000)))
(assert (and (= ge_46 ((_ extract 63 63) x3_31)) (= dc_147 ((_ extract 62 0) x3_31))))
(assert (= ge_47 (bvnot ge_46)))
(assert (= ge_48 (ite (= ne_16 #b1) ge_47 #b0)))
(assert (and (= dc_148 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_31))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_16 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_31))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_32 (ite (= ge_48 #b1) x3_neg_16 x3_31)))
(assert (and (= dc_149 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_31))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_16 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_31))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_32 (ite (= ge_48 #b1) x10_neg_16 x10_31)))
(assert (= x7_19 (ite (= ge_48 #b1) x8_32 x7_18)))
(assert (and (= dc_150 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_32) ((_ zero_extend 1) x10_32)))) (= x8_33 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_32) ((_ zero_extend 1) x10_32))))))
(assert (= x3_33 (bvadd x3_32 #x0000000000000002)))
(assert (and (= dc_151 ((_ extract 63 2) x8_33)) (= x8_lo_17 ((_ extract 1 0) x8_33))))
(assert (and (= x8_target_16 ((_ extract 1 1) x8_lo_17)) (= dc_152 ((_ extract 0 0) x8_lo_17))))
(assert (= ne_17 (bvand x8_target_16 #b1)))
(assert (and (= x8_34 ((_ sign_extend 1) ((_ extract 63 1) x8_33))) (= dc_153 ((_ zero_extend 63) ((_ extract 0 0) x8_33)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_32) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_19 x7_18)) (= (bvmul x8_34 #x0000000000000002) x8_32)) (= x3_33 (bvadd #x0000000000000002 x3_31))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_32) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_31 #x0000000000000000)) (= x7_19 x7_18)) (= (bvmul x8_34 #x0000000000000002) (bvadd x8_32 x7_18))) (= x3_33 (bvadd #x0000000000000002 x3_31)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_32) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_31 #x0000000000000000)) (= x7_19 x8_32)) (= (bvmul x8_34 #x0000000000000002) (bvsub x8_32 x7_18))) (= x3_33 (bvsub #x0000000000000002 x3_31))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_e0f462.smt2
Execution time of boolector: 3.1866 seconds
OUTPUT FROM boolector:
unsat

=== Cut #6 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #6
; Range assertion #44: or [and [smod (sub (uext x8_52 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_30 = x7_29, mul x8_54 2@64 = x8_52, x3_51 = add 2@64 x3_49], and [smod (sub (uext x8_52 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_49 <s 0@64, x7_30 = x7_29, mul x8_54 2@64 = add x8_52 x7_29, x3_51 = add 2@64 x3_49], and [smod (sub (uext x8_52 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_49 >=s 0@64, x7_30 = x8_52, mul x8_54 2@64 = sub x8_52 x7_29, x3_51 = sub 2@64 x3_49]]
; Range condition: ((x8_52@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_30 = x7_29 /\ x8_54 * 2 = x8_52 /\ x3_51 = 2 + x3_49 \/ ((x8_52@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_49 <s 0 /\ x7_30 = x7_29 /\ x8_54 * 2 = x8_52 + x7_29 /\ x3_51 = 2 + x3_49 \/ ((x8_52@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_49 >=s 0 /\ x7_30 = x8_52 /\ x8_54 * 2 = x8_52 - x7_29 /\ x3_51 = 2 - x3_49
; Output file: /tmp/outputqfbv_2442ae.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_24 () (_ BitVec 1))
(declare-fun x8_target_23 () (_ BitVec 1))
(declare-fun x8_target_22 () (_ BitVec 1))
(declare-fun x8_target_21 () (_ BitVec 1))
(declare-fun x8_target_20 () (_ BitVec 1))
(declare-fun x8_lo_26 () (_ BitVec 2))
(declare-fun x8_lo_25 () (_ BitVec 2))
(declare-fun x8_lo_24 () (_ BitVec 2))
(declare-fun x8_lo_23 () (_ BitVec 2))
(declare-fun x8_lo_22 () (_ BitVec 2))
(declare-fun x8_lo_21 () (_ BitVec 1))
(declare-fun x8_54 () (_ BitVec 64))
(declare-fun x8_53 () (_ BitVec 64))
(declare-fun x8_52 () (_ BitVec 64))
(declare-fun x8_51 () (_ BitVec 64))
(declare-fun x8_50 () (_ BitVec 64))
(declare-fun x8_49 () (_ BitVec 64))
(declare-fun x8_48 () (_ BitVec 64))
(declare-fun x8_47 () (_ BitVec 64))
(declare-fun x8_46 () (_ BitVec 64))
(declare-fun x8_45 () (_ BitVec 64))
(declare-fun x8_44 () (_ BitVec 64))
(declare-fun x7_30 () (_ BitVec 64))
(declare-fun x7_29 () (_ BitVec 64))
(declare-fun x7_28 () (_ BitVec 64))
(declare-fun x7_27 () (_ BitVec 64))
(declare-fun x7_26 () (_ BitVec 64))
(declare-fun x7_25 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_25 () (_ BitVec 64))
(declare-fun x3_neg_24 () (_ BitVec 64))
(declare-fun x3_neg_23 () (_ BitVec 64))
(declare-fun x3_neg_22 () (_ BitVec 64))
(declare-fun x3_neg_21 () (_ BitVec 64))
(declare-fun x3_51 () (_ BitVec 64))
(declare-fun x3_50 () (_ BitVec 64))
(declare-fun x3_49 () (_ BitVec 64))
(declare-fun x3_48 () (_ BitVec 64))
(declare-fun x3_47 () (_ BitVec 64))
(declare-fun x3_46 () (_ BitVec 64))
(declare-fun x3_45 () (_ BitVec 64))
(declare-fun x3_44 () (_ BitVec 64))
(declare-fun x3_43 () (_ BitVec 64))
(declare-fun x3_42 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x10_neg_25 () (_ BitVec 64))
(declare-fun x10_neg_24 () (_ BitVec 64))
(declare-fun x10_neg_23 () (_ BitVec 64))
(declare-fun x10_neg_22 () (_ BitVec 64))
(declare-fun x10_neg_21 () (_ BitVec 64))
(declare-fun x10_52 () (_ BitVec 64))
(declare-fun x10_51 () (_ BitVec 64))
(declare-fun x10_50 () (_ BitVec 64))
(declare-fun x10_49 () (_ BitVec 64))
(declare-fun x10_48 () (_ BitVec 64))
(declare-fun x10_47 () (_ BitVec 64))
(declare-fun x10_46 () (_ BitVec 64))
(declare-fun x10_45 () (_ BitVec 64))
(declare-fun x10_44 () (_ BitVec 64))
(declare-fun x10_43 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun ne_26 () (_ BitVec 1))
(declare-fun ne_25 () (_ BitVec 1))
(declare-fun ne_24 () (_ BitVec 1))
(declare-fun ne_23 () (_ BitVec 1))
(declare-fun ne_22 () (_ BitVec 1))
(declare-fun ne_21 () (_ BitVec 1))
(declare-fun ge_75 () (_ BitVec 1))
(declare-fun ge_74 () (_ BitVec 1))
(declare-fun ge_73 () (_ BitVec 1))
(declare-fun ge_72 () (_ BitVec 1))
(declare-fun ge_71 () (_ BitVec 1))
(declare-fun ge_70 () (_ BitVec 1))
(declare-fun ge_69 () (_ BitVec 1))
(declare-fun ge_68 () (_ BitVec 1))
(declare-fun ge_67 () (_ BitVec 1))
(declare-fun ge_66 () (_ BitVec 1))
(declare-fun ge_65 () (_ BitVec 1))
(declare-fun ge_64 () (_ BitVec 1))
(declare-fun ge_63 () (_ BitVec 1))
(declare-fun ge_62 () (_ BitVec 1))
(declare-fun ge_61 () (_ BitVec 1))
(declare-fun dc_223 () (_ BitVec 64))
(declare-fun dc_222 () (_ BitVec 1))
(declare-fun dc_221 () (_ BitVec 62))
(declare-fun dc_220 () (_ BitVec 1))
(declare-fun dc_219 () (_ BitVec 1))
(declare-fun dc_218 () (_ BitVec 1))
(declare-fun dc_217 () (_ BitVec 63))
(declare-fun dc_216 () (_ BitVec 64))
(declare-fun dc_215 () (_ BitVec 1))
(declare-fun dc_214 () (_ BitVec 62))
(declare-fun dc_213 () (_ BitVec 1))
(declare-fun dc_212 () (_ BitVec 1))
(declare-fun dc_211 () (_ BitVec 1))
(declare-fun dc_210 () (_ BitVec 63))
(declare-fun dc_209 () (_ BitVec 64))
(declare-fun dc_208 () (_ BitVec 1))
(declare-fun dc_207 () (_ BitVec 62))
(declare-fun dc_206 () (_ BitVec 1))
(declare-fun dc_205 () (_ BitVec 1))
(declare-fun dc_204 () (_ BitVec 1))
(declare-fun dc_203 () (_ BitVec 63))
(declare-fun dc_202 () (_ BitVec 64))
(declare-fun dc_201 () (_ BitVec 1))
(declare-fun dc_200 () (_ BitVec 62))
(declare-fun dc_199 () (_ BitVec 1))
(declare-fun dc_198 () (_ BitVec 1))
(declare-fun dc_197 () (_ BitVec 1))
(declare-fun dc_196 () (_ BitVec 63))
(declare-fun dc_195 () (_ BitVec 64))
(declare-fun dc_194 () (_ BitVec 1))
(declare-fun dc_193 () (_ BitVec 62))
(declare-fun dc_192 () (_ BitVec 1))
(declare-fun dc_191 () (_ BitVec 1))
(declare-fun dc_190 () (_ BitVec 1))
(declare-fun dc_189 () (_ BitVec 63))
(declare-fun dc_188 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_25 (bvadd (bvadd neg_f_0_low60_20_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_44 (bvadd (bvadd neg_g_0_low60_20_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_0_1)) (bvsle neg_f_0_low60_20_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_0_1)) (bvsle neg_g_0_low60_20_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_25) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_188 ((_ extract 63 1) x8_44)) (= x8_lo_21 ((_ extract 0 0) x8_44))))
(assert (= ne_21 (bvand x8_lo_21 #b1)))
(assert (= x10_43 (ite (= ne_21 #b1) x7_25 #x0000000000000000)))
(assert (and (= ge_61 ((_ extract 63 63) x3_41)) (= dc_189 ((_ extract 62 0) x3_41))))
(assert (= ge_62 (bvnot ge_61)))
(assert (= ge_63 (ite (= ne_21 #b1) ge_62 #b0)))
(assert (and (= dc_190 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_42 (ite (= ge_63 #b1) x3_neg_21 x3_41)))
(assert (and (= dc_191 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_44 (ite (= ge_63 #b1) x10_neg_21 x10_43)))
(assert (= x7_26 (ite (= ge_63 #b1) x8_44 x7_25)))
(assert (and (= dc_192 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44)))) (= x8_45 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44))))))
(assert (= x3_43 (bvadd x3_42 #x0000000000000002)))
(assert (and (= dc_193 ((_ extract 63 2) x8_45)) (= x8_lo_22 ((_ extract 1 0) x8_45))))
(assert (and (= x8_target_20 ((_ extract 1 1) x8_lo_22)) (= dc_194 ((_ extract 0 0) x8_lo_22))))
(assert (= ne_22 (bvand x8_target_20 #b1)))
(assert (and (= x8_46 ((_ sign_extend 1) ((_ extract 63 1) x8_45))) (= dc_195 ((_ zero_extend 63) ((_ extract 0 0) x8_45)))))
(assert true)
(assert (= x10_45 (ite (= ne_22 #b1) x7_26 #x0000000000000000)))
(assert (and (= ge_64 ((_ extract 63 63) x3_43)) (= dc_196 ((_ extract 62 0) x3_43))))
(assert (= ge_65 (bvnot ge_64)))
(assert (= ge_66 (ite (= ne_22 #b1) ge_65 #b0)))
(assert (and (= dc_197 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_44 (ite (= ge_66 #b1) x3_neg_22 x3_43)))
(assert (and (= dc_198 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_46 (ite (= ge_66 #b1) x10_neg_22 x10_45)))
(assert (= x7_27 (ite (= ge_66 #b1) x8_46 x7_26)))
(assert (and (= dc_199 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46)))) (= x8_47 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46))))))
(assert (= x3_45 (bvadd x3_44 #x0000000000000002)))
(assert (and (= dc_200 ((_ extract 63 2) x8_47)) (= x8_lo_23 ((_ extract 1 0) x8_47))))
(assert (and (= x8_target_21 ((_ extract 1 1) x8_lo_23)) (= dc_201 ((_ extract 0 0) x8_lo_23))))
(assert (= ne_23 (bvand x8_target_21 #b1)))
(assert (and (= x8_48 ((_ sign_extend 1) ((_ extract 63 1) x8_47))) (= dc_202 ((_ zero_extend 63) ((_ extract 0 0) x8_47)))))
(assert true)
(assert (= x10_47 (ite (= ne_23 #b1) x7_27 #x0000000000000000)))
(assert (and (= ge_67 ((_ extract 63 63) x3_45)) (= dc_203 ((_ extract 62 0) x3_45))))
(assert (= ge_68 (bvnot ge_67)))
(assert (= ge_69 (ite (= ne_23 #b1) ge_68 #b0)))
(assert (and (= dc_204 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_46 (ite (= ge_69 #b1) x3_neg_23 x3_45)))
(assert (and (= dc_205 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_48 (ite (= ge_69 #b1) x10_neg_23 x10_47)))
(assert (= x7_28 (ite (= ge_69 #b1) x8_48 x7_27)))
(assert (and (= dc_206 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48)))) (= x8_49 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48))))))
(assert (= x3_47 (bvadd x3_46 #x0000000000000002)))
(assert (and (= dc_207 ((_ extract 63 2) x8_49)) (= x8_lo_24 ((_ extract 1 0) x8_49))))
(assert (and (= x8_target_22 ((_ extract 1 1) x8_lo_24)) (= dc_208 ((_ extract 0 0) x8_lo_24))))
(assert (= ne_24 (bvand x8_target_22 #b1)))
(assert (and (= x8_50 ((_ sign_extend 1) ((_ extract 63 1) x8_49))) (= dc_209 ((_ zero_extend 63) ((_ extract 0 0) x8_49)))))
(assert true)
(assert (= x10_49 (ite (= ne_24 #b1) x7_28 #x0000000000000000)))
(assert (and (= ge_70 ((_ extract 63 63) x3_47)) (= dc_210 ((_ extract 62 0) x3_47))))
(assert (= ge_71 (bvnot ge_70)))
(assert (= ge_72 (ite (= ne_24 #b1) ge_71 #b0)))
(assert (and (= dc_211 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_47))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_24 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_47))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_48 (ite (= ge_72 #b1) x3_neg_24 x3_47)))
(assert (and (= dc_212 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_49))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_24 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_49))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_50 (ite (= ge_72 #b1) x10_neg_24 x10_49)))
(assert (= x7_29 (ite (= ge_72 #b1) x8_50 x7_28)))
(assert (and (= dc_213 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_50) ((_ zero_extend 1) x10_50)))) (= x8_51 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_50) ((_ zero_extend 1) x10_50))))))
(assert (= x3_49 (bvadd x3_48 #x0000000000000002)))
(assert (and (= dc_214 ((_ extract 63 2) x8_51)) (= x8_lo_25 ((_ extract 1 0) x8_51))))
(assert (and (= x8_target_23 ((_ extract 1 1) x8_lo_25)) (= dc_215 ((_ extract 0 0) x8_lo_25))))
(assert (= ne_25 (bvand x8_target_23 #b1)))
(assert (and (= x8_52 ((_ sign_extend 1) ((_ extract 63 1) x8_51))) (= dc_216 ((_ zero_extend 63) ((_ extract 0 0) x8_51)))))
(assert true)
(assert (= x10_51 (ite (= ne_25 #b1) x7_29 #x0000000000000000)))
(assert (and (= ge_73 ((_ extract 63 63) x3_49)) (= dc_217 ((_ extract 62 0) x3_49))))
(assert (= ge_74 (bvnot ge_73)))
(assert (= ge_75 (ite (= ne_25 #b1) ge_74 #b0)))
(assert (and (= dc_218 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_49))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_25 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_49))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_50 (ite (= ge_75 #b1) x3_neg_25 x3_49)))
(assert (and (= dc_219 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_51))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_25 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_51))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_52 (ite (= ge_75 #b1) x10_neg_25 x10_51)))
(assert (= x7_30 (ite (= ge_75 #b1) x8_52 x7_29)))
(assert (and (= dc_220 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_52) ((_ zero_extend 1) x10_52)))) (= x8_53 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_52) ((_ zero_extend 1) x10_52))))))
(assert (= x3_51 (bvadd x3_50 #x0000000000000002)))
(assert (and (= dc_221 ((_ extract 63 2) x8_53)) (= x8_lo_26 ((_ extract 1 0) x8_53))))
(assert (and (= x8_target_24 ((_ extract 1 1) x8_lo_26)) (= dc_222 ((_ extract 0 0) x8_lo_26))))
(assert (= ne_26 (bvand x8_target_24 #b1)))
(assert (and (= x8_54 ((_ sign_extend 1) ((_ extract 63 1) x8_53))) (= dc_223 ((_ zero_extend 63) ((_ extract 0 0) x8_53)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_52) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_30 x7_29)) (= (bvmul x8_54 #x0000000000000002) x8_52)) (= x3_51 (bvadd #x0000000000000002 x3_49))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_52) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_49 #x0000000000000000)) (= x7_30 x7_29)) (= (bvmul x8_54 #x0000000000000002) (bvadd x8_52 x7_29))) (= x3_51 (bvadd #x0000000000000002 x3_49)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_52) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_49 #x0000000000000000)) (= x7_30 x8_52)) (= (bvmul x8_54 #x0000000000000002) (bvsub x8_52 x7_29))) (= x3_51 (bvsub #x0000000000000002 x3_49))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_4f3162.smt2
Execution time of boolector: 0.4937 seconds
OUTPUT FROM boolector:
unsat

=== Cut #6 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #6
; Range assertion #45: or [and [smod (sub (uext x8_54 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_31 = x7_30, mul x8_56 2@64 = x8_54, x3_53 = add 2@64 x3_51], and [smod (sub (uext x8_54 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_51 <s 0@64, x7_31 = x7_30, mul x8_56 2@64 = add x8_54 x7_30, x3_53 = add 2@64 x3_51], and [smod (sub (uext x8_54 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_51 >=s 0@64, x7_31 = x8_54, mul x8_56 2@64 = sub x8_54 x7_30, x3_53 = sub 2@64 x3_51]]
; Range condition: ((x8_54@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_31 = x7_30 /\ x8_56 * 2 = x8_54 /\ x3_53 = 2 + x3_51 \/ ((x8_54@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_51 <s 0 /\ x7_31 = x7_30 /\ x8_56 * 2 = x8_54 + x7_30 /\ x3_53 = 2 + x3_51 \/ ((x8_54@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_51 >=s 0 /\ x7_31 = x8_54 /\ x8_56 * 2 = x8_54 - x7_30 /\ x3_53 = 2 - x3_51
; Output file: /tmp/outputqfbv_06b325.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_25 () (_ BitVec 1))
(declare-fun x8_target_24 () (_ BitVec 1))
(declare-fun x8_target_23 () (_ BitVec 1))
(declare-fun x8_target_22 () (_ BitVec 1))
(declare-fun x8_target_21 () (_ BitVec 1))
(declare-fun x8_target_20 () (_ BitVec 1))
(declare-fun x8_lo_27 () (_ BitVec 2))
(declare-fun x8_lo_26 () (_ BitVec 2))
(declare-fun x8_lo_25 () (_ BitVec 2))
(declare-fun x8_lo_24 () (_ BitVec 2))
(declare-fun x8_lo_23 () (_ BitVec 2))
(declare-fun x8_lo_22 () (_ BitVec 2))
(declare-fun x8_lo_21 () (_ BitVec 1))
(declare-fun x8_56 () (_ BitVec 64))
(declare-fun x8_55 () (_ BitVec 64))
(declare-fun x8_54 () (_ BitVec 64))
(declare-fun x8_53 () (_ BitVec 64))
(declare-fun x8_52 () (_ BitVec 64))
(declare-fun x8_51 () (_ BitVec 64))
(declare-fun x8_50 () (_ BitVec 64))
(declare-fun x8_49 () (_ BitVec 64))
(declare-fun x8_48 () (_ BitVec 64))
(declare-fun x8_47 () (_ BitVec 64))
(declare-fun x8_46 () (_ BitVec 64))
(declare-fun x8_45 () (_ BitVec 64))
(declare-fun x8_44 () (_ BitVec 64))
(declare-fun x7_31 () (_ BitVec 64))
(declare-fun x7_30 () (_ BitVec 64))
(declare-fun x7_29 () (_ BitVec 64))
(declare-fun x7_28 () (_ BitVec 64))
(declare-fun x7_27 () (_ BitVec 64))
(declare-fun x7_26 () (_ BitVec 64))
(declare-fun x7_25 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_26 () (_ BitVec 64))
(declare-fun x3_neg_25 () (_ BitVec 64))
(declare-fun x3_neg_24 () (_ BitVec 64))
(declare-fun x3_neg_23 () (_ BitVec 64))
(declare-fun x3_neg_22 () (_ BitVec 64))
(declare-fun x3_neg_21 () (_ BitVec 64))
(declare-fun x3_53 () (_ BitVec 64))
(declare-fun x3_52 () (_ BitVec 64))
(declare-fun x3_51 () (_ BitVec 64))
(declare-fun x3_50 () (_ BitVec 64))
(declare-fun x3_49 () (_ BitVec 64))
(declare-fun x3_48 () (_ BitVec 64))
(declare-fun x3_47 () (_ BitVec 64))
(declare-fun x3_46 () (_ BitVec 64))
(declare-fun x3_45 () (_ BitVec 64))
(declare-fun x3_44 () (_ BitVec 64))
(declare-fun x3_43 () (_ BitVec 64))
(declare-fun x3_42 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x10_neg_26 () (_ BitVec 64))
(declare-fun x10_neg_25 () (_ BitVec 64))
(declare-fun x10_neg_24 () (_ BitVec 64))
(declare-fun x10_neg_23 () (_ BitVec 64))
(declare-fun x10_neg_22 () (_ BitVec 64))
(declare-fun x10_neg_21 () (_ BitVec 64))
(declare-fun x10_54 () (_ BitVec 64))
(declare-fun x10_53 () (_ BitVec 64))
(declare-fun x10_52 () (_ BitVec 64))
(declare-fun x10_51 () (_ BitVec 64))
(declare-fun x10_50 () (_ BitVec 64))
(declare-fun x10_49 () (_ BitVec 64))
(declare-fun x10_48 () (_ BitVec 64))
(declare-fun x10_47 () (_ BitVec 64))
(declare-fun x10_46 () (_ BitVec 64))
(declare-fun x10_45 () (_ BitVec 64))
(declare-fun x10_44 () (_ BitVec 64))
(declare-fun x10_43 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun ne_27 () (_ BitVec 1))
(declare-fun ne_26 () (_ BitVec 1))
(declare-fun ne_25 () (_ BitVec 1))
(declare-fun ne_24 () (_ BitVec 1))
(declare-fun ne_23 () (_ BitVec 1))
(declare-fun ne_22 () (_ BitVec 1))
(declare-fun ne_21 () (_ BitVec 1))
(declare-fun ge_78 () (_ BitVec 1))
(declare-fun ge_77 () (_ BitVec 1))
(declare-fun ge_76 () (_ BitVec 1))
(declare-fun ge_75 () (_ BitVec 1))
(declare-fun ge_74 () (_ BitVec 1))
(declare-fun ge_73 () (_ BitVec 1))
(declare-fun ge_72 () (_ BitVec 1))
(declare-fun ge_71 () (_ BitVec 1))
(declare-fun ge_70 () (_ BitVec 1))
(declare-fun ge_69 () (_ BitVec 1))
(declare-fun ge_68 () (_ BitVec 1))
(declare-fun ge_67 () (_ BitVec 1))
(declare-fun ge_66 () (_ BitVec 1))
(declare-fun ge_65 () (_ BitVec 1))
(declare-fun ge_64 () (_ BitVec 1))
(declare-fun ge_63 () (_ BitVec 1))
(declare-fun ge_62 () (_ BitVec 1))
(declare-fun ge_61 () (_ BitVec 1))
(declare-fun dc_230 () (_ BitVec 64))
(declare-fun dc_229 () (_ BitVec 1))
(declare-fun dc_228 () (_ BitVec 62))
(declare-fun dc_227 () (_ BitVec 1))
(declare-fun dc_226 () (_ BitVec 1))
(declare-fun dc_225 () (_ BitVec 1))
(declare-fun dc_224 () (_ BitVec 63))
(declare-fun dc_223 () (_ BitVec 64))
(declare-fun dc_222 () (_ BitVec 1))
(declare-fun dc_221 () (_ BitVec 62))
(declare-fun dc_220 () (_ BitVec 1))
(declare-fun dc_219 () (_ BitVec 1))
(declare-fun dc_218 () (_ BitVec 1))
(declare-fun dc_217 () (_ BitVec 63))
(declare-fun dc_216 () (_ BitVec 64))
(declare-fun dc_215 () (_ BitVec 1))
(declare-fun dc_214 () (_ BitVec 62))
(declare-fun dc_213 () (_ BitVec 1))
(declare-fun dc_212 () (_ BitVec 1))
(declare-fun dc_211 () (_ BitVec 1))
(declare-fun dc_210 () (_ BitVec 63))
(declare-fun dc_209 () (_ BitVec 64))
(declare-fun dc_208 () (_ BitVec 1))
(declare-fun dc_207 () (_ BitVec 62))
(declare-fun dc_206 () (_ BitVec 1))
(declare-fun dc_205 () (_ BitVec 1))
(declare-fun dc_204 () (_ BitVec 1))
(declare-fun dc_203 () (_ BitVec 63))
(declare-fun dc_202 () (_ BitVec 64))
(declare-fun dc_201 () (_ BitVec 1))
(declare-fun dc_200 () (_ BitVec 62))
(declare-fun dc_199 () (_ BitVec 1))
(declare-fun dc_198 () (_ BitVec 1))
(declare-fun dc_197 () (_ BitVec 1))
(declare-fun dc_196 () (_ BitVec 63))
(declare-fun dc_195 () (_ BitVec 64))
(declare-fun dc_194 () (_ BitVec 1))
(declare-fun dc_193 () (_ BitVec 62))
(declare-fun dc_192 () (_ BitVec 1))
(declare-fun dc_191 () (_ BitVec 1))
(declare-fun dc_190 () (_ BitVec 1))
(declare-fun dc_189 () (_ BitVec 63))
(declare-fun dc_188 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_25 (bvadd (bvadd neg_f_0_low60_20_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_44 (bvadd (bvadd neg_g_0_low60_20_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_0_1)) (bvsle neg_f_0_low60_20_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_0_1)) (bvsle neg_g_0_low60_20_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_25) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_188 ((_ extract 63 1) x8_44)) (= x8_lo_21 ((_ extract 0 0) x8_44))))
(assert (= ne_21 (bvand x8_lo_21 #b1)))
(assert (= x10_43 (ite (= ne_21 #b1) x7_25 #x0000000000000000)))
(assert (and (= ge_61 ((_ extract 63 63) x3_41)) (= dc_189 ((_ extract 62 0) x3_41))))
(assert (= ge_62 (bvnot ge_61)))
(assert (= ge_63 (ite (= ne_21 #b1) ge_62 #b0)))
(assert (and (= dc_190 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_42 (ite (= ge_63 #b1) x3_neg_21 x3_41)))
(assert (and (= dc_191 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_44 (ite (= ge_63 #b1) x10_neg_21 x10_43)))
(assert (= x7_26 (ite (= ge_63 #b1) x8_44 x7_25)))
(assert (and (= dc_192 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44)))) (= x8_45 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44))))))
(assert (= x3_43 (bvadd x3_42 #x0000000000000002)))
(assert (and (= dc_193 ((_ extract 63 2) x8_45)) (= x8_lo_22 ((_ extract 1 0) x8_45))))
(assert (and (= x8_target_20 ((_ extract 1 1) x8_lo_22)) (= dc_194 ((_ extract 0 0) x8_lo_22))))
(assert (= ne_22 (bvand x8_target_20 #b1)))
(assert (and (= x8_46 ((_ sign_extend 1) ((_ extract 63 1) x8_45))) (= dc_195 ((_ zero_extend 63) ((_ extract 0 0) x8_45)))))
(assert true)
(assert (= x10_45 (ite (= ne_22 #b1) x7_26 #x0000000000000000)))
(assert (and (= ge_64 ((_ extract 63 63) x3_43)) (= dc_196 ((_ extract 62 0) x3_43))))
(assert (= ge_65 (bvnot ge_64)))
(assert (= ge_66 (ite (= ne_22 #b1) ge_65 #b0)))
(assert (and (= dc_197 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_44 (ite (= ge_66 #b1) x3_neg_22 x3_43)))
(assert (and (= dc_198 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_46 (ite (= ge_66 #b1) x10_neg_22 x10_45)))
(assert (= x7_27 (ite (= ge_66 #b1) x8_46 x7_26)))
(assert (and (= dc_199 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46)))) (= x8_47 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46))))))
(assert (= x3_45 (bvadd x3_44 #x0000000000000002)))
(assert (and (= dc_200 ((_ extract 63 2) x8_47)) (= x8_lo_23 ((_ extract 1 0) x8_47))))
(assert (and (= x8_target_21 ((_ extract 1 1) x8_lo_23)) (= dc_201 ((_ extract 0 0) x8_lo_23))))
(assert (= ne_23 (bvand x8_target_21 #b1)))
(assert (and (= x8_48 ((_ sign_extend 1) ((_ extract 63 1) x8_47))) (= dc_202 ((_ zero_extend 63) ((_ extract 0 0) x8_47)))))
(assert true)
(assert (= x10_47 (ite (= ne_23 #b1) x7_27 #x0000000000000000)))
(assert (and (= ge_67 ((_ extract 63 63) x3_45)) (= dc_203 ((_ extract 62 0) x3_45))))
(assert (= ge_68 (bvnot ge_67)))
(assert (= ge_69 (ite (= ne_23 #b1) ge_68 #b0)))
(assert (and (= dc_204 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_46 (ite (= ge_69 #b1) x3_neg_23 x3_45)))
(assert (and (= dc_205 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_48 (ite (= ge_69 #b1) x10_neg_23 x10_47)))
(assert (= x7_28 (ite (= ge_69 #b1) x8_48 x7_27)))
(assert (and (= dc_206 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48)))) (= x8_49 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48))))))
(assert (= x3_47 (bvadd x3_46 #x0000000000000002)))
(assert (and (= dc_207 ((_ extract 63 2) x8_49)) (= x8_lo_24 ((_ extract 1 0) x8_49))))
(assert (and (= x8_target_22 ((_ extract 1 1) x8_lo_24)) (= dc_208 ((_ extract 0 0) x8_lo_24))))
(assert (= ne_24 (bvand x8_target_22 #b1)))
(assert (and (= x8_50 ((_ sign_extend 1) ((_ extract 63 1) x8_49))) (= dc_209 ((_ zero_extend 63) ((_ extract 0 0) x8_49)))))
(assert true)
(assert (= x10_49 (ite (= ne_24 #b1) x7_28 #x0000000000000000)))
(assert (and (= ge_70 ((_ extract 63 63) x3_47)) (= dc_210 ((_ extract 62 0) x3_47))))
(assert (= ge_71 (bvnot ge_70)))
(assert (= ge_72 (ite (= ne_24 #b1) ge_71 #b0)))
(assert (and (= dc_211 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_47))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_24 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_47))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_48 (ite (= ge_72 #b1) x3_neg_24 x3_47)))
(assert (and (= dc_212 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_49))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_24 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_49))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_50 (ite (= ge_72 #b1) x10_neg_24 x10_49)))
(assert (= x7_29 (ite (= ge_72 #b1) x8_50 x7_28)))
(assert (and (= dc_213 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_50) ((_ zero_extend 1) x10_50)))) (= x8_51 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_50) ((_ zero_extend 1) x10_50))))))
(assert (= x3_49 (bvadd x3_48 #x0000000000000002)))
(assert (and (= dc_214 ((_ extract 63 2) x8_51)) (= x8_lo_25 ((_ extract 1 0) x8_51))))
(assert (and (= x8_target_23 ((_ extract 1 1) x8_lo_25)) (= dc_215 ((_ extract 0 0) x8_lo_25))))
(assert (= ne_25 (bvand x8_target_23 #b1)))
(assert (and (= x8_52 ((_ sign_extend 1) ((_ extract 63 1) x8_51))) (= dc_216 ((_ zero_extend 63) ((_ extract 0 0) x8_51)))))
(assert true)
(assert (= x10_51 (ite (= ne_25 #b1) x7_29 #x0000000000000000)))
(assert (and (= ge_73 ((_ extract 63 63) x3_49)) (= dc_217 ((_ extract 62 0) x3_49))))
(assert (= ge_74 (bvnot ge_73)))
(assert (= ge_75 (ite (= ne_25 #b1) ge_74 #b0)))
(assert (and (= dc_218 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_49))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_25 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_49))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_50 (ite (= ge_75 #b1) x3_neg_25 x3_49)))
(assert (and (= dc_219 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_51))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_25 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_51))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_52 (ite (= ge_75 #b1) x10_neg_25 x10_51)))
(assert (= x7_30 (ite (= ge_75 #b1) x8_52 x7_29)))
(assert (and (= dc_220 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_52) ((_ zero_extend 1) x10_52)))) (= x8_53 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_52) ((_ zero_extend 1) x10_52))))))
(assert (= x3_51 (bvadd x3_50 #x0000000000000002)))
(assert (and (= dc_221 ((_ extract 63 2) x8_53)) (= x8_lo_26 ((_ extract 1 0) x8_53))))
(assert (and (= x8_target_24 ((_ extract 1 1) x8_lo_26)) (= dc_222 ((_ extract 0 0) x8_lo_26))))
(assert (= ne_26 (bvand x8_target_24 #b1)))
(assert (and (= x8_54 ((_ sign_extend 1) ((_ extract 63 1) x8_53))) (= dc_223 ((_ zero_extend 63) ((_ extract 0 0) x8_53)))))
(assert true)
(assert (= x10_53 (ite (= ne_26 #b1) x7_30 #x0000000000000000)))
(assert (and (= ge_76 ((_ extract 63 63) x3_51)) (= dc_224 ((_ extract 62 0) x3_51))))
(assert (= ge_77 (bvnot ge_76)))
(assert (= ge_78 (ite (= ne_26 #b1) ge_77 #b0)))
(assert (and (= dc_225 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_51))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_26 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_51))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_52 (ite (= ge_78 #b1) x3_neg_26 x3_51)))
(assert (and (= dc_226 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_53))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_26 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_53))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_54 (ite (= ge_78 #b1) x10_neg_26 x10_53)))
(assert (= x7_31 (ite (= ge_78 #b1) x8_54 x7_30)))
(assert (and (= dc_227 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_54) ((_ zero_extend 1) x10_54)))) (= x8_55 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_54) ((_ zero_extend 1) x10_54))))))
(assert (= x3_53 (bvadd x3_52 #x0000000000000002)))
(assert (and (= dc_228 ((_ extract 63 2) x8_55)) (= x8_lo_27 ((_ extract 1 0) x8_55))))
(assert (and (= x8_target_25 ((_ extract 1 1) x8_lo_27)) (= dc_229 ((_ extract 0 0) x8_lo_27))))
(assert (= ne_27 (bvand x8_target_25 #b1)))
(assert (and (= x8_56 ((_ sign_extend 1) ((_ extract 63 1) x8_55))) (= dc_230 ((_ zero_extend 63) ((_ extract 0 0) x8_55)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_54) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_31 x7_30)) (= (bvmul x8_56 #x0000000000000002) x8_54)) (= x3_53 (bvadd #x0000000000000002 x3_51))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_54) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_51 #x0000000000000000)) (= x7_31 x7_30)) (= (bvmul x8_56 #x0000000000000002) (bvadd x8_54 x7_30))) (= x3_53 (bvadd #x0000000000000002 x3_51)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_54) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_51 #x0000000000000000)) (= x7_31 x8_54)) (= (bvmul x8_56 #x0000000000000002) (bvsub x8_54 x7_30))) (= x3_53 (bvsub #x0000000000000002 x3_51))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_efaca3.smt2
Execution time of boolector: 0.5976 seconds
OUTPUT FROM boolector:
unsat

=== Cut #6 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #6
; Range assertion #49: or [and [smod (sub (uext x8_62 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_35 = x7_34, mul x8_64 2@64 = x8_62, x3_61 = add 2@64 x3_59], and [smod (sub (uext x8_62 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_59 <s 0@64, x7_35 = x7_34, mul x8_64 2@64 = add x8_62 x7_34, x3_61 = add 2@64 x3_59], and [smod (sub (uext x8_62 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_59 >=s 0@64, x7_35 = x8_62, mul x8_64 2@64 = sub x8_62 x7_34, x3_61 = sub 2@64 x3_59]]
; Range condition: ((x8_62@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_35 = x7_34 /\ x8_64 * 2 = x8_62 /\ x3_61 = 2 + x3_59 \/ ((x8_62@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_59 <s 0 /\ x7_35 = x7_34 /\ x8_64 * 2 = x8_62 + x7_34 /\ x3_61 = 2 + x3_59 \/ ((x8_62@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_59 >=s 0 /\ x7_35 = x8_62 /\ x8_64 * 2 = x8_62 - x7_34 /\ x3_61 = 2 - x3_59
; Output file: /tmp/outputqfbv_50699d.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_29 () (_ BitVec 1))
(declare-fun x8_target_28 () (_ BitVec 1))
(declare-fun x8_target_27 () (_ BitVec 1))
(declare-fun x8_target_26 () (_ BitVec 1))
(declare-fun x8_target_25 () (_ BitVec 1))
(declare-fun x8_target_24 () (_ BitVec 1))
(declare-fun x8_target_23 () (_ BitVec 1))
(declare-fun x8_target_22 () (_ BitVec 1))
(declare-fun x8_target_21 () (_ BitVec 1))
(declare-fun x8_target_20 () (_ BitVec 1))
(declare-fun x8_lo_31 () (_ BitVec 2))
(declare-fun x8_lo_30 () (_ BitVec 2))
(declare-fun x8_lo_29 () (_ BitVec 2))
(declare-fun x8_lo_28 () (_ BitVec 2))
(declare-fun x8_lo_27 () (_ BitVec 2))
(declare-fun x8_lo_26 () (_ BitVec 2))
(declare-fun x8_lo_25 () (_ BitVec 2))
(declare-fun x8_lo_24 () (_ BitVec 2))
(declare-fun x8_lo_23 () (_ BitVec 2))
(declare-fun x8_lo_22 () (_ BitVec 2))
(declare-fun x8_lo_21 () (_ BitVec 1))
(declare-fun x8_64 () (_ BitVec 64))
(declare-fun x8_63 () (_ BitVec 64))
(declare-fun x8_62 () (_ BitVec 64))
(declare-fun x8_61 () (_ BitVec 64))
(declare-fun x8_60 () (_ BitVec 64))
(declare-fun x8_59 () (_ BitVec 64))
(declare-fun x8_58 () (_ BitVec 64))
(declare-fun x8_57 () (_ BitVec 64))
(declare-fun x8_56 () (_ BitVec 64))
(declare-fun x8_55 () (_ BitVec 64))
(declare-fun x8_54 () (_ BitVec 64))
(declare-fun x8_53 () (_ BitVec 64))
(declare-fun x8_52 () (_ BitVec 64))
(declare-fun x8_51 () (_ BitVec 64))
(declare-fun x8_50 () (_ BitVec 64))
(declare-fun x8_49 () (_ BitVec 64))
(declare-fun x8_48 () (_ BitVec 64))
(declare-fun x8_47 () (_ BitVec 64))
(declare-fun x8_46 () (_ BitVec 64))
(declare-fun x8_45 () (_ BitVec 64))
(declare-fun x8_44 () (_ BitVec 64))
(declare-fun x7_35 () (_ BitVec 64))
(declare-fun x7_34 () (_ BitVec 64))
(declare-fun x7_33 () (_ BitVec 64))
(declare-fun x7_32 () (_ BitVec 64))
(declare-fun x7_31 () (_ BitVec 64))
(declare-fun x7_30 () (_ BitVec 64))
(declare-fun x7_29 () (_ BitVec 64))
(declare-fun x7_28 () (_ BitVec 64))
(declare-fun x7_27 () (_ BitVec 64))
(declare-fun x7_26 () (_ BitVec 64))
(declare-fun x7_25 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_30 () (_ BitVec 64))
(declare-fun x3_neg_29 () (_ BitVec 64))
(declare-fun x3_neg_28 () (_ BitVec 64))
(declare-fun x3_neg_27 () (_ BitVec 64))
(declare-fun x3_neg_26 () (_ BitVec 64))
(declare-fun x3_neg_25 () (_ BitVec 64))
(declare-fun x3_neg_24 () (_ BitVec 64))
(declare-fun x3_neg_23 () (_ BitVec 64))
(declare-fun x3_neg_22 () (_ BitVec 64))
(declare-fun x3_neg_21 () (_ BitVec 64))
(declare-fun x3_61 () (_ BitVec 64))
(declare-fun x3_60 () (_ BitVec 64))
(declare-fun x3_59 () (_ BitVec 64))
(declare-fun x3_58 () (_ BitVec 64))
(declare-fun x3_57 () (_ BitVec 64))
(declare-fun x3_56 () (_ BitVec 64))
(declare-fun x3_55 () (_ BitVec 64))
(declare-fun x3_54 () (_ BitVec 64))
(declare-fun x3_53 () (_ BitVec 64))
(declare-fun x3_52 () (_ BitVec 64))
(declare-fun x3_51 () (_ BitVec 64))
(declare-fun x3_50 () (_ BitVec 64))
(declare-fun x3_49 () (_ BitVec 64))
(declare-fun x3_48 () (_ BitVec 64))
(declare-fun x3_47 () (_ BitVec 64))
(declare-fun x3_46 () (_ BitVec 64))
(declare-fun x3_45 () (_ BitVec 64))
(declare-fun x3_44 () (_ BitVec 64))
(declare-fun x3_43 () (_ BitVec 64))
(declare-fun x3_42 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x10_neg_30 () (_ BitVec 64))
(declare-fun x10_neg_29 () (_ BitVec 64))
(declare-fun x10_neg_28 () (_ BitVec 64))
(declare-fun x10_neg_27 () (_ BitVec 64))
(declare-fun x10_neg_26 () (_ BitVec 64))
(declare-fun x10_neg_25 () (_ BitVec 64))
(declare-fun x10_neg_24 () (_ BitVec 64))
(declare-fun x10_neg_23 () (_ BitVec 64))
(declare-fun x10_neg_22 () (_ BitVec 64))
(declare-fun x10_neg_21 () (_ BitVec 64))
(declare-fun x10_62 () (_ BitVec 64))
(declare-fun x10_61 () (_ BitVec 64))
(declare-fun x10_60 () (_ BitVec 64))
(declare-fun x10_59 () (_ BitVec 64))
(declare-fun x10_58 () (_ BitVec 64))
(declare-fun x10_57 () (_ BitVec 64))
(declare-fun x10_56 () (_ BitVec 64))
(declare-fun x10_55 () (_ BitVec 64))
(declare-fun x10_54 () (_ BitVec 64))
(declare-fun x10_53 () (_ BitVec 64))
(declare-fun x10_52 () (_ BitVec 64))
(declare-fun x10_51 () (_ BitVec 64))
(declare-fun x10_50 () (_ BitVec 64))
(declare-fun x10_49 () (_ BitVec 64))
(declare-fun x10_48 () (_ BitVec 64))
(declare-fun x10_47 () (_ BitVec 64))
(declare-fun x10_46 () (_ BitVec 64))
(declare-fun x10_45 () (_ BitVec 64))
(declare-fun x10_44 () (_ BitVec 64))
(declare-fun x10_43 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun ne_31 () (_ BitVec 1))
(declare-fun ne_30 () (_ BitVec 1))
(declare-fun ne_29 () (_ BitVec 1))
(declare-fun ne_28 () (_ BitVec 1))
(declare-fun ne_27 () (_ BitVec 1))
(declare-fun ne_26 () (_ BitVec 1))
(declare-fun ne_25 () (_ BitVec 1))
(declare-fun ne_24 () (_ BitVec 1))
(declare-fun ne_23 () (_ BitVec 1))
(declare-fun ne_22 () (_ BitVec 1))
(declare-fun ne_21 () (_ BitVec 1))
(declare-fun ge_90 () (_ BitVec 1))
(declare-fun ge_89 () (_ BitVec 1))
(declare-fun ge_88 () (_ BitVec 1))
(declare-fun ge_87 () (_ BitVec 1))
(declare-fun ge_86 () (_ BitVec 1))
(declare-fun ge_85 () (_ BitVec 1))
(declare-fun ge_84 () (_ BitVec 1))
(declare-fun ge_83 () (_ BitVec 1))
(declare-fun ge_82 () (_ BitVec 1))
(declare-fun ge_81 () (_ BitVec 1))
(declare-fun ge_80 () (_ BitVec 1))
(declare-fun ge_79 () (_ BitVec 1))
(declare-fun ge_78 () (_ BitVec 1))
(declare-fun ge_77 () (_ BitVec 1))
(declare-fun ge_76 () (_ BitVec 1))
(declare-fun ge_75 () (_ BitVec 1))
(declare-fun ge_74 () (_ BitVec 1))
(declare-fun ge_73 () (_ BitVec 1))
(declare-fun ge_72 () (_ BitVec 1))
(declare-fun ge_71 () (_ BitVec 1))
(declare-fun ge_70 () (_ BitVec 1))
(declare-fun ge_69 () (_ BitVec 1))
(declare-fun ge_68 () (_ BitVec 1))
(declare-fun ge_67 () (_ BitVec 1))
(declare-fun ge_66 () (_ BitVec 1))
(declare-fun ge_65 () (_ BitVec 1))
(declare-fun ge_64 () (_ BitVec 1))
(declare-fun ge_63 () (_ BitVec 1))
(declare-fun ge_62 () (_ BitVec 1))
(declare-fun ge_61 () (_ BitVec 1))
(declare-fun dc_258 () (_ BitVec 64))
(declare-fun dc_257 () (_ BitVec 1))
(declare-fun dc_256 () (_ BitVec 62))
(declare-fun dc_255 () (_ BitVec 1))
(declare-fun dc_254 () (_ BitVec 1))
(declare-fun dc_253 () (_ BitVec 1))
(declare-fun dc_252 () (_ BitVec 63))
(declare-fun dc_251 () (_ BitVec 64))
(declare-fun dc_250 () (_ BitVec 1))
(declare-fun dc_249 () (_ BitVec 62))
(declare-fun dc_248 () (_ BitVec 1))
(declare-fun dc_247 () (_ BitVec 1))
(declare-fun dc_246 () (_ BitVec 1))
(declare-fun dc_245 () (_ BitVec 63))
(declare-fun dc_244 () (_ BitVec 64))
(declare-fun dc_243 () (_ BitVec 1))
(declare-fun dc_242 () (_ BitVec 62))
(declare-fun dc_241 () (_ BitVec 1))
(declare-fun dc_240 () (_ BitVec 1))
(declare-fun dc_239 () (_ BitVec 1))
(declare-fun dc_238 () (_ BitVec 63))
(declare-fun dc_237 () (_ BitVec 64))
(declare-fun dc_236 () (_ BitVec 1))
(declare-fun dc_235 () (_ BitVec 62))
(declare-fun dc_234 () (_ BitVec 1))
(declare-fun dc_233 () (_ BitVec 1))
(declare-fun dc_232 () (_ BitVec 1))
(declare-fun dc_231 () (_ BitVec 63))
(declare-fun dc_230 () (_ BitVec 64))
(declare-fun dc_229 () (_ BitVec 1))
(declare-fun dc_228 () (_ BitVec 62))
(declare-fun dc_227 () (_ BitVec 1))
(declare-fun dc_226 () (_ BitVec 1))
(declare-fun dc_225 () (_ BitVec 1))
(declare-fun dc_224 () (_ BitVec 63))
(declare-fun dc_223 () (_ BitVec 64))
(declare-fun dc_222 () (_ BitVec 1))
(declare-fun dc_221 () (_ BitVec 62))
(declare-fun dc_220 () (_ BitVec 1))
(declare-fun dc_219 () (_ BitVec 1))
(declare-fun dc_218 () (_ BitVec 1))
(declare-fun dc_217 () (_ BitVec 63))
(declare-fun dc_216 () (_ BitVec 64))
(declare-fun dc_215 () (_ BitVec 1))
(declare-fun dc_214 () (_ BitVec 62))
(declare-fun dc_213 () (_ BitVec 1))
(declare-fun dc_212 () (_ BitVec 1))
(declare-fun dc_211 () (_ BitVec 1))
(declare-fun dc_210 () (_ BitVec 63))
(declare-fun dc_209 () (_ BitVec 64))
(declare-fun dc_208 () (_ BitVec 1))
(declare-fun dc_207 () (_ BitVec 62))
(declare-fun dc_206 () (_ BitVec 1))
(declare-fun dc_205 () (_ BitVec 1))
(declare-fun dc_204 () (_ BitVec 1))
(declare-fun dc_203 () (_ BitVec 63))
(declare-fun dc_202 () (_ BitVec 64))
(declare-fun dc_201 () (_ BitVec 1))
(declare-fun dc_200 () (_ BitVec 62))
(declare-fun dc_199 () (_ BitVec 1))
(declare-fun dc_198 () (_ BitVec 1))
(declare-fun dc_197 () (_ BitVec 1))
(declare-fun dc_196 () (_ BitVec 63))
(declare-fun dc_195 () (_ BitVec 64))
(declare-fun dc_194 () (_ BitVec 1))
(declare-fun dc_193 () (_ BitVec 62))
(declare-fun dc_192 () (_ BitVec 1))
(declare-fun dc_191 () (_ BitVec 1))
(declare-fun dc_190 () (_ BitVec 1))
(declare-fun dc_189 () (_ BitVec 63))
(declare-fun dc_188 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_25 (bvadd (bvadd neg_f_0_low60_20_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_44 (bvadd (bvadd neg_g_0_low60_20_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_0_1)) (bvsle neg_f_0_low60_20_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_0_1)) (bvsle neg_g_0_low60_20_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_25) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_188 ((_ extract 63 1) x8_44)) (= x8_lo_21 ((_ extract 0 0) x8_44))))
(assert (= ne_21 (bvand x8_lo_21 #b1)))
(assert (= x10_43 (ite (= ne_21 #b1) x7_25 #x0000000000000000)))
(assert (and (= ge_61 ((_ extract 63 63) x3_41)) (= dc_189 ((_ extract 62 0) x3_41))))
(assert (= ge_62 (bvnot ge_61)))
(assert (= ge_63 (ite (= ne_21 #b1) ge_62 #b0)))
(assert (and (= dc_190 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_42 (ite (= ge_63 #b1) x3_neg_21 x3_41)))
(assert (and (= dc_191 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_44 (ite (= ge_63 #b1) x10_neg_21 x10_43)))
(assert (= x7_26 (ite (= ge_63 #b1) x8_44 x7_25)))
(assert (and (= dc_192 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44)))) (= x8_45 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44))))))
(assert (= x3_43 (bvadd x3_42 #x0000000000000002)))
(assert (and (= dc_193 ((_ extract 63 2) x8_45)) (= x8_lo_22 ((_ extract 1 0) x8_45))))
(assert (and (= x8_target_20 ((_ extract 1 1) x8_lo_22)) (= dc_194 ((_ extract 0 0) x8_lo_22))))
(assert (= ne_22 (bvand x8_target_20 #b1)))
(assert (and (= x8_46 ((_ sign_extend 1) ((_ extract 63 1) x8_45))) (= dc_195 ((_ zero_extend 63) ((_ extract 0 0) x8_45)))))
(assert true)
(assert (= x10_45 (ite (= ne_22 #b1) x7_26 #x0000000000000000)))
(assert (and (= ge_64 ((_ extract 63 63) x3_43)) (= dc_196 ((_ extract 62 0) x3_43))))
(assert (= ge_65 (bvnot ge_64)))
(assert (= ge_66 (ite (= ne_22 #b1) ge_65 #b0)))
(assert (and (= dc_197 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_44 (ite (= ge_66 #b1) x3_neg_22 x3_43)))
(assert (and (= dc_198 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_46 (ite (= ge_66 #b1) x10_neg_22 x10_45)))
(assert (= x7_27 (ite (= ge_66 #b1) x8_46 x7_26)))
(assert (and (= dc_199 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46)))) (= x8_47 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46))))))
(assert (= x3_45 (bvadd x3_44 #x0000000000000002)))
(assert (and (= dc_200 ((_ extract 63 2) x8_47)) (= x8_lo_23 ((_ extract 1 0) x8_47))))
(assert (and (= x8_target_21 ((_ extract 1 1) x8_lo_23)) (= dc_201 ((_ extract 0 0) x8_lo_23))))
(assert (= ne_23 (bvand x8_target_21 #b1)))
(assert (and (= x8_48 ((_ sign_extend 1) ((_ extract 63 1) x8_47))) (= dc_202 ((_ zero_extend 63) ((_ extract 0 0) x8_47)))))
(assert true)
(assert (= x10_47 (ite (= ne_23 #b1) x7_27 #x0000000000000000)))
(assert (and (= ge_67 ((_ extract 63 63) x3_45)) (= dc_203 ((_ extract 62 0) x3_45))))
(assert (= ge_68 (bvnot ge_67)))
(assert (= ge_69 (ite (= ne_23 #b1) ge_68 #b0)))
(assert (and (= dc_204 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_46 (ite (= ge_69 #b1) x3_neg_23 x3_45)))
(assert (and (= dc_205 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_48 (ite (= ge_69 #b1) x10_neg_23 x10_47)))
(assert (= x7_28 (ite (= ge_69 #b1) x8_48 x7_27)))
(assert (and (= dc_206 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48)))) (= x8_49 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48))))))
(assert (= x3_47 (bvadd x3_46 #x0000000000000002)))
(assert (and (= dc_207 ((_ extract 63 2) x8_49)) (= x8_lo_24 ((_ extract 1 0) x8_49))))
(assert (and (= x8_target_22 ((_ extract 1 1) x8_lo_24)) (= dc_208 ((_ extract 0 0) x8_lo_24))))
(assert (= ne_24 (bvand x8_target_22 #b1)))
(assert (and (= x8_50 ((_ sign_extend 1) ((_ extract 63 1) x8_49))) (= dc_209 ((_ zero_extend 63) ((_ extract 0 0) x8_49)))))
(assert true)
(assert (= x10_49 (ite (= ne_24 #b1) x7_28 #x0000000000000000)))
(assert (and (= ge_70 ((_ extract 63 63) x3_47)) (= dc_210 ((_ extract 62 0) x3_47))))
(assert (= ge_71 (bvnot ge_70)))
(assert (= ge_72 (ite (= ne_24 #b1) ge_71 #b0)))
(assert (and (= dc_211 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_47))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_24 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_47))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_48 (ite (= ge_72 #b1) x3_neg_24 x3_47)))
(assert (and (= dc_212 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_49))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_24 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_49))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_50 (ite (= ge_72 #b1) x10_neg_24 x10_49)))
(assert (= x7_29 (ite (= ge_72 #b1) x8_50 x7_28)))
(assert (and (= dc_213 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_50) ((_ zero_extend 1) x10_50)))) (= x8_51 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_50) ((_ zero_extend 1) x10_50))))))
(assert (= x3_49 (bvadd x3_48 #x0000000000000002)))
(assert (and (= dc_214 ((_ extract 63 2) x8_51)) (= x8_lo_25 ((_ extract 1 0) x8_51))))
(assert (and (= x8_target_23 ((_ extract 1 1) x8_lo_25)) (= dc_215 ((_ extract 0 0) x8_lo_25))))
(assert (= ne_25 (bvand x8_target_23 #b1)))
(assert (and (= x8_52 ((_ sign_extend 1) ((_ extract 63 1) x8_51))) (= dc_216 ((_ zero_extend 63) ((_ extract 0 0) x8_51)))))
(assert true)
(assert (= x10_51 (ite (= ne_25 #b1) x7_29 #x0000000000000000)))
(assert (and (= ge_73 ((_ extract 63 63) x3_49)) (= dc_217 ((_ extract 62 0) x3_49))))
(assert (= ge_74 (bvnot ge_73)))
(assert (= ge_75 (ite (= ne_25 #b1) ge_74 #b0)))
(assert (and (= dc_218 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_49))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_25 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_49))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_50 (ite (= ge_75 #b1) x3_neg_25 x3_49)))
(assert (and (= dc_219 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_51))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_25 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_51))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_52 (ite (= ge_75 #b1) x10_neg_25 x10_51)))
(assert (= x7_30 (ite (= ge_75 #b1) x8_52 x7_29)))
(assert (and (= dc_220 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_52) ((_ zero_extend 1) x10_52)))) (= x8_53 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_52) ((_ zero_extend 1) x10_52))))))
(assert (= x3_51 (bvadd x3_50 #x0000000000000002)))
(assert (and (= dc_221 ((_ extract 63 2) x8_53)) (= x8_lo_26 ((_ extract 1 0) x8_53))))
(assert (and (= x8_target_24 ((_ extract 1 1) x8_lo_26)) (= dc_222 ((_ extract 0 0) x8_lo_26))))
(assert (= ne_26 (bvand x8_target_24 #b1)))
(assert (and (= x8_54 ((_ sign_extend 1) ((_ extract 63 1) x8_53))) (= dc_223 ((_ zero_extend 63) ((_ extract 0 0) x8_53)))))
(assert true)
(assert (= x10_53 (ite (= ne_26 #b1) x7_30 #x0000000000000000)))
(assert (and (= ge_76 ((_ extract 63 63) x3_51)) (= dc_224 ((_ extract 62 0) x3_51))))
(assert (= ge_77 (bvnot ge_76)))
(assert (= ge_78 (ite (= ne_26 #b1) ge_77 #b0)))
(assert (and (= dc_225 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_51))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_26 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_51))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_52 (ite (= ge_78 #b1) x3_neg_26 x3_51)))
(assert (and (= dc_226 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_53))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_26 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_53))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_54 (ite (= ge_78 #b1) x10_neg_26 x10_53)))
(assert (= x7_31 (ite (= ge_78 #b1) x8_54 x7_30)))
(assert (and (= dc_227 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_54) ((_ zero_extend 1) x10_54)))) (= x8_55 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_54) ((_ zero_extend 1) x10_54))))))
(assert (= x3_53 (bvadd x3_52 #x0000000000000002)))
(assert (and (= dc_228 ((_ extract 63 2) x8_55)) (= x8_lo_27 ((_ extract 1 0) x8_55))))
(assert (and (= x8_target_25 ((_ extract 1 1) x8_lo_27)) (= dc_229 ((_ extract 0 0) x8_lo_27))))
(assert (= ne_27 (bvand x8_target_25 #b1)))
(assert (and (= x8_56 ((_ sign_extend 1) ((_ extract 63 1) x8_55))) (= dc_230 ((_ zero_extend 63) ((_ extract 0 0) x8_55)))))
(assert true)
(assert (= x10_55 (ite (= ne_27 #b1) x7_31 #x0000000000000000)))
(assert (and (= ge_79 ((_ extract 63 63) x3_53)) (= dc_231 ((_ extract 62 0) x3_53))))
(assert (= ge_80 (bvnot ge_79)))
(assert (= ge_81 (ite (= ne_27 #b1) ge_80 #b0)))
(assert (and (= dc_232 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_53))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_27 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_53))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_54 (ite (= ge_81 #b1) x3_neg_27 x3_53)))
(assert (and (= dc_233 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_55))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_27 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_55))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_56 (ite (= ge_81 #b1) x10_neg_27 x10_55)))
(assert (= x7_32 (ite (= ge_81 #b1) x8_56 x7_31)))
(assert (and (= dc_234 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_56) ((_ zero_extend 1) x10_56)))) (= x8_57 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_56) ((_ zero_extend 1) x10_56))))))
(assert (= x3_55 (bvadd x3_54 #x0000000000000002)))
(assert (and (= dc_235 ((_ extract 63 2) x8_57)) (= x8_lo_28 ((_ extract 1 0) x8_57))))
(assert (and (= x8_target_26 ((_ extract 1 1) x8_lo_28)) (= dc_236 ((_ extract 0 0) x8_lo_28))))
(assert (= ne_28 (bvand x8_target_26 #b1)))
(assert (and (= x8_58 ((_ sign_extend 1) ((_ extract 63 1) x8_57))) (= dc_237 ((_ zero_extend 63) ((_ extract 0 0) x8_57)))))
(assert true)
(assert (= x10_57 (ite (= ne_28 #b1) x7_32 #x0000000000000000)))
(assert (and (= ge_82 ((_ extract 63 63) x3_55)) (= dc_238 ((_ extract 62 0) x3_55))))
(assert (= ge_83 (bvnot ge_82)))
(assert (= ge_84 (ite (= ne_28 #b1) ge_83 #b0)))
(assert (and (= dc_239 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_55))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_28 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_55))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_56 (ite (= ge_84 #b1) x3_neg_28 x3_55)))
(assert (and (= dc_240 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_57))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_28 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_57))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_58 (ite (= ge_84 #b1) x10_neg_28 x10_57)))
(assert (= x7_33 (ite (= ge_84 #b1) x8_58 x7_32)))
(assert (and (= dc_241 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_58) ((_ zero_extend 1) x10_58)))) (= x8_59 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_58) ((_ zero_extend 1) x10_58))))))
(assert (= x3_57 (bvadd x3_56 #x0000000000000002)))
(assert (and (= dc_242 ((_ extract 63 2) x8_59)) (= x8_lo_29 ((_ extract 1 0) x8_59))))
(assert (and (= x8_target_27 ((_ extract 1 1) x8_lo_29)) (= dc_243 ((_ extract 0 0) x8_lo_29))))
(assert (= ne_29 (bvand x8_target_27 #b1)))
(assert (and (= x8_60 ((_ sign_extend 1) ((_ extract 63 1) x8_59))) (= dc_244 ((_ zero_extend 63) ((_ extract 0 0) x8_59)))))
(assert true)
(assert (= x10_59 (ite (= ne_29 #b1) x7_33 #x0000000000000000)))
(assert (and (= ge_85 ((_ extract 63 63) x3_57)) (= dc_245 ((_ extract 62 0) x3_57))))
(assert (= ge_86 (bvnot ge_85)))
(assert (= ge_87 (ite (= ne_29 #b1) ge_86 #b0)))
(assert (and (= dc_246 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_57))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_29 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_57))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_58 (ite (= ge_87 #b1) x3_neg_29 x3_57)))
(assert (and (= dc_247 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_59))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_29 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_59))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_60 (ite (= ge_87 #b1) x10_neg_29 x10_59)))
(assert (= x7_34 (ite (= ge_87 #b1) x8_60 x7_33)))
(assert (and (= dc_248 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_60) ((_ zero_extend 1) x10_60)))) (= x8_61 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_60) ((_ zero_extend 1) x10_60))))))
(assert (= x3_59 (bvadd x3_58 #x0000000000000002)))
(assert (and (= dc_249 ((_ extract 63 2) x8_61)) (= x8_lo_30 ((_ extract 1 0) x8_61))))
(assert (and (= x8_target_28 ((_ extract 1 1) x8_lo_30)) (= dc_250 ((_ extract 0 0) x8_lo_30))))
(assert (= ne_30 (bvand x8_target_28 #b1)))
(assert (and (= x8_62 ((_ sign_extend 1) ((_ extract 63 1) x8_61))) (= dc_251 ((_ zero_extend 63) ((_ extract 0 0) x8_61)))))
(assert true)
(assert (= x10_61 (ite (= ne_30 #b1) x7_34 #x0000000000000000)))
(assert (and (= ge_88 ((_ extract 63 63) x3_59)) (= dc_252 ((_ extract 62 0) x3_59))))
(assert (= ge_89 (bvnot ge_88)))
(assert (= ge_90 (ite (= ne_30 #b1) ge_89 #b0)))
(assert (and (= dc_253 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_59))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_30 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_59))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_60 (ite (= ge_90 #b1) x3_neg_30 x3_59)))
(assert (and (= dc_254 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_61))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_30 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_61))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_62 (ite (= ge_90 #b1) x10_neg_30 x10_61)))
(assert (= x7_35 (ite (= ge_90 #b1) x8_62 x7_34)))
(assert (and (= dc_255 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_62) ((_ zero_extend 1) x10_62)))) (= x8_63 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_62) ((_ zero_extend 1) x10_62))))))
(assert (= x3_61 (bvadd x3_60 #x0000000000000002)))
(assert (and (= dc_256 ((_ extract 63 2) x8_63)) (= x8_lo_31 ((_ extract 1 0) x8_63))))
(assert (and (= x8_target_29 ((_ extract 1 1) x8_lo_31)) (= dc_257 ((_ extract 0 0) x8_lo_31))))
(assert (= ne_31 (bvand x8_target_29 #b1)))
(assert (and (= x8_64 ((_ sign_extend 1) ((_ extract 63 1) x8_63))) (= dc_258 ((_ zero_extend 63) ((_ extract 0 0) x8_63)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_62) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_35 x7_34)) (= (bvmul x8_64 #x0000000000000002) x8_62)) (= x3_61 (bvadd #x0000000000000002 x3_59))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_62) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_59 #x0000000000000000)) (= x7_35 x7_34)) (= (bvmul x8_64 #x0000000000000002) (bvadd x8_62 x7_34))) (= x3_61 (bvadd #x0000000000000002 x3_59)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_62) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_59 #x0000000000000000)) (= x7_35 x8_62)) (= (bvmul x8_64 #x0000000000000002) (bvsub x8_62 x7_34))) (= x3_61 (bvsub #x0000000000000002 x3_59))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_a13999.smt2
Execution time of boolector: 0.6894 seconds
OUTPUT FROM boolector:
unsat

=== Cut #6 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #6
; Range assertion #46: or [and [smod (sub (uext x8_56 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_32 = x7_31, mul x8_58 2@64 = x8_56, x3_55 = add 2@64 x3_53], and [smod (sub (uext x8_56 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_53 <s 0@64, x7_32 = x7_31, mul x8_58 2@64 = add x8_56 x7_31, x3_55 = add 2@64 x3_53], and [smod (sub (uext x8_56 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_53 >=s 0@64, x7_32 = x8_56, mul x8_58 2@64 = sub x8_56 x7_31, x3_55 = sub 2@64 x3_53]]
; Range condition: ((x8_56@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_32 = x7_31 /\ x8_58 * 2 = x8_56 /\ x3_55 = 2 + x3_53 \/ ((x8_56@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_53 <s 0 /\ x7_32 = x7_31 /\ x8_58 * 2 = x8_56 + x7_31 /\ x3_55 = 2 + x3_53 \/ ((x8_56@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_53 >=s 0 /\ x7_32 = x8_56 /\ x8_58 * 2 = x8_56 - x7_31 /\ x3_55 = 2 - x3_53
; Output file: /tmp/outputqfbv_471e37.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_26 () (_ BitVec 1))
(declare-fun x8_target_25 () (_ BitVec 1))
(declare-fun x8_target_24 () (_ BitVec 1))
(declare-fun x8_target_23 () (_ BitVec 1))
(declare-fun x8_target_22 () (_ BitVec 1))
(declare-fun x8_target_21 () (_ BitVec 1))
(declare-fun x8_target_20 () (_ BitVec 1))
(declare-fun x8_lo_28 () (_ BitVec 2))
(declare-fun x8_lo_27 () (_ BitVec 2))
(declare-fun x8_lo_26 () (_ BitVec 2))
(declare-fun x8_lo_25 () (_ BitVec 2))
(declare-fun x8_lo_24 () (_ BitVec 2))
(declare-fun x8_lo_23 () (_ BitVec 2))
(declare-fun x8_lo_22 () (_ BitVec 2))
(declare-fun x8_lo_21 () (_ BitVec 1))
(declare-fun x8_58 () (_ BitVec 64))
(declare-fun x8_57 () (_ BitVec 64))
(declare-fun x8_56 () (_ BitVec 64))
(declare-fun x8_55 () (_ BitVec 64))
(declare-fun x8_54 () (_ BitVec 64))
(declare-fun x8_53 () (_ BitVec 64))
(declare-fun x8_52 () (_ BitVec 64))
(declare-fun x8_51 () (_ BitVec 64))
(declare-fun x8_50 () (_ BitVec 64))
(declare-fun x8_49 () (_ BitVec 64))
(declare-fun x8_48 () (_ BitVec 64))
(declare-fun x8_47 () (_ BitVec 64))
(declare-fun x8_46 () (_ BitVec 64))
(declare-fun x8_45 () (_ BitVec 64))
(declare-fun x8_44 () (_ BitVec 64))
(declare-fun x7_32 () (_ BitVec 64))
(declare-fun x7_31 () (_ BitVec 64))
(declare-fun x7_30 () (_ BitVec 64))
(declare-fun x7_29 () (_ BitVec 64))
(declare-fun x7_28 () (_ BitVec 64))
(declare-fun x7_27 () (_ BitVec 64))
(declare-fun x7_26 () (_ BitVec 64))
(declare-fun x7_25 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_27 () (_ BitVec 64))
(declare-fun x3_neg_26 () (_ BitVec 64))
(declare-fun x3_neg_25 () (_ BitVec 64))
(declare-fun x3_neg_24 () (_ BitVec 64))
(declare-fun x3_neg_23 () (_ BitVec 64))
(declare-fun x3_neg_22 () (_ BitVec 64))
(declare-fun x3_neg_21 () (_ BitVec 64))
(declare-fun x3_55 () (_ BitVec 64))
(declare-fun x3_54 () (_ BitVec 64))
(declare-fun x3_53 () (_ BitVec 64))
(declare-fun x3_52 () (_ BitVec 64))
(declare-fun x3_51 () (_ BitVec 64))
(declare-fun x3_50 () (_ BitVec 64))
(declare-fun x3_49 () (_ BitVec 64))
(declare-fun x3_48 () (_ BitVec 64))
(declare-fun x3_47 () (_ BitVec 64))
(declare-fun x3_46 () (_ BitVec 64))
(declare-fun x3_45 () (_ BitVec 64))
(declare-fun x3_44 () (_ BitVec 64))
(declare-fun x3_43 () (_ BitVec 64))
(declare-fun x3_42 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x10_neg_27 () (_ BitVec 64))
(declare-fun x10_neg_26 () (_ BitVec 64))
(declare-fun x10_neg_25 () (_ BitVec 64))
(declare-fun x10_neg_24 () (_ BitVec 64))
(declare-fun x10_neg_23 () (_ BitVec 64))
(declare-fun x10_neg_22 () (_ BitVec 64))
(declare-fun x10_neg_21 () (_ BitVec 64))
(declare-fun x10_56 () (_ BitVec 64))
(declare-fun x10_55 () (_ BitVec 64))
(declare-fun x10_54 () (_ BitVec 64))
(declare-fun x10_53 () (_ BitVec 64))
(declare-fun x10_52 () (_ BitVec 64))
(declare-fun x10_51 () (_ BitVec 64))
(declare-fun x10_50 () (_ BitVec 64))
(declare-fun x10_49 () (_ BitVec 64))
(declare-fun x10_48 () (_ BitVec 64))
(declare-fun x10_47 () (_ BitVec 64))
(declare-fun x10_46 () (_ BitVec 64))
(declare-fun x10_45 () (_ BitVec 64))
(declare-fun x10_44 () (_ BitVec 64))
(declare-fun x10_43 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun ne_28 () (_ BitVec 1))
(declare-fun ne_27 () (_ BitVec 1))
(declare-fun ne_26 () (_ BitVec 1))
(declare-fun ne_25 () (_ BitVec 1))
(declare-fun ne_24 () (_ BitVec 1))
(declare-fun ne_23 () (_ BitVec 1))
(declare-fun ne_22 () (_ BitVec 1))
(declare-fun ne_21 () (_ BitVec 1))
(declare-fun ge_81 () (_ BitVec 1))
(declare-fun ge_80 () (_ BitVec 1))
(declare-fun ge_79 () (_ BitVec 1))
(declare-fun ge_78 () (_ BitVec 1))
(declare-fun ge_77 () (_ BitVec 1))
(declare-fun ge_76 () (_ BitVec 1))
(declare-fun ge_75 () (_ BitVec 1))
(declare-fun ge_74 () (_ BitVec 1))
(declare-fun ge_73 () (_ BitVec 1))
(declare-fun ge_72 () (_ BitVec 1))
(declare-fun ge_71 () (_ BitVec 1))
(declare-fun ge_70 () (_ BitVec 1))
(declare-fun ge_69 () (_ BitVec 1))
(declare-fun ge_68 () (_ BitVec 1))
(declare-fun ge_67 () (_ BitVec 1))
(declare-fun ge_66 () (_ BitVec 1))
(declare-fun ge_65 () (_ BitVec 1))
(declare-fun ge_64 () (_ BitVec 1))
(declare-fun ge_63 () (_ BitVec 1))
(declare-fun ge_62 () (_ BitVec 1))
(declare-fun ge_61 () (_ BitVec 1))
(declare-fun dc_237 () (_ BitVec 64))
(declare-fun dc_236 () (_ BitVec 1))
(declare-fun dc_235 () (_ BitVec 62))
(declare-fun dc_234 () (_ BitVec 1))
(declare-fun dc_233 () (_ BitVec 1))
(declare-fun dc_232 () (_ BitVec 1))
(declare-fun dc_231 () (_ BitVec 63))
(declare-fun dc_230 () (_ BitVec 64))
(declare-fun dc_229 () (_ BitVec 1))
(declare-fun dc_228 () (_ BitVec 62))
(declare-fun dc_227 () (_ BitVec 1))
(declare-fun dc_226 () (_ BitVec 1))
(declare-fun dc_225 () (_ BitVec 1))
(declare-fun dc_224 () (_ BitVec 63))
(declare-fun dc_223 () (_ BitVec 64))
(declare-fun dc_222 () (_ BitVec 1))
(declare-fun dc_221 () (_ BitVec 62))
(declare-fun dc_220 () (_ BitVec 1))
(declare-fun dc_219 () (_ BitVec 1))
(declare-fun dc_218 () (_ BitVec 1))
(declare-fun dc_217 () (_ BitVec 63))
(declare-fun dc_216 () (_ BitVec 64))
(declare-fun dc_215 () (_ BitVec 1))
(declare-fun dc_214 () (_ BitVec 62))
(declare-fun dc_213 () (_ BitVec 1))
(declare-fun dc_212 () (_ BitVec 1))
(declare-fun dc_211 () (_ BitVec 1))
(declare-fun dc_210 () (_ BitVec 63))
(declare-fun dc_209 () (_ BitVec 64))
(declare-fun dc_208 () (_ BitVec 1))
(declare-fun dc_207 () (_ BitVec 62))
(declare-fun dc_206 () (_ BitVec 1))
(declare-fun dc_205 () (_ BitVec 1))
(declare-fun dc_204 () (_ BitVec 1))
(declare-fun dc_203 () (_ BitVec 63))
(declare-fun dc_202 () (_ BitVec 64))
(declare-fun dc_201 () (_ BitVec 1))
(declare-fun dc_200 () (_ BitVec 62))
(declare-fun dc_199 () (_ BitVec 1))
(declare-fun dc_198 () (_ BitVec 1))
(declare-fun dc_197 () (_ BitVec 1))
(declare-fun dc_196 () (_ BitVec 63))
(declare-fun dc_195 () (_ BitVec 64))
(declare-fun dc_194 () (_ BitVec 1))
(declare-fun dc_193 () (_ BitVec 62))
(declare-fun dc_192 () (_ BitVec 1))
(declare-fun dc_191 () (_ BitVec 1))
(declare-fun dc_190 () (_ BitVec 1))
(declare-fun dc_189 () (_ BitVec 63))
(declare-fun dc_188 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_25 (bvadd (bvadd neg_f_0_low60_20_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_44 (bvadd (bvadd neg_g_0_low60_20_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_0_1)) (bvsle neg_f_0_low60_20_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_0_1)) (bvsle neg_g_0_low60_20_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_25) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_188 ((_ extract 63 1) x8_44)) (= x8_lo_21 ((_ extract 0 0) x8_44))))
(assert (= ne_21 (bvand x8_lo_21 #b1)))
(assert (= x10_43 (ite (= ne_21 #b1) x7_25 #x0000000000000000)))
(assert (and (= ge_61 ((_ extract 63 63) x3_41)) (= dc_189 ((_ extract 62 0) x3_41))))
(assert (= ge_62 (bvnot ge_61)))
(assert (= ge_63 (ite (= ne_21 #b1) ge_62 #b0)))
(assert (and (= dc_190 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_42 (ite (= ge_63 #b1) x3_neg_21 x3_41)))
(assert (and (= dc_191 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_44 (ite (= ge_63 #b1) x10_neg_21 x10_43)))
(assert (= x7_26 (ite (= ge_63 #b1) x8_44 x7_25)))
(assert (and (= dc_192 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44)))) (= x8_45 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44))))))
(assert (= x3_43 (bvadd x3_42 #x0000000000000002)))
(assert (and (= dc_193 ((_ extract 63 2) x8_45)) (= x8_lo_22 ((_ extract 1 0) x8_45))))
(assert (and (= x8_target_20 ((_ extract 1 1) x8_lo_22)) (= dc_194 ((_ extract 0 0) x8_lo_22))))
(assert (= ne_22 (bvand x8_target_20 #b1)))
(assert (and (= x8_46 ((_ sign_extend 1) ((_ extract 63 1) x8_45))) (= dc_195 ((_ zero_extend 63) ((_ extract 0 0) x8_45)))))
(assert true)
(assert (= x10_45 (ite (= ne_22 #b1) x7_26 #x0000000000000000)))
(assert (and (= ge_64 ((_ extract 63 63) x3_43)) (= dc_196 ((_ extract 62 0) x3_43))))
(assert (= ge_65 (bvnot ge_64)))
(assert (= ge_66 (ite (= ne_22 #b1) ge_65 #b0)))
(assert (and (= dc_197 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_44 (ite (= ge_66 #b1) x3_neg_22 x3_43)))
(assert (and (= dc_198 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_46 (ite (= ge_66 #b1) x10_neg_22 x10_45)))
(assert (= x7_27 (ite (= ge_66 #b1) x8_46 x7_26)))
(assert (and (= dc_199 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46)))) (= x8_47 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46))))))
(assert (= x3_45 (bvadd x3_44 #x0000000000000002)))
(assert (and (= dc_200 ((_ extract 63 2) x8_47)) (= x8_lo_23 ((_ extract 1 0) x8_47))))
(assert (and (= x8_target_21 ((_ extract 1 1) x8_lo_23)) (= dc_201 ((_ extract 0 0) x8_lo_23))))
(assert (= ne_23 (bvand x8_target_21 #b1)))
(assert (and (= x8_48 ((_ sign_extend 1) ((_ extract 63 1) x8_47))) (= dc_202 ((_ zero_extend 63) ((_ extract 0 0) x8_47)))))
(assert true)
(assert (= x10_47 (ite (= ne_23 #b1) x7_27 #x0000000000000000)))
(assert (and (= ge_67 ((_ extract 63 63) x3_45)) (= dc_203 ((_ extract 62 0) x3_45))))
(assert (= ge_68 (bvnot ge_67)))
(assert (= ge_69 (ite (= ne_23 #b1) ge_68 #b0)))
(assert (and (= dc_204 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_46 (ite (= ge_69 #b1) x3_neg_23 x3_45)))
(assert (and (= dc_205 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_48 (ite (= ge_69 #b1) x10_neg_23 x10_47)))
(assert (= x7_28 (ite (= ge_69 #b1) x8_48 x7_27)))
(assert (and (= dc_206 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48)))) (= x8_49 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48))))))
(assert (= x3_47 (bvadd x3_46 #x0000000000000002)))
(assert (and (= dc_207 ((_ extract 63 2) x8_49)) (= x8_lo_24 ((_ extract 1 0) x8_49))))
(assert (and (= x8_target_22 ((_ extract 1 1) x8_lo_24)) (= dc_208 ((_ extract 0 0) x8_lo_24))))
(assert (= ne_24 (bvand x8_target_22 #b1)))
(assert (and (= x8_50 ((_ sign_extend 1) ((_ extract 63 1) x8_49))) (= dc_209 ((_ zero_extend 63) ((_ extract 0 0) x8_49)))))
(assert true)
(assert (= x10_49 (ite (= ne_24 #b1) x7_28 #x0000000000000000)))
(assert (and (= ge_70 ((_ extract 63 63) x3_47)) (= dc_210 ((_ extract 62 0) x3_47))))
(assert (= ge_71 (bvnot ge_70)))
(assert (= ge_72 (ite (= ne_24 #b1) ge_71 #b0)))
(assert (and (= dc_211 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_47))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_24 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_47))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_48 (ite (= ge_72 #b1) x3_neg_24 x3_47)))
(assert (and (= dc_212 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_49))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_24 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_49))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_50 (ite (= ge_72 #b1) x10_neg_24 x10_49)))
(assert (= x7_29 (ite (= ge_72 #b1) x8_50 x7_28)))
(assert (and (= dc_213 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_50) ((_ zero_extend 1) x10_50)))) (= x8_51 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_50) ((_ zero_extend 1) x10_50))))))
(assert (= x3_49 (bvadd x3_48 #x0000000000000002)))
(assert (and (= dc_214 ((_ extract 63 2) x8_51)) (= x8_lo_25 ((_ extract 1 0) x8_51))))
(assert (and (= x8_target_23 ((_ extract 1 1) x8_lo_25)) (= dc_215 ((_ extract 0 0) x8_lo_25))))
(assert (= ne_25 (bvand x8_target_23 #b1)))
(assert (and (= x8_52 ((_ sign_extend 1) ((_ extract 63 1) x8_51))) (= dc_216 ((_ zero_extend 63) ((_ extract 0 0) x8_51)))))
(assert true)
(assert (= x10_51 (ite (= ne_25 #b1) x7_29 #x0000000000000000)))
(assert (and (= ge_73 ((_ extract 63 63) x3_49)) (= dc_217 ((_ extract 62 0) x3_49))))
(assert (= ge_74 (bvnot ge_73)))
(assert (= ge_75 (ite (= ne_25 #b1) ge_74 #b0)))
(assert (and (= dc_218 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_49))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_25 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_49))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_50 (ite (= ge_75 #b1) x3_neg_25 x3_49)))
(assert (and (= dc_219 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_51))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_25 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_51))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_52 (ite (= ge_75 #b1) x10_neg_25 x10_51)))
(assert (= x7_30 (ite (= ge_75 #b1) x8_52 x7_29)))
(assert (and (= dc_220 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_52) ((_ zero_extend 1) x10_52)))) (= x8_53 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_52) ((_ zero_extend 1) x10_52))))))
(assert (= x3_51 (bvadd x3_50 #x0000000000000002)))
(assert (and (= dc_221 ((_ extract 63 2) x8_53)) (= x8_lo_26 ((_ extract 1 0) x8_53))))
(assert (and (= x8_target_24 ((_ extract 1 1) x8_lo_26)) (= dc_222 ((_ extract 0 0) x8_lo_26))))
(assert (= ne_26 (bvand x8_target_24 #b1)))
(assert (and (= x8_54 ((_ sign_extend 1) ((_ extract 63 1) x8_53))) (= dc_223 ((_ zero_extend 63) ((_ extract 0 0) x8_53)))))
(assert true)
(assert (= x10_53 (ite (= ne_26 #b1) x7_30 #x0000000000000000)))
(assert (and (= ge_76 ((_ extract 63 63) x3_51)) (= dc_224 ((_ extract 62 0) x3_51))))
(assert (= ge_77 (bvnot ge_76)))
(assert (= ge_78 (ite (= ne_26 #b1) ge_77 #b0)))
(assert (and (= dc_225 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_51))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_26 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_51))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_52 (ite (= ge_78 #b1) x3_neg_26 x3_51)))
(assert (and (= dc_226 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_53))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_26 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_53))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_54 (ite (= ge_78 #b1) x10_neg_26 x10_53)))
(assert (= x7_31 (ite (= ge_78 #b1) x8_54 x7_30)))
(assert (and (= dc_227 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_54) ((_ zero_extend 1) x10_54)))) (= x8_55 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_54) ((_ zero_extend 1) x10_54))))))
(assert (= x3_53 (bvadd x3_52 #x0000000000000002)))
(assert (and (= dc_228 ((_ extract 63 2) x8_55)) (= x8_lo_27 ((_ extract 1 0) x8_55))))
(assert (and (= x8_target_25 ((_ extract 1 1) x8_lo_27)) (= dc_229 ((_ extract 0 0) x8_lo_27))))
(assert (= ne_27 (bvand x8_target_25 #b1)))
(assert (and (= x8_56 ((_ sign_extend 1) ((_ extract 63 1) x8_55))) (= dc_230 ((_ zero_extend 63) ((_ extract 0 0) x8_55)))))
(assert true)
(assert (= x10_55 (ite (= ne_27 #b1) x7_31 #x0000000000000000)))
(assert (and (= ge_79 ((_ extract 63 63) x3_53)) (= dc_231 ((_ extract 62 0) x3_53))))
(assert (= ge_80 (bvnot ge_79)))
(assert (= ge_81 (ite (= ne_27 #b1) ge_80 #b0)))
(assert (and (= dc_232 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_53))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_27 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_53))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_54 (ite (= ge_81 #b1) x3_neg_27 x3_53)))
(assert (and (= dc_233 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_55))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_27 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_55))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_56 (ite (= ge_81 #b1) x10_neg_27 x10_55)))
(assert (= x7_32 (ite (= ge_81 #b1) x8_56 x7_31)))
(assert (and (= dc_234 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_56) ((_ zero_extend 1) x10_56)))) (= x8_57 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_56) ((_ zero_extend 1) x10_56))))))
(assert (= x3_55 (bvadd x3_54 #x0000000000000002)))
(assert (and (= dc_235 ((_ extract 63 2) x8_57)) (= x8_lo_28 ((_ extract 1 0) x8_57))))
(assert (and (= x8_target_26 ((_ extract 1 1) x8_lo_28)) (= dc_236 ((_ extract 0 0) x8_lo_28))))
(assert (= ne_28 (bvand x8_target_26 #b1)))
(assert (and (= x8_58 ((_ sign_extend 1) ((_ extract 63 1) x8_57))) (= dc_237 ((_ zero_extend 63) ((_ extract 0 0) x8_57)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_56) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_32 x7_31)) (= (bvmul x8_58 #x0000000000000002) x8_56)) (= x3_55 (bvadd #x0000000000000002 x3_53))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_56) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_53 #x0000000000000000)) (= x7_32 x7_31)) (= (bvmul x8_58 #x0000000000000002) (bvadd x8_56 x7_31))) (= x3_55 (bvadd #x0000000000000002 x3_53)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_56) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_53 #x0000000000000000)) (= x7_32 x8_56)) (= (bvmul x8_58 #x0000000000000002) (bvsub x8_56 x7_31))) (= x3_55 (bvsub #x0000000000000002 x3_53))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_c9c29b.smt2
Execution time of boolector: 1.4004 seconds
OUTPUT FROM boolector:
unsat

=== Cut #6 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #6
; Range assertion #47: or [and [smod (sub (uext x8_58 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_33 = x7_32, mul x8_60 2@64 = x8_58, x3_57 = add 2@64 x3_55], and [smod (sub (uext x8_58 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_55 <s 0@64, x7_33 = x7_32, mul x8_60 2@64 = add x8_58 x7_32, x3_57 = add 2@64 x3_55], and [smod (sub (uext x8_58 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_55 >=s 0@64, x7_33 = x8_58, mul x8_60 2@64 = sub x8_58 x7_32, x3_57 = sub 2@64 x3_55]]
; Range condition: ((x8_58@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_33 = x7_32 /\ x8_60 * 2 = x8_58 /\ x3_57 = 2 + x3_55 \/ ((x8_58@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_55 <s 0 /\ x7_33 = x7_32 /\ x8_60 * 2 = x8_58 + x7_32 /\ x3_57 = 2 + x3_55 \/ ((x8_58@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_55 >=s 0 /\ x7_33 = x8_58 /\ x8_60 * 2 = x8_58 - x7_32 /\ x3_57 = 2 - x3_55
; Output file: /tmp/outputqfbv_5882de.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_27 () (_ BitVec 1))
(declare-fun x8_target_26 () (_ BitVec 1))
(declare-fun x8_target_25 () (_ BitVec 1))
(declare-fun x8_target_24 () (_ BitVec 1))
(declare-fun x8_target_23 () (_ BitVec 1))
(declare-fun x8_target_22 () (_ BitVec 1))
(declare-fun x8_target_21 () (_ BitVec 1))
(declare-fun x8_target_20 () (_ BitVec 1))
(declare-fun x8_lo_29 () (_ BitVec 2))
(declare-fun x8_lo_28 () (_ BitVec 2))
(declare-fun x8_lo_27 () (_ BitVec 2))
(declare-fun x8_lo_26 () (_ BitVec 2))
(declare-fun x8_lo_25 () (_ BitVec 2))
(declare-fun x8_lo_24 () (_ BitVec 2))
(declare-fun x8_lo_23 () (_ BitVec 2))
(declare-fun x8_lo_22 () (_ BitVec 2))
(declare-fun x8_lo_21 () (_ BitVec 1))
(declare-fun x8_60 () (_ BitVec 64))
(declare-fun x8_59 () (_ BitVec 64))
(declare-fun x8_58 () (_ BitVec 64))
(declare-fun x8_57 () (_ BitVec 64))
(declare-fun x8_56 () (_ BitVec 64))
(declare-fun x8_55 () (_ BitVec 64))
(declare-fun x8_54 () (_ BitVec 64))
(declare-fun x8_53 () (_ BitVec 64))
(declare-fun x8_52 () (_ BitVec 64))
(declare-fun x8_51 () (_ BitVec 64))
(declare-fun x8_50 () (_ BitVec 64))
(declare-fun x8_49 () (_ BitVec 64))
(declare-fun x8_48 () (_ BitVec 64))
(declare-fun x8_47 () (_ BitVec 64))
(declare-fun x8_46 () (_ BitVec 64))
(declare-fun x8_45 () (_ BitVec 64))
(declare-fun x8_44 () (_ BitVec 64))
(declare-fun x7_33 () (_ BitVec 64))
(declare-fun x7_32 () (_ BitVec 64))
(declare-fun x7_31 () (_ BitVec 64))
(declare-fun x7_30 () (_ BitVec 64))
(declare-fun x7_29 () (_ BitVec 64))
(declare-fun x7_28 () (_ BitVec 64))
(declare-fun x7_27 () (_ BitVec 64))
(declare-fun x7_26 () (_ BitVec 64))
(declare-fun x7_25 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_28 () (_ BitVec 64))
(declare-fun x3_neg_27 () (_ BitVec 64))
(declare-fun x3_neg_26 () (_ BitVec 64))
(declare-fun x3_neg_25 () (_ BitVec 64))
(declare-fun x3_neg_24 () (_ BitVec 64))
(declare-fun x3_neg_23 () (_ BitVec 64))
(declare-fun x3_neg_22 () (_ BitVec 64))
(declare-fun x3_neg_21 () (_ BitVec 64))
(declare-fun x3_57 () (_ BitVec 64))
(declare-fun x3_56 () (_ BitVec 64))
(declare-fun x3_55 () (_ BitVec 64))
(declare-fun x3_54 () (_ BitVec 64))
(declare-fun x3_53 () (_ BitVec 64))
(declare-fun x3_52 () (_ BitVec 64))
(declare-fun x3_51 () (_ BitVec 64))
(declare-fun x3_50 () (_ BitVec 64))
(declare-fun x3_49 () (_ BitVec 64))
(declare-fun x3_48 () (_ BitVec 64))
(declare-fun x3_47 () (_ BitVec 64))
(declare-fun x3_46 () (_ BitVec 64))
(declare-fun x3_45 () (_ BitVec 64))
(declare-fun x3_44 () (_ BitVec 64))
(declare-fun x3_43 () (_ BitVec 64))
(declare-fun x3_42 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x10_neg_28 () (_ BitVec 64))
(declare-fun x10_neg_27 () (_ BitVec 64))
(declare-fun x10_neg_26 () (_ BitVec 64))
(declare-fun x10_neg_25 () (_ BitVec 64))
(declare-fun x10_neg_24 () (_ BitVec 64))
(declare-fun x10_neg_23 () (_ BitVec 64))
(declare-fun x10_neg_22 () (_ BitVec 64))
(declare-fun x10_neg_21 () (_ BitVec 64))
(declare-fun x10_58 () (_ BitVec 64))
(declare-fun x10_57 () (_ BitVec 64))
(declare-fun x10_56 () (_ BitVec 64))
(declare-fun x10_55 () (_ BitVec 64))
(declare-fun x10_54 () (_ BitVec 64))
(declare-fun x10_53 () (_ BitVec 64))
(declare-fun x10_52 () (_ BitVec 64))
(declare-fun x10_51 () (_ BitVec 64))
(declare-fun x10_50 () (_ BitVec 64))
(declare-fun x10_49 () (_ BitVec 64))
(declare-fun x10_48 () (_ BitVec 64))
(declare-fun x10_47 () (_ BitVec 64))
(declare-fun x10_46 () (_ BitVec 64))
(declare-fun x10_45 () (_ BitVec 64))
(declare-fun x10_44 () (_ BitVec 64))
(declare-fun x10_43 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun ne_29 () (_ BitVec 1))
(declare-fun ne_28 () (_ BitVec 1))
(declare-fun ne_27 () (_ BitVec 1))
(declare-fun ne_26 () (_ BitVec 1))
(declare-fun ne_25 () (_ BitVec 1))
(declare-fun ne_24 () (_ BitVec 1))
(declare-fun ne_23 () (_ BitVec 1))
(declare-fun ne_22 () (_ BitVec 1))
(declare-fun ne_21 () (_ BitVec 1))
(declare-fun ge_84 () (_ BitVec 1))
(declare-fun ge_83 () (_ BitVec 1))
(declare-fun ge_82 () (_ BitVec 1))
(declare-fun ge_81 () (_ BitVec 1))
(declare-fun ge_80 () (_ BitVec 1))
(declare-fun ge_79 () (_ BitVec 1))
(declare-fun ge_78 () (_ BitVec 1))
(declare-fun ge_77 () (_ BitVec 1))
(declare-fun ge_76 () (_ BitVec 1))
(declare-fun ge_75 () (_ BitVec 1))
(declare-fun ge_74 () (_ BitVec 1))
(declare-fun ge_73 () (_ BitVec 1))
(declare-fun ge_72 () (_ BitVec 1))
(declare-fun ge_71 () (_ BitVec 1))
(declare-fun ge_70 () (_ BitVec 1))
(declare-fun ge_69 () (_ BitVec 1))
(declare-fun ge_68 () (_ BitVec 1))
(declare-fun ge_67 () (_ BitVec 1))
(declare-fun ge_66 () (_ BitVec 1))
(declare-fun ge_65 () (_ BitVec 1))
(declare-fun ge_64 () (_ BitVec 1))
(declare-fun ge_63 () (_ BitVec 1))
(declare-fun ge_62 () (_ BitVec 1))
(declare-fun ge_61 () (_ BitVec 1))
(declare-fun dc_244 () (_ BitVec 64))
(declare-fun dc_243 () (_ BitVec 1))
(declare-fun dc_242 () (_ BitVec 62))
(declare-fun dc_241 () (_ BitVec 1))
(declare-fun dc_240 () (_ BitVec 1))
(declare-fun dc_239 () (_ BitVec 1))
(declare-fun dc_238 () (_ BitVec 63))
(declare-fun dc_237 () (_ BitVec 64))
(declare-fun dc_236 () (_ BitVec 1))
(declare-fun dc_235 () (_ BitVec 62))
(declare-fun dc_234 () (_ BitVec 1))
(declare-fun dc_233 () (_ BitVec 1))
(declare-fun dc_232 () (_ BitVec 1))
(declare-fun dc_231 () (_ BitVec 63))
(declare-fun dc_230 () (_ BitVec 64))
(declare-fun dc_229 () (_ BitVec 1))
(declare-fun dc_228 () (_ BitVec 62))
(declare-fun dc_227 () (_ BitVec 1))
(declare-fun dc_226 () (_ BitVec 1))
(declare-fun dc_225 () (_ BitVec 1))
(declare-fun dc_224 () (_ BitVec 63))
(declare-fun dc_223 () (_ BitVec 64))
(declare-fun dc_222 () (_ BitVec 1))
(declare-fun dc_221 () (_ BitVec 62))
(declare-fun dc_220 () (_ BitVec 1))
(declare-fun dc_219 () (_ BitVec 1))
(declare-fun dc_218 () (_ BitVec 1))
(declare-fun dc_217 () (_ BitVec 63))
(declare-fun dc_216 () (_ BitVec 64))
(declare-fun dc_215 () (_ BitVec 1))
(declare-fun dc_214 () (_ BitVec 62))
(declare-fun dc_213 () (_ BitVec 1))
(declare-fun dc_212 () (_ BitVec 1))
(declare-fun dc_211 () (_ BitVec 1))
(declare-fun dc_210 () (_ BitVec 63))
(declare-fun dc_209 () (_ BitVec 64))
(declare-fun dc_208 () (_ BitVec 1))
(declare-fun dc_207 () (_ BitVec 62))
(declare-fun dc_206 () (_ BitVec 1))
(declare-fun dc_205 () (_ BitVec 1))
(declare-fun dc_204 () (_ BitVec 1))
(declare-fun dc_203 () (_ BitVec 63))
(declare-fun dc_202 () (_ BitVec 64))
(declare-fun dc_201 () (_ BitVec 1))
(declare-fun dc_200 () (_ BitVec 62))
(declare-fun dc_199 () (_ BitVec 1))
(declare-fun dc_198 () (_ BitVec 1))
(declare-fun dc_197 () (_ BitVec 1))
(declare-fun dc_196 () (_ BitVec 63))
(declare-fun dc_195 () (_ BitVec 64))
(declare-fun dc_194 () (_ BitVec 1))
(declare-fun dc_193 () (_ BitVec 62))
(declare-fun dc_192 () (_ BitVec 1))
(declare-fun dc_191 () (_ BitVec 1))
(declare-fun dc_190 () (_ BitVec 1))
(declare-fun dc_189 () (_ BitVec 63))
(declare-fun dc_188 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_25 (bvadd (bvadd neg_f_0_low60_20_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_44 (bvadd (bvadd neg_g_0_low60_20_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_0_1)) (bvsle neg_f_0_low60_20_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_0_1)) (bvsle neg_g_0_low60_20_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_25) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_188 ((_ extract 63 1) x8_44)) (= x8_lo_21 ((_ extract 0 0) x8_44))))
(assert (= ne_21 (bvand x8_lo_21 #b1)))
(assert (= x10_43 (ite (= ne_21 #b1) x7_25 #x0000000000000000)))
(assert (and (= ge_61 ((_ extract 63 63) x3_41)) (= dc_189 ((_ extract 62 0) x3_41))))
(assert (= ge_62 (bvnot ge_61)))
(assert (= ge_63 (ite (= ne_21 #b1) ge_62 #b0)))
(assert (and (= dc_190 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_42 (ite (= ge_63 #b1) x3_neg_21 x3_41)))
(assert (and (= dc_191 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_44 (ite (= ge_63 #b1) x10_neg_21 x10_43)))
(assert (= x7_26 (ite (= ge_63 #b1) x8_44 x7_25)))
(assert (and (= dc_192 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44)))) (= x8_45 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44))))))
(assert (= x3_43 (bvadd x3_42 #x0000000000000002)))
(assert (and (= dc_193 ((_ extract 63 2) x8_45)) (= x8_lo_22 ((_ extract 1 0) x8_45))))
(assert (and (= x8_target_20 ((_ extract 1 1) x8_lo_22)) (= dc_194 ((_ extract 0 0) x8_lo_22))))
(assert (= ne_22 (bvand x8_target_20 #b1)))
(assert (and (= x8_46 ((_ sign_extend 1) ((_ extract 63 1) x8_45))) (= dc_195 ((_ zero_extend 63) ((_ extract 0 0) x8_45)))))
(assert true)
(assert (= x10_45 (ite (= ne_22 #b1) x7_26 #x0000000000000000)))
(assert (and (= ge_64 ((_ extract 63 63) x3_43)) (= dc_196 ((_ extract 62 0) x3_43))))
(assert (= ge_65 (bvnot ge_64)))
(assert (= ge_66 (ite (= ne_22 #b1) ge_65 #b0)))
(assert (and (= dc_197 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_44 (ite (= ge_66 #b1) x3_neg_22 x3_43)))
(assert (and (= dc_198 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_46 (ite (= ge_66 #b1) x10_neg_22 x10_45)))
(assert (= x7_27 (ite (= ge_66 #b1) x8_46 x7_26)))
(assert (and (= dc_199 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46)))) (= x8_47 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46))))))
(assert (= x3_45 (bvadd x3_44 #x0000000000000002)))
(assert (and (= dc_200 ((_ extract 63 2) x8_47)) (= x8_lo_23 ((_ extract 1 0) x8_47))))
(assert (and (= x8_target_21 ((_ extract 1 1) x8_lo_23)) (= dc_201 ((_ extract 0 0) x8_lo_23))))
(assert (= ne_23 (bvand x8_target_21 #b1)))
(assert (and (= x8_48 ((_ sign_extend 1) ((_ extract 63 1) x8_47))) (= dc_202 ((_ zero_extend 63) ((_ extract 0 0) x8_47)))))
(assert true)
(assert (= x10_47 (ite (= ne_23 #b1) x7_27 #x0000000000000000)))
(assert (and (= ge_67 ((_ extract 63 63) x3_45)) (= dc_203 ((_ extract 62 0) x3_45))))
(assert (= ge_68 (bvnot ge_67)))
(assert (= ge_69 (ite (= ne_23 #b1) ge_68 #b0)))
(assert (and (= dc_204 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_46 (ite (= ge_69 #b1) x3_neg_23 x3_45)))
(assert (and (= dc_205 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_48 (ite (= ge_69 #b1) x10_neg_23 x10_47)))
(assert (= x7_28 (ite (= ge_69 #b1) x8_48 x7_27)))
(assert (and (= dc_206 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48)))) (= x8_49 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48))))))
(assert (= x3_47 (bvadd x3_46 #x0000000000000002)))
(assert (and (= dc_207 ((_ extract 63 2) x8_49)) (= x8_lo_24 ((_ extract 1 0) x8_49))))
(assert (and (= x8_target_22 ((_ extract 1 1) x8_lo_24)) (= dc_208 ((_ extract 0 0) x8_lo_24))))
(assert (= ne_24 (bvand x8_target_22 #b1)))
(assert (and (= x8_50 ((_ sign_extend 1) ((_ extract 63 1) x8_49))) (= dc_209 ((_ zero_extend 63) ((_ extract 0 0) x8_49)))))
(assert true)
(assert (= x10_49 (ite (= ne_24 #b1) x7_28 #x0000000000000000)))
(assert (and (= ge_70 ((_ extract 63 63) x3_47)) (= dc_210 ((_ extract 62 0) x3_47))))
(assert (= ge_71 (bvnot ge_70)))
(assert (= ge_72 (ite (= ne_24 #b1) ge_71 #b0)))
(assert (and (= dc_211 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_47))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_24 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_47))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_48 (ite (= ge_72 #b1) x3_neg_24 x3_47)))
(assert (and (= dc_212 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_49))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_24 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_49))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_50 (ite (= ge_72 #b1) x10_neg_24 x10_49)))
(assert (= x7_29 (ite (= ge_72 #b1) x8_50 x7_28)))
(assert (and (= dc_213 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_50) ((_ zero_extend 1) x10_50)))) (= x8_51 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_50) ((_ zero_extend 1) x10_50))))))
(assert (= x3_49 (bvadd x3_48 #x0000000000000002)))
(assert (and (= dc_214 ((_ extract 63 2) x8_51)) (= x8_lo_25 ((_ extract 1 0) x8_51))))
(assert (and (= x8_target_23 ((_ extract 1 1) x8_lo_25)) (= dc_215 ((_ extract 0 0) x8_lo_25))))
(assert (= ne_25 (bvand x8_target_23 #b1)))
(assert (and (= x8_52 ((_ sign_extend 1) ((_ extract 63 1) x8_51))) (= dc_216 ((_ zero_extend 63) ((_ extract 0 0) x8_51)))))
(assert true)
(assert (= x10_51 (ite (= ne_25 #b1) x7_29 #x0000000000000000)))
(assert (and (= ge_73 ((_ extract 63 63) x3_49)) (= dc_217 ((_ extract 62 0) x3_49))))
(assert (= ge_74 (bvnot ge_73)))
(assert (= ge_75 (ite (= ne_25 #b1) ge_74 #b0)))
(assert (and (= dc_218 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_49))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_25 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_49))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_50 (ite (= ge_75 #b1) x3_neg_25 x3_49)))
(assert (and (= dc_219 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_51))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_25 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_51))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_52 (ite (= ge_75 #b1) x10_neg_25 x10_51)))
(assert (= x7_30 (ite (= ge_75 #b1) x8_52 x7_29)))
(assert (and (= dc_220 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_52) ((_ zero_extend 1) x10_52)))) (= x8_53 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_52) ((_ zero_extend 1) x10_52))))))
(assert (= x3_51 (bvadd x3_50 #x0000000000000002)))
(assert (and (= dc_221 ((_ extract 63 2) x8_53)) (= x8_lo_26 ((_ extract 1 0) x8_53))))
(assert (and (= x8_target_24 ((_ extract 1 1) x8_lo_26)) (= dc_222 ((_ extract 0 0) x8_lo_26))))
(assert (= ne_26 (bvand x8_target_24 #b1)))
(assert (and (= x8_54 ((_ sign_extend 1) ((_ extract 63 1) x8_53))) (= dc_223 ((_ zero_extend 63) ((_ extract 0 0) x8_53)))))
(assert true)
(assert (= x10_53 (ite (= ne_26 #b1) x7_30 #x0000000000000000)))
(assert (and (= ge_76 ((_ extract 63 63) x3_51)) (= dc_224 ((_ extract 62 0) x3_51))))
(assert (= ge_77 (bvnot ge_76)))
(assert (= ge_78 (ite (= ne_26 #b1) ge_77 #b0)))
(assert (and (= dc_225 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_51))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_26 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_51))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_52 (ite (= ge_78 #b1) x3_neg_26 x3_51)))
(assert (and (= dc_226 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_53))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_26 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_53))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_54 (ite (= ge_78 #b1) x10_neg_26 x10_53)))
(assert (= x7_31 (ite (= ge_78 #b1) x8_54 x7_30)))
(assert (and (= dc_227 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_54) ((_ zero_extend 1) x10_54)))) (= x8_55 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_54) ((_ zero_extend 1) x10_54))))))
(assert (= x3_53 (bvadd x3_52 #x0000000000000002)))
(assert (and (= dc_228 ((_ extract 63 2) x8_55)) (= x8_lo_27 ((_ extract 1 0) x8_55))))
(assert (and (= x8_target_25 ((_ extract 1 1) x8_lo_27)) (= dc_229 ((_ extract 0 0) x8_lo_27))))
(assert (= ne_27 (bvand x8_target_25 #b1)))
(assert (and (= x8_56 ((_ sign_extend 1) ((_ extract 63 1) x8_55))) (= dc_230 ((_ zero_extend 63) ((_ extract 0 0) x8_55)))))
(assert true)
(assert (= x10_55 (ite (= ne_27 #b1) x7_31 #x0000000000000000)))
(assert (and (= ge_79 ((_ extract 63 63) x3_53)) (= dc_231 ((_ extract 62 0) x3_53))))
(assert (= ge_80 (bvnot ge_79)))
(assert (= ge_81 (ite (= ne_27 #b1) ge_80 #b0)))
(assert (and (= dc_232 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_53))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_27 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_53))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_54 (ite (= ge_81 #b1) x3_neg_27 x3_53)))
(assert (and (= dc_233 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_55))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_27 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_55))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_56 (ite (= ge_81 #b1) x10_neg_27 x10_55)))
(assert (= x7_32 (ite (= ge_81 #b1) x8_56 x7_31)))
(assert (and (= dc_234 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_56) ((_ zero_extend 1) x10_56)))) (= x8_57 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_56) ((_ zero_extend 1) x10_56))))))
(assert (= x3_55 (bvadd x3_54 #x0000000000000002)))
(assert (and (= dc_235 ((_ extract 63 2) x8_57)) (= x8_lo_28 ((_ extract 1 0) x8_57))))
(assert (and (= x8_target_26 ((_ extract 1 1) x8_lo_28)) (= dc_236 ((_ extract 0 0) x8_lo_28))))
(assert (= ne_28 (bvand x8_target_26 #b1)))
(assert (and (= x8_58 ((_ sign_extend 1) ((_ extract 63 1) x8_57))) (= dc_237 ((_ zero_extend 63) ((_ extract 0 0) x8_57)))))
(assert true)
(assert (= x10_57 (ite (= ne_28 #b1) x7_32 #x0000000000000000)))
(assert (and (= ge_82 ((_ extract 63 63) x3_55)) (= dc_238 ((_ extract 62 0) x3_55))))
(assert (= ge_83 (bvnot ge_82)))
(assert (= ge_84 (ite (= ne_28 #b1) ge_83 #b0)))
(assert (and (= dc_239 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_55))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_28 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_55))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_56 (ite (= ge_84 #b1) x3_neg_28 x3_55)))
(assert (and (= dc_240 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_57))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_28 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_57))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_58 (ite (= ge_84 #b1) x10_neg_28 x10_57)))
(assert (= x7_33 (ite (= ge_84 #b1) x8_58 x7_32)))
(assert (and (= dc_241 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_58) ((_ zero_extend 1) x10_58)))) (= x8_59 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_58) ((_ zero_extend 1) x10_58))))))
(assert (= x3_57 (bvadd x3_56 #x0000000000000002)))
(assert (and (= dc_242 ((_ extract 63 2) x8_59)) (= x8_lo_29 ((_ extract 1 0) x8_59))))
(assert (and (= x8_target_27 ((_ extract 1 1) x8_lo_29)) (= dc_243 ((_ extract 0 0) x8_lo_29))))
(assert (= ne_29 (bvand x8_target_27 #b1)))
(assert (and (= x8_60 ((_ sign_extend 1) ((_ extract 63 1) x8_59))) (= dc_244 ((_ zero_extend 63) ((_ extract 0 0) x8_59)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_58) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_33 x7_32)) (= (bvmul x8_60 #x0000000000000002) x8_58)) (= x3_57 (bvadd #x0000000000000002 x3_55))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_58) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_55 #x0000000000000000)) (= x7_33 x7_32)) (= (bvmul x8_60 #x0000000000000002) (bvadd x8_58 x7_32))) (= x3_57 (bvadd #x0000000000000002 x3_55)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_58) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_55 #x0000000000000000)) (= x7_33 x8_58)) (= (bvmul x8_60 #x0000000000000002) (bvsub x8_58 x7_32))) (= x3_57 (bvsub #x0000000000000002 x3_55))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_2637d2.smt2
Execution time of boolector: 1.3268 seconds
OUTPUT FROM boolector:
unsat

=== Cut #6 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #6
; Range assertion #48: or [and [smod (sub (uext x8_60 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_34 = x7_33, mul x8_62 2@64 = x8_60, x3_59 = add 2@64 x3_57], and [smod (sub (uext x8_60 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_57 <s 0@64, x7_34 = x7_33, mul x8_62 2@64 = add x8_60 x7_33, x3_59 = add 2@64 x3_57], and [smod (sub (uext x8_60 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_57 >=s 0@64, x7_34 = x8_60, mul x8_62 2@64 = sub x8_60 x7_33, x3_59 = sub 2@64 x3_57]]
; Range condition: ((x8_60@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_34 = x7_33 /\ x8_62 * 2 = x8_60 /\ x3_59 = 2 + x3_57 \/ ((x8_60@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_57 <s 0 /\ x7_34 = x7_33 /\ x8_62 * 2 = x8_60 + x7_33 /\ x3_59 = 2 + x3_57 \/ ((x8_60@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_57 >=s 0 /\ x7_34 = x8_60 /\ x8_62 * 2 = x8_60 - x7_33 /\ x3_59 = 2 - x3_57
; Output file: /tmp/outputqfbv_b8a40d.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_28 () (_ BitVec 1))
(declare-fun x8_target_27 () (_ BitVec 1))
(declare-fun x8_target_26 () (_ BitVec 1))
(declare-fun x8_target_25 () (_ BitVec 1))
(declare-fun x8_target_24 () (_ BitVec 1))
(declare-fun x8_target_23 () (_ BitVec 1))
(declare-fun x8_target_22 () (_ BitVec 1))
(declare-fun x8_target_21 () (_ BitVec 1))
(declare-fun x8_target_20 () (_ BitVec 1))
(declare-fun x8_lo_30 () (_ BitVec 2))
(declare-fun x8_lo_29 () (_ BitVec 2))
(declare-fun x8_lo_28 () (_ BitVec 2))
(declare-fun x8_lo_27 () (_ BitVec 2))
(declare-fun x8_lo_26 () (_ BitVec 2))
(declare-fun x8_lo_25 () (_ BitVec 2))
(declare-fun x8_lo_24 () (_ BitVec 2))
(declare-fun x8_lo_23 () (_ BitVec 2))
(declare-fun x8_lo_22 () (_ BitVec 2))
(declare-fun x8_lo_21 () (_ BitVec 1))
(declare-fun x8_62 () (_ BitVec 64))
(declare-fun x8_61 () (_ BitVec 64))
(declare-fun x8_60 () (_ BitVec 64))
(declare-fun x8_59 () (_ BitVec 64))
(declare-fun x8_58 () (_ BitVec 64))
(declare-fun x8_57 () (_ BitVec 64))
(declare-fun x8_56 () (_ BitVec 64))
(declare-fun x8_55 () (_ BitVec 64))
(declare-fun x8_54 () (_ BitVec 64))
(declare-fun x8_53 () (_ BitVec 64))
(declare-fun x8_52 () (_ BitVec 64))
(declare-fun x8_51 () (_ BitVec 64))
(declare-fun x8_50 () (_ BitVec 64))
(declare-fun x8_49 () (_ BitVec 64))
(declare-fun x8_48 () (_ BitVec 64))
(declare-fun x8_47 () (_ BitVec 64))
(declare-fun x8_46 () (_ BitVec 64))
(declare-fun x8_45 () (_ BitVec 64))
(declare-fun x8_44 () (_ BitVec 64))
(declare-fun x7_34 () (_ BitVec 64))
(declare-fun x7_33 () (_ BitVec 64))
(declare-fun x7_32 () (_ BitVec 64))
(declare-fun x7_31 () (_ BitVec 64))
(declare-fun x7_30 () (_ BitVec 64))
(declare-fun x7_29 () (_ BitVec 64))
(declare-fun x7_28 () (_ BitVec 64))
(declare-fun x7_27 () (_ BitVec 64))
(declare-fun x7_26 () (_ BitVec 64))
(declare-fun x7_25 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_29 () (_ BitVec 64))
(declare-fun x3_neg_28 () (_ BitVec 64))
(declare-fun x3_neg_27 () (_ BitVec 64))
(declare-fun x3_neg_26 () (_ BitVec 64))
(declare-fun x3_neg_25 () (_ BitVec 64))
(declare-fun x3_neg_24 () (_ BitVec 64))
(declare-fun x3_neg_23 () (_ BitVec 64))
(declare-fun x3_neg_22 () (_ BitVec 64))
(declare-fun x3_neg_21 () (_ BitVec 64))
(declare-fun x3_59 () (_ BitVec 64))
(declare-fun x3_58 () (_ BitVec 64))
(declare-fun x3_57 () (_ BitVec 64))
(declare-fun x3_56 () (_ BitVec 64))
(declare-fun x3_55 () (_ BitVec 64))
(declare-fun x3_54 () (_ BitVec 64))
(declare-fun x3_53 () (_ BitVec 64))
(declare-fun x3_52 () (_ BitVec 64))
(declare-fun x3_51 () (_ BitVec 64))
(declare-fun x3_50 () (_ BitVec 64))
(declare-fun x3_49 () (_ BitVec 64))
(declare-fun x3_48 () (_ BitVec 64))
(declare-fun x3_47 () (_ BitVec 64))
(declare-fun x3_46 () (_ BitVec 64))
(declare-fun x3_45 () (_ BitVec 64))
(declare-fun x3_44 () (_ BitVec 64))
(declare-fun x3_43 () (_ BitVec 64))
(declare-fun x3_42 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x10_neg_29 () (_ BitVec 64))
(declare-fun x10_neg_28 () (_ BitVec 64))
(declare-fun x10_neg_27 () (_ BitVec 64))
(declare-fun x10_neg_26 () (_ BitVec 64))
(declare-fun x10_neg_25 () (_ BitVec 64))
(declare-fun x10_neg_24 () (_ BitVec 64))
(declare-fun x10_neg_23 () (_ BitVec 64))
(declare-fun x10_neg_22 () (_ BitVec 64))
(declare-fun x10_neg_21 () (_ BitVec 64))
(declare-fun x10_60 () (_ BitVec 64))
(declare-fun x10_59 () (_ BitVec 64))
(declare-fun x10_58 () (_ BitVec 64))
(declare-fun x10_57 () (_ BitVec 64))
(declare-fun x10_56 () (_ BitVec 64))
(declare-fun x10_55 () (_ BitVec 64))
(declare-fun x10_54 () (_ BitVec 64))
(declare-fun x10_53 () (_ BitVec 64))
(declare-fun x10_52 () (_ BitVec 64))
(declare-fun x10_51 () (_ BitVec 64))
(declare-fun x10_50 () (_ BitVec 64))
(declare-fun x10_49 () (_ BitVec 64))
(declare-fun x10_48 () (_ BitVec 64))
(declare-fun x10_47 () (_ BitVec 64))
(declare-fun x10_46 () (_ BitVec 64))
(declare-fun x10_45 () (_ BitVec 64))
(declare-fun x10_44 () (_ BitVec 64))
(declare-fun x10_43 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun ne_30 () (_ BitVec 1))
(declare-fun ne_29 () (_ BitVec 1))
(declare-fun ne_28 () (_ BitVec 1))
(declare-fun ne_27 () (_ BitVec 1))
(declare-fun ne_26 () (_ BitVec 1))
(declare-fun ne_25 () (_ BitVec 1))
(declare-fun ne_24 () (_ BitVec 1))
(declare-fun ne_23 () (_ BitVec 1))
(declare-fun ne_22 () (_ BitVec 1))
(declare-fun ne_21 () (_ BitVec 1))
(declare-fun ge_87 () (_ BitVec 1))
(declare-fun ge_86 () (_ BitVec 1))
(declare-fun ge_85 () (_ BitVec 1))
(declare-fun ge_84 () (_ BitVec 1))
(declare-fun ge_83 () (_ BitVec 1))
(declare-fun ge_82 () (_ BitVec 1))
(declare-fun ge_81 () (_ BitVec 1))
(declare-fun ge_80 () (_ BitVec 1))
(declare-fun ge_79 () (_ BitVec 1))
(declare-fun ge_78 () (_ BitVec 1))
(declare-fun ge_77 () (_ BitVec 1))
(declare-fun ge_76 () (_ BitVec 1))
(declare-fun ge_75 () (_ BitVec 1))
(declare-fun ge_74 () (_ BitVec 1))
(declare-fun ge_73 () (_ BitVec 1))
(declare-fun ge_72 () (_ BitVec 1))
(declare-fun ge_71 () (_ BitVec 1))
(declare-fun ge_70 () (_ BitVec 1))
(declare-fun ge_69 () (_ BitVec 1))
(declare-fun ge_68 () (_ BitVec 1))
(declare-fun ge_67 () (_ BitVec 1))
(declare-fun ge_66 () (_ BitVec 1))
(declare-fun ge_65 () (_ BitVec 1))
(declare-fun ge_64 () (_ BitVec 1))
(declare-fun ge_63 () (_ BitVec 1))
(declare-fun ge_62 () (_ BitVec 1))
(declare-fun ge_61 () (_ BitVec 1))
(declare-fun dc_251 () (_ BitVec 64))
(declare-fun dc_250 () (_ BitVec 1))
(declare-fun dc_249 () (_ BitVec 62))
(declare-fun dc_248 () (_ BitVec 1))
(declare-fun dc_247 () (_ BitVec 1))
(declare-fun dc_246 () (_ BitVec 1))
(declare-fun dc_245 () (_ BitVec 63))
(declare-fun dc_244 () (_ BitVec 64))
(declare-fun dc_243 () (_ BitVec 1))
(declare-fun dc_242 () (_ BitVec 62))
(declare-fun dc_241 () (_ BitVec 1))
(declare-fun dc_240 () (_ BitVec 1))
(declare-fun dc_239 () (_ BitVec 1))
(declare-fun dc_238 () (_ BitVec 63))
(declare-fun dc_237 () (_ BitVec 64))
(declare-fun dc_236 () (_ BitVec 1))
(declare-fun dc_235 () (_ BitVec 62))
(declare-fun dc_234 () (_ BitVec 1))
(declare-fun dc_233 () (_ BitVec 1))
(declare-fun dc_232 () (_ BitVec 1))
(declare-fun dc_231 () (_ BitVec 63))
(declare-fun dc_230 () (_ BitVec 64))
(declare-fun dc_229 () (_ BitVec 1))
(declare-fun dc_228 () (_ BitVec 62))
(declare-fun dc_227 () (_ BitVec 1))
(declare-fun dc_226 () (_ BitVec 1))
(declare-fun dc_225 () (_ BitVec 1))
(declare-fun dc_224 () (_ BitVec 63))
(declare-fun dc_223 () (_ BitVec 64))
(declare-fun dc_222 () (_ BitVec 1))
(declare-fun dc_221 () (_ BitVec 62))
(declare-fun dc_220 () (_ BitVec 1))
(declare-fun dc_219 () (_ BitVec 1))
(declare-fun dc_218 () (_ BitVec 1))
(declare-fun dc_217 () (_ BitVec 63))
(declare-fun dc_216 () (_ BitVec 64))
(declare-fun dc_215 () (_ BitVec 1))
(declare-fun dc_214 () (_ BitVec 62))
(declare-fun dc_213 () (_ BitVec 1))
(declare-fun dc_212 () (_ BitVec 1))
(declare-fun dc_211 () (_ BitVec 1))
(declare-fun dc_210 () (_ BitVec 63))
(declare-fun dc_209 () (_ BitVec 64))
(declare-fun dc_208 () (_ BitVec 1))
(declare-fun dc_207 () (_ BitVec 62))
(declare-fun dc_206 () (_ BitVec 1))
(declare-fun dc_205 () (_ BitVec 1))
(declare-fun dc_204 () (_ BitVec 1))
(declare-fun dc_203 () (_ BitVec 63))
(declare-fun dc_202 () (_ BitVec 64))
(declare-fun dc_201 () (_ BitVec 1))
(declare-fun dc_200 () (_ BitVec 62))
(declare-fun dc_199 () (_ BitVec 1))
(declare-fun dc_198 () (_ BitVec 1))
(declare-fun dc_197 () (_ BitVec 1))
(declare-fun dc_196 () (_ BitVec 63))
(declare-fun dc_195 () (_ BitVec 64))
(declare-fun dc_194 () (_ BitVec 1))
(declare-fun dc_193 () (_ BitVec 62))
(declare-fun dc_192 () (_ BitVec 1))
(declare-fun dc_191 () (_ BitVec 1))
(declare-fun dc_190 () (_ BitVec 1))
(declare-fun dc_189 () (_ BitVec 63))
(declare-fun dc_188 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_25 (bvadd (bvadd neg_f_0_low60_20_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_44 (bvadd (bvadd neg_g_0_low60_20_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_0_1)) (bvsle neg_f_0_low60_20_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_0_1)) (bvsle neg_g_0_low60_20_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_25) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_188 ((_ extract 63 1) x8_44)) (= x8_lo_21 ((_ extract 0 0) x8_44))))
(assert (= ne_21 (bvand x8_lo_21 #b1)))
(assert (= x10_43 (ite (= ne_21 #b1) x7_25 #x0000000000000000)))
(assert (and (= ge_61 ((_ extract 63 63) x3_41)) (= dc_189 ((_ extract 62 0) x3_41))))
(assert (= ge_62 (bvnot ge_61)))
(assert (= ge_63 (ite (= ne_21 #b1) ge_62 #b0)))
(assert (and (= dc_190 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_42 (ite (= ge_63 #b1) x3_neg_21 x3_41)))
(assert (and (= dc_191 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_44 (ite (= ge_63 #b1) x10_neg_21 x10_43)))
(assert (= x7_26 (ite (= ge_63 #b1) x8_44 x7_25)))
(assert (and (= dc_192 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44)))) (= x8_45 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44))))))
(assert (= x3_43 (bvadd x3_42 #x0000000000000002)))
(assert (and (= dc_193 ((_ extract 63 2) x8_45)) (= x8_lo_22 ((_ extract 1 0) x8_45))))
(assert (and (= x8_target_20 ((_ extract 1 1) x8_lo_22)) (= dc_194 ((_ extract 0 0) x8_lo_22))))
(assert (= ne_22 (bvand x8_target_20 #b1)))
(assert (and (= x8_46 ((_ sign_extend 1) ((_ extract 63 1) x8_45))) (= dc_195 ((_ zero_extend 63) ((_ extract 0 0) x8_45)))))
(assert true)
(assert (= x10_45 (ite (= ne_22 #b1) x7_26 #x0000000000000000)))
(assert (and (= ge_64 ((_ extract 63 63) x3_43)) (= dc_196 ((_ extract 62 0) x3_43))))
(assert (= ge_65 (bvnot ge_64)))
(assert (= ge_66 (ite (= ne_22 #b1) ge_65 #b0)))
(assert (and (= dc_197 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_44 (ite (= ge_66 #b1) x3_neg_22 x3_43)))
(assert (and (= dc_198 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_46 (ite (= ge_66 #b1) x10_neg_22 x10_45)))
(assert (= x7_27 (ite (= ge_66 #b1) x8_46 x7_26)))
(assert (and (= dc_199 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46)))) (= x8_47 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46))))))
(assert (= x3_45 (bvadd x3_44 #x0000000000000002)))
(assert (and (= dc_200 ((_ extract 63 2) x8_47)) (= x8_lo_23 ((_ extract 1 0) x8_47))))
(assert (and (= x8_target_21 ((_ extract 1 1) x8_lo_23)) (= dc_201 ((_ extract 0 0) x8_lo_23))))
(assert (= ne_23 (bvand x8_target_21 #b1)))
(assert (and (= x8_48 ((_ sign_extend 1) ((_ extract 63 1) x8_47))) (= dc_202 ((_ zero_extend 63) ((_ extract 0 0) x8_47)))))
(assert true)
(assert (= x10_47 (ite (= ne_23 #b1) x7_27 #x0000000000000000)))
(assert (and (= ge_67 ((_ extract 63 63) x3_45)) (= dc_203 ((_ extract 62 0) x3_45))))
(assert (= ge_68 (bvnot ge_67)))
(assert (= ge_69 (ite (= ne_23 #b1) ge_68 #b0)))
(assert (and (= dc_204 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_46 (ite (= ge_69 #b1) x3_neg_23 x3_45)))
(assert (and (= dc_205 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_48 (ite (= ge_69 #b1) x10_neg_23 x10_47)))
(assert (= x7_28 (ite (= ge_69 #b1) x8_48 x7_27)))
(assert (and (= dc_206 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48)))) (= x8_49 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48))))))
(assert (= x3_47 (bvadd x3_46 #x0000000000000002)))
(assert (and (= dc_207 ((_ extract 63 2) x8_49)) (= x8_lo_24 ((_ extract 1 0) x8_49))))
(assert (and (= x8_target_22 ((_ extract 1 1) x8_lo_24)) (= dc_208 ((_ extract 0 0) x8_lo_24))))
(assert (= ne_24 (bvand x8_target_22 #b1)))
(assert (and (= x8_50 ((_ sign_extend 1) ((_ extract 63 1) x8_49))) (= dc_209 ((_ zero_extend 63) ((_ extract 0 0) x8_49)))))
(assert true)
(assert (= x10_49 (ite (= ne_24 #b1) x7_28 #x0000000000000000)))
(assert (and (= ge_70 ((_ extract 63 63) x3_47)) (= dc_210 ((_ extract 62 0) x3_47))))
(assert (= ge_71 (bvnot ge_70)))
(assert (= ge_72 (ite (= ne_24 #b1) ge_71 #b0)))
(assert (and (= dc_211 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_47))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_24 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_47))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_48 (ite (= ge_72 #b1) x3_neg_24 x3_47)))
(assert (and (= dc_212 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_49))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_24 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_49))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_50 (ite (= ge_72 #b1) x10_neg_24 x10_49)))
(assert (= x7_29 (ite (= ge_72 #b1) x8_50 x7_28)))
(assert (and (= dc_213 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_50) ((_ zero_extend 1) x10_50)))) (= x8_51 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_50) ((_ zero_extend 1) x10_50))))))
(assert (= x3_49 (bvadd x3_48 #x0000000000000002)))
(assert (and (= dc_214 ((_ extract 63 2) x8_51)) (= x8_lo_25 ((_ extract 1 0) x8_51))))
(assert (and (= x8_target_23 ((_ extract 1 1) x8_lo_25)) (= dc_215 ((_ extract 0 0) x8_lo_25))))
(assert (= ne_25 (bvand x8_target_23 #b1)))
(assert (and (= x8_52 ((_ sign_extend 1) ((_ extract 63 1) x8_51))) (= dc_216 ((_ zero_extend 63) ((_ extract 0 0) x8_51)))))
(assert true)
(assert (= x10_51 (ite (= ne_25 #b1) x7_29 #x0000000000000000)))
(assert (and (= ge_73 ((_ extract 63 63) x3_49)) (= dc_217 ((_ extract 62 0) x3_49))))
(assert (= ge_74 (bvnot ge_73)))
(assert (= ge_75 (ite (= ne_25 #b1) ge_74 #b0)))
(assert (and (= dc_218 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_49))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_25 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_49))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_50 (ite (= ge_75 #b1) x3_neg_25 x3_49)))
(assert (and (= dc_219 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_51))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_25 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_51))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_52 (ite (= ge_75 #b1) x10_neg_25 x10_51)))
(assert (= x7_30 (ite (= ge_75 #b1) x8_52 x7_29)))
(assert (and (= dc_220 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_52) ((_ zero_extend 1) x10_52)))) (= x8_53 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_52) ((_ zero_extend 1) x10_52))))))
(assert (= x3_51 (bvadd x3_50 #x0000000000000002)))
(assert (and (= dc_221 ((_ extract 63 2) x8_53)) (= x8_lo_26 ((_ extract 1 0) x8_53))))
(assert (and (= x8_target_24 ((_ extract 1 1) x8_lo_26)) (= dc_222 ((_ extract 0 0) x8_lo_26))))
(assert (= ne_26 (bvand x8_target_24 #b1)))
(assert (and (= x8_54 ((_ sign_extend 1) ((_ extract 63 1) x8_53))) (= dc_223 ((_ zero_extend 63) ((_ extract 0 0) x8_53)))))
(assert true)
(assert (= x10_53 (ite (= ne_26 #b1) x7_30 #x0000000000000000)))
(assert (and (= ge_76 ((_ extract 63 63) x3_51)) (= dc_224 ((_ extract 62 0) x3_51))))
(assert (= ge_77 (bvnot ge_76)))
(assert (= ge_78 (ite (= ne_26 #b1) ge_77 #b0)))
(assert (and (= dc_225 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_51))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_26 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_51))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_52 (ite (= ge_78 #b1) x3_neg_26 x3_51)))
(assert (and (= dc_226 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_53))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_26 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_53))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_54 (ite (= ge_78 #b1) x10_neg_26 x10_53)))
(assert (= x7_31 (ite (= ge_78 #b1) x8_54 x7_30)))
(assert (and (= dc_227 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_54) ((_ zero_extend 1) x10_54)))) (= x8_55 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_54) ((_ zero_extend 1) x10_54))))))
(assert (= x3_53 (bvadd x3_52 #x0000000000000002)))
(assert (and (= dc_228 ((_ extract 63 2) x8_55)) (= x8_lo_27 ((_ extract 1 0) x8_55))))
(assert (and (= x8_target_25 ((_ extract 1 1) x8_lo_27)) (= dc_229 ((_ extract 0 0) x8_lo_27))))
(assert (= ne_27 (bvand x8_target_25 #b1)))
(assert (and (= x8_56 ((_ sign_extend 1) ((_ extract 63 1) x8_55))) (= dc_230 ((_ zero_extend 63) ((_ extract 0 0) x8_55)))))
(assert true)
(assert (= x10_55 (ite (= ne_27 #b1) x7_31 #x0000000000000000)))
(assert (and (= ge_79 ((_ extract 63 63) x3_53)) (= dc_231 ((_ extract 62 0) x3_53))))
(assert (= ge_80 (bvnot ge_79)))
(assert (= ge_81 (ite (= ne_27 #b1) ge_80 #b0)))
(assert (and (= dc_232 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_53))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_27 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_53))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_54 (ite (= ge_81 #b1) x3_neg_27 x3_53)))
(assert (and (= dc_233 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_55))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_27 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_55))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_56 (ite (= ge_81 #b1) x10_neg_27 x10_55)))
(assert (= x7_32 (ite (= ge_81 #b1) x8_56 x7_31)))
(assert (and (= dc_234 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_56) ((_ zero_extend 1) x10_56)))) (= x8_57 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_56) ((_ zero_extend 1) x10_56))))))
(assert (= x3_55 (bvadd x3_54 #x0000000000000002)))
(assert (and (= dc_235 ((_ extract 63 2) x8_57)) (= x8_lo_28 ((_ extract 1 0) x8_57))))
(assert (and (= x8_target_26 ((_ extract 1 1) x8_lo_28)) (= dc_236 ((_ extract 0 0) x8_lo_28))))
(assert (= ne_28 (bvand x8_target_26 #b1)))
(assert (and (= x8_58 ((_ sign_extend 1) ((_ extract 63 1) x8_57))) (= dc_237 ((_ zero_extend 63) ((_ extract 0 0) x8_57)))))
(assert true)
(assert (= x10_57 (ite (= ne_28 #b1) x7_32 #x0000000000000000)))
(assert (and (= ge_82 ((_ extract 63 63) x3_55)) (= dc_238 ((_ extract 62 0) x3_55))))
(assert (= ge_83 (bvnot ge_82)))
(assert (= ge_84 (ite (= ne_28 #b1) ge_83 #b0)))
(assert (and (= dc_239 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_55))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_28 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_55))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_56 (ite (= ge_84 #b1) x3_neg_28 x3_55)))
(assert (and (= dc_240 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_57))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_28 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_57))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_58 (ite (= ge_84 #b1) x10_neg_28 x10_57)))
(assert (= x7_33 (ite (= ge_84 #b1) x8_58 x7_32)))
(assert (and (= dc_241 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_58) ((_ zero_extend 1) x10_58)))) (= x8_59 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_58) ((_ zero_extend 1) x10_58))))))
(assert (= x3_57 (bvadd x3_56 #x0000000000000002)))
(assert (and (= dc_242 ((_ extract 63 2) x8_59)) (= x8_lo_29 ((_ extract 1 0) x8_59))))
(assert (and (= x8_target_27 ((_ extract 1 1) x8_lo_29)) (= dc_243 ((_ extract 0 0) x8_lo_29))))
(assert (= ne_29 (bvand x8_target_27 #b1)))
(assert (and (= x8_60 ((_ sign_extend 1) ((_ extract 63 1) x8_59))) (= dc_244 ((_ zero_extend 63) ((_ extract 0 0) x8_59)))))
(assert true)
(assert (= x10_59 (ite (= ne_29 #b1) x7_33 #x0000000000000000)))
(assert (and (= ge_85 ((_ extract 63 63) x3_57)) (= dc_245 ((_ extract 62 0) x3_57))))
(assert (= ge_86 (bvnot ge_85)))
(assert (= ge_87 (ite (= ne_29 #b1) ge_86 #b0)))
(assert (and (= dc_246 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_57))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_29 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_57))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_58 (ite (= ge_87 #b1) x3_neg_29 x3_57)))
(assert (and (= dc_247 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_59))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_29 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_59))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_60 (ite (= ge_87 #b1) x10_neg_29 x10_59)))
(assert (= x7_34 (ite (= ge_87 #b1) x8_60 x7_33)))
(assert (and (= dc_248 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_60) ((_ zero_extend 1) x10_60)))) (= x8_61 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_60) ((_ zero_extend 1) x10_60))))))
(assert (= x3_59 (bvadd x3_58 #x0000000000000002)))
(assert (and (= dc_249 ((_ extract 63 2) x8_61)) (= x8_lo_30 ((_ extract 1 0) x8_61))))
(assert (and (= x8_target_28 ((_ extract 1 1) x8_lo_30)) (= dc_250 ((_ extract 0 0) x8_lo_30))))
(assert (= ne_30 (bvand x8_target_28 #b1)))
(assert (and (= x8_62 ((_ sign_extend 1) ((_ extract 63 1) x8_61))) (= dc_251 ((_ zero_extend 63) ((_ extract 0 0) x8_61)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_60) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_34 x7_33)) (= (bvmul x8_62 #x0000000000000002) x8_60)) (= x3_59 (bvadd #x0000000000000002 x3_57))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_60) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_57 #x0000000000000000)) (= x7_34 x7_33)) (= (bvmul x8_62 #x0000000000000002) (bvadd x8_60 x7_33))) (= x3_59 (bvadd #x0000000000000002 x3_57)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_60) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_57 #x0000000000000000)) (= x7_34 x8_60)) (= (bvmul x8_62 #x0000000000000002) (bvsub x8_60 x7_33))) (= x3_59 (bvsub #x0000000000000002 x3_57))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_73c78a.smt2
Execution time of boolector: 1.5014 seconds
OUTPUT FROM boolector:
unsat

=== Cut #6 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #6
; Range assertion #50: or [and [smod (sub (uext x8_64 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_36 = x7_35, mul x8_66 2@64 = x8_64, x3_63 = add 2@64 x3_61], and [smod (sub (uext x8_64 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_61 <s 0@64, x7_36 = x7_35, mul x8_66 2@64 = add x8_64 x7_35, x3_63 = add 2@64 x3_61], and [smod (sub (uext x8_64 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_61 >=s 0@64, x7_36 = x8_64, mul x8_66 2@64 = sub x8_64 x7_35, x3_63 = sub 2@64 x3_61]]
; Range condition: ((x8_64@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_36 = x7_35 /\ x8_66 * 2 = x8_64 /\ x3_63 = 2 + x3_61 \/ ((x8_64@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_61 <s 0 /\ x7_36 = x7_35 /\ x8_66 * 2 = x8_64 + x7_35 /\ x3_63 = 2 + x3_61 \/ ((x8_64@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_61 >=s 0 /\ x7_36 = x8_64 /\ x8_66 * 2 = x8_64 - x7_35 /\ x3_63 = 2 - x3_61
; Output file: /tmp/outputqfbv_095971.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_30 () (_ BitVec 1))
(declare-fun x8_target_29 () (_ BitVec 1))
(declare-fun x8_target_28 () (_ BitVec 1))
(declare-fun x8_target_27 () (_ BitVec 1))
(declare-fun x8_target_26 () (_ BitVec 1))
(declare-fun x8_target_25 () (_ BitVec 1))
(declare-fun x8_target_24 () (_ BitVec 1))
(declare-fun x8_target_23 () (_ BitVec 1))
(declare-fun x8_target_22 () (_ BitVec 1))
(declare-fun x8_target_21 () (_ BitVec 1))
(declare-fun x8_target_20 () (_ BitVec 1))
(declare-fun x8_lo_32 () (_ BitVec 2))
(declare-fun x8_lo_31 () (_ BitVec 2))
(declare-fun x8_lo_30 () (_ BitVec 2))
(declare-fun x8_lo_29 () (_ BitVec 2))
(declare-fun x8_lo_28 () (_ BitVec 2))
(declare-fun x8_lo_27 () (_ BitVec 2))
(declare-fun x8_lo_26 () (_ BitVec 2))
(declare-fun x8_lo_25 () (_ BitVec 2))
(declare-fun x8_lo_24 () (_ BitVec 2))
(declare-fun x8_lo_23 () (_ BitVec 2))
(declare-fun x8_lo_22 () (_ BitVec 2))
(declare-fun x8_lo_21 () (_ BitVec 1))
(declare-fun x8_66 () (_ BitVec 64))
(declare-fun x8_65 () (_ BitVec 64))
(declare-fun x8_64 () (_ BitVec 64))
(declare-fun x8_63 () (_ BitVec 64))
(declare-fun x8_62 () (_ BitVec 64))
(declare-fun x8_61 () (_ BitVec 64))
(declare-fun x8_60 () (_ BitVec 64))
(declare-fun x8_59 () (_ BitVec 64))
(declare-fun x8_58 () (_ BitVec 64))
(declare-fun x8_57 () (_ BitVec 64))
(declare-fun x8_56 () (_ BitVec 64))
(declare-fun x8_55 () (_ BitVec 64))
(declare-fun x8_54 () (_ BitVec 64))
(declare-fun x8_53 () (_ BitVec 64))
(declare-fun x8_52 () (_ BitVec 64))
(declare-fun x8_51 () (_ BitVec 64))
(declare-fun x8_50 () (_ BitVec 64))
(declare-fun x8_49 () (_ BitVec 64))
(declare-fun x8_48 () (_ BitVec 64))
(declare-fun x8_47 () (_ BitVec 64))
(declare-fun x8_46 () (_ BitVec 64))
(declare-fun x8_45 () (_ BitVec 64))
(declare-fun x8_44 () (_ BitVec 64))
(declare-fun x7_36 () (_ BitVec 64))
(declare-fun x7_35 () (_ BitVec 64))
(declare-fun x7_34 () (_ BitVec 64))
(declare-fun x7_33 () (_ BitVec 64))
(declare-fun x7_32 () (_ BitVec 64))
(declare-fun x7_31 () (_ BitVec 64))
(declare-fun x7_30 () (_ BitVec 64))
(declare-fun x7_29 () (_ BitVec 64))
(declare-fun x7_28 () (_ BitVec 64))
(declare-fun x7_27 () (_ BitVec 64))
(declare-fun x7_26 () (_ BitVec 64))
(declare-fun x7_25 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_31 () (_ BitVec 64))
(declare-fun x3_neg_30 () (_ BitVec 64))
(declare-fun x3_neg_29 () (_ BitVec 64))
(declare-fun x3_neg_28 () (_ BitVec 64))
(declare-fun x3_neg_27 () (_ BitVec 64))
(declare-fun x3_neg_26 () (_ BitVec 64))
(declare-fun x3_neg_25 () (_ BitVec 64))
(declare-fun x3_neg_24 () (_ BitVec 64))
(declare-fun x3_neg_23 () (_ BitVec 64))
(declare-fun x3_neg_22 () (_ BitVec 64))
(declare-fun x3_neg_21 () (_ BitVec 64))
(declare-fun x3_63 () (_ BitVec 64))
(declare-fun x3_62 () (_ BitVec 64))
(declare-fun x3_61 () (_ BitVec 64))
(declare-fun x3_60 () (_ BitVec 64))
(declare-fun x3_59 () (_ BitVec 64))
(declare-fun x3_58 () (_ BitVec 64))
(declare-fun x3_57 () (_ BitVec 64))
(declare-fun x3_56 () (_ BitVec 64))
(declare-fun x3_55 () (_ BitVec 64))
(declare-fun x3_54 () (_ BitVec 64))
(declare-fun x3_53 () (_ BitVec 64))
(declare-fun x3_52 () (_ BitVec 64))
(declare-fun x3_51 () (_ BitVec 64))
(declare-fun x3_50 () (_ BitVec 64))
(declare-fun x3_49 () (_ BitVec 64))
(declare-fun x3_48 () (_ BitVec 64))
(declare-fun x3_47 () (_ BitVec 64))
(declare-fun x3_46 () (_ BitVec 64))
(declare-fun x3_45 () (_ BitVec 64))
(declare-fun x3_44 () (_ BitVec 64))
(declare-fun x3_43 () (_ BitVec 64))
(declare-fun x3_42 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x10_neg_31 () (_ BitVec 64))
(declare-fun x10_neg_30 () (_ BitVec 64))
(declare-fun x10_neg_29 () (_ BitVec 64))
(declare-fun x10_neg_28 () (_ BitVec 64))
(declare-fun x10_neg_27 () (_ BitVec 64))
(declare-fun x10_neg_26 () (_ BitVec 64))
(declare-fun x10_neg_25 () (_ BitVec 64))
(declare-fun x10_neg_24 () (_ BitVec 64))
(declare-fun x10_neg_23 () (_ BitVec 64))
(declare-fun x10_neg_22 () (_ BitVec 64))
(declare-fun x10_neg_21 () (_ BitVec 64))
(declare-fun x10_64 () (_ BitVec 64))
(declare-fun x10_63 () (_ BitVec 64))
(declare-fun x10_62 () (_ BitVec 64))
(declare-fun x10_61 () (_ BitVec 64))
(declare-fun x10_60 () (_ BitVec 64))
(declare-fun x10_59 () (_ BitVec 64))
(declare-fun x10_58 () (_ BitVec 64))
(declare-fun x10_57 () (_ BitVec 64))
(declare-fun x10_56 () (_ BitVec 64))
(declare-fun x10_55 () (_ BitVec 64))
(declare-fun x10_54 () (_ BitVec 64))
(declare-fun x10_53 () (_ BitVec 64))
(declare-fun x10_52 () (_ BitVec 64))
(declare-fun x10_51 () (_ BitVec 64))
(declare-fun x10_50 () (_ BitVec 64))
(declare-fun x10_49 () (_ BitVec 64))
(declare-fun x10_48 () (_ BitVec 64))
(declare-fun x10_47 () (_ BitVec 64))
(declare-fun x10_46 () (_ BitVec 64))
(declare-fun x10_45 () (_ BitVec 64))
(declare-fun x10_44 () (_ BitVec 64))
(declare-fun x10_43 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun ne_32 () (_ BitVec 1))
(declare-fun ne_31 () (_ BitVec 1))
(declare-fun ne_30 () (_ BitVec 1))
(declare-fun ne_29 () (_ BitVec 1))
(declare-fun ne_28 () (_ BitVec 1))
(declare-fun ne_27 () (_ BitVec 1))
(declare-fun ne_26 () (_ BitVec 1))
(declare-fun ne_25 () (_ BitVec 1))
(declare-fun ne_24 () (_ BitVec 1))
(declare-fun ne_23 () (_ BitVec 1))
(declare-fun ne_22 () (_ BitVec 1))
(declare-fun ne_21 () (_ BitVec 1))
(declare-fun ge_93 () (_ BitVec 1))
(declare-fun ge_92 () (_ BitVec 1))
(declare-fun ge_91 () (_ BitVec 1))
(declare-fun ge_90 () (_ BitVec 1))
(declare-fun ge_89 () (_ BitVec 1))
(declare-fun ge_88 () (_ BitVec 1))
(declare-fun ge_87 () (_ BitVec 1))
(declare-fun ge_86 () (_ BitVec 1))
(declare-fun ge_85 () (_ BitVec 1))
(declare-fun ge_84 () (_ BitVec 1))
(declare-fun ge_83 () (_ BitVec 1))
(declare-fun ge_82 () (_ BitVec 1))
(declare-fun ge_81 () (_ BitVec 1))
(declare-fun ge_80 () (_ BitVec 1))
(declare-fun ge_79 () (_ BitVec 1))
(declare-fun ge_78 () (_ BitVec 1))
(declare-fun ge_77 () (_ BitVec 1))
(declare-fun ge_76 () (_ BitVec 1))
(declare-fun ge_75 () (_ BitVec 1))
(declare-fun ge_74 () (_ BitVec 1))
(declare-fun ge_73 () (_ BitVec 1))
(declare-fun ge_72 () (_ BitVec 1))
(declare-fun ge_71 () (_ BitVec 1))
(declare-fun ge_70 () (_ BitVec 1))
(declare-fun ge_69 () (_ BitVec 1))
(declare-fun ge_68 () (_ BitVec 1))
(declare-fun ge_67 () (_ BitVec 1))
(declare-fun ge_66 () (_ BitVec 1))
(declare-fun ge_65 () (_ BitVec 1))
(declare-fun ge_64 () (_ BitVec 1))
(declare-fun ge_63 () (_ BitVec 1))
(declare-fun ge_62 () (_ BitVec 1))
(declare-fun ge_61 () (_ BitVec 1))
(declare-fun dc_265 () (_ BitVec 64))
(declare-fun dc_264 () (_ BitVec 1))
(declare-fun dc_263 () (_ BitVec 62))
(declare-fun dc_262 () (_ BitVec 1))
(declare-fun dc_261 () (_ BitVec 1))
(declare-fun dc_260 () (_ BitVec 1))
(declare-fun dc_259 () (_ BitVec 63))
(declare-fun dc_258 () (_ BitVec 64))
(declare-fun dc_257 () (_ BitVec 1))
(declare-fun dc_256 () (_ BitVec 62))
(declare-fun dc_255 () (_ BitVec 1))
(declare-fun dc_254 () (_ BitVec 1))
(declare-fun dc_253 () (_ BitVec 1))
(declare-fun dc_252 () (_ BitVec 63))
(declare-fun dc_251 () (_ BitVec 64))
(declare-fun dc_250 () (_ BitVec 1))
(declare-fun dc_249 () (_ BitVec 62))
(declare-fun dc_248 () (_ BitVec 1))
(declare-fun dc_247 () (_ BitVec 1))
(declare-fun dc_246 () (_ BitVec 1))
(declare-fun dc_245 () (_ BitVec 63))
(declare-fun dc_244 () (_ BitVec 64))
(declare-fun dc_243 () (_ BitVec 1))
(declare-fun dc_242 () (_ BitVec 62))
(declare-fun dc_241 () (_ BitVec 1))
(declare-fun dc_240 () (_ BitVec 1))
(declare-fun dc_239 () (_ BitVec 1))
(declare-fun dc_238 () (_ BitVec 63))
(declare-fun dc_237 () (_ BitVec 64))
(declare-fun dc_236 () (_ BitVec 1))
(declare-fun dc_235 () (_ BitVec 62))
(declare-fun dc_234 () (_ BitVec 1))
(declare-fun dc_233 () (_ BitVec 1))
(declare-fun dc_232 () (_ BitVec 1))
(declare-fun dc_231 () (_ BitVec 63))
(declare-fun dc_230 () (_ BitVec 64))
(declare-fun dc_229 () (_ BitVec 1))
(declare-fun dc_228 () (_ BitVec 62))
(declare-fun dc_227 () (_ BitVec 1))
(declare-fun dc_226 () (_ BitVec 1))
(declare-fun dc_225 () (_ BitVec 1))
(declare-fun dc_224 () (_ BitVec 63))
(declare-fun dc_223 () (_ BitVec 64))
(declare-fun dc_222 () (_ BitVec 1))
(declare-fun dc_221 () (_ BitVec 62))
(declare-fun dc_220 () (_ BitVec 1))
(declare-fun dc_219 () (_ BitVec 1))
(declare-fun dc_218 () (_ BitVec 1))
(declare-fun dc_217 () (_ BitVec 63))
(declare-fun dc_216 () (_ BitVec 64))
(declare-fun dc_215 () (_ BitVec 1))
(declare-fun dc_214 () (_ BitVec 62))
(declare-fun dc_213 () (_ BitVec 1))
(declare-fun dc_212 () (_ BitVec 1))
(declare-fun dc_211 () (_ BitVec 1))
(declare-fun dc_210 () (_ BitVec 63))
(declare-fun dc_209 () (_ BitVec 64))
(declare-fun dc_208 () (_ BitVec 1))
(declare-fun dc_207 () (_ BitVec 62))
(declare-fun dc_206 () (_ BitVec 1))
(declare-fun dc_205 () (_ BitVec 1))
(declare-fun dc_204 () (_ BitVec 1))
(declare-fun dc_203 () (_ BitVec 63))
(declare-fun dc_202 () (_ BitVec 64))
(declare-fun dc_201 () (_ BitVec 1))
(declare-fun dc_200 () (_ BitVec 62))
(declare-fun dc_199 () (_ BitVec 1))
(declare-fun dc_198 () (_ BitVec 1))
(declare-fun dc_197 () (_ BitVec 1))
(declare-fun dc_196 () (_ BitVec 63))
(declare-fun dc_195 () (_ BitVec 64))
(declare-fun dc_194 () (_ BitVec 1))
(declare-fun dc_193 () (_ BitVec 62))
(declare-fun dc_192 () (_ BitVec 1))
(declare-fun dc_191 () (_ BitVec 1))
(declare-fun dc_190 () (_ BitVec 1))
(declare-fun dc_189 () (_ BitVec 63))
(declare-fun dc_188 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_25 (bvadd (bvadd neg_f_0_low60_20_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_44 (bvadd (bvadd neg_g_0_low60_20_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_0_1)) (bvsle neg_f_0_low60_20_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_0_1)) (bvsle neg_g_0_low60_20_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_25) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_188 ((_ extract 63 1) x8_44)) (= x8_lo_21 ((_ extract 0 0) x8_44))))
(assert (= ne_21 (bvand x8_lo_21 #b1)))
(assert (= x10_43 (ite (= ne_21 #b1) x7_25 #x0000000000000000)))
(assert (and (= ge_61 ((_ extract 63 63) x3_41)) (= dc_189 ((_ extract 62 0) x3_41))))
(assert (= ge_62 (bvnot ge_61)))
(assert (= ge_63 (ite (= ne_21 #b1) ge_62 #b0)))
(assert (and (= dc_190 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_42 (ite (= ge_63 #b1) x3_neg_21 x3_41)))
(assert (and (= dc_191 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_44 (ite (= ge_63 #b1) x10_neg_21 x10_43)))
(assert (= x7_26 (ite (= ge_63 #b1) x8_44 x7_25)))
(assert (and (= dc_192 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44)))) (= x8_45 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44))))))
(assert (= x3_43 (bvadd x3_42 #x0000000000000002)))
(assert (and (= dc_193 ((_ extract 63 2) x8_45)) (= x8_lo_22 ((_ extract 1 0) x8_45))))
(assert (and (= x8_target_20 ((_ extract 1 1) x8_lo_22)) (= dc_194 ((_ extract 0 0) x8_lo_22))))
(assert (= ne_22 (bvand x8_target_20 #b1)))
(assert (and (= x8_46 ((_ sign_extend 1) ((_ extract 63 1) x8_45))) (= dc_195 ((_ zero_extend 63) ((_ extract 0 0) x8_45)))))
(assert true)
(assert (= x10_45 (ite (= ne_22 #b1) x7_26 #x0000000000000000)))
(assert (and (= ge_64 ((_ extract 63 63) x3_43)) (= dc_196 ((_ extract 62 0) x3_43))))
(assert (= ge_65 (bvnot ge_64)))
(assert (= ge_66 (ite (= ne_22 #b1) ge_65 #b0)))
(assert (and (= dc_197 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_44 (ite (= ge_66 #b1) x3_neg_22 x3_43)))
(assert (and (= dc_198 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_46 (ite (= ge_66 #b1) x10_neg_22 x10_45)))
(assert (= x7_27 (ite (= ge_66 #b1) x8_46 x7_26)))
(assert (and (= dc_199 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46)))) (= x8_47 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46))))))
(assert (= x3_45 (bvadd x3_44 #x0000000000000002)))
(assert (and (= dc_200 ((_ extract 63 2) x8_47)) (= x8_lo_23 ((_ extract 1 0) x8_47))))
(assert (and (= x8_target_21 ((_ extract 1 1) x8_lo_23)) (= dc_201 ((_ extract 0 0) x8_lo_23))))
(assert (= ne_23 (bvand x8_target_21 #b1)))
(assert (and (= x8_48 ((_ sign_extend 1) ((_ extract 63 1) x8_47))) (= dc_202 ((_ zero_extend 63) ((_ extract 0 0) x8_47)))))
(assert true)
(assert (= x10_47 (ite (= ne_23 #b1) x7_27 #x0000000000000000)))
(assert (and (= ge_67 ((_ extract 63 63) x3_45)) (= dc_203 ((_ extract 62 0) x3_45))))
(assert (= ge_68 (bvnot ge_67)))
(assert (= ge_69 (ite (= ne_23 #b1) ge_68 #b0)))
(assert (and (= dc_204 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_46 (ite (= ge_69 #b1) x3_neg_23 x3_45)))
(assert (and (= dc_205 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_48 (ite (= ge_69 #b1) x10_neg_23 x10_47)))
(assert (= x7_28 (ite (= ge_69 #b1) x8_48 x7_27)))
(assert (and (= dc_206 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48)))) (= x8_49 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48))))))
(assert (= x3_47 (bvadd x3_46 #x0000000000000002)))
(assert (and (= dc_207 ((_ extract 63 2) x8_49)) (= x8_lo_24 ((_ extract 1 0) x8_49))))
(assert (and (= x8_target_22 ((_ extract 1 1) x8_lo_24)) (= dc_208 ((_ extract 0 0) x8_lo_24))))
(assert (= ne_24 (bvand x8_target_22 #b1)))
(assert (and (= x8_50 ((_ sign_extend 1) ((_ extract 63 1) x8_49))) (= dc_209 ((_ zero_extend 63) ((_ extract 0 0) x8_49)))))
(assert true)
(assert (= x10_49 (ite (= ne_24 #b1) x7_28 #x0000000000000000)))
(assert (and (= ge_70 ((_ extract 63 63) x3_47)) (= dc_210 ((_ extract 62 0) x3_47))))
(assert (= ge_71 (bvnot ge_70)))
(assert (= ge_72 (ite (= ne_24 #b1) ge_71 #b0)))
(assert (and (= dc_211 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_47))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_24 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_47))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_48 (ite (= ge_72 #b1) x3_neg_24 x3_47)))
(assert (and (= dc_212 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_49))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_24 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_49))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_50 (ite (= ge_72 #b1) x10_neg_24 x10_49)))
(assert (= x7_29 (ite (= ge_72 #b1) x8_50 x7_28)))
(assert (and (= dc_213 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_50) ((_ zero_extend 1) x10_50)))) (= x8_51 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_50) ((_ zero_extend 1) x10_50))))))
(assert (= x3_49 (bvadd x3_48 #x0000000000000002)))
(assert (and (= dc_214 ((_ extract 63 2) x8_51)) (= x8_lo_25 ((_ extract 1 0) x8_51))))
(assert (and (= x8_target_23 ((_ extract 1 1) x8_lo_25)) (= dc_215 ((_ extract 0 0) x8_lo_25))))
(assert (= ne_25 (bvand x8_target_23 #b1)))
(assert (and (= x8_52 ((_ sign_extend 1) ((_ extract 63 1) x8_51))) (= dc_216 ((_ zero_extend 63) ((_ extract 0 0) x8_51)))))
(assert true)
(assert (= x10_51 (ite (= ne_25 #b1) x7_29 #x0000000000000000)))
(assert (and (= ge_73 ((_ extract 63 63) x3_49)) (= dc_217 ((_ extract 62 0) x3_49))))
(assert (= ge_74 (bvnot ge_73)))
(assert (= ge_75 (ite (= ne_25 #b1) ge_74 #b0)))
(assert (and (= dc_218 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_49))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_25 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_49))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_50 (ite (= ge_75 #b1) x3_neg_25 x3_49)))
(assert (and (= dc_219 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_51))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_25 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_51))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_52 (ite (= ge_75 #b1) x10_neg_25 x10_51)))
(assert (= x7_30 (ite (= ge_75 #b1) x8_52 x7_29)))
(assert (and (= dc_220 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_52) ((_ zero_extend 1) x10_52)))) (= x8_53 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_52) ((_ zero_extend 1) x10_52))))))
(assert (= x3_51 (bvadd x3_50 #x0000000000000002)))
(assert (and (= dc_221 ((_ extract 63 2) x8_53)) (= x8_lo_26 ((_ extract 1 0) x8_53))))
(assert (and (= x8_target_24 ((_ extract 1 1) x8_lo_26)) (= dc_222 ((_ extract 0 0) x8_lo_26))))
(assert (= ne_26 (bvand x8_target_24 #b1)))
(assert (and (= x8_54 ((_ sign_extend 1) ((_ extract 63 1) x8_53))) (= dc_223 ((_ zero_extend 63) ((_ extract 0 0) x8_53)))))
(assert true)
(assert (= x10_53 (ite (= ne_26 #b1) x7_30 #x0000000000000000)))
(assert (and (= ge_76 ((_ extract 63 63) x3_51)) (= dc_224 ((_ extract 62 0) x3_51))))
(assert (= ge_77 (bvnot ge_76)))
(assert (= ge_78 (ite (= ne_26 #b1) ge_77 #b0)))
(assert (and (= dc_225 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_51))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_26 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_51))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_52 (ite (= ge_78 #b1) x3_neg_26 x3_51)))
(assert (and (= dc_226 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_53))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_26 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_53))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_54 (ite (= ge_78 #b1) x10_neg_26 x10_53)))
(assert (= x7_31 (ite (= ge_78 #b1) x8_54 x7_30)))
(assert (and (= dc_227 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_54) ((_ zero_extend 1) x10_54)))) (= x8_55 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_54) ((_ zero_extend 1) x10_54))))))
(assert (= x3_53 (bvadd x3_52 #x0000000000000002)))
(assert (and (= dc_228 ((_ extract 63 2) x8_55)) (= x8_lo_27 ((_ extract 1 0) x8_55))))
(assert (and (= x8_target_25 ((_ extract 1 1) x8_lo_27)) (= dc_229 ((_ extract 0 0) x8_lo_27))))
(assert (= ne_27 (bvand x8_target_25 #b1)))
(assert (and (= x8_56 ((_ sign_extend 1) ((_ extract 63 1) x8_55))) (= dc_230 ((_ zero_extend 63) ((_ extract 0 0) x8_55)))))
(assert true)
(assert (= x10_55 (ite (= ne_27 #b1) x7_31 #x0000000000000000)))
(assert (and (= ge_79 ((_ extract 63 63) x3_53)) (= dc_231 ((_ extract 62 0) x3_53))))
(assert (= ge_80 (bvnot ge_79)))
(assert (= ge_81 (ite (= ne_27 #b1) ge_80 #b0)))
(assert (and (= dc_232 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_53))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_27 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_53))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_54 (ite (= ge_81 #b1) x3_neg_27 x3_53)))
(assert (and (= dc_233 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_55))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_27 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_55))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_56 (ite (= ge_81 #b1) x10_neg_27 x10_55)))
(assert (= x7_32 (ite (= ge_81 #b1) x8_56 x7_31)))
(assert (and (= dc_234 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_56) ((_ zero_extend 1) x10_56)))) (= x8_57 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_56) ((_ zero_extend 1) x10_56))))))
(assert (= x3_55 (bvadd x3_54 #x0000000000000002)))
(assert (and (= dc_235 ((_ extract 63 2) x8_57)) (= x8_lo_28 ((_ extract 1 0) x8_57))))
(assert (and (= x8_target_26 ((_ extract 1 1) x8_lo_28)) (= dc_236 ((_ extract 0 0) x8_lo_28))))
(assert (= ne_28 (bvand x8_target_26 #b1)))
(assert (and (= x8_58 ((_ sign_extend 1) ((_ extract 63 1) x8_57))) (= dc_237 ((_ zero_extend 63) ((_ extract 0 0) x8_57)))))
(assert true)
(assert (= x10_57 (ite (= ne_28 #b1) x7_32 #x0000000000000000)))
(assert (and (= ge_82 ((_ extract 63 63) x3_55)) (= dc_238 ((_ extract 62 0) x3_55))))
(assert (= ge_83 (bvnot ge_82)))
(assert (= ge_84 (ite (= ne_28 #b1) ge_83 #b0)))
(assert (and (= dc_239 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_55))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_28 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_55))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_56 (ite (= ge_84 #b1) x3_neg_28 x3_55)))
(assert (and (= dc_240 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_57))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_28 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_57))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_58 (ite (= ge_84 #b1) x10_neg_28 x10_57)))
(assert (= x7_33 (ite (= ge_84 #b1) x8_58 x7_32)))
(assert (and (= dc_241 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_58) ((_ zero_extend 1) x10_58)))) (= x8_59 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_58) ((_ zero_extend 1) x10_58))))))
(assert (= x3_57 (bvadd x3_56 #x0000000000000002)))
(assert (and (= dc_242 ((_ extract 63 2) x8_59)) (= x8_lo_29 ((_ extract 1 0) x8_59))))
(assert (and (= x8_target_27 ((_ extract 1 1) x8_lo_29)) (= dc_243 ((_ extract 0 0) x8_lo_29))))
(assert (= ne_29 (bvand x8_target_27 #b1)))
(assert (and (= x8_60 ((_ sign_extend 1) ((_ extract 63 1) x8_59))) (= dc_244 ((_ zero_extend 63) ((_ extract 0 0) x8_59)))))
(assert true)
(assert (= x10_59 (ite (= ne_29 #b1) x7_33 #x0000000000000000)))
(assert (and (= ge_85 ((_ extract 63 63) x3_57)) (= dc_245 ((_ extract 62 0) x3_57))))
(assert (= ge_86 (bvnot ge_85)))
(assert (= ge_87 (ite (= ne_29 #b1) ge_86 #b0)))
(assert (and (= dc_246 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_57))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_29 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_57))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_58 (ite (= ge_87 #b1) x3_neg_29 x3_57)))
(assert (and (= dc_247 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_59))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_29 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_59))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_60 (ite (= ge_87 #b1) x10_neg_29 x10_59)))
(assert (= x7_34 (ite (= ge_87 #b1) x8_60 x7_33)))
(assert (and (= dc_248 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_60) ((_ zero_extend 1) x10_60)))) (= x8_61 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_60) ((_ zero_extend 1) x10_60))))))
(assert (= x3_59 (bvadd x3_58 #x0000000000000002)))
(assert (and (= dc_249 ((_ extract 63 2) x8_61)) (= x8_lo_30 ((_ extract 1 0) x8_61))))
(assert (and (= x8_target_28 ((_ extract 1 1) x8_lo_30)) (= dc_250 ((_ extract 0 0) x8_lo_30))))
(assert (= ne_30 (bvand x8_target_28 #b1)))
(assert (and (= x8_62 ((_ sign_extend 1) ((_ extract 63 1) x8_61))) (= dc_251 ((_ zero_extend 63) ((_ extract 0 0) x8_61)))))
(assert true)
(assert (= x10_61 (ite (= ne_30 #b1) x7_34 #x0000000000000000)))
(assert (and (= ge_88 ((_ extract 63 63) x3_59)) (= dc_252 ((_ extract 62 0) x3_59))))
(assert (= ge_89 (bvnot ge_88)))
(assert (= ge_90 (ite (= ne_30 #b1) ge_89 #b0)))
(assert (and (= dc_253 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_59))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_30 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_59))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_60 (ite (= ge_90 #b1) x3_neg_30 x3_59)))
(assert (and (= dc_254 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_61))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_30 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_61))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_62 (ite (= ge_90 #b1) x10_neg_30 x10_61)))
(assert (= x7_35 (ite (= ge_90 #b1) x8_62 x7_34)))
(assert (and (= dc_255 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_62) ((_ zero_extend 1) x10_62)))) (= x8_63 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_62) ((_ zero_extend 1) x10_62))))))
(assert (= x3_61 (bvadd x3_60 #x0000000000000002)))
(assert (and (= dc_256 ((_ extract 63 2) x8_63)) (= x8_lo_31 ((_ extract 1 0) x8_63))))
(assert (and (= x8_target_29 ((_ extract 1 1) x8_lo_31)) (= dc_257 ((_ extract 0 0) x8_lo_31))))
(assert (= ne_31 (bvand x8_target_29 #b1)))
(assert (and (= x8_64 ((_ sign_extend 1) ((_ extract 63 1) x8_63))) (= dc_258 ((_ zero_extend 63) ((_ extract 0 0) x8_63)))))
(assert true)
(assert (= x10_63 (ite (= ne_31 #b1) x7_35 #x0000000000000000)))
(assert (and (= ge_91 ((_ extract 63 63) x3_61)) (= dc_259 ((_ extract 62 0) x3_61))))
(assert (= ge_92 (bvnot ge_91)))
(assert (= ge_93 (ite (= ne_31 #b1) ge_92 #b0)))
(assert (and (= dc_260 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_61))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_31 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_61))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_62 (ite (= ge_93 #b1) x3_neg_31 x3_61)))
(assert (and (= dc_261 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_63))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_31 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_63))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_64 (ite (= ge_93 #b1) x10_neg_31 x10_63)))
(assert (= x7_36 (ite (= ge_93 #b1) x8_64 x7_35)))
(assert (and (= dc_262 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_64) ((_ zero_extend 1) x10_64)))) (= x8_65 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_64) ((_ zero_extend 1) x10_64))))))
(assert (= x3_63 (bvadd x3_62 #x0000000000000002)))
(assert (and (= dc_263 ((_ extract 63 2) x8_65)) (= x8_lo_32 ((_ extract 1 0) x8_65))))
(assert (and (= x8_target_30 ((_ extract 1 1) x8_lo_32)) (= dc_264 ((_ extract 0 0) x8_lo_32))))
(assert (= ne_32 (bvand x8_target_30 #b1)))
(assert (and (= x8_66 ((_ sign_extend 1) ((_ extract 63 1) x8_65))) (= dc_265 ((_ zero_extend 63) ((_ extract 0 0) x8_65)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_64) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_36 x7_35)) (= (bvmul x8_66 #x0000000000000002) x8_64)) (= x3_63 (bvadd #x0000000000000002 x3_61))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_64) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_61 #x0000000000000000)) (= x7_36 x7_35)) (= (bvmul x8_66 #x0000000000000002) (bvadd x8_64 x7_35))) (= x3_63 (bvadd #x0000000000000002 x3_61)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_64) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_61 #x0000000000000000)) (= x7_36 x8_64)) (= (bvmul x8_66 #x0000000000000002) (bvsub x8_64 x7_35))) (= x3_63 (bvsub #x0000000000000002 x3_61))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_7953a0.smt2
Execution time of boolector: 0.7969 seconds
OUTPUT FROM boolector:
unsat

=== Cut #6 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #6
; Range assertion #51: or [and [smod (sub (uext x8_66 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_37 = x7_36, mul x8_68 2@64 = x8_66, x3_65 = add 2@64 x3_63], and [smod (sub (uext x8_66 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_63 <s 0@64, x7_37 = x7_36, mul x8_68 2@64 = add x8_66 x7_36, x3_65 = add 2@64 x3_63], and [smod (sub (uext x8_66 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_63 >=s 0@64, x7_37 = x8_66, mul x8_68 2@64 = sub x8_66 x7_36, x3_65 = sub 2@64 x3_63]]
; Range condition: ((x8_66@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_37 = x7_36 /\ x8_68 * 2 = x8_66 /\ x3_65 = 2 + x3_63 \/ ((x8_66@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_63 <s 0 /\ x7_37 = x7_36 /\ x8_68 * 2 = x8_66 + x7_36 /\ x3_65 = 2 + x3_63 \/ ((x8_66@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_63 >=s 0 /\ x7_37 = x8_66 /\ x8_68 * 2 = x8_66 - x7_36 /\ x3_65 = 2 - x3_63
; Output file: /tmp/outputqfbv_453de9.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_31 () (_ BitVec 1))
(declare-fun x8_target_30 () (_ BitVec 1))
(declare-fun x8_target_29 () (_ BitVec 1))
(declare-fun x8_target_28 () (_ BitVec 1))
(declare-fun x8_target_27 () (_ BitVec 1))
(declare-fun x8_target_26 () (_ BitVec 1))
(declare-fun x8_target_25 () (_ BitVec 1))
(declare-fun x8_target_24 () (_ BitVec 1))
(declare-fun x8_target_23 () (_ BitVec 1))
(declare-fun x8_target_22 () (_ BitVec 1))
(declare-fun x8_target_21 () (_ BitVec 1))
(declare-fun x8_target_20 () (_ BitVec 1))
(declare-fun x8_lo_33 () (_ BitVec 2))
(declare-fun x8_lo_32 () (_ BitVec 2))
(declare-fun x8_lo_31 () (_ BitVec 2))
(declare-fun x8_lo_30 () (_ BitVec 2))
(declare-fun x8_lo_29 () (_ BitVec 2))
(declare-fun x8_lo_28 () (_ BitVec 2))
(declare-fun x8_lo_27 () (_ BitVec 2))
(declare-fun x8_lo_26 () (_ BitVec 2))
(declare-fun x8_lo_25 () (_ BitVec 2))
(declare-fun x8_lo_24 () (_ BitVec 2))
(declare-fun x8_lo_23 () (_ BitVec 2))
(declare-fun x8_lo_22 () (_ BitVec 2))
(declare-fun x8_lo_21 () (_ BitVec 1))
(declare-fun x8_68 () (_ BitVec 64))
(declare-fun x8_67 () (_ BitVec 64))
(declare-fun x8_66 () (_ BitVec 64))
(declare-fun x8_65 () (_ BitVec 64))
(declare-fun x8_64 () (_ BitVec 64))
(declare-fun x8_63 () (_ BitVec 64))
(declare-fun x8_62 () (_ BitVec 64))
(declare-fun x8_61 () (_ BitVec 64))
(declare-fun x8_60 () (_ BitVec 64))
(declare-fun x8_59 () (_ BitVec 64))
(declare-fun x8_58 () (_ BitVec 64))
(declare-fun x8_57 () (_ BitVec 64))
(declare-fun x8_56 () (_ BitVec 64))
(declare-fun x8_55 () (_ BitVec 64))
(declare-fun x8_54 () (_ BitVec 64))
(declare-fun x8_53 () (_ BitVec 64))
(declare-fun x8_52 () (_ BitVec 64))
(declare-fun x8_51 () (_ BitVec 64))
(declare-fun x8_50 () (_ BitVec 64))
(declare-fun x8_49 () (_ BitVec 64))
(declare-fun x8_48 () (_ BitVec 64))
(declare-fun x8_47 () (_ BitVec 64))
(declare-fun x8_46 () (_ BitVec 64))
(declare-fun x8_45 () (_ BitVec 64))
(declare-fun x8_44 () (_ BitVec 64))
(declare-fun x7_37 () (_ BitVec 64))
(declare-fun x7_36 () (_ BitVec 64))
(declare-fun x7_35 () (_ BitVec 64))
(declare-fun x7_34 () (_ BitVec 64))
(declare-fun x7_33 () (_ BitVec 64))
(declare-fun x7_32 () (_ BitVec 64))
(declare-fun x7_31 () (_ BitVec 64))
(declare-fun x7_30 () (_ BitVec 64))
(declare-fun x7_29 () (_ BitVec 64))
(declare-fun x7_28 () (_ BitVec 64))
(declare-fun x7_27 () (_ BitVec 64))
(declare-fun x7_26 () (_ BitVec 64))
(declare-fun x7_25 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_32 () (_ BitVec 64))
(declare-fun x3_neg_31 () (_ BitVec 64))
(declare-fun x3_neg_30 () (_ BitVec 64))
(declare-fun x3_neg_29 () (_ BitVec 64))
(declare-fun x3_neg_28 () (_ BitVec 64))
(declare-fun x3_neg_27 () (_ BitVec 64))
(declare-fun x3_neg_26 () (_ BitVec 64))
(declare-fun x3_neg_25 () (_ BitVec 64))
(declare-fun x3_neg_24 () (_ BitVec 64))
(declare-fun x3_neg_23 () (_ BitVec 64))
(declare-fun x3_neg_22 () (_ BitVec 64))
(declare-fun x3_neg_21 () (_ BitVec 64))
(declare-fun x3_65 () (_ BitVec 64))
(declare-fun x3_64 () (_ BitVec 64))
(declare-fun x3_63 () (_ BitVec 64))
(declare-fun x3_62 () (_ BitVec 64))
(declare-fun x3_61 () (_ BitVec 64))
(declare-fun x3_60 () (_ BitVec 64))
(declare-fun x3_59 () (_ BitVec 64))
(declare-fun x3_58 () (_ BitVec 64))
(declare-fun x3_57 () (_ BitVec 64))
(declare-fun x3_56 () (_ BitVec 64))
(declare-fun x3_55 () (_ BitVec 64))
(declare-fun x3_54 () (_ BitVec 64))
(declare-fun x3_53 () (_ BitVec 64))
(declare-fun x3_52 () (_ BitVec 64))
(declare-fun x3_51 () (_ BitVec 64))
(declare-fun x3_50 () (_ BitVec 64))
(declare-fun x3_49 () (_ BitVec 64))
(declare-fun x3_48 () (_ BitVec 64))
(declare-fun x3_47 () (_ BitVec 64))
(declare-fun x3_46 () (_ BitVec 64))
(declare-fun x3_45 () (_ BitVec 64))
(declare-fun x3_44 () (_ BitVec 64))
(declare-fun x3_43 () (_ BitVec 64))
(declare-fun x3_42 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x10_neg_32 () (_ BitVec 64))
(declare-fun x10_neg_31 () (_ BitVec 64))
(declare-fun x10_neg_30 () (_ BitVec 64))
(declare-fun x10_neg_29 () (_ BitVec 64))
(declare-fun x10_neg_28 () (_ BitVec 64))
(declare-fun x10_neg_27 () (_ BitVec 64))
(declare-fun x10_neg_26 () (_ BitVec 64))
(declare-fun x10_neg_25 () (_ BitVec 64))
(declare-fun x10_neg_24 () (_ BitVec 64))
(declare-fun x10_neg_23 () (_ BitVec 64))
(declare-fun x10_neg_22 () (_ BitVec 64))
(declare-fun x10_neg_21 () (_ BitVec 64))
(declare-fun x10_66 () (_ BitVec 64))
(declare-fun x10_65 () (_ BitVec 64))
(declare-fun x10_64 () (_ BitVec 64))
(declare-fun x10_63 () (_ BitVec 64))
(declare-fun x10_62 () (_ BitVec 64))
(declare-fun x10_61 () (_ BitVec 64))
(declare-fun x10_60 () (_ BitVec 64))
(declare-fun x10_59 () (_ BitVec 64))
(declare-fun x10_58 () (_ BitVec 64))
(declare-fun x10_57 () (_ BitVec 64))
(declare-fun x10_56 () (_ BitVec 64))
(declare-fun x10_55 () (_ BitVec 64))
(declare-fun x10_54 () (_ BitVec 64))
(declare-fun x10_53 () (_ BitVec 64))
(declare-fun x10_52 () (_ BitVec 64))
(declare-fun x10_51 () (_ BitVec 64))
(declare-fun x10_50 () (_ BitVec 64))
(declare-fun x10_49 () (_ BitVec 64))
(declare-fun x10_48 () (_ BitVec 64))
(declare-fun x10_47 () (_ BitVec 64))
(declare-fun x10_46 () (_ BitVec 64))
(declare-fun x10_45 () (_ BitVec 64))
(declare-fun x10_44 () (_ BitVec 64))
(declare-fun x10_43 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun ne_33 () (_ BitVec 1))
(declare-fun ne_32 () (_ BitVec 1))
(declare-fun ne_31 () (_ BitVec 1))
(declare-fun ne_30 () (_ BitVec 1))
(declare-fun ne_29 () (_ BitVec 1))
(declare-fun ne_28 () (_ BitVec 1))
(declare-fun ne_27 () (_ BitVec 1))
(declare-fun ne_26 () (_ BitVec 1))
(declare-fun ne_25 () (_ BitVec 1))
(declare-fun ne_24 () (_ BitVec 1))
(declare-fun ne_23 () (_ BitVec 1))
(declare-fun ne_22 () (_ BitVec 1))
(declare-fun ne_21 () (_ BitVec 1))
(declare-fun ge_96 () (_ BitVec 1))
(declare-fun ge_95 () (_ BitVec 1))
(declare-fun ge_94 () (_ BitVec 1))
(declare-fun ge_93 () (_ BitVec 1))
(declare-fun ge_92 () (_ BitVec 1))
(declare-fun ge_91 () (_ BitVec 1))
(declare-fun ge_90 () (_ BitVec 1))
(declare-fun ge_89 () (_ BitVec 1))
(declare-fun ge_88 () (_ BitVec 1))
(declare-fun ge_87 () (_ BitVec 1))
(declare-fun ge_86 () (_ BitVec 1))
(declare-fun ge_85 () (_ BitVec 1))
(declare-fun ge_84 () (_ BitVec 1))
(declare-fun ge_83 () (_ BitVec 1))
(declare-fun ge_82 () (_ BitVec 1))
(declare-fun ge_81 () (_ BitVec 1))
(declare-fun ge_80 () (_ BitVec 1))
(declare-fun ge_79 () (_ BitVec 1))
(declare-fun ge_78 () (_ BitVec 1))
(declare-fun ge_77 () (_ BitVec 1))
(declare-fun ge_76 () (_ BitVec 1))
(declare-fun ge_75 () (_ BitVec 1))
(declare-fun ge_74 () (_ BitVec 1))
(declare-fun ge_73 () (_ BitVec 1))
(declare-fun ge_72 () (_ BitVec 1))
(declare-fun ge_71 () (_ BitVec 1))
(declare-fun ge_70 () (_ BitVec 1))
(declare-fun ge_69 () (_ BitVec 1))
(declare-fun ge_68 () (_ BitVec 1))
(declare-fun ge_67 () (_ BitVec 1))
(declare-fun ge_66 () (_ BitVec 1))
(declare-fun ge_65 () (_ BitVec 1))
(declare-fun ge_64 () (_ BitVec 1))
(declare-fun ge_63 () (_ BitVec 1))
(declare-fun ge_62 () (_ BitVec 1))
(declare-fun ge_61 () (_ BitVec 1))
(declare-fun dc_272 () (_ BitVec 64))
(declare-fun dc_271 () (_ BitVec 1))
(declare-fun dc_270 () (_ BitVec 62))
(declare-fun dc_269 () (_ BitVec 1))
(declare-fun dc_268 () (_ BitVec 1))
(declare-fun dc_267 () (_ BitVec 1))
(declare-fun dc_266 () (_ BitVec 63))
(declare-fun dc_265 () (_ BitVec 64))
(declare-fun dc_264 () (_ BitVec 1))
(declare-fun dc_263 () (_ BitVec 62))
(declare-fun dc_262 () (_ BitVec 1))
(declare-fun dc_261 () (_ BitVec 1))
(declare-fun dc_260 () (_ BitVec 1))
(declare-fun dc_259 () (_ BitVec 63))
(declare-fun dc_258 () (_ BitVec 64))
(declare-fun dc_257 () (_ BitVec 1))
(declare-fun dc_256 () (_ BitVec 62))
(declare-fun dc_255 () (_ BitVec 1))
(declare-fun dc_254 () (_ BitVec 1))
(declare-fun dc_253 () (_ BitVec 1))
(declare-fun dc_252 () (_ BitVec 63))
(declare-fun dc_251 () (_ BitVec 64))
(declare-fun dc_250 () (_ BitVec 1))
(declare-fun dc_249 () (_ BitVec 62))
(declare-fun dc_248 () (_ BitVec 1))
(declare-fun dc_247 () (_ BitVec 1))
(declare-fun dc_246 () (_ BitVec 1))
(declare-fun dc_245 () (_ BitVec 63))
(declare-fun dc_244 () (_ BitVec 64))
(declare-fun dc_243 () (_ BitVec 1))
(declare-fun dc_242 () (_ BitVec 62))
(declare-fun dc_241 () (_ BitVec 1))
(declare-fun dc_240 () (_ BitVec 1))
(declare-fun dc_239 () (_ BitVec 1))
(declare-fun dc_238 () (_ BitVec 63))
(declare-fun dc_237 () (_ BitVec 64))
(declare-fun dc_236 () (_ BitVec 1))
(declare-fun dc_235 () (_ BitVec 62))
(declare-fun dc_234 () (_ BitVec 1))
(declare-fun dc_233 () (_ BitVec 1))
(declare-fun dc_232 () (_ BitVec 1))
(declare-fun dc_231 () (_ BitVec 63))
(declare-fun dc_230 () (_ BitVec 64))
(declare-fun dc_229 () (_ BitVec 1))
(declare-fun dc_228 () (_ BitVec 62))
(declare-fun dc_227 () (_ BitVec 1))
(declare-fun dc_226 () (_ BitVec 1))
(declare-fun dc_225 () (_ BitVec 1))
(declare-fun dc_224 () (_ BitVec 63))
(declare-fun dc_223 () (_ BitVec 64))
(declare-fun dc_222 () (_ BitVec 1))
(declare-fun dc_221 () (_ BitVec 62))
(declare-fun dc_220 () (_ BitVec 1))
(declare-fun dc_219 () (_ BitVec 1))
(declare-fun dc_218 () (_ BitVec 1))
(declare-fun dc_217 () (_ BitVec 63))
(declare-fun dc_216 () (_ BitVec 64))
(declare-fun dc_215 () (_ BitVec 1))
(declare-fun dc_214 () (_ BitVec 62))
(declare-fun dc_213 () (_ BitVec 1))
(declare-fun dc_212 () (_ BitVec 1))
(declare-fun dc_211 () (_ BitVec 1))
(declare-fun dc_210 () (_ BitVec 63))
(declare-fun dc_209 () (_ BitVec 64))
(declare-fun dc_208 () (_ BitVec 1))
(declare-fun dc_207 () (_ BitVec 62))
(declare-fun dc_206 () (_ BitVec 1))
(declare-fun dc_205 () (_ BitVec 1))
(declare-fun dc_204 () (_ BitVec 1))
(declare-fun dc_203 () (_ BitVec 63))
(declare-fun dc_202 () (_ BitVec 64))
(declare-fun dc_201 () (_ BitVec 1))
(declare-fun dc_200 () (_ BitVec 62))
(declare-fun dc_199 () (_ BitVec 1))
(declare-fun dc_198 () (_ BitVec 1))
(declare-fun dc_197 () (_ BitVec 1))
(declare-fun dc_196 () (_ BitVec 63))
(declare-fun dc_195 () (_ BitVec 64))
(declare-fun dc_194 () (_ BitVec 1))
(declare-fun dc_193 () (_ BitVec 62))
(declare-fun dc_192 () (_ BitVec 1))
(declare-fun dc_191 () (_ BitVec 1))
(declare-fun dc_190 () (_ BitVec 1))
(declare-fun dc_189 () (_ BitVec 63))
(declare-fun dc_188 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_25 (bvadd (bvadd neg_f_0_low60_20_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_44 (bvadd (bvadd neg_g_0_low60_20_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_0_1)) (bvsle neg_f_0_low60_20_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_0_1)) (bvsle neg_g_0_low60_20_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_25) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_188 ((_ extract 63 1) x8_44)) (= x8_lo_21 ((_ extract 0 0) x8_44))))
(assert (= ne_21 (bvand x8_lo_21 #b1)))
(assert (= x10_43 (ite (= ne_21 #b1) x7_25 #x0000000000000000)))
(assert (and (= ge_61 ((_ extract 63 63) x3_41)) (= dc_189 ((_ extract 62 0) x3_41))))
(assert (= ge_62 (bvnot ge_61)))
(assert (= ge_63 (ite (= ne_21 #b1) ge_62 #b0)))
(assert (and (= dc_190 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_42 (ite (= ge_63 #b1) x3_neg_21 x3_41)))
(assert (and (= dc_191 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_44 (ite (= ge_63 #b1) x10_neg_21 x10_43)))
(assert (= x7_26 (ite (= ge_63 #b1) x8_44 x7_25)))
(assert (and (= dc_192 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44)))) (= x8_45 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44))))))
(assert (= x3_43 (bvadd x3_42 #x0000000000000002)))
(assert (and (= dc_193 ((_ extract 63 2) x8_45)) (= x8_lo_22 ((_ extract 1 0) x8_45))))
(assert (and (= x8_target_20 ((_ extract 1 1) x8_lo_22)) (= dc_194 ((_ extract 0 0) x8_lo_22))))
(assert (= ne_22 (bvand x8_target_20 #b1)))
(assert (and (= x8_46 ((_ sign_extend 1) ((_ extract 63 1) x8_45))) (= dc_195 ((_ zero_extend 63) ((_ extract 0 0) x8_45)))))
(assert true)
(assert (= x10_45 (ite (= ne_22 #b1) x7_26 #x0000000000000000)))
(assert (and (= ge_64 ((_ extract 63 63) x3_43)) (= dc_196 ((_ extract 62 0) x3_43))))
(assert (= ge_65 (bvnot ge_64)))
(assert (= ge_66 (ite (= ne_22 #b1) ge_65 #b0)))
(assert (and (= dc_197 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_44 (ite (= ge_66 #b1) x3_neg_22 x3_43)))
(assert (and (= dc_198 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_46 (ite (= ge_66 #b1) x10_neg_22 x10_45)))
(assert (= x7_27 (ite (= ge_66 #b1) x8_46 x7_26)))
(assert (and (= dc_199 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46)))) (= x8_47 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46))))))
(assert (= x3_45 (bvadd x3_44 #x0000000000000002)))
(assert (and (= dc_200 ((_ extract 63 2) x8_47)) (= x8_lo_23 ((_ extract 1 0) x8_47))))
(assert (and (= x8_target_21 ((_ extract 1 1) x8_lo_23)) (= dc_201 ((_ extract 0 0) x8_lo_23))))
(assert (= ne_23 (bvand x8_target_21 #b1)))
(assert (and (= x8_48 ((_ sign_extend 1) ((_ extract 63 1) x8_47))) (= dc_202 ((_ zero_extend 63) ((_ extract 0 0) x8_47)))))
(assert true)
(assert (= x10_47 (ite (= ne_23 #b1) x7_27 #x0000000000000000)))
(assert (and (= ge_67 ((_ extract 63 63) x3_45)) (= dc_203 ((_ extract 62 0) x3_45))))
(assert (= ge_68 (bvnot ge_67)))
(assert (= ge_69 (ite (= ne_23 #b1) ge_68 #b0)))
(assert (and (= dc_204 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_46 (ite (= ge_69 #b1) x3_neg_23 x3_45)))
(assert (and (= dc_205 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_48 (ite (= ge_69 #b1) x10_neg_23 x10_47)))
(assert (= x7_28 (ite (= ge_69 #b1) x8_48 x7_27)))
(assert (and (= dc_206 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48)))) (= x8_49 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48))))))
(assert (= x3_47 (bvadd x3_46 #x0000000000000002)))
(assert (and (= dc_207 ((_ extract 63 2) x8_49)) (= x8_lo_24 ((_ extract 1 0) x8_49))))
(assert (and (= x8_target_22 ((_ extract 1 1) x8_lo_24)) (= dc_208 ((_ extract 0 0) x8_lo_24))))
(assert (= ne_24 (bvand x8_target_22 #b1)))
(assert (and (= x8_50 ((_ sign_extend 1) ((_ extract 63 1) x8_49))) (= dc_209 ((_ zero_extend 63) ((_ extract 0 0) x8_49)))))
(assert true)
(assert (= x10_49 (ite (= ne_24 #b1) x7_28 #x0000000000000000)))
(assert (and (= ge_70 ((_ extract 63 63) x3_47)) (= dc_210 ((_ extract 62 0) x3_47))))
(assert (= ge_71 (bvnot ge_70)))
(assert (= ge_72 (ite (= ne_24 #b1) ge_71 #b0)))
(assert (and (= dc_211 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_47))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_24 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_47))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_48 (ite (= ge_72 #b1) x3_neg_24 x3_47)))
(assert (and (= dc_212 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_49))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_24 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_49))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_50 (ite (= ge_72 #b1) x10_neg_24 x10_49)))
(assert (= x7_29 (ite (= ge_72 #b1) x8_50 x7_28)))
(assert (and (= dc_213 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_50) ((_ zero_extend 1) x10_50)))) (= x8_51 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_50) ((_ zero_extend 1) x10_50))))))
(assert (= x3_49 (bvadd x3_48 #x0000000000000002)))
(assert (and (= dc_214 ((_ extract 63 2) x8_51)) (= x8_lo_25 ((_ extract 1 0) x8_51))))
(assert (and (= x8_target_23 ((_ extract 1 1) x8_lo_25)) (= dc_215 ((_ extract 0 0) x8_lo_25))))
(assert (= ne_25 (bvand x8_target_23 #b1)))
(assert (and (= x8_52 ((_ sign_extend 1) ((_ extract 63 1) x8_51))) (= dc_216 ((_ zero_extend 63) ((_ extract 0 0) x8_51)))))
(assert true)
(assert (= x10_51 (ite (= ne_25 #b1) x7_29 #x0000000000000000)))
(assert (and (= ge_73 ((_ extract 63 63) x3_49)) (= dc_217 ((_ extract 62 0) x3_49))))
(assert (= ge_74 (bvnot ge_73)))
(assert (= ge_75 (ite (= ne_25 #b1) ge_74 #b0)))
(assert (and (= dc_218 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_49))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_25 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_49))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_50 (ite (= ge_75 #b1) x3_neg_25 x3_49)))
(assert (and (= dc_219 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_51))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_25 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_51))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_52 (ite (= ge_75 #b1) x10_neg_25 x10_51)))
(assert (= x7_30 (ite (= ge_75 #b1) x8_52 x7_29)))
(assert (and (= dc_220 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_52) ((_ zero_extend 1) x10_52)))) (= x8_53 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_52) ((_ zero_extend 1) x10_52))))))
(assert (= x3_51 (bvadd x3_50 #x0000000000000002)))
(assert (and (= dc_221 ((_ extract 63 2) x8_53)) (= x8_lo_26 ((_ extract 1 0) x8_53))))
(assert (and (= x8_target_24 ((_ extract 1 1) x8_lo_26)) (= dc_222 ((_ extract 0 0) x8_lo_26))))
(assert (= ne_26 (bvand x8_target_24 #b1)))
(assert (and (= x8_54 ((_ sign_extend 1) ((_ extract 63 1) x8_53))) (= dc_223 ((_ zero_extend 63) ((_ extract 0 0) x8_53)))))
(assert true)
(assert (= x10_53 (ite (= ne_26 #b1) x7_30 #x0000000000000000)))
(assert (and (= ge_76 ((_ extract 63 63) x3_51)) (= dc_224 ((_ extract 62 0) x3_51))))
(assert (= ge_77 (bvnot ge_76)))
(assert (= ge_78 (ite (= ne_26 #b1) ge_77 #b0)))
(assert (and (= dc_225 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_51))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_26 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_51))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_52 (ite (= ge_78 #b1) x3_neg_26 x3_51)))
(assert (and (= dc_226 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_53))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_26 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_53))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_54 (ite (= ge_78 #b1) x10_neg_26 x10_53)))
(assert (= x7_31 (ite (= ge_78 #b1) x8_54 x7_30)))
(assert (and (= dc_227 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_54) ((_ zero_extend 1) x10_54)))) (= x8_55 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_54) ((_ zero_extend 1) x10_54))))))
(assert (= x3_53 (bvadd x3_52 #x0000000000000002)))
(assert (and (= dc_228 ((_ extract 63 2) x8_55)) (= x8_lo_27 ((_ extract 1 0) x8_55))))
(assert (and (= x8_target_25 ((_ extract 1 1) x8_lo_27)) (= dc_229 ((_ extract 0 0) x8_lo_27))))
(assert (= ne_27 (bvand x8_target_25 #b1)))
(assert (and (= x8_56 ((_ sign_extend 1) ((_ extract 63 1) x8_55))) (= dc_230 ((_ zero_extend 63) ((_ extract 0 0) x8_55)))))
(assert true)
(assert (= x10_55 (ite (= ne_27 #b1) x7_31 #x0000000000000000)))
(assert (and (= ge_79 ((_ extract 63 63) x3_53)) (= dc_231 ((_ extract 62 0) x3_53))))
(assert (= ge_80 (bvnot ge_79)))
(assert (= ge_81 (ite (= ne_27 #b1) ge_80 #b0)))
(assert (and (= dc_232 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_53))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_27 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_53))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_54 (ite (= ge_81 #b1) x3_neg_27 x3_53)))
(assert (and (= dc_233 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_55))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_27 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_55))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_56 (ite (= ge_81 #b1) x10_neg_27 x10_55)))
(assert (= x7_32 (ite (= ge_81 #b1) x8_56 x7_31)))
(assert (and (= dc_234 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_56) ((_ zero_extend 1) x10_56)))) (= x8_57 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_56) ((_ zero_extend 1) x10_56))))))
(assert (= x3_55 (bvadd x3_54 #x0000000000000002)))
(assert (and (= dc_235 ((_ extract 63 2) x8_57)) (= x8_lo_28 ((_ extract 1 0) x8_57))))
(assert (and (= x8_target_26 ((_ extract 1 1) x8_lo_28)) (= dc_236 ((_ extract 0 0) x8_lo_28))))
(assert (= ne_28 (bvand x8_target_26 #b1)))
(assert (and (= x8_58 ((_ sign_extend 1) ((_ extract 63 1) x8_57))) (= dc_237 ((_ zero_extend 63) ((_ extract 0 0) x8_57)))))
(assert true)
(assert (= x10_57 (ite (= ne_28 #b1) x7_32 #x0000000000000000)))
(assert (and (= ge_82 ((_ extract 63 63) x3_55)) (= dc_238 ((_ extract 62 0) x3_55))))
(assert (= ge_83 (bvnot ge_82)))
(assert (= ge_84 (ite (= ne_28 #b1) ge_83 #b0)))
(assert (and (= dc_239 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_55))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_28 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_55))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_56 (ite (= ge_84 #b1) x3_neg_28 x3_55)))
(assert (and (= dc_240 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_57))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_28 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_57))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_58 (ite (= ge_84 #b1) x10_neg_28 x10_57)))
(assert (= x7_33 (ite (= ge_84 #b1) x8_58 x7_32)))
(assert (and (= dc_241 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_58) ((_ zero_extend 1) x10_58)))) (= x8_59 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_58) ((_ zero_extend 1) x10_58))))))
(assert (= x3_57 (bvadd x3_56 #x0000000000000002)))
(assert (and (= dc_242 ((_ extract 63 2) x8_59)) (= x8_lo_29 ((_ extract 1 0) x8_59))))
(assert (and (= x8_target_27 ((_ extract 1 1) x8_lo_29)) (= dc_243 ((_ extract 0 0) x8_lo_29))))
(assert (= ne_29 (bvand x8_target_27 #b1)))
(assert (and (= x8_60 ((_ sign_extend 1) ((_ extract 63 1) x8_59))) (= dc_244 ((_ zero_extend 63) ((_ extract 0 0) x8_59)))))
(assert true)
(assert (= x10_59 (ite (= ne_29 #b1) x7_33 #x0000000000000000)))
(assert (and (= ge_85 ((_ extract 63 63) x3_57)) (= dc_245 ((_ extract 62 0) x3_57))))
(assert (= ge_86 (bvnot ge_85)))
(assert (= ge_87 (ite (= ne_29 #b1) ge_86 #b0)))
(assert (and (= dc_246 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_57))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_29 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_57))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_58 (ite (= ge_87 #b1) x3_neg_29 x3_57)))
(assert (and (= dc_247 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_59))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_29 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_59))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_60 (ite (= ge_87 #b1) x10_neg_29 x10_59)))
(assert (= x7_34 (ite (= ge_87 #b1) x8_60 x7_33)))
(assert (and (= dc_248 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_60) ((_ zero_extend 1) x10_60)))) (= x8_61 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_60) ((_ zero_extend 1) x10_60))))))
(assert (= x3_59 (bvadd x3_58 #x0000000000000002)))
(assert (and (= dc_249 ((_ extract 63 2) x8_61)) (= x8_lo_30 ((_ extract 1 0) x8_61))))
(assert (and (= x8_target_28 ((_ extract 1 1) x8_lo_30)) (= dc_250 ((_ extract 0 0) x8_lo_30))))
(assert (= ne_30 (bvand x8_target_28 #b1)))
(assert (and (= x8_62 ((_ sign_extend 1) ((_ extract 63 1) x8_61))) (= dc_251 ((_ zero_extend 63) ((_ extract 0 0) x8_61)))))
(assert true)
(assert (= x10_61 (ite (= ne_30 #b1) x7_34 #x0000000000000000)))
(assert (and (= ge_88 ((_ extract 63 63) x3_59)) (= dc_252 ((_ extract 62 0) x3_59))))
(assert (= ge_89 (bvnot ge_88)))
(assert (= ge_90 (ite (= ne_30 #b1) ge_89 #b0)))
(assert (and (= dc_253 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_59))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_30 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_59))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_60 (ite (= ge_90 #b1) x3_neg_30 x3_59)))
(assert (and (= dc_254 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_61))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_30 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_61))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_62 (ite (= ge_90 #b1) x10_neg_30 x10_61)))
(assert (= x7_35 (ite (= ge_90 #b1) x8_62 x7_34)))
(assert (and (= dc_255 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_62) ((_ zero_extend 1) x10_62)))) (= x8_63 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_62) ((_ zero_extend 1) x10_62))))))
(assert (= x3_61 (bvadd x3_60 #x0000000000000002)))
(assert (and (= dc_256 ((_ extract 63 2) x8_63)) (= x8_lo_31 ((_ extract 1 0) x8_63))))
(assert (and (= x8_target_29 ((_ extract 1 1) x8_lo_31)) (= dc_257 ((_ extract 0 0) x8_lo_31))))
(assert (= ne_31 (bvand x8_target_29 #b1)))
(assert (and (= x8_64 ((_ sign_extend 1) ((_ extract 63 1) x8_63))) (= dc_258 ((_ zero_extend 63) ((_ extract 0 0) x8_63)))))
(assert true)
(assert (= x10_63 (ite (= ne_31 #b1) x7_35 #x0000000000000000)))
(assert (and (= ge_91 ((_ extract 63 63) x3_61)) (= dc_259 ((_ extract 62 0) x3_61))))
(assert (= ge_92 (bvnot ge_91)))
(assert (= ge_93 (ite (= ne_31 #b1) ge_92 #b0)))
(assert (and (= dc_260 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_61))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_31 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_61))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_62 (ite (= ge_93 #b1) x3_neg_31 x3_61)))
(assert (and (= dc_261 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_63))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_31 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_63))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_64 (ite (= ge_93 #b1) x10_neg_31 x10_63)))
(assert (= x7_36 (ite (= ge_93 #b1) x8_64 x7_35)))
(assert (and (= dc_262 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_64) ((_ zero_extend 1) x10_64)))) (= x8_65 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_64) ((_ zero_extend 1) x10_64))))))
(assert (= x3_63 (bvadd x3_62 #x0000000000000002)))
(assert (and (= dc_263 ((_ extract 63 2) x8_65)) (= x8_lo_32 ((_ extract 1 0) x8_65))))
(assert (and (= x8_target_30 ((_ extract 1 1) x8_lo_32)) (= dc_264 ((_ extract 0 0) x8_lo_32))))
(assert (= ne_32 (bvand x8_target_30 #b1)))
(assert (and (= x8_66 ((_ sign_extend 1) ((_ extract 63 1) x8_65))) (= dc_265 ((_ zero_extend 63) ((_ extract 0 0) x8_65)))))
(assert true)
(assert (= x10_65 (ite (= ne_32 #b1) x7_36 #x0000000000000000)))
(assert (and (= ge_94 ((_ extract 63 63) x3_63)) (= dc_266 ((_ extract 62 0) x3_63))))
(assert (= ge_95 (bvnot ge_94)))
(assert (= ge_96 (ite (= ne_32 #b1) ge_95 #b0)))
(assert (and (= dc_267 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_63))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_32 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_63))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_64 (ite (= ge_96 #b1) x3_neg_32 x3_63)))
(assert (and (= dc_268 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_65))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_32 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_65))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_66 (ite (= ge_96 #b1) x10_neg_32 x10_65)))
(assert (= x7_37 (ite (= ge_96 #b1) x8_66 x7_36)))
(assert (and (= dc_269 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_66) ((_ zero_extend 1) x10_66)))) (= x8_67 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_66) ((_ zero_extend 1) x10_66))))))
(assert (= x3_65 (bvadd x3_64 #x0000000000000002)))
(assert (and (= dc_270 ((_ extract 63 2) x8_67)) (= x8_lo_33 ((_ extract 1 0) x8_67))))
(assert (and (= x8_target_31 ((_ extract 1 1) x8_lo_33)) (= dc_271 ((_ extract 0 0) x8_lo_33))))
(assert (= ne_33 (bvand x8_target_31 #b1)))
(assert (and (= x8_68 ((_ sign_extend 1) ((_ extract 63 1) x8_67))) (= dc_272 ((_ zero_extend 63) ((_ extract 0 0) x8_67)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_66) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_37 x7_36)) (= (bvmul x8_68 #x0000000000000002) x8_66)) (= x3_65 (bvadd #x0000000000000002 x3_63))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_66) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_63 #x0000000000000000)) (= x7_37 x7_36)) (= (bvmul x8_68 #x0000000000000002) (bvadd x8_66 x7_36))) (= x3_65 (bvadd #x0000000000000002 x3_63)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_66) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_63 #x0000000000000000)) (= x7_37 x8_66)) (= (bvmul x8_68 #x0000000000000002) (bvsub x8_66 x7_36))) (= x3_65 (bvsub #x0000000000000002 x3_63))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_06dc42.smt2
Execution time of boolector: 0.6729 seconds
OUTPUT FROM boolector:
unsat

=== Cut #6 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #6
; Range assertion #52: or [and [smod (sub (uext x8_68 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_38 = x7_37, mul x8_70 2@64 = x8_68, x3_67 = add 2@64 x3_65], and [smod (sub (uext x8_68 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_65 <s 0@64, x7_38 = x7_37, mul x8_70 2@64 = add x8_68 x7_37, x3_67 = add 2@64 x3_65], and [smod (sub (uext x8_68 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_65 >=s 0@64, x7_38 = x8_68, mul x8_70 2@64 = sub x8_68 x7_37, x3_67 = sub 2@64 x3_65]]
; Range condition: ((x8_68@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_38 = x7_37 /\ x8_70 * 2 = x8_68 /\ x3_67 = 2 + x3_65 \/ ((x8_68@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_65 <s 0 /\ x7_38 = x7_37 /\ x8_70 * 2 = x8_68 + x7_37 /\ x3_67 = 2 + x3_65 \/ ((x8_68@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_65 >=s 0 /\ x7_38 = x8_68 /\ x8_70 * 2 = x8_68 - x7_37 /\ x3_67 = 2 - x3_65
; Output file: /tmp/outputqfbv_1f7504.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_32 () (_ BitVec 1))
(declare-fun x8_target_31 () (_ BitVec 1))
(declare-fun x8_target_30 () (_ BitVec 1))
(declare-fun x8_target_29 () (_ BitVec 1))
(declare-fun x8_target_28 () (_ BitVec 1))
(declare-fun x8_target_27 () (_ BitVec 1))
(declare-fun x8_target_26 () (_ BitVec 1))
(declare-fun x8_target_25 () (_ BitVec 1))
(declare-fun x8_target_24 () (_ BitVec 1))
(declare-fun x8_target_23 () (_ BitVec 1))
(declare-fun x8_target_22 () (_ BitVec 1))
(declare-fun x8_target_21 () (_ BitVec 1))
(declare-fun x8_target_20 () (_ BitVec 1))
(declare-fun x8_lo_34 () (_ BitVec 2))
(declare-fun x8_lo_33 () (_ BitVec 2))
(declare-fun x8_lo_32 () (_ BitVec 2))
(declare-fun x8_lo_31 () (_ BitVec 2))
(declare-fun x8_lo_30 () (_ BitVec 2))
(declare-fun x8_lo_29 () (_ BitVec 2))
(declare-fun x8_lo_28 () (_ BitVec 2))
(declare-fun x8_lo_27 () (_ BitVec 2))
(declare-fun x8_lo_26 () (_ BitVec 2))
(declare-fun x8_lo_25 () (_ BitVec 2))
(declare-fun x8_lo_24 () (_ BitVec 2))
(declare-fun x8_lo_23 () (_ BitVec 2))
(declare-fun x8_lo_22 () (_ BitVec 2))
(declare-fun x8_lo_21 () (_ BitVec 1))
(declare-fun x8_70 () (_ BitVec 64))
(declare-fun x8_69 () (_ BitVec 64))
(declare-fun x8_68 () (_ BitVec 64))
(declare-fun x8_67 () (_ BitVec 64))
(declare-fun x8_66 () (_ BitVec 64))
(declare-fun x8_65 () (_ BitVec 64))
(declare-fun x8_64 () (_ BitVec 64))
(declare-fun x8_63 () (_ BitVec 64))
(declare-fun x8_62 () (_ BitVec 64))
(declare-fun x8_61 () (_ BitVec 64))
(declare-fun x8_60 () (_ BitVec 64))
(declare-fun x8_59 () (_ BitVec 64))
(declare-fun x8_58 () (_ BitVec 64))
(declare-fun x8_57 () (_ BitVec 64))
(declare-fun x8_56 () (_ BitVec 64))
(declare-fun x8_55 () (_ BitVec 64))
(declare-fun x8_54 () (_ BitVec 64))
(declare-fun x8_53 () (_ BitVec 64))
(declare-fun x8_52 () (_ BitVec 64))
(declare-fun x8_51 () (_ BitVec 64))
(declare-fun x8_50 () (_ BitVec 64))
(declare-fun x8_49 () (_ BitVec 64))
(declare-fun x8_48 () (_ BitVec 64))
(declare-fun x8_47 () (_ BitVec 64))
(declare-fun x8_46 () (_ BitVec 64))
(declare-fun x8_45 () (_ BitVec 64))
(declare-fun x8_44 () (_ BitVec 64))
(declare-fun x7_38 () (_ BitVec 64))
(declare-fun x7_37 () (_ BitVec 64))
(declare-fun x7_36 () (_ BitVec 64))
(declare-fun x7_35 () (_ BitVec 64))
(declare-fun x7_34 () (_ BitVec 64))
(declare-fun x7_33 () (_ BitVec 64))
(declare-fun x7_32 () (_ BitVec 64))
(declare-fun x7_31 () (_ BitVec 64))
(declare-fun x7_30 () (_ BitVec 64))
(declare-fun x7_29 () (_ BitVec 64))
(declare-fun x7_28 () (_ BitVec 64))
(declare-fun x7_27 () (_ BitVec 64))
(declare-fun x7_26 () (_ BitVec 64))
(declare-fun x7_25 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_33 () (_ BitVec 64))
(declare-fun x3_neg_32 () (_ BitVec 64))
(declare-fun x3_neg_31 () (_ BitVec 64))
(declare-fun x3_neg_30 () (_ BitVec 64))
(declare-fun x3_neg_29 () (_ BitVec 64))
(declare-fun x3_neg_28 () (_ BitVec 64))
(declare-fun x3_neg_27 () (_ BitVec 64))
(declare-fun x3_neg_26 () (_ BitVec 64))
(declare-fun x3_neg_25 () (_ BitVec 64))
(declare-fun x3_neg_24 () (_ BitVec 64))
(declare-fun x3_neg_23 () (_ BitVec 64))
(declare-fun x3_neg_22 () (_ BitVec 64))
(declare-fun x3_neg_21 () (_ BitVec 64))
(declare-fun x3_67 () (_ BitVec 64))
(declare-fun x3_66 () (_ BitVec 64))
(declare-fun x3_65 () (_ BitVec 64))
(declare-fun x3_64 () (_ BitVec 64))
(declare-fun x3_63 () (_ BitVec 64))
(declare-fun x3_62 () (_ BitVec 64))
(declare-fun x3_61 () (_ BitVec 64))
(declare-fun x3_60 () (_ BitVec 64))
(declare-fun x3_59 () (_ BitVec 64))
(declare-fun x3_58 () (_ BitVec 64))
(declare-fun x3_57 () (_ BitVec 64))
(declare-fun x3_56 () (_ BitVec 64))
(declare-fun x3_55 () (_ BitVec 64))
(declare-fun x3_54 () (_ BitVec 64))
(declare-fun x3_53 () (_ BitVec 64))
(declare-fun x3_52 () (_ BitVec 64))
(declare-fun x3_51 () (_ BitVec 64))
(declare-fun x3_50 () (_ BitVec 64))
(declare-fun x3_49 () (_ BitVec 64))
(declare-fun x3_48 () (_ BitVec 64))
(declare-fun x3_47 () (_ BitVec 64))
(declare-fun x3_46 () (_ BitVec 64))
(declare-fun x3_45 () (_ BitVec 64))
(declare-fun x3_44 () (_ BitVec 64))
(declare-fun x3_43 () (_ BitVec 64))
(declare-fun x3_42 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x10_neg_33 () (_ BitVec 64))
(declare-fun x10_neg_32 () (_ BitVec 64))
(declare-fun x10_neg_31 () (_ BitVec 64))
(declare-fun x10_neg_30 () (_ BitVec 64))
(declare-fun x10_neg_29 () (_ BitVec 64))
(declare-fun x10_neg_28 () (_ BitVec 64))
(declare-fun x10_neg_27 () (_ BitVec 64))
(declare-fun x10_neg_26 () (_ BitVec 64))
(declare-fun x10_neg_25 () (_ BitVec 64))
(declare-fun x10_neg_24 () (_ BitVec 64))
(declare-fun x10_neg_23 () (_ BitVec 64))
(declare-fun x10_neg_22 () (_ BitVec 64))
(declare-fun x10_neg_21 () (_ BitVec 64))
(declare-fun x10_68 () (_ BitVec 64))
(declare-fun x10_67 () (_ BitVec 64))
(declare-fun x10_66 () (_ BitVec 64))
(declare-fun x10_65 () (_ BitVec 64))
(declare-fun x10_64 () (_ BitVec 64))
(declare-fun x10_63 () (_ BitVec 64))
(declare-fun x10_62 () (_ BitVec 64))
(declare-fun x10_61 () (_ BitVec 64))
(declare-fun x10_60 () (_ BitVec 64))
(declare-fun x10_59 () (_ BitVec 64))
(declare-fun x10_58 () (_ BitVec 64))
(declare-fun x10_57 () (_ BitVec 64))
(declare-fun x10_56 () (_ BitVec 64))
(declare-fun x10_55 () (_ BitVec 64))
(declare-fun x10_54 () (_ BitVec 64))
(declare-fun x10_53 () (_ BitVec 64))
(declare-fun x10_52 () (_ BitVec 64))
(declare-fun x10_51 () (_ BitVec 64))
(declare-fun x10_50 () (_ BitVec 64))
(declare-fun x10_49 () (_ BitVec 64))
(declare-fun x10_48 () (_ BitVec 64))
(declare-fun x10_47 () (_ BitVec 64))
(declare-fun x10_46 () (_ BitVec 64))
(declare-fun x10_45 () (_ BitVec 64))
(declare-fun x10_44 () (_ BitVec 64))
(declare-fun x10_43 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun ne_34 () (_ BitVec 1))
(declare-fun ne_33 () (_ BitVec 1))
(declare-fun ne_32 () (_ BitVec 1))
(declare-fun ne_31 () (_ BitVec 1))
(declare-fun ne_30 () (_ BitVec 1))
(declare-fun ne_29 () (_ BitVec 1))
(declare-fun ne_28 () (_ BitVec 1))
(declare-fun ne_27 () (_ BitVec 1))
(declare-fun ne_26 () (_ BitVec 1))
(declare-fun ne_25 () (_ BitVec 1))
(declare-fun ne_24 () (_ BitVec 1))
(declare-fun ne_23 () (_ BitVec 1))
(declare-fun ne_22 () (_ BitVec 1))
(declare-fun ne_21 () (_ BitVec 1))
(declare-fun ge_99 () (_ BitVec 1))
(declare-fun ge_98 () (_ BitVec 1))
(declare-fun ge_97 () (_ BitVec 1))
(declare-fun ge_96 () (_ BitVec 1))
(declare-fun ge_95 () (_ BitVec 1))
(declare-fun ge_94 () (_ BitVec 1))
(declare-fun ge_93 () (_ BitVec 1))
(declare-fun ge_92 () (_ BitVec 1))
(declare-fun ge_91 () (_ BitVec 1))
(declare-fun ge_90 () (_ BitVec 1))
(declare-fun ge_89 () (_ BitVec 1))
(declare-fun ge_88 () (_ BitVec 1))
(declare-fun ge_87 () (_ BitVec 1))
(declare-fun ge_86 () (_ BitVec 1))
(declare-fun ge_85 () (_ BitVec 1))
(declare-fun ge_84 () (_ BitVec 1))
(declare-fun ge_83 () (_ BitVec 1))
(declare-fun ge_82 () (_ BitVec 1))
(declare-fun ge_81 () (_ BitVec 1))
(declare-fun ge_80 () (_ BitVec 1))
(declare-fun ge_79 () (_ BitVec 1))
(declare-fun ge_78 () (_ BitVec 1))
(declare-fun ge_77 () (_ BitVec 1))
(declare-fun ge_76 () (_ BitVec 1))
(declare-fun ge_75 () (_ BitVec 1))
(declare-fun ge_74 () (_ BitVec 1))
(declare-fun ge_73 () (_ BitVec 1))
(declare-fun ge_72 () (_ BitVec 1))
(declare-fun ge_71 () (_ BitVec 1))
(declare-fun ge_70 () (_ BitVec 1))
(declare-fun ge_69 () (_ BitVec 1))
(declare-fun ge_68 () (_ BitVec 1))
(declare-fun ge_67 () (_ BitVec 1))
(declare-fun ge_66 () (_ BitVec 1))
(declare-fun ge_65 () (_ BitVec 1))
(declare-fun ge_64 () (_ BitVec 1))
(declare-fun ge_63 () (_ BitVec 1))
(declare-fun ge_62 () (_ BitVec 1))
(declare-fun ge_61 () (_ BitVec 1))
(declare-fun dc_279 () (_ BitVec 64))
(declare-fun dc_278 () (_ BitVec 1))
(declare-fun dc_277 () (_ BitVec 62))
(declare-fun dc_276 () (_ BitVec 1))
(declare-fun dc_275 () (_ BitVec 1))
(declare-fun dc_274 () (_ BitVec 1))
(declare-fun dc_273 () (_ BitVec 63))
(declare-fun dc_272 () (_ BitVec 64))
(declare-fun dc_271 () (_ BitVec 1))
(declare-fun dc_270 () (_ BitVec 62))
(declare-fun dc_269 () (_ BitVec 1))
(declare-fun dc_268 () (_ BitVec 1))
(declare-fun dc_267 () (_ BitVec 1))
(declare-fun dc_266 () (_ BitVec 63))
(declare-fun dc_265 () (_ BitVec 64))
(declare-fun dc_264 () (_ BitVec 1))
(declare-fun dc_263 () (_ BitVec 62))
(declare-fun dc_262 () (_ BitVec 1))
(declare-fun dc_261 () (_ BitVec 1))
(declare-fun dc_260 () (_ BitVec 1))
(declare-fun dc_259 () (_ BitVec 63))
(declare-fun dc_258 () (_ BitVec 64))
(declare-fun dc_257 () (_ BitVec 1))
(declare-fun dc_256 () (_ BitVec 62))
(declare-fun dc_255 () (_ BitVec 1))
(declare-fun dc_254 () (_ BitVec 1))
(declare-fun dc_253 () (_ BitVec 1))
(declare-fun dc_252 () (_ BitVec 63))
(declare-fun dc_251 () (_ BitVec 64))
(declare-fun dc_250 () (_ BitVec 1))
(declare-fun dc_249 () (_ BitVec 62))
(declare-fun dc_248 () (_ BitVec 1))
(declare-fun dc_247 () (_ BitVec 1))
(declare-fun dc_246 () (_ BitVec 1))
(declare-fun dc_245 () (_ BitVec 63))
(declare-fun dc_244 () (_ BitVec 64))
(declare-fun dc_243 () (_ BitVec 1))
(declare-fun dc_242 () (_ BitVec 62))
(declare-fun dc_241 () (_ BitVec 1))
(declare-fun dc_240 () (_ BitVec 1))
(declare-fun dc_239 () (_ BitVec 1))
(declare-fun dc_238 () (_ BitVec 63))
(declare-fun dc_237 () (_ BitVec 64))
(declare-fun dc_236 () (_ BitVec 1))
(declare-fun dc_235 () (_ BitVec 62))
(declare-fun dc_234 () (_ BitVec 1))
(declare-fun dc_233 () (_ BitVec 1))
(declare-fun dc_232 () (_ BitVec 1))
(declare-fun dc_231 () (_ BitVec 63))
(declare-fun dc_230 () (_ BitVec 64))
(declare-fun dc_229 () (_ BitVec 1))
(declare-fun dc_228 () (_ BitVec 62))
(declare-fun dc_227 () (_ BitVec 1))
(declare-fun dc_226 () (_ BitVec 1))
(declare-fun dc_225 () (_ BitVec 1))
(declare-fun dc_224 () (_ BitVec 63))
(declare-fun dc_223 () (_ BitVec 64))
(declare-fun dc_222 () (_ BitVec 1))
(declare-fun dc_221 () (_ BitVec 62))
(declare-fun dc_220 () (_ BitVec 1))
(declare-fun dc_219 () (_ BitVec 1))
(declare-fun dc_218 () (_ BitVec 1))
(declare-fun dc_217 () (_ BitVec 63))
(declare-fun dc_216 () (_ BitVec 64))
(declare-fun dc_215 () (_ BitVec 1))
(declare-fun dc_214 () (_ BitVec 62))
(declare-fun dc_213 () (_ BitVec 1))
(declare-fun dc_212 () (_ BitVec 1))
(declare-fun dc_211 () (_ BitVec 1))
(declare-fun dc_210 () (_ BitVec 63))
(declare-fun dc_209 () (_ BitVec 64))
(declare-fun dc_208 () (_ BitVec 1))
(declare-fun dc_207 () (_ BitVec 62))
(declare-fun dc_206 () (_ BitVec 1))
(declare-fun dc_205 () (_ BitVec 1))
(declare-fun dc_204 () (_ BitVec 1))
(declare-fun dc_203 () (_ BitVec 63))
(declare-fun dc_202 () (_ BitVec 64))
(declare-fun dc_201 () (_ BitVec 1))
(declare-fun dc_200 () (_ BitVec 62))
(declare-fun dc_199 () (_ BitVec 1))
(declare-fun dc_198 () (_ BitVec 1))
(declare-fun dc_197 () (_ BitVec 1))
(declare-fun dc_196 () (_ BitVec 63))
(declare-fun dc_195 () (_ BitVec 64))
(declare-fun dc_194 () (_ BitVec 1))
(declare-fun dc_193 () (_ BitVec 62))
(declare-fun dc_192 () (_ BitVec 1))
(declare-fun dc_191 () (_ BitVec 1))
(declare-fun dc_190 () (_ BitVec 1))
(declare-fun dc_189 () (_ BitVec 63))
(declare-fun dc_188 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_25 (bvadd (bvadd neg_f_0_low60_20_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_44 (bvadd (bvadd neg_g_0_low60_20_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_0_1)) (bvsle neg_f_0_low60_20_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_0_1)) (bvsle neg_g_0_low60_20_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_25) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_188 ((_ extract 63 1) x8_44)) (= x8_lo_21 ((_ extract 0 0) x8_44))))
(assert (= ne_21 (bvand x8_lo_21 #b1)))
(assert (= x10_43 (ite (= ne_21 #b1) x7_25 #x0000000000000000)))
(assert (and (= ge_61 ((_ extract 63 63) x3_41)) (= dc_189 ((_ extract 62 0) x3_41))))
(assert (= ge_62 (bvnot ge_61)))
(assert (= ge_63 (ite (= ne_21 #b1) ge_62 #b0)))
(assert (and (= dc_190 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_42 (ite (= ge_63 #b1) x3_neg_21 x3_41)))
(assert (and (= dc_191 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_44 (ite (= ge_63 #b1) x10_neg_21 x10_43)))
(assert (= x7_26 (ite (= ge_63 #b1) x8_44 x7_25)))
(assert (and (= dc_192 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44)))) (= x8_45 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44))))))
(assert (= x3_43 (bvadd x3_42 #x0000000000000002)))
(assert (and (= dc_193 ((_ extract 63 2) x8_45)) (= x8_lo_22 ((_ extract 1 0) x8_45))))
(assert (and (= x8_target_20 ((_ extract 1 1) x8_lo_22)) (= dc_194 ((_ extract 0 0) x8_lo_22))))
(assert (= ne_22 (bvand x8_target_20 #b1)))
(assert (and (= x8_46 ((_ sign_extend 1) ((_ extract 63 1) x8_45))) (= dc_195 ((_ zero_extend 63) ((_ extract 0 0) x8_45)))))
(assert true)
(assert (= x10_45 (ite (= ne_22 #b1) x7_26 #x0000000000000000)))
(assert (and (= ge_64 ((_ extract 63 63) x3_43)) (= dc_196 ((_ extract 62 0) x3_43))))
(assert (= ge_65 (bvnot ge_64)))
(assert (= ge_66 (ite (= ne_22 #b1) ge_65 #b0)))
(assert (and (= dc_197 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_44 (ite (= ge_66 #b1) x3_neg_22 x3_43)))
(assert (and (= dc_198 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_46 (ite (= ge_66 #b1) x10_neg_22 x10_45)))
(assert (= x7_27 (ite (= ge_66 #b1) x8_46 x7_26)))
(assert (and (= dc_199 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46)))) (= x8_47 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46))))))
(assert (= x3_45 (bvadd x3_44 #x0000000000000002)))
(assert (and (= dc_200 ((_ extract 63 2) x8_47)) (= x8_lo_23 ((_ extract 1 0) x8_47))))
(assert (and (= x8_target_21 ((_ extract 1 1) x8_lo_23)) (= dc_201 ((_ extract 0 0) x8_lo_23))))
(assert (= ne_23 (bvand x8_target_21 #b1)))
(assert (and (= x8_48 ((_ sign_extend 1) ((_ extract 63 1) x8_47))) (= dc_202 ((_ zero_extend 63) ((_ extract 0 0) x8_47)))))
(assert true)
(assert (= x10_47 (ite (= ne_23 #b1) x7_27 #x0000000000000000)))
(assert (and (= ge_67 ((_ extract 63 63) x3_45)) (= dc_203 ((_ extract 62 0) x3_45))))
(assert (= ge_68 (bvnot ge_67)))
(assert (= ge_69 (ite (= ne_23 #b1) ge_68 #b0)))
(assert (and (= dc_204 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_46 (ite (= ge_69 #b1) x3_neg_23 x3_45)))
(assert (and (= dc_205 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_48 (ite (= ge_69 #b1) x10_neg_23 x10_47)))
(assert (= x7_28 (ite (= ge_69 #b1) x8_48 x7_27)))
(assert (and (= dc_206 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48)))) (= x8_49 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48))))))
(assert (= x3_47 (bvadd x3_46 #x0000000000000002)))
(assert (and (= dc_207 ((_ extract 63 2) x8_49)) (= x8_lo_24 ((_ extract 1 0) x8_49))))
(assert (and (= x8_target_22 ((_ extract 1 1) x8_lo_24)) (= dc_208 ((_ extract 0 0) x8_lo_24))))
(assert (= ne_24 (bvand x8_target_22 #b1)))
(assert (and (= x8_50 ((_ sign_extend 1) ((_ extract 63 1) x8_49))) (= dc_209 ((_ zero_extend 63) ((_ extract 0 0) x8_49)))))
(assert true)
(assert (= x10_49 (ite (= ne_24 #b1) x7_28 #x0000000000000000)))
(assert (and (= ge_70 ((_ extract 63 63) x3_47)) (= dc_210 ((_ extract 62 0) x3_47))))
(assert (= ge_71 (bvnot ge_70)))
(assert (= ge_72 (ite (= ne_24 #b1) ge_71 #b0)))
(assert (and (= dc_211 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_47))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_24 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_47))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_48 (ite (= ge_72 #b1) x3_neg_24 x3_47)))
(assert (and (= dc_212 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_49))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_24 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_49))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_50 (ite (= ge_72 #b1) x10_neg_24 x10_49)))
(assert (= x7_29 (ite (= ge_72 #b1) x8_50 x7_28)))
(assert (and (= dc_213 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_50) ((_ zero_extend 1) x10_50)))) (= x8_51 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_50) ((_ zero_extend 1) x10_50))))))
(assert (= x3_49 (bvadd x3_48 #x0000000000000002)))
(assert (and (= dc_214 ((_ extract 63 2) x8_51)) (= x8_lo_25 ((_ extract 1 0) x8_51))))
(assert (and (= x8_target_23 ((_ extract 1 1) x8_lo_25)) (= dc_215 ((_ extract 0 0) x8_lo_25))))
(assert (= ne_25 (bvand x8_target_23 #b1)))
(assert (and (= x8_52 ((_ sign_extend 1) ((_ extract 63 1) x8_51))) (= dc_216 ((_ zero_extend 63) ((_ extract 0 0) x8_51)))))
(assert true)
(assert (= x10_51 (ite (= ne_25 #b1) x7_29 #x0000000000000000)))
(assert (and (= ge_73 ((_ extract 63 63) x3_49)) (= dc_217 ((_ extract 62 0) x3_49))))
(assert (= ge_74 (bvnot ge_73)))
(assert (= ge_75 (ite (= ne_25 #b1) ge_74 #b0)))
(assert (and (= dc_218 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_49))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_25 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_49))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_50 (ite (= ge_75 #b1) x3_neg_25 x3_49)))
(assert (and (= dc_219 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_51))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_25 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_51))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_52 (ite (= ge_75 #b1) x10_neg_25 x10_51)))
(assert (= x7_30 (ite (= ge_75 #b1) x8_52 x7_29)))
(assert (and (= dc_220 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_52) ((_ zero_extend 1) x10_52)))) (= x8_53 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_52) ((_ zero_extend 1) x10_52))))))
(assert (= x3_51 (bvadd x3_50 #x0000000000000002)))
(assert (and (= dc_221 ((_ extract 63 2) x8_53)) (= x8_lo_26 ((_ extract 1 0) x8_53))))
(assert (and (= x8_target_24 ((_ extract 1 1) x8_lo_26)) (= dc_222 ((_ extract 0 0) x8_lo_26))))
(assert (= ne_26 (bvand x8_target_24 #b1)))
(assert (and (= x8_54 ((_ sign_extend 1) ((_ extract 63 1) x8_53))) (= dc_223 ((_ zero_extend 63) ((_ extract 0 0) x8_53)))))
(assert true)
(assert (= x10_53 (ite (= ne_26 #b1) x7_30 #x0000000000000000)))
(assert (and (= ge_76 ((_ extract 63 63) x3_51)) (= dc_224 ((_ extract 62 0) x3_51))))
(assert (= ge_77 (bvnot ge_76)))
(assert (= ge_78 (ite (= ne_26 #b1) ge_77 #b0)))
(assert (and (= dc_225 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_51))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_26 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_51))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_52 (ite (= ge_78 #b1) x3_neg_26 x3_51)))
(assert (and (= dc_226 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_53))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_26 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_53))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_54 (ite (= ge_78 #b1) x10_neg_26 x10_53)))
(assert (= x7_31 (ite (= ge_78 #b1) x8_54 x7_30)))
(assert (and (= dc_227 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_54) ((_ zero_extend 1) x10_54)))) (= x8_55 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_54) ((_ zero_extend 1) x10_54))))))
(assert (= x3_53 (bvadd x3_52 #x0000000000000002)))
(assert (and (= dc_228 ((_ extract 63 2) x8_55)) (= x8_lo_27 ((_ extract 1 0) x8_55))))
(assert (and (= x8_target_25 ((_ extract 1 1) x8_lo_27)) (= dc_229 ((_ extract 0 0) x8_lo_27))))
(assert (= ne_27 (bvand x8_target_25 #b1)))
(assert (and (= x8_56 ((_ sign_extend 1) ((_ extract 63 1) x8_55))) (= dc_230 ((_ zero_extend 63) ((_ extract 0 0) x8_55)))))
(assert true)
(assert (= x10_55 (ite (= ne_27 #b1) x7_31 #x0000000000000000)))
(assert (and (= ge_79 ((_ extract 63 63) x3_53)) (= dc_231 ((_ extract 62 0) x3_53))))
(assert (= ge_80 (bvnot ge_79)))
(assert (= ge_81 (ite (= ne_27 #b1) ge_80 #b0)))
(assert (and (= dc_232 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_53))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_27 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_53))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_54 (ite (= ge_81 #b1) x3_neg_27 x3_53)))
(assert (and (= dc_233 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_55))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_27 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_55))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_56 (ite (= ge_81 #b1) x10_neg_27 x10_55)))
(assert (= x7_32 (ite (= ge_81 #b1) x8_56 x7_31)))
(assert (and (= dc_234 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_56) ((_ zero_extend 1) x10_56)))) (= x8_57 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_56) ((_ zero_extend 1) x10_56))))))
(assert (= x3_55 (bvadd x3_54 #x0000000000000002)))
(assert (and (= dc_235 ((_ extract 63 2) x8_57)) (= x8_lo_28 ((_ extract 1 0) x8_57))))
(assert (and (= x8_target_26 ((_ extract 1 1) x8_lo_28)) (= dc_236 ((_ extract 0 0) x8_lo_28))))
(assert (= ne_28 (bvand x8_target_26 #b1)))
(assert (and (= x8_58 ((_ sign_extend 1) ((_ extract 63 1) x8_57))) (= dc_237 ((_ zero_extend 63) ((_ extract 0 0) x8_57)))))
(assert true)
(assert (= x10_57 (ite (= ne_28 #b1) x7_32 #x0000000000000000)))
(assert (and (= ge_82 ((_ extract 63 63) x3_55)) (= dc_238 ((_ extract 62 0) x3_55))))
(assert (= ge_83 (bvnot ge_82)))
(assert (= ge_84 (ite (= ne_28 #b1) ge_83 #b0)))
(assert (and (= dc_239 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_55))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_28 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_55))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_56 (ite (= ge_84 #b1) x3_neg_28 x3_55)))
(assert (and (= dc_240 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_57))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_28 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_57))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_58 (ite (= ge_84 #b1) x10_neg_28 x10_57)))
(assert (= x7_33 (ite (= ge_84 #b1) x8_58 x7_32)))
(assert (and (= dc_241 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_58) ((_ zero_extend 1) x10_58)))) (= x8_59 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_58) ((_ zero_extend 1) x10_58))))))
(assert (= x3_57 (bvadd x3_56 #x0000000000000002)))
(assert (and (= dc_242 ((_ extract 63 2) x8_59)) (= x8_lo_29 ((_ extract 1 0) x8_59))))
(assert (and (= x8_target_27 ((_ extract 1 1) x8_lo_29)) (= dc_243 ((_ extract 0 0) x8_lo_29))))
(assert (= ne_29 (bvand x8_target_27 #b1)))
(assert (and (= x8_60 ((_ sign_extend 1) ((_ extract 63 1) x8_59))) (= dc_244 ((_ zero_extend 63) ((_ extract 0 0) x8_59)))))
(assert true)
(assert (= x10_59 (ite (= ne_29 #b1) x7_33 #x0000000000000000)))
(assert (and (= ge_85 ((_ extract 63 63) x3_57)) (= dc_245 ((_ extract 62 0) x3_57))))
(assert (= ge_86 (bvnot ge_85)))
(assert (= ge_87 (ite (= ne_29 #b1) ge_86 #b0)))
(assert (and (= dc_246 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_57))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_29 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_57))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_58 (ite (= ge_87 #b1) x3_neg_29 x3_57)))
(assert (and (= dc_247 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_59))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_29 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_59))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_60 (ite (= ge_87 #b1) x10_neg_29 x10_59)))
(assert (= x7_34 (ite (= ge_87 #b1) x8_60 x7_33)))
(assert (and (= dc_248 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_60) ((_ zero_extend 1) x10_60)))) (= x8_61 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_60) ((_ zero_extend 1) x10_60))))))
(assert (= x3_59 (bvadd x3_58 #x0000000000000002)))
(assert (and (= dc_249 ((_ extract 63 2) x8_61)) (= x8_lo_30 ((_ extract 1 0) x8_61))))
(assert (and (= x8_target_28 ((_ extract 1 1) x8_lo_30)) (= dc_250 ((_ extract 0 0) x8_lo_30))))
(assert (= ne_30 (bvand x8_target_28 #b1)))
(assert (and (= x8_62 ((_ sign_extend 1) ((_ extract 63 1) x8_61))) (= dc_251 ((_ zero_extend 63) ((_ extract 0 0) x8_61)))))
(assert true)
(assert (= x10_61 (ite (= ne_30 #b1) x7_34 #x0000000000000000)))
(assert (and (= ge_88 ((_ extract 63 63) x3_59)) (= dc_252 ((_ extract 62 0) x3_59))))
(assert (= ge_89 (bvnot ge_88)))
(assert (= ge_90 (ite (= ne_30 #b1) ge_89 #b0)))
(assert (and (= dc_253 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_59))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_30 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_59))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_60 (ite (= ge_90 #b1) x3_neg_30 x3_59)))
(assert (and (= dc_254 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_61))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_30 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_61))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_62 (ite (= ge_90 #b1) x10_neg_30 x10_61)))
(assert (= x7_35 (ite (= ge_90 #b1) x8_62 x7_34)))
(assert (and (= dc_255 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_62) ((_ zero_extend 1) x10_62)))) (= x8_63 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_62) ((_ zero_extend 1) x10_62))))))
(assert (= x3_61 (bvadd x3_60 #x0000000000000002)))
(assert (and (= dc_256 ((_ extract 63 2) x8_63)) (= x8_lo_31 ((_ extract 1 0) x8_63))))
(assert (and (= x8_target_29 ((_ extract 1 1) x8_lo_31)) (= dc_257 ((_ extract 0 0) x8_lo_31))))
(assert (= ne_31 (bvand x8_target_29 #b1)))
(assert (and (= x8_64 ((_ sign_extend 1) ((_ extract 63 1) x8_63))) (= dc_258 ((_ zero_extend 63) ((_ extract 0 0) x8_63)))))
(assert true)
(assert (= x10_63 (ite (= ne_31 #b1) x7_35 #x0000000000000000)))
(assert (and (= ge_91 ((_ extract 63 63) x3_61)) (= dc_259 ((_ extract 62 0) x3_61))))
(assert (= ge_92 (bvnot ge_91)))
(assert (= ge_93 (ite (= ne_31 #b1) ge_92 #b0)))
(assert (and (= dc_260 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_61))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_31 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_61))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_62 (ite (= ge_93 #b1) x3_neg_31 x3_61)))
(assert (and (= dc_261 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_63))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_31 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_63))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_64 (ite (= ge_93 #b1) x10_neg_31 x10_63)))
(assert (= x7_36 (ite (= ge_93 #b1) x8_64 x7_35)))
(assert (and (= dc_262 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_64) ((_ zero_extend 1) x10_64)))) (= x8_65 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_64) ((_ zero_extend 1) x10_64))))))
(assert (= x3_63 (bvadd x3_62 #x0000000000000002)))
(assert (and (= dc_263 ((_ extract 63 2) x8_65)) (= x8_lo_32 ((_ extract 1 0) x8_65))))
(assert (and (= x8_target_30 ((_ extract 1 1) x8_lo_32)) (= dc_264 ((_ extract 0 0) x8_lo_32))))
(assert (= ne_32 (bvand x8_target_30 #b1)))
(assert (and (= x8_66 ((_ sign_extend 1) ((_ extract 63 1) x8_65))) (= dc_265 ((_ zero_extend 63) ((_ extract 0 0) x8_65)))))
(assert true)
(assert (= x10_65 (ite (= ne_32 #b1) x7_36 #x0000000000000000)))
(assert (and (= ge_94 ((_ extract 63 63) x3_63)) (= dc_266 ((_ extract 62 0) x3_63))))
(assert (= ge_95 (bvnot ge_94)))
(assert (= ge_96 (ite (= ne_32 #b1) ge_95 #b0)))
(assert (and (= dc_267 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_63))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_32 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_63))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_64 (ite (= ge_96 #b1) x3_neg_32 x3_63)))
(assert (and (= dc_268 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_65))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_32 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_65))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_66 (ite (= ge_96 #b1) x10_neg_32 x10_65)))
(assert (= x7_37 (ite (= ge_96 #b1) x8_66 x7_36)))
(assert (and (= dc_269 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_66) ((_ zero_extend 1) x10_66)))) (= x8_67 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_66) ((_ zero_extend 1) x10_66))))))
(assert (= x3_65 (bvadd x3_64 #x0000000000000002)))
(assert (and (= dc_270 ((_ extract 63 2) x8_67)) (= x8_lo_33 ((_ extract 1 0) x8_67))))
(assert (and (= x8_target_31 ((_ extract 1 1) x8_lo_33)) (= dc_271 ((_ extract 0 0) x8_lo_33))))
(assert (= ne_33 (bvand x8_target_31 #b1)))
(assert (and (= x8_68 ((_ sign_extend 1) ((_ extract 63 1) x8_67))) (= dc_272 ((_ zero_extend 63) ((_ extract 0 0) x8_67)))))
(assert true)
(assert (= x10_67 (ite (= ne_33 #b1) x7_37 #x0000000000000000)))
(assert (and (= ge_97 ((_ extract 63 63) x3_65)) (= dc_273 ((_ extract 62 0) x3_65))))
(assert (= ge_98 (bvnot ge_97)))
(assert (= ge_99 (ite (= ne_33 #b1) ge_98 #b0)))
(assert (and (= dc_274 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_65))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_33 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_65))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_66 (ite (= ge_99 #b1) x3_neg_33 x3_65)))
(assert (and (= dc_275 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_67))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_33 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_67))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_68 (ite (= ge_99 #b1) x10_neg_33 x10_67)))
(assert (= x7_38 (ite (= ge_99 #b1) x8_68 x7_37)))
(assert (and (= dc_276 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_68) ((_ zero_extend 1) x10_68)))) (= x8_69 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_68) ((_ zero_extend 1) x10_68))))))
(assert (= x3_67 (bvadd x3_66 #x0000000000000002)))
(assert (and (= dc_277 ((_ extract 63 2) x8_69)) (= x8_lo_34 ((_ extract 1 0) x8_69))))
(assert (and (= x8_target_32 ((_ extract 1 1) x8_lo_34)) (= dc_278 ((_ extract 0 0) x8_lo_34))))
(assert (= ne_34 (bvand x8_target_32 #b1)))
(assert (and (= x8_70 ((_ sign_extend 1) ((_ extract 63 1) x8_69))) (= dc_279 ((_ zero_extend 63) ((_ extract 0 0) x8_69)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_68) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_38 x7_37)) (= (bvmul x8_70 #x0000000000000002) x8_68)) (= x3_67 (bvadd #x0000000000000002 x3_65))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_68) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_65 #x0000000000000000)) (= x7_38 x7_37)) (= (bvmul x8_70 #x0000000000000002) (bvadd x8_68 x7_37))) (= x3_67 (bvadd #x0000000000000002 x3_65)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_68) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_65 #x0000000000000000)) (= x7_38 x8_68)) (= (bvmul x8_70 #x0000000000000002) (bvsub x8_68 x7_37))) (= x3_67 (bvsub #x0000000000000002 x3_65))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_f9bcf1.smt2
Execution time of boolector: 0.7491 seconds
OUTPUT FROM boolector:
unsat

=== Cut #6 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #6
; Range assertion #54: or [and [smod (sub (uext x8_72 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_40 = x7_39, mul x8_74 2@64 = x8_72, x3_71 = add 2@64 x3_69], and [smod (sub (uext x8_72 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_69 <s 0@64, x7_40 = x7_39, mul x8_74 2@64 = add x8_72 x7_39, x3_71 = add 2@64 x3_69], and [smod (sub (uext x8_72 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_69 >=s 0@64, x7_40 = x8_72, mul x8_74 2@64 = sub x8_72 x7_39, x3_71 = sub 2@64 x3_69]]
; Range condition: ((x8_72@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_40 = x7_39 /\ x8_74 * 2 = x8_72 /\ x3_71 = 2 + x3_69 \/ ((x8_72@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_69 <s 0 /\ x7_40 = x7_39 /\ x8_74 * 2 = x8_72 + x7_39 /\ x3_71 = 2 + x3_69 \/ ((x8_72@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_69 >=s 0 /\ x7_40 = x8_72 /\ x8_74 * 2 = x8_72 - x7_39 /\ x3_71 = 2 - x3_69
; Output file: /tmp/outputqfbv_3e9d0e.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_34 () (_ BitVec 1))
(declare-fun x8_target_33 () (_ BitVec 1))
(declare-fun x8_target_32 () (_ BitVec 1))
(declare-fun x8_target_31 () (_ BitVec 1))
(declare-fun x8_target_30 () (_ BitVec 1))
(declare-fun x8_target_29 () (_ BitVec 1))
(declare-fun x8_target_28 () (_ BitVec 1))
(declare-fun x8_target_27 () (_ BitVec 1))
(declare-fun x8_target_26 () (_ BitVec 1))
(declare-fun x8_target_25 () (_ BitVec 1))
(declare-fun x8_target_24 () (_ BitVec 1))
(declare-fun x8_target_23 () (_ BitVec 1))
(declare-fun x8_target_22 () (_ BitVec 1))
(declare-fun x8_target_21 () (_ BitVec 1))
(declare-fun x8_target_20 () (_ BitVec 1))
(declare-fun x8_lo_36 () (_ BitVec 2))
(declare-fun x8_lo_35 () (_ BitVec 2))
(declare-fun x8_lo_34 () (_ BitVec 2))
(declare-fun x8_lo_33 () (_ BitVec 2))
(declare-fun x8_lo_32 () (_ BitVec 2))
(declare-fun x8_lo_31 () (_ BitVec 2))
(declare-fun x8_lo_30 () (_ BitVec 2))
(declare-fun x8_lo_29 () (_ BitVec 2))
(declare-fun x8_lo_28 () (_ BitVec 2))
(declare-fun x8_lo_27 () (_ BitVec 2))
(declare-fun x8_lo_26 () (_ BitVec 2))
(declare-fun x8_lo_25 () (_ BitVec 2))
(declare-fun x8_lo_24 () (_ BitVec 2))
(declare-fun x8_lo_23 () (_ BitVec 2))
(declare-fun x8_lo_22 () (_ BitVec 2))
(declare-fun x8_lo_21 () (_ BitVec 1))
(declare-fun x8_74 () (_ BitVec 64))
(declare-fun x8_73 () (_ BitVec 64))
(declare-fun x8_72 () (_ BitVec 64))
(declare-fun x8_71 () (_ BitVec 64))
(declare-fun x8_70 () (_ BitVec 64))
(declare-fun x8_69 () (_ BitVec 64))
(declare-fun x8_68 () (_ BitVec 64))
(declare-fun x8_67 () (_ BitVec 64))
(declare-fun x8_66 () (_ BitVec 64))
(declare-fun x8_65 () (_ BitVec 64))
(declare-fun x8_64 () (_ BitVec 64))
(declare-fun x8_63 () (_ BitVec 64))
(declare-fun x8_62 () (_ BitVec 64))
(declare-fun x8_61 () (_ BitVec 64))
(declare-fun x8_60 () (_ BitVec 64))
(declare-fun x8_59 () (_ BitVec 64))
(declare-fun x8_58 () (_ BitVec 64))
(declare-fun x8_57 () (_ BitVec 64))
(declare-fun x8_56 () (_ BitVec 64))
(declare-fun x8_55 () (_ BitVec 64))
(declare-fun x8_54 () (_ BitVec 64))
(declare-fun x8_53 () (_ BitVec 64))
(declare-fun x8_52 () (_ BitVec 64))
(declare-fun x8_51 () (_ BitVec 64))
(declare-fun x8_50 () (_ BitVec 64))
(declare-fun x8_49 () (_ BitVec 64))
(declare-fun x8_48 () (_ BitVec 64))
(declare-fun x8_47 () (_ BitVec 64))
(declare-fun x8_46 () (_ BitVec 64))
(declare-fun x8_45 () (_ BitVec 64))
(declare-fun x8_44 () (_ BitVec 64))
(declare-fun x7_40 () (_ BitVec 64))
(declare-fun x7_39 () (_ BitVec 64))
(declare-fun x7_38 () (_ BitVec 64))
(declare-fun x7_37 () (_ BitVec 64))
(declare-fun x7_36 () (_ BitVec 64))
(declare-fun x7_35 () (_ BitVec 64))
(declare-fun x7_34 () (_ BitVec 64))
(declare-fun x7_33 () (_ BitVec 64))
(declare-fun x7_32 () (_ BitVec 64))
(declare-fun x7_31 () (_ BitVec 64))
(declare-fun x7_30 () (_ BitVec 64))
(declare-fun x7_29 () (_ BitVec 64))
(declare-fun x7_28 () (_ BitVec 64))
(declare-fun x7_27 () (_ BitVec 64))
(declare-fun x7_26 () (_ BitVec 64))
(declare-fun x7_25 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_35 () (_ BitVec 64))
(declare-fun x3_neg_34 () (_ BitVec 64))
(declare-fun x3_neg_33 () (_ BitVec 64))
(declare-fun x3_neg_32 () (_ BitVec 64))
(declare-fun x3_neg_31 () (_ BitVec 64))
(declare-fun x3_neg_30 () (_ BitVec 64))
(declare-fun x3_neg_29 () (_ BitVec 64))
(declare-fun x3_neg_28 () (_ BitVec 64))
(declare-fun x3_neg_27 () (_ BitVec 64))
(declare-fun x3_neg_26 () (_ BitVec 64))
(declare-fun x3_neg_25 () (_ BitVec 64))
(declare-fun x3_neg_24 () (_ BitVec 64))
(declare-fun x3_neg_23 () (_ BitVec 64))
(declare-fun x3_neg_22 () (_ BitVec 64))
(declare-fun x3_neg_21 () (_ BitVec 64))
(declare-fun x3_71 () (_ BitVec 64))
(declare-fun x3_70 () (_ BitVec 64))
(declare-fun x3_69 () (_ BitVec 64))
(declare-fun x3_68 () (_ BitVec 64))
(declare-fun x3_67 () (_ BitVec 64))
(declare-fun x3_66 () (_ BitVec 64))
(declare-fun x3_65 () (_ BitVec 64))
(declare-fun x3_64 () (_ BitVec 64))
(declare-fun x3_63 () (_ BitVec 64))
(declare-fun x3_62 () (_ BitVec 64))
(declare-fun x3_61 () (_ BitVec 64))
(declare-fun x3_60 () (_ BitVec 64))
(declare-fun x3_59 () (_ BitVec 64))
(declare-fun x3_58 () (_ BitVec 64))
(declare-fun x3_57 () (_ BitVec 64))
(declare-fun x3_56 () (_ BitVec 64))
(declare-fun x3_55 () (_ BitVec 64))
(declare-fun x3_54 () (_ BitVec 64))
(declare-fun x3_53 () (_ BitVec 64))
(declare-fun x3_52 () (_ BitVec 64))
(declare-fun x3_51 () (_ BitVec 64))
(declare-fun x3_50 () (_ BitVec 64))
(declare-fun x3_49 () (_ BitVec 64))
(declare-fun x3_48 () (_ BitVec 64))
(declare-fun x3_47 () (_ BitVec 64))
(declare-fun x3_46 () (_ BitVec 64))
(declare-fun x3_45 () (_ BitVec 64))
(declare-fun x3_44 () (_ BitVec 64))
(declare-fun x3_43 () (_ BitVec 64))
(declare-fun x3_42 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x10_neg_35 () (_ BitVec 64))
(declare-fun x10_neg_34 () (_ BitVec 64))
(declare-fun x10_neg_33 () (_ BitVec 64))
(declare-fun x10_neg_32 () (_ BitVec 64))
(declare-fun x10_neg_31 () (_ BitVec 64))
(declare-fun x10_neg_30 () (_ BitVec 64))
(declare-fun x10_neg_29 () (_ BitVec 64))
(declare-fun x10_neg_28 () (_ BitVec 64))
(declare-fun x10_neg_27 () (_ BitVec 64))
(declare-fun x10_neg_26 () (_ BitVec 64))
(declare-fun x10_neg_25 () (_ BitVec 64))
(declare-fun x10_neg_24 () (_ BitVec 64))
(declare-fun x10_neg_23 () (_ BitVec 64))
(declare-fun x10_neg_22 () (_ BitVec 64))
(declare-fun x10_neg_21 () (_ BitVec 64))
(declare-fun x10_72 () (_ BitVec 64))
(declare-fun x10_71 () (_ BitVec 64))
(declare-fun x10_70 () (_ BitVec 64))
(declare-fun x10_69 () (_ BitVec 64))
(declare-fun x10_68 () (_ BitVec 64))
(declare-fun x10_67 () (_ BitVec 64))
(declare-fun x10_66 () (_ BitVec 64))
(declare-fun x10_65 () (_ BitVec 64))
(declare-fun x10_64 () (_ BitVec 64))
(declare-fun x10_63 () (_ BitVec 64))
(declare-fun x10_62 () (_ BitVec 64))
(declare-fun x10_61 () (_ BitVec 64))
(declare-fun x10_60 () (_ BitVec 64))
(declare-fun x10_59 () (_ BitVec 64))
(declare-fun x10_58 () (_ BitVec 64))
(declare-fun x10_57 () (_ BitVec 64))
(declare-fun x10_56 () (_ BitVec 64))
(declare-fun x10_55 () (_ BitVec 64))
(declare-fun x10_54 () (_ BitVec 64))
(declare-fun x10_53 () (_ BitVec 64))
(declare-fun x10_52 () (_ BitVec 64))
(declare-fun x10_51 () (_ BitVec 64))
(declare-fun x10_50 () (_ BitVec 64))
(declare-fun x10_49 () (_ BitVec 64))
(declare-fun x10_48 () (_ BitVec 64))
(declare-fun x10_47 () (_ BitVec 64))
(declare-fun x10_46 () (_ BitVec 64))
(declare-fun x10_45 () (_ BitVec 64))
(declare-fun x10_44 () (_ BitVec 64))
(declare-fun x10_43 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun ne_36 () (_ BitVec 1))
(declare-fun ne_35 () (_ BitVec 1))
(declare-fun ne_34 () (_ BitVec 1))
(declare-fun ne_33 () (_ BitVec 1))
(declare-fun ne_32 () (_ BitVec 1))
(declare-fun ne_31 () (_ BitVec 1))
(declare-fun ne_30 () (_ BitVec 1))
(declare-fun ne_29 () (_ BitVec 1))
(declare-fun ne_28 () (_ BitVec 1))
(declare-fun ne_27 () (_ BitVec 1))
(declare-fun ne_26 () (_ BitVec 1))
(declare-fun ne_25 () (_ BitVec 1))
(declare-fun ne_24 () (_ BitVec 1))
(declare-fun ne_23 () (_ BitVec 1))
(declare-fun ne_22 () (_ BitVec 1))
(declare-fun ne_21 () (_ BitVec 1))
(declare-fun ge_105 () (_ BitVec 1))
(declare-fun ge_104 () (_ BitVec 1))
(declare-fun ge_103 () (_ BitVec 1))
(declare-fun ge_102 () (_ BitVec 1))
(declare-fun ge_101 () (_ BitVec 1))
(declare-fun ge_100 () (_ BitVec 1))
(declare-fun ge_99 () (_ BitVec 1))
(declare-fun ge_98 () (_ BitVec 1))
(declare-fun ge_97 () (_ BitVec 1))
(declare-fun ge_96 () (_ BitVec 1))
(declare-fun ge_95 () (_ BitVec 1))
(declare-fun ge_94 () (_ BitVec 1))
(declare-fun ge_93 () (_ BitVec 1))
(declare-fun ge_92 () (_ BitVec 1))
(declare-fun ge_91 () (_ BitVec 1))
(declare-fun ge_90 () (_ BitVec 1))
(declare-fun ge_89 () (_ BitVec 1))
(declare-fun ge_88 () (_ BitVec 1))
(declare-fun ge_87 () (_ BitVec 1))
(declare-fun ge_86 () (_ BitVec 1))
(declare-fun ge_85 () (_ BitVec 1))
(declare-fun ge_84 () (_ BitVec 1))
(declare-fun ge_83 () (_ BitVec 1))
(declare-fun ge_82 () (_ BitVec 1))
(declare-fun ge_81 () (_ BitVec 1))
(declare-fun ge_80 () (_ BitVec 1))
(declare-fun ge_79 () (_ BitVec 1))
(declare-fun ge_78 () (_ BitVec 1))
(declare-fun ge_77 () (_ BitVec 1))
(declare-fun ge_76 () (_ BitVec 1))
(declare-fun ge_75 () (_ BitVec 1))
(declare-fun ge_74 () (_ BitVec 1))
(declare-fun ge_73 () (_ BitVec 1))
(declare-fun ge_72 () (_ BitVec 1))
(declare-fun ge_71 () (_ BitVec 1))
(declare-fun ge_70 () (_ BitVec 1))
(declare-fun ge_69 () (_ BitVec 1))
(declare-fun ge_68 () (_ BitVec 1))
(declare-fun ge_67 () (_ BitVec 1))
(declare-fun ge_66 () (_ BitVec 1))
(declare-fun ge_65 () (_ BitVec 1))
(declare-fun ge_64 () (_ BitVec 1))
(declare-fun ge_63 () (_ BitVec 1))
(declare-fun ge_62 () (_ BitVec 1))
(declare-fun ge_61 () (_ BitVec 1))
(declare-fun dc_293 () (_ BitVec 64))
(declare-fun dc_292 () (_ BitVec 1))
(declare-fun dc_291 () (_ BitVec 62))
(declare-fun dc_290 () (_ BitVec 1))
(declare-fun dc_289 () (_ BitVec 1))
(declare-fun dc_288 () (_ BitVec 1))
(declare-fun dc_287 () (_ BitVec 63))
(declare-fun dc_286 () (_ BitVec 64))
(declare-fun dc_285 () (_ BitVec 1))
(declare-fun dc_284 () (_ BitVec 62))
(declare-fun dc_283 () (_ BitVec 1))
(declare-fun dc_282 () (_ BitVec 1))
(declare-fun dc_281 () (_ BitVec 1))
(declare-fun dc_280 () (_ BitVec 63))
(declare-fun dc_279 () (_ BitVec 64))
(declare-fun dc_278 () (_ BitVec 1))
(declare-fun dc_277 () (_ BitVec 62))
(declare-fun dc_276 () (_ BitVec 1))
(declare-fun dc_275 () (_ BitVec 1))
(declare-fun dc_274 () (_ BitVec 1))
(declare-fun dc_273 () (_ BitVec 63))
(declare-fun dc_272 () (_ BitVec 64))
(declare-fun dc_271 () (_ BitVec 1))
(declare-fun dc_270 () (_ BitVec 62))
(declare-fun dc_269 () (_ BitVec 1))
(declare-fun dc_268 () (_ BitVec 1))
(declare-fun dc_267 () (_ BitVec 1))
(declare-fun dc_266 () (_ BitVec 63))
(declare-fun dc_265 () (_ BitVec 64))
(declare-fun dc_264 () (_ BitVec 1))
(declare-fun dc_263 () (_ BitVec 62))
(declare-fun dc_262 () (_ BitVec 1))
(declare-fun dc_261 () (_ BitVec 1))
(declare-fun dc_260 () (_ BitVec 1))
(declare-fun dc_259 () (_ BitVec 63))
(declare-fun dc_258 () (_ BitVec 64))
(declare-fun dc_257 () (_ BitVec 1))
(declare-fun dc_256 () (_ BitVec 62))
(declare-fun dc_255 () (_ BitVec 1))
(declare-fun dc_254 () (_ BitVec 1))
(declare-fun dc_253 () (_ BitVec 1))
(declare-fun dc_252 () (_ BitVec 63))
(declare-fun dc_251 () (_ BitVec 64))
(declare-fun dc_250 () (_ BitVec 1))
(declare-fun dc_249 () (_ BitVec 62))
(declare-fun dc_248 () (_ BitVec 1))
(declare-fun dc_247 () (_ BitVec 1))
(declare-fun dc_246 () (_ BitVec 1))
(declare-fun dc_245 () (_ BitVec 63))
(declare-fun dc_244 () (_ BitVec 64))
(declare-fun dc_243 () (_ BitVec 1))
(declare-fun dc_242 () (_ BitVec 62))
(declare-fun dc_241 () (_ BitVec 1))
(declare-fun dc_240 () (_ BitVec 1))
(declare-fun dc_239 () (_ BitVec 1))
(declare-fun dc_238 () (_ BitVec 63))
(declare-fun dc_237 () (_ BitVec 64))
(declare-fun dc_236 () (_ BitVec 1))
(declare-fun dc_235 () (_ BitVec 62))
(declare-fun dc_234 () (_ BitVec 1))
(declare-fun dc_233 () (_ BitVec 1))
(declare-fun dc_232 () (_ BitVec 1))
(declare-fun dc_231 () (_ BitVec 63))
(declare-fun dc_230 () (_ BitVec 64))
(declare-fun dc_229 () (_ BitVec 1))
(declare-fun dc_228 () (_ BitVec 62))
(declare-fun dc_227 () (_ BitVec 1))
(declare-fun dc_226 () (_ BitVec 1))
(declare-fun dc_225 () (_ BitVec 1))
(declare-fun dc_224 () (_ BitVec 63))
(declare-fun dc_223 () (_ BitVec 64))
(declare-fun dc_222 () (_ BitVec 1))
(declare-fun dc_221 () (_ BitVec 62))
(declare-fun dc_220 () (_ BitVec 1))
(declare-fun dc_219 () (_ BitVec 1))
(declare-fun dc_218 () (_ BitVec 1))
(declare-fun dc_217 () (_ BitVec 63))
(declare-fun dc_216 () (_ BitVec 64))
(declare-fun dc_215 () (_ BitVec 1))
(declare-fun dc_214 () (_ BitVec 62))
(declare-fun dc_213 () (_ BitVec 1))
(declare-fun dc_212 () (_ BitVec 1))
(declare-fun dc_211 () (_ BitVec 1))
(declare-fun dc_210 () (_ BitVec 63))
(declare-fun dc_209 () (_ BitVec 64))
(declare-fun dc_208 () (_ BitVec 1))
(declare-fun dc_207 () (_ BitVec 62))
(declare-fun dc_206 () (_ BitVec 1))
(declare-fun dc_205 () (_ BitVec 1))
(declare-fun dc_204 () (_ BitVec 1))
(declare-fun dc_203 () (_ BitVec 63))
(declare-fun dc_202 () (_ BitVec 64))
(declare-fun dc_201 () (_ BitVec 1))
(declare-fun dc_200 () (_ BitVec 62))
(declare-fun dc_199 () (_ BitVec 1))
(declare-fun dc_198 () (_ BitVec 1))
(declare-fun dc_197 () (_ BitVec 1))
(declare-fun dc_196 () (_ BitVec 63))
(declare-fun dc_195 () (_ BitVec 64))
(declare-fun dc_194 () (_ BitVec 1))
(declare-fun dc_193 () (_ BitVec 62))
(declare-fun dc_192 () (_ BitVec 1))
(declare-fun dc_191 () (_ BitVec 1))
(declare-fun dc_190 () (_ BitVec 1))
(declare-fun dc_189 () (_ BitVec 63))
(declare-fun dc_188 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_25 (bvadd (bvadd neg_f_0_low60_20_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_44 (bvadd (bvadd neg_g_0_low60_20_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_0_1)) (bvsle neg_f_0_low60_20_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_0_1)) (bvsle neg_g_0_low60_20_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_25) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_188 ((_ extract 63 1) x8_44)) (= x8_lo_21 ((_ extract 0 0) x8_44))))
(assert (= ne_21 (bvand x8_lo_21 #b1)))
(assert (= x10_43 (ite (= ne_21 #b1) x7_25 #x0000000000000000)))
(assert (and (= ge_61 ((_ extract 63 63) x3_41)) (= dc_189 ((_ extract 62 0) x3_41))))
(assert (= ge_62 (bvnot ge_61)))
(assert (= ge_63 (ite (= ne_21 #b1) ge_62 #b0)))
(assert (and (= dc_190 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_42 (ite (= ge_63 #b1) x3_neg_21 x3_41)))
(assert (and (= dc_191 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_44 (ite (= ge_63 #b1) x10_neg_21 x10_43)))
(assert (= x7_26 (ite (= ge_63 #b1) x8_44 x7_25)))
(assert (and (= dc_192 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44)))) (= x8_45 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44))))))
(assert (= x3_43 (bvadd x3_42 #x0000000000000002)))
(assert (and (= dc_193 ((_ extract 63 2) x8_45)) (= x8_lo_22 ((_ extract 1 0) x8_45))))
(assert (and (= x8_target_20 ((_ extract 1 1) x8_lo_22)) (= dc_194 ((_ extract 0 0) x8_lo_22))))
(assert (= ne_22 (bvand x8_target_20 #b1)))
(assert (and (= x8_46 ((_ sign_extend 1) ((_ extract 63 1) x8_45))) (= dc_195 ((_ zero_extend 63) ((_ extract 0 0) x8_45)))))
(assert true)
(assert (= x10_45 (ite (= ne_22 #b1) x7_26 #x0000000000000000)))
(assert (and (= ge_64 ((_ extract 63 63) x3_43)) (= dc_196 ((_ extract 62 0) x3_43))))
(assert (= ge_65 (bvnot ge_64)))
(assert (= ge_66 (ite (= ne_22 #b1) ge_65 #b0)))
(assert (and (= dc_197 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_44 (ite (= ge_66 #b1) x3_neg_22 x3_43)))
(assert (and (= dc_198 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_46 (ite (= ge_66 #b1) x10_neg_22 x10_45)))
(assert (= x7_27 (ite (= ge_66 #b1) x8_46 x7_26)))
(assert (and (= dc_199 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46)))) (= x8_47 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46))))))
(assert (= x3_45 (bvadd x3_44 #x0000000000000002)))
(assert (and (= dc_200 ((_ extract 63 2) x8_47)) (= x8_lo_23 ((_ extract 1 0) x8_47))))
(assert (and (= x8_target_21 ((_ extract 1 1) x8_lo_23)) (= dc_201 ((_ extract 0 0) x8_lo_23))))
(assert (= ne_23 (bvand x8_target_21 #b1)))
(assert (and (= x8_48 ((_ sign_extend 1) ((_ extract 63 1) x8_47))) (= dc_202 ((_ zero_extend 63) ((_ extract 0 0) x8_47)))))
(assert true)
(assert (= x10_47 (ite (= ne_23 #b1) x7_27 #x0000000000000000)))
(assert (and (= ge_67 ((_ extract 63 63) x3_45)) (= dc_203 ((_ extract 62 0) x3_45))))
(assert (= ge_68 (bvnot ge_67)))
(assert (= ge_69 (ite (= ne_23 #b1) ge_68 #b0)))
(assert (and (= dc_204 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_46 (ite (= ge_69 #b1) x3_neg_23 x3_45)))
(assert (and (= dc_205 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_48 (ite (= ge_69 #b1) x10_neg_23 x10_47)))
(assert (= x7_28 (ite (= ge_69 #b1) x8_48 x7_27)))
(assert (and (= dc_206 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48)))) (= x8_49 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48))))))
(assert (= x3_47 (bvadd x3_46 #x0000000000000002)))
(assert (and (= dc_207 ((_ extract 63 2) x8_49)) (= x8_lo_24 ((_ extract 1 0) x8_49))))
(assert (and (= x8_target_22 ((_ extract 1 1) x8_lo_24)) (= dc_208 ((_ extract 0 0) x8_lo_24))))
(assert (= ne_24 (bvand x8_target_22 #b1)))
(assert (and (= x8_50 ((_ sign_extend 1) ((_ extract 63 1) x8_49))) (= dc_209 ((_ zero_extend 63) ((_ extract 0 0) x8_49)))))
(assert true)
(assert (= x10_49 (ite (= ne_24 #b1) x7_28 #x0000000000000000)))
(assert (and (= ge_70 ((_ extract 63 63) x3_47)) (= dc_210 ((_ extract 62 0) x3_47))))
(assert (= ge_71 (bvnot ge_70)))
(assert (= ge_72 (ite (= ne_24 #b1) ge_71 #b0)))
(assert (and (= dc_211 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_47))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_24 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_47))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_48 (ite (= ge_72 #b1) x3_neg_24 x3_47)))
(assert (and (= dc_212 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_49))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_24 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_49))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_50 (ite (= ge_72 #b1) x10_neg_24 x10_49)))
(assert (= x7_29 (ite (= ge_72 #b1) x8_50 x7_28)))
(assert (and (= dc_213 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_50) ((_ zero_extend 1) x10_50)))) (= x8_51 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_50) ((_ zero_extend 1) x10_50))))))
(assert (= x3_49 (bvadd x3_48 #x0000000000000002)))
(assert (and (= dc_214 ((_ extract 63 2) x8_51)) (= x8_lo_25 ((_ extract 1 0) x8_51))))
(assert (and (= x8_target_23 ((_ extract 1 1) x8_lo_25)) (= dc_215 ((_ extract 0 0) x8_lo_25))))
(assert (= ne_25 (bvand x8_target_23 #b1)))
(assert (and (= x8_52 ((_ sign_extend 1) ((_ extract 63 1) x8_51))) (= dc_216 ((_ zero_extend 63) ((_ extract 0 0) x8_51)))))
(assert true)
(assert (= x10_51 (ite (= ne_25 #b1) x7_29 #x0000000000000000)))
(assert (and (= ge_73 ((_ extract 63 63) x3_49)) (= dc_217 ((_ extract 62 0) x3_49))))
(assert (= ge_74 (bvnot ge_73)))
(assert (= ge_75 (ite (= ne_25 #b1) ge_74 #b0)))
(assert (and (= dc_218 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_49))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_25 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_49))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_50 (ite (= ge_75 #b1) x3_neg_25 x3_49)))
(assert (and (= dc_219 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_51))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_25 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_51))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_52 (ite (= ge_75 #b1) x10_neg_25 x10_51)))
(assert (= x7_30 (ite (= ge_75 #b1) x8_52 x7_29)))
(assert (and (= dc_220 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_52) ((_ zero_extend 1) x10_52)))) (= x8_53 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_52) ((_ zero_extend 1) x10_52))))))
(assert (= x3_51 (bvadd x3_50 #x0000000000000002)))
(assert (and (= dc_221 ((_ extract 63 2) x8_53)) (= x8_lo_26 ((_ extract 1 0) x8_53))))
(assert (and (= x8_target_24 ((_ extract 1 1) x8_lo_26)) (= dc_222 ((_ extract 0 0) x8_lo_26))))
(assert (= ne_26 (bvand x8_target_24 #b1)))
(assert (and (= x8_54 ((_ sign_extend 1) ((_ extract 63 1) x8_53))) (= dc_223 ((_ zero_extend 63) ((_ extract 0 0) x8_53)))))
(assert true)
(assert (= x10_53 (ite (= ne_26 #b1) x7_30 #x0000000000000000)))
(assert (and (= ge_76 ((_ extract 63 63) x3_51)) (= dc_224 ((_ extract 62 0) x3_51))))
(assert (= ge_77 (bvnot ge_76)))
(assert (= ge_78 (ite (= ne_26 #b1) ge_77 #b0)))
(assert (and (= dc_225 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_51))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_26 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_51))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_52 (ite (= ge_78 #b1) x3_neg_26 x3_51)))
(assert (and (= dc_226 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_53))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_26 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_53))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_54 (ite (= ge_78 #b1) x10_neg_26 x10_53)))
(assert (= x7_31 (ite (= ge_78 #b1) x8_54 x7_30)))
(assert (and (= dc_227 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_54) ((_ zero_extend 1) x10_54)))) (= x8_55 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_54) ((_ zero_extend 1) x10_54))))))
(assert (= x3_53 (bvadd x3_52 #x0000000000000002)))
(assert (and (= dc_228 ((_ extract 63 2) x8_55)) (= x8_lo_27 ((_ extract 1 0) x8_55))))
(assert (and (= x8_target_25 ((_ extract 1 1) x8_lo_27)) (= dc_229 ((_ extract 0 0) x8_lo_27))))
(assert (= ne_27 (bvand x8_target_25 #b1)))
(assert (and (= x8_56 ((_ sign_extend 1) ((_ extract 63 1) x8_55))) (= dc_230 ((_ zero_extend 63) ((_ extract 0 0) x8_55)))))
(assert true)
(assert (= x10_55 (ite (= ne_27 #b1) x7_31 #x0000000000000000)))
(assert (and (= ge_79 ((_ extract 63 63) x3_53)) (= dc_231 ((_ extract 62 0) x3_53))))
(assert (= ge_80 (bvnot ge_79)))
(assert (= ge_81 (ite (= ne_27 #b1) ge_80 #b0)))
(assert (and (= dc_232 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_53))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_27 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_53))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_54 (ite (= ge_81 #b1) x3_neg_27 x3_53)))
(assert (and (= dc_233 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_55))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_27 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_55))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_56 (ite (= ge_81 #b1) x10_neg_27 x10_55)))
(assert (= x7_32 (ite (= ge_81 #b1) x8_56 x7_31)))
(assert (and (= dc_234 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_56) ((_ zero_extend 1) x10_56)))) (= x8_57 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_56) ((_ zero_extend 1) x10_56))))))
(assert (= x3_55 (bvadd x3_54 #x0000000000000002)))
(assert (and (= dc_235 ((_ extract 63 2) x8_57)) (= x8_lo_28 ((_ extract 1 0) x8_57))))
(assert (and (= x8_target_26 ((_ extract 1 1) x8_lo_28)) (= dc_236 ((_ extract 0 0) x8_lo_28))))
(assert (= ne_28 (bvand x8_target_26 #b1)))
(assert (and (= x8_58 ((_ sign_extend 1) ((_ extract 63 1) x8_57))) (= dc_237 ((_ zero_extend 63) ((_ extract 0 0) x8_57)))))
(assert true)
(assert (= x10_57 (ite (= ne_28 #b1) x7_32 #x0000000000000000)))
(assert (and (= ge_82 ((_ extract 63 63) x3_55)) (= dc_238 ((_ extract 62 0) x3_55))))
(assert (= ge_83 (bvnot ge_82)))
(assert (= ge_84 (ite (= ne_28 #b1) ge_83 #b0)))
(assert (and (= dc_239 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_55))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_28 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_55))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_56 (ite (= ge_84 #b1) x3_neg_28 x3_55)))
(assert (and (= dc_240 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_57))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_28 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_57))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_58 (ite (= ge_84 #b1) x10_neg_28 x10_57)))
(assert (= x7_33 (ite (= ge_84 #b1) x8_58 x7_32)))
(assert (and (= dc_241 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_58) ((_ zero_extend 1) x10_58)))) (= x8_59 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_58) ((_ zero_extend 1) x10_58))))))
(assert (= x3_57 (bvadd x3_56 #x0000000000000002)))
(assert (and (= dc_242 ((_ extract 63 2) x8_59)) (= x8_lo_29 ((_ extract 1 0) x8_59))))
(assert (and (= x8_target_27 ((_ extract 1 1) x8_lo_29)) (= dc_243 ((_ extract 0 0) x8_lo_29))))
(assert (= ne_29 (bvand x8_target_27 #b1)))
(assert (and (= x8_60 ((_ sign_extend 1) ((_ extract 63 1) x8_59))) (= dc_244 ((_ zero_extend 63) ((_ extract 0 0) x8_59)))))
(assert true)
(assert (= x10_59 (ite (= ne_29 #b1) x7_33 #x0000000000000000)))
(assert (and (= ge_85 ((_ extract 63 63) x3_57)) (= dc_245 ((_ extract 62 0) x3_57))))
(assert (= ge_86 (bvnot ge_85)))
(assert (= ge_87 (ite (= ne_29 #b1) ge_86 #b0)))
(assert (and (= dc_246 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_57))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_29 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_57))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_58 (ite (= ge_87 #b1) x3_neg_29 x3_57)))
(assert (and (= dc_247 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_59))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_29 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_59))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_60 (ite (= ge_87 #b1) x10_neg_29 x10_59)))
(assert (= x7_34 (ite (= ge_87 #b1) x8_60 x7_33)))
(assert (and (= dc_248 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_60) ((_ zero_extend 1) x10_60)))) (= x8_61 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_60) ((_ zero_extend 1) x10_60))))))
(assert (= x3_59 (bvadd x3_58 #x0000000000000002)))
(assert (and (= dc_249 ((_ extract 63 2) x8_61)) (= x8_lo_30 ((_ extract 1 0) x8_61))))
(assert (and (= x8_target_28 ((_ extract 1 1) x8_lo_30)) (= dc_250 ((_ extract 0 0) x8_lo_30))))
(assert (= ne_30 (bvand x8_target_28 #b1)))
(assert (and (= x8_62 ((_ sign_extend 1) ((_ extract 63 1) x8_61))) (= dc_251 ((_ zero_extend 63) ((_ extract 0 0) x8_61)))))
(assert true)
(assert (= x10_61 (ite (= ne_30 #b1) x7_34 #x0000000000000000)))
(assert (and (= ge_88 ((_ extract 63 63) x3_59)) (= dc_252 ((_ extract 62 0) x3_59))))
(assert (= ge_89 (bvnot ge_88)))
(assert (= ge_90 (ite (= ne_30 #b1) ge_89 #b0)))
(assert (and (= dc_253 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_59))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_30 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_59))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_60 (ite (= ge_90 #b1) x3_neg_30 x3_59)))
(assert (and (= dc_254 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_61))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_30 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_61))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_62 (ite (= ge_90 #b1) x10_neg_30 x10_61)))
(assert (= x7_35 (ite (= ge_90 #b1) x8_62 x7_34)))
(assert (and (= dc_255 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_62) ((_ zero_extend 1) x10_62)))) (= x8_63 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_62) ((_ zero_extend 1) x10_62))))))
(assert (= x3_61 (bvadd x3_60 #x0000000000000002)))
(assert (and (= dc_256 ((_ extract 63 2) x8_63)) (= x8_lo_31 ((_ extract 1 0) x8_63))))
(assert (and (= x8_target_29 ((_ extract 1 1) x8_lo_31)) (= dc_257 ((_ extract 0 0) x8_lo_31))))
(assert (= ne_31 (bvand x8_target_29 #b1)))
(assert (and (= x8_64 ((_ sign_extend 1) ((_ extract 63 1) x8_63))) (= dc_258 ((_ zero_extend 63) ((_ extract 0 0) x8_63)))))
(assert true)
(assert (= x10_63 (ite (= ne_31 #b1) x7_35 #x0000000000000000)))
(assert (and (= ge_91 ((_ extract 63 63) x3_61)) (= dc_259 ((_ extract 62 0) x3_61))))
(assert (= ge_92 (bvnot ge_91)))
(assert (= ge_93 (ite (= ne_31 #b1) ge_92 #b0)))
(assert (and (= dc_260 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_61))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_31 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_61))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_62 (ite (= ge_93 #b1) x3_neg_31 x3_61)))
(assert (and (= dc_261 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_63))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_31 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_63))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_64 (ite (= ge_93 #b1) x10_neg_31 x10_63)))
(assert (= x7_36 (ite (= ge_93 #b1) x8_64 x7_35)))
(assert (and (= dc_262 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_64) ((_ zero_extend 1) x10_64)))) (= x8_65 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_64) ((_ zero_extend 1) x10_64))))))
(assert (= x3_63 (bvadd x3_62 #x0000000000000002)))
(assert (and (= dc_263 ((_ extract 63 2) x8_65)) (= x8_lo_32 ((_ extract 1 0) x8_65))))
(assert (and (= x8_target_30 ((_ extract 1 1) x8_lo_32)) (= dc_264 ((_ extract 0 0) x8_lo_32))))
(assert (= ne_32 (bvand x8_target_30 #b1)))
(assert (and (= x8_66 ((_ sign_extend 1) ((_ extract 63 1) x8_65))) (= dc_265 ((_ zero_extend 63) ((_ extract 0 0) x8_65)))))
(assert true)
(assert (= x10_65 (ite (= ne_32 #b1) x7_36 #x0000000000000000)))
(assert (and (= ge_94 ((_ extract 63 63) x3_63)) (= dc_266 ((_ extract 62 0) x3_63))))
(assert (= ge_95 (bvnot ge_94)))
(assert (= ge_96 (ite (= ne_32 #b1) ge_95 #b0)))
(assert (and (= dc_267 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_63))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_32 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_63))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_64 (ite (= ge_96 #b1) x3_neg_32 x3_63)))
(assert (and (= dc_268 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_65))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_32 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_65))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_66 (ite (= ge_96 #b1) x10_neg_32 x10_65)))
(assert (= x7_37 (ite (= ge_96 #b1) x8_66 x7_36)))
(assert (and (= dc_269 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_66) ((_ zero_extend 1) x10_66)))) (= x8_67 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_66) ((_ zero_extend 1) x10_66))))))
(assert (= x3_65 (bvadd x3_64 #x0000000000000002)))
(assert (and (= dc_270 ((_ extract 63 2) x8_67)) (= x8_lo_33 ((_ extract 1 0) x8_67))))
(assert (and (= x8_target_31 ((_ extract 1 1) x8_lo_33)) (= dc_271 ((_ extract 0 0) x8_lo_33))))
(assert (= ne_33 (bvand x8_target_31 #b1)))
(assert (and (= x8_68 ((_ sign_extend 1) ((_ extract 63 1) x8_67))) (= dc_272 ((_ zero_extend 63) ((_ extract 0 0) x8_67)))))
(assert true)
(assert (= x10_67 (ite (= ne_33 #b1) x7_37 #x0000000000000000)))
(assert (and (= ge_97 ((_ extract 63 63) x3_65)) (= dc_273 ((_ extract 62 0) x3_65))))
(assert (= ge_98 (bvnot ge_97)))
(assert (= ge_99 (ite (= ne_33 #b1) ge_98 #b0)))
(assert (and (= dc_274 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_65))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_33 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_65))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_66 (ite (= ge_99 #b1) x3_neg_33 x3_65)))
(assert (and (= dc_275 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_67))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_33 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_67))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_68 (ite (= ge_99 #b1) x10_neg_33 x10_67)))
(assert (= x7_38 (ite (= ge_99 #b1) x8_68 x7_37)))
(assert (and (= dc_276 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_68) ((_ zero_extend 1) x10_68)))) (= x8_69 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_68) ((_ zero_extend 1) x10_68))))))
(assert (= x3_67 (bvadd x3_66 #x0000000000000002)))
(assert (and (= dc_277 ((_ extract 63 2) x8_69)) (= x8_lo_34 ((_ extract 1 0) x8_69))))
(assert (and (= x8_target_32 ((_ extract 1 1) x8_lo_34)) (= dc_278 ((_ extract 0 0) x8_lo_34))))
(assert (= ne_34 (bvand x8_target_32 #b1)))
(assert (and (= x8_70 ((_ sign_extend 1) ((_ extract 63 1) x8_69))) (= dc_279 ((_ zero_extend 63) ((_ extract 0 0) x8_69)))))
(assert true)
(assert (= x10_69 (ite (= ne_34 #b1) x7_38 #x0000000000000000)))
(assert (and (= ge_100 ((_ extract 63 63) x3_67)) (= dc_280 ((_ extract 62 0) x3_67))))
(assert (= ge_101 (bvnot ge_100)))
(assert (= ge_102 (ite (= ne_34 #b1) ge_101 #b0)))
(assert (and (= dc_281 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_67))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_34 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_67))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_68 (ite (= ge_102 #b1) x3_neg_34 x3_67)))
(assert (and (= dc_282 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_69))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_34 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_69))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_70 (ite (= ge_102 #b1) x10_neg_34 x10_69)))
(assert (= x7_39 (ite (= ge_102 #b1) x8_70 x7_38)))
(assert (and (= dc_283 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_70) ((_ zero_extend 1) x10_70)))) (= x8_71 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_70) ((_ zero_extend 1) x10_70))))))
(assert (= x3_69 (bvadd x3_68 #x0000000000000002)))
(assert (and (= dc_284 ((_ extract 63 2) x8_71)) (= x8_lo_35 ((_ extract 1 0) x8_71))))
(assert (and (= x8_target_33 ((_ extract 1 1) x8_lo_35)) (= dc_285 ((_ extract 0 0) x8_lo_35))))
(assert (= ne_35 (bvand x8_target_33 #b1)))
(assert (and (= x8_72 ((_ sign_extend 1) ((_ extract 63 1) x8_71))) (= dc_286 ((_ zero_extend 63) ((_ extract 0 0) x8_71)))))
(assert true)
(assert (= x10_71 (ite (= ne_35 #b1) x7_39 #x0000000000000000)))
(assert (and (= ge_103 ((_ extract 63 63) x3_69)) (= dc_287 ((_ extract 62 0) x3_69))))
(assert (= ge_104 (bvnot ge_103)))
(assert (= ge_105 (ite (= ne_35 #b1) ge_104 #b0)))
(assert (and (= dc_288 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_69))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_35 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_69))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_70 (ite (= ge_105 #b1) x3_neg_35 x3_69)))
(assert (and (= dc_289 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_71))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_35 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_71))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_72 (ite (= ge_105 #b1) x10_neg_35 x10_71)))
(assert (= x7_40 (ite (= ge_105 #b1) x8_72 x7_39)))
(assert (and (= dc_290 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_72) ((_ zero_extend 1) x10_72)))) (= x8_73 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_72) ((_ zero_extend 1) x10_72))))))
(assert (= x3_71 (bvadd x3_70 #x0000000000000002)))
(assert (and (= dc_291 ((_ extract 63 2) x8_73)) (= x8_lo_36 ((_ extract 1 0) x8_73))))
(assert (and (= x8_target_34 ((_ extract 1 1) x8_lo_36)) (= dc_292 ((_ extract 0 0) x8_lo_36))))
(assert (= ne_36 (bvand x8_target_34 #b1)))
(assert (and (= x8_74 ((_ sign_extend 1) ((_ extract 63 1) x8_73))) (= dc_293 ((_ zero_extend 63) ((_ extract 0 0) x8_73)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_72) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_40 x7_39)) (= (bvmul x8_74 #x0000000000000002) x8_72)) (= x3_71 (bvadd #x0000000000000002 x3_69))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_72) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_69 #x0000000000000000)) (= x7_40 x7_39)) (= (bvmul x8_74 #x0000000000000002) (bvadd x8_72 x7_39))) (= x3_71 (bvadd #x0000000000000002 x3_69)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_72) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_69 #x0000000000000000)) (= x7_40 x8_72)) (= (bvmul x8_74 #x0000000000000002) (bvsub x8_72 x7_39))) (= x3_71 (bvsub #x0000000000000002 x3_69))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_20b7a2.smt2
Execution time of boolector: 0.7053 seconds
OUTPUT FROM boolector:
unsat

=== Cut #6 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #6
; Range assertion #53: or [and [smod (sub (uext x8_70 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_39 = x7_38, mul x8_72 2@64 = x8_70, x3_69 = add 2@64 x3_67], and [smod (sub (uext x8_70 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_67 <s 0@64, x7_39 = x7_38, mul x8_72 2@64 = add x8_70 x7_38, x3_69 = add 2@64 x3_67], and [smod (sub (uext x8_70 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_67 >=s 0@64, x7_39 = x8_70, mul x8_72 2@64 = sub x8_70 x7_38, x3_69 = sub 2@64 x3_67]]
; Range condition: ((x8_70@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_39 = x7_38 /\ x8_72 * 2 = x8_70 /\ x3_69 = 2 + x3_67 \/ ((x8_70@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_67 <s 0 /\ x7_39 = x7_38 /\ x8_72 * 2 = x8_70 + x7_38 /\ x3_69 = 2 + x3_67 \/ ((x8_70@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_67 >=s 0 /\ x7_39 = x8_70 /\ x8_72 * 2 = x8_70 - x7_38 /\ x3_69 = 2 - x3_67
; Output file: /tmp/outputqfbv_c8591d.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_33 () (_ BitVec 1))
(declare-fun x8_target_32 () (_ BitVec 1))
(declare-fun x8_target_31 () (_ BitVec 1))
(declare-fun x8_target_30 () (_ BitVec 1))
(declare-fun x8_target_29 () (_ BitVec 1))
(declare-fun x8_target_28 () (_ BitVec 1))
(declare-fun x8_target_27 () (_ BitVec 1))
(declare-fun x8_target_26 () (_ BitVec 1))
(declare-fun x8_target_25 () (_ BitVec 1))
(declare-fun x8_target_24 () (_ BitVec 1))
(declare-fun x8_target_23 () (_ BitVec 1))
(declare-fun x8_target_22 () (_ BitVec 1))
(declare-fun x8_target_21 () (_ BitVec 1))
(declare-fun x8_target_20 () (_ BitVec 1))
(declare-fun x8_lo_35 () (_ BitVec 2))
(declare-fun x8_lo_34 () (_ BitVec 2))
(declare-fun x8_lo_33 () (_ BitVec 2))
(declare-fun x8_lo_32 () (_ BitVec 2))
(declare-fun x8_lo_31 () (_ BitVec 2))
(declare-fun x8_lo_30 () (_ BitVec 2))
(declare-fun x8_lo_29 () (_ BitVec 2))
(declare-fun x8_lo_28 () (_ BitVec 2))
(declare-fun x8_lo_27 () (_ BitVec 2))
(declare-fun x8_lo_26 () (_ BitVec 2))
(declare-fun x8_lo_25 () (_ BitVec 2))
(declare-fun x8_lo_24 () (_ BitVec 2))
(declare-fun x8_lo_23 () (_ BitVec 2))
(declare-fun x8_lo_22 () (_ BitVec 2))
(declare-fun x8_lo_21 () (_ BitVec 1))
(declare-fun x8_72 () (_ BitVec 64))
(declare-fun x8_71 () (_ BitVec 64))
(declare-fun x8_70 () (_ BitVec 64))
(declare-fun x8_69 () (_ BitVec 64))
(declare-fun x8_68 () (_ BitVec 64))
(declare-fun x8_67 () (_ BitVec 64))
(declare-fun x8_66 () (_ BitVec 64))
(declare-fun x8_65 () (_ BitVec 64))
(declare-fun x8_64 () (_ BitVec 64))
(declare-fun x8_63 () (_ BitVec 64))
(declare-fun x8_62 () (_ BitVec 64))
(declare-fun x8_61 () (_ BitVec 64))
(declare-fun x8_60 () (_ BitVec 64))
(declare-fun x8_59 () (_ BitVec 64))
(declare-fun x8_58 () (_ BitVec 64))
(declare-fun x8_57 () (_ BitVec 64))
(declare-fun x8_56 () (_ BitVec 64))
(declare-fun x8_55 () (_ BitVec 64))
(declare-fun x8_54 () (_ BitVec 64))
(declare-fun x8_53 () (_ BitVec 64))
(declare-fun x8_52 () (_ BitVec 64))
(declare-fun x8_51 () (_ BitVec 64))
(declare-fun x8_50 () (_ BitVec 64))
(declare-fun x8_49 () (_ BitVec 64))
(declare-fun x8_48 () (_ BitVec 64))
(declare-fun x8_47 () (_ BitVec 64))
(declare-fun x8_46 () (_ BitVec 64))
(declare-fun x8_45 () (_ BitVec 64))
(declare-fun x8_44 () (_ BitVec 64))
(declare-fun x7_39 () (_ BitVec 64))
(declare-fun x7_38 () (_ BitVec 64))
(declare-fun x7_37 () (_ BitVec 64))
(declare-fun x7_36 () (_ BitVec 64))
(declare-fun x7_35 () (_ BitVec 64))
(declare-fun x7_34 () (_ BitVec 64))
(declare-fun x7_33 () (_ BitVec 64))
(declare-fun x7_32 () (_ BitVec 64))
(declare-fun x7_31 () (_ BitVec 64))
(declare-fun x7_30 () (_ BitVec 64))
(declare-fun x7_29 () (_ BitVec 64))
(declare-fun x7_28 () (_ BitVec 64))
(declare-fun x7_27 () (_ BitVec 64))
(declare-fun x7_26 () (_ BitVec 64))
(declare-fun x7_25 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_34 () (_ BitVec 64))
(declare-fun x3_neg_33 () (_ BitVec 64))
(declare-fun x3_neg_32 () (_ BitVec 64))
(declare-fun x3_neg_31 () (_ BitVec 64))
(declare-fun x3_neg_30 () (_ BitVec 64))
(declare-fun x3_neg_29 () (_ BitVec 64))
(declare-fun x3_neg_28 () (_ BitVec 64))
(declare-fun x3_neg_27 () (_ BitVec 64))
(declare-fun x3_neg_26 () (_ BitVec 64))
(declare-fun x3_neg_25 () (_ BitVec 64))
(declare-fun x3_neg_24 () (_ BitVec 64))
(declare-fun x3_neg_23 () (_ BitVec 64))
(declare-fun x3_neg_22 () (_ BitVec 64))
(declare-fun x3_neg_21 () (_ BitVec 64))
(declare-fun x3_69 () (_ BitVec 64))
(declare-fun x3_68 () (_ BitVec 64))
(declare-fun x3_67 () (_ BitVec 64))
(declare-fun x3_66 () (_ BitVec 64))
(declare-fun x3_65 () (_ BitVec 64))
(declare-fun x3_64 () (_ BitVec 64))
(declare-fun x3_63 () (_ BitVec 64))
(declare-fun x3_62 () (_ BitVec 64))
(declare-fun x3_61 () (_ BitVec 64))
(declare-fun x3_60 () (_ BitVec 64))
(declare-fun x3_59 () (_ BitVec 64))
(declare-fun x3_58 () (_ BitVec 64))
(declare-fun x3_57 () (_ BitVec 64))
(declare-fun x3_56 () (_ BitVec 64))
(declare-fun x3_55 () (_ BitVec 64))
(declare-fun x3_54 () (_ BitVec 64))
(declare-fun x3_53 () (_ BitVec 64))
(declare-fun x3_52 () (_ BitVec 64))
(declare-fun x3_51 () (_ BitVec 64))
(declare-fun x3_50 () (_ BitVec 64))
(declare-fun x3_49 () (_ BitVec 64))
(declare-fun x3_48 () (_ BitVec 64))
(declare-fun x3_47 () (_ BitVec 64))
(declare-fun x3_46 () (_ BitVec 64))
(declare-fun x3_45 () (_ BitVec 64))
(declare-fun x3_44 () (_ BitVec 64))
(declare-fun x3_43 () (_ BitVec 64))
(declare-fun x3_42 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x10_neg_34 () (_ BitVec 64))
(declare-fun x10_neg_33 () (_ BitVec 64))
(declare-fun x10_neg_32 () (_ BitVec 64))
(declare-fun x10_neg_31 () (_ BitVec 64))
(declare-fun x10_neg_30 () (_ BitVec 64))
(declare-fun x10_neg_29 () (_ BitVec 64))
(declare-fun x10_neg_28 () (_ BitVec 64))
(declare-fun x10_neg_27 () (_ BitVec 64))
(declare-fun x10_neg_26 () (_ BitVec 64))
(declare-fun x10_neg_25 () (_ BitVec 64))
(declare-fun x10_neg_24 () (_ BitVec 64))
(declare-fun x10_neg_23 () (_ BitVec 64))
(declare-fun x10_neg_22 () (_ BitVec 64))
(declare-fun x10_neg_21 () (_ BitVec 64))
(declare-fun x10_70 () (_ BitVec 64))
(declare-fun x10_69 () (_ BitVec 64))
(declare-fun x10_68 () (_ BitVec 64))
(declare-fun x10_67 () (_ BitVec 64))
(declare-fun x10_66 () (_ BitVec 64))
(declare-fun x10_65 () (_ BitVec 64))
(declare-fun x10_64 () (_ BitVec 64))
(declare-fun x10_63 () (_ BitVec 64))
(declare-fun x10_62 () (_ BitVec 64))
(declare-fun x10_61 () (_ BitVec 64))
(declare-fun x10_60 () (_ BitVec 64))
(declare-fun x10_59 () (_ BitVec 64))
(declare-fun x10_58 () (_ BitVec 64))
(declare-fun x10_57 () (_ BitVec 64))
(declare-fun x10_56 () (_ BitVec 64))
(declare-fun x10_55 () (_ BitVec 64))
(declare-fun x10_54 () (_ BitVec 64))
(declare-fun x10_53 () (_ BitVec 64))
(declare-fun x10_52 () (_ BitVec 64))
(declare-fun x10_51 () (_ BitVec 64))
(declare-fun x10_50 () (_ BitVec 64))
(declare-fun x10_49 () (_ BitVec 64))
(declare-fun x10_48 () (_ BitVec 64))
(declare-fun x10_47 () (_ BitVec 64))
(declare-fun x10_46 () (_ BitVec 64))
(declare-fun x10_45 () (_ BitVec 64))
(declare-fun x10_44 () (_ BitVec 64))
(declare-fun x10_43 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun ne_35 () (_ BitVec 1))
(declare-fun ne_34 () (_ BitVec 1))
(declare-fun ne_33 () (_ BitVec 1))
(declare-fun ne_32 () (_ BitVec 1))
(declare-fun ne_31 () (_ BitVec 1))
(declare-fun ne_30 () (_ BitVec 1))
(declare-fun ne_29 () (_ BitVec 1))
(declare-fun ne_28 () (_ BitVec 1))
(declare-fun ne_27 () (_ BitVec 1))
(declare-fun ne_26 () (_ BitVec 1))
(declare-fun ne_25 () (_ BitVec 1))
(declare-fun ne_24 () (_ BitVec 1))
(declare-fun ne_23 () (_ BitVec 1))
(declare-fun ne_22 () (_ BitVec 1))
(declare-fun ne_21 () (_ BitVec 1))
(declare-fun ge_102 () (_ BitVec 1))
(declare-fun ge_101 () (_ BitVec 1))
(declare-fun ge_100 () (_ BitVec 1))
(declare-fun ge_99 () (_ BitVec 1))
(declare-fun ge_98 () (_ BitVec 1))
(declare-fun ge_97 () (_ BitVec 1))
(declare-fun ge_96 () (_ BitVec 1))
(declare-fun ge_95 () (_ BitVec 1))
(declare-fun ge_94 () (_ BitVec 1))
(declare-fun ge_93 () (_ BitVec 1))
(declare-fun ge_92 () (_ BitVec 1))
(declare-fun ge_91 () (_ BitVec 1))
(declare-fun ge_90 () (_ BitVec 1))
(declare-fun ge_89 () (_ BitVec 1))
(declare-fun ge_88 () (_ BitVec 1))
(declare-fun ge_87 () (_ BitVec 1))
(declare-fun ge_86 () (_ BitVec 1))
(declare-fun ge_85 () (_ BitVec 1))
(declare-fun ge_84 () (_ BitVec 1))
(declare-fun ge_83 () (_ BitVec 1))
(declare-fun ge_82 () (_ BitVec 1))
(declare-fun ge_81 () (_ BitVec 1))
(declare-fun ge_80 () (_ BitVec 1))
(declare-fun ge_79 () (_ BitVec 1))
(declare-fun ge_78 () (_ BitVec 1))
(declare-fun ge_77 () (_ BitVec 1))
(declare-fun ge_76 () (_ BitVec 1))
(declare-fun ge_75 () (_ BitVec 1))
(declare-fun ge_74 () (_ BitVec 1))
(declare-fun ge_73 () (_ BitVec 1))
(declare-fun ge_72 () (_ BitVec 1))
(declare-fun ge_71 () (_ BitVec 1))
(declare-fun ge_70 () (_ BitVec 1))
(declare-fun ge_69 () (_ BitVec 1))
(declare-fun ge_68 () (_ BitVec 1))
(declare-fun ge_67 () (_ BitVec 1))
(declare-fun ge_66 () (_ BitVec 1))
(declare-fun ge_65 () (_ BitVec 1))
(declare-fun ge_64 () (_ BitVec 1))
(declare-fun ge_63 () (_ BitVec 1))
(declare-fun ge_62 () (_ BitVec 1))
(declare-fun ge_61 () (_ BitVec 1))
(declare-fun dc_286 () (_ BitVec 64))
(declare-fun dc_285 () (_ BitVec 1))
(declare-fun dc_284 () (_ BitVec 62))
(declare-fun dc_283 () (_ BitVec 1))
(declare-fun dc_282 () (_ BitVec 1))
(declare-fun dc_281 () (_ BitVec 1))
(declare-fun dc_280 () (_ BitVec 63))
(declare-fun dc_279 () (_ BitVec 64))
(declare-fun dc_278 () (_ BitVec 1))
(declare-fun dc_277 () (_ BitVec 62))
(declare-fun dc_276 () (_ BitVec 1))
(declare-fun dc_275 () (_ BitVec 1))
(declare-fun dc_274 () (_ BitVec 1))
(declare-fun dc_273 () (_ BitVec 63))
(declare-fun dc_272 () (_ BitVec 64))
(declare-fun dc_271 () (_ BitVec 1))
(declare-fun dc_270 () (_ BitVec 62))
(declare-fun dc_269 () (_ BitVec 1))
(declare-fun dc_268 () (_ BitVec 1))
(declare-fun dc_267 () (_ BitVec 1))
(declare-fun dc_266 () (_ BitVec 63))
(declare-fun dc_265 () (_ BitVec 64))
(declare-fun dc_264 () (_ BitVec 1))
(declare-fun dc_263 () (_ BitVec 62))
(declare-fun dc_262 () (_ BitVec 1))
(declare-fun dc_261 () (_ BitVec 1))
(declare-fun dc_260 () (_ BitVec 1))
(declare-fun dc_259 () (_ BitVec 63))
(declare-fun dc_258 () (_ BitVec 64))
(declare-fun dc_257 () (_ BitVec 1))
(declare-fun dc_256 () (_ BitVec 62))
(declare-fun dc_255 () (_ BitVec 1))
(declare-fun dc_254 () (_ BitVec 1))
(declare-fun dc_253 () (_ BitVec 1))
(declare-fun dc_252 () (_ BitVec 63))
(declare-fun dc_251 () (_ BitVec 64))
(declare-fun dc_250 () (_ BitVec 1))
(declare-fun dc_249 () (_ BitVec 62))
(declare-fun dc_248 () (_ BitVec 1))
(declare-fun dc_247 () (_ BitVec 1))
(declare-fun dc_246 () (_ BitVec 1))
(declare-fun dc_245 () (_ BitVec 63))
(declare-fun dc_244 () (_ BitVec 64))
(declare-fun dc_243 () (_ BitVec 1))
(declare-fun dc_242 () (_ BitVec 62))
(declare-fun dc_241 () (_ BitVec 1))
(declare-fun dc_240 () (_ BitVec 1))
(declare-fun dc_239 () (_ BitVec 1))
(declare-fun dc_238 () (_ BitVec 63))
(declare-fun dc_237 () (_ BitVec 64))
(declare-fun dc_236 () (_ BitVec 1))
(declare-fun dc_235 () (_ BitVec 62))
(declare-fun dc_234 () (_ BitVec 1))
(declare-fun dc_233 () (_ BitVec 1))
(declare-fun dc_232 () (_ BitVec 1))
(declare-fun dc_231 () (_ BitVec 63))
(declare-fun dc_230 () (_ BitVec 64))
(declare-fun dc_229 () (_ BitVec 1))
(declare-fun dc_228 () (_ BitVec 62))
(declare-fun dc_227 () (_ BitVec 1))
(declare-fun dc_226 () (_ BitVec 1))
(declare-fun dc_225 () (_ BitVec 1))
(declare-fun dc_224 () (_ BitVec 63))
(declare-fun dc_223 () (_ BitVec 64))
(declare-fun dc_222 () (_ BitVec 1))
(declare-fun dc_221 () (_ BitVec 62))
(declare-fun dc_220 () (_ BitVec 1))
(declare-fun dc_219 () (_ BitVec 1))
(declare-fun dc_218 () (_ BitVec 1))
(declare-fun dc_217 () (_ BitVec 63))
(declare-fun dc_216 () (_ BitVec 64))
(declare-fun dc_215 () (_ BitVec 1))
(declare-fun dc_214 () (_ BitVec 62))
(declare-fun dc_213 () (_ BitVec 1))
(declare-fun dc_212 () (_ BitVec 1))
(declare-fun dc_211 () (_ BitVec 1))
(declare-fun dc_210 () (_ BitVec 63))
(declare-fun dc_209 () (_ BitVec 64))
(declare-fun dc_208 () (_ BitVec 1))
(declare-fun dc_207 () (_ BitVec 62))
(declare-fun dc_206 () (_ BitVec 1))
(declare-fun dc_205 () (_ BitVec 1))
(declare-fun dc_204 () (_ BitVec 1))
(declare-fun dc_203 () (_ BitVec 63))
(declare-fun dc_202 () (_ BitVec 64))
(declare-fun dc_201 () (_ BitVec 1))
(declare-fun dc_200 () (_ BitVec 62))
(declare-fun dc_199 () (_ BitVec 1))
(declare-fun dc_198 () (_ BitVec 1))
(declare-fun dc_197 () (_ BitVec 1))
(declare-fun dc_196 () (_ BitVec 63))
(declare-fun dc_195 () (_ BitVec 64))
(declare-fun dc_194 () (_ BitVec 1))
(declare-fun dc_193 () (_ BitVec 62))
(declare-fun dc_192 () (_ BitVec 1))
(declare-fun dc_191 () (_ BitVec 1))
(declare-fun dc_190 () (_ BitVec 1))
(declare-fun dc_189 () (_ BitVec 63))
(declare-fun dc_188 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_25 (bvadd (bvadd neg_f_0_low60_20_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_44 (bvadd (bvadd neg_g_0_low60_20_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_0_1)) (bvsle neg_f_0_low60_20_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_0_1)) (bvsle neg_g_0_low60_20_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_25) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_188 ((_ extract 63 1) x8_44)) (= x8_lo_21 ((_ extract 0 0) x8_44))))
(assert (= ne_21 (bvand x8_lo_21 #b1)))
(assert (= x10_43 (ite (= ne_21 #b1) x7_25 #x0000000000000000)))
(assert (and (= ge_61 ((_ extract 63 63) x3_41)) (= dc_189 ((_ extract 62 0) x3_41))))
(assert (= ge_62 (bvnot ge_61)))
(assert (= ge_63 (ite (= ne_21 #b1) ge_62 #b0)))
(assert (and (= dc_190 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_42 (ite (= ge_63 #b1) x3_neg_21 x3_41)))
(assert (and (= dc_191 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_44 (ite (= ge_63 #b1) x10_neg_21 x10_43)))
(assert (= x7_26 (ite (= ge_63 #b1) x8_44 x7_25)))
(assert (and (= dc_192 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44)))) (= x8_45 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44))))))
(assert (= x3_43 (bvadd x3_42 #x0000000000000002)))
(assert (and (= dc_193 ((_ extract 63 2) x8_45)) (= x8_lo_22 ((_ extract 1 0) x8_45))))
(assert (and (= x8_target_20 ((_ extract 1 1) x8_lo_22)) (= dc_194 ((_ extract 0 0) x8_lo_22))))
(assert (= ne_22 (bvand x8_target_20 #b1)))
(assert (and (= x8_46 ((_ sign_extend 1) ((_ extract 63 1) x8_45))) (= dc_195 ((_ zero_extend 63) ((_ extract 0 0) x8_45)))))
(assert true)
(assert (= x10_45 (ite (= ne_22 #b1) x7_26 #x0000000000000000)))
(assert (and (= ge_64 ((_ extract 63 63) x3_43)) (= dc_196 ((_ extract 62 0) x3_43))))
(assert (= ge_65 (bvnot ge_64)))
(assert (= ge_66 (ite (= ne_22 #b1) ge_65 #b0)))
(assert (and (= dc_197 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_44 (ite (= ge_66 #b1) x3_neg_22 x3_43)))
(assert (and (= dc_198 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_46 (ite (= ge_66 #b1) x10_neg_22 x10_45)))
(assert (= x7_27 (ite (= ge_66 #b1) x8_46 x7_26)))
(assert (and (= dc_199 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46)))) (= x8_47 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46))))))
(assert (= x3_45 (bvadd x3_44 #x0000000000000002)))
(assert (and (= dc_200 ((_ extract 63 2) x8_47)) (= x8_lo_23 ((_ extract 1 0) x8_47))))
(assert (and (= x8_target_21 ((_ extract 1 1) x8_lo_23)) (= dc_201 ((_ extract 0 0) x8_lo_23))))
(assert (= ne_23 (bvand x8_target_21 #b1)))
(assert (and (= x8_48 ((_ sign_extend 1) ((_ extract 63 1) x8_47))) (= dc_202 ((_ zero_extend 63) ((_ extract 0 0) x8_47)))))
(assert true)
(assert (= x10_47 (ite (= ne_23 #b1) x7_27 #x0000000000000000)))
(assert (and (= ge_67 ((_ extract 63 63) x3_45)) (= dc_203 ((_ extract 62 0) x3_45))))
(assert (= ge_68 (bvnot ge_67)))
(assert (= ge_69 (ite (= ne_23 #b1) ge_68 #b0)))
(assert (and (= dc_204 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_46 (ite (= ge_69 #b1) x3_neg_23 x3_45)))
(assert (and (= dc_205 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_48 (ite (= ge_69 #b1) x10_neg_23 x10_47)))
(assert (= x7_28 (ite (= ge_69 #b1) x8_48 x7_27)))
(assert (and (= dc_206 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48)))) (= x8_49 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48))))))
(assert (= x3_47 (bvadd x3_46 #x0000000000000002)))
(assert (and (= dc_207 ((_ extract 63 2) x8_49)) (= x8_lo_24 ((_ extract 1 0) x8_49))))
(assert (and (= x8_target_22 ((_ extract 1 1) x8_lo_24)) (= dc_208 ((_ extract 0 0) x8_lo_24))))
(assert (= ne_24 (bvand x8_target_22 #b1)))
(assert (and (= x8_50 ((_ sign_extend 1) ((_ extract 63 1) x8_49))) (= dc_209 ((_ zero_extend 63) ((_ extract 0 0) x8_49)))))
(assert true)
(assert (= x10_49 (ite (= ne_24 #b1) x7_28 #x0000000000000000)))
(assert (and (= ge_70 ((_ extract 63 63) x3_47)) (= dc_210 ((_ extract 62 0) x3_47))))
(assert (= ge_71 (bvnot ge_70)))
(assert (= ge_72 (ite (= ne_24 #b1) ge_71 #b0)))
(assert (and (= dc_211 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_47))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_24 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_47))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_48 (ite (= ge_72 #b1) x3_neg_24 x3_47)))
(assert (and (= dc_212 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_49))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_24 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_49))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_50 (ite (= ge_72 #b1) x10_neg_24 x10_49)))
(assert (= x7_29 (ite (= ge_72 #b1) x8_50 x7_28)))
(assert (and (= dc_213 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_50) ((_ zero_extend 1) x10_50)))) (= x8_51 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_50) ((_ zero_extend 1) x10_50))))))
(assert (= x3_49 (bvadd x3_48 #x0000000000000002)))
(assert (and (= dc_214 ((_ extract 63 2) x8_51)) (= x8_lo_25 ((_ extract 1 0) x8_51))))
(assert (and (= x8_target_23 ((_ extract 1 1) x8_lo_25)) (= dc_215 ((_ extract 0 0) x8_lo_25))))
(assert (= ne_25 (bvand x8_target_23 #b1)))
(assert (and (= x8_52 ((_ sign_extend 1) ((_ extract 63 1) x8_51))) (= dc_216 ((_ zero_extend 63) ((_ extract 0 0) x8_51)))))
(assert true)
(assert (= x10_51 (ite (= ne_25 #b1) x7_29 #x0000000000000000)))
(assert (and (= ge_73 ((_ extract 63 63) x3_49)) (= dc_217 ((_ extract 62 0) x3_49))))
(assert (= ge_74 (bvnot ge_73)))
(assert (= ge_75 (ite (= ne_25 #b1) ge_74 #b0)))
(assert (and (= dc_218 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_49))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_25 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_49))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_50 (ite (= ge_75 #b1) x3_neg_25 x3_49)))
(assert (and (= dc_219 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_51))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_25 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_51))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_52 (ite (= ge_75 #b1) x10_neg_25 x10_51)))
(assert (= x7_30 (ite (= ge_75 #b1) x8_52 x7_29)))
(assert (and (= dc_220 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_52) ((_ zero_extend 1) x10_52)))) (= x8_53 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_52) ((_ zero_extend 1) x10_52))))))
(assert (= x3_51 (bvadd x3_50 #x0000000000000002)))
(assert (and (= dc_221 ((_ extract 63 2) x8_53)) (= x8_lo_26 ((_ extract 1 0) x8_53))))
(assert (and (= x8_target_24 ((_ extract 1 1) x8_lo_26)) (= dc_222 ((_ extract 0 0) x8_lo_26))))
(assert (= ne_26 (bvand x8_target_24 #b1)))
(assert (and (= x8_54 ((_ sign_extend 1) ((_ extract 63 1) x8_53))) (= dc_223 ((_ zero_extend 63) ((_ extract 0 0) x8_53)))))
(assert true)
(assert (= x10_53 (ite (= ne_26 #b1) x7_30 #x0000000000000000)))
(assert (and (= ge_76 ((_ extract 63 63) x3_51)) (= dc_224 ((_ extract 62 0) x3_51))))
(assert (= ge_77 (bvnot ge_76)))
(assert (= ge_78 (ite (= ne_26 #b1) ge_77 #b0)))
(assert (and (= dc_225 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_51))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_26 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_51))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_52 (ite (= ge_78 #b1) x3_neg_26 x3_51)))
(assert (and (= dc_226 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_53))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_26 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_53))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_54 (ite (= ge_78 #b1) x10_neg_26 x10_53)))
(assert (= x7_31 (ite (= ge_78 #b1) x8_54 x7_30)))
(assert (and (= dc_227 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_54) ((_ zero_extend 1) x10_54)))) (= x8_55 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_54) ((_ zero_extend 1) x10_54))))))
(assert (= x3_53 (bvadd x3_52 #x0000000000000002)))
(assert (and (= dc_228 ((_ extract 63 2) x8_55)) (= x8_lo_27 ((_ extract 1 0) x8_55))))
(assert (and (= x8_target_25 ((_ extract 1 1) x8_lo_27)) (= dc_229 ((_ extract 0 0) x8_lo_27))))
(assert (= ne_27 (bvand x8_target_25 #b1)))
(assert (and (= x8_56 ((_ sign_extend 1) ((_ extract 63 1) x8_55))) (= dc_230 ((_ zero_extend 63) ((_ extract 0 0) x8_55)))))
(assert true)
(assert (= x10_55 (ite (= ne_27 #b1) x7_31 #x0000000000000000)))
(assert (and (= ge_79 ((_ extract 63 63) x3_53)) (= dc_231 ((_ extract 62 0) x3_53))))
(assert (= ge_80 (bvnot ge_79)))
(assert (= ge_81 (ite (= ne_27 #b1) ge_80 #b0)))
(assert (and (= dc_232 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_53))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_27 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_53))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_54 (ite (= ge_81 #b1) x3_neg_27 x3_53)))
(assert (and (= dc_233 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_55))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_27 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_55))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_56 (ite (= ge_81 #b1) x10_neg_27 x10_55)))
(assert (= x7_32 (ite (= ge_81 #b1) x8_56 x7_31)))
(assert (and (= dc_234 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_56) ((_ zero_extend 1) x10_56)))) (= x8_57 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_56) ((_ zero_extend 1) x10_56))))))
(assert (= x3_55 (bvadd x3_54 #x0000000000000002)))
(assert (and (= dc_235 ((_ extract 63 2) x8_57)) (= x8_lo_28 ((_ extract 1 0) x8_57))))
(assert (and (= x8_target_26 ((_ extract 1 1) x8_lo_28)) (= dc_236 ((_ extract 0 0) x8_lo_28))))
(assert (= ne_28 (bvand x8_target_26 #b1)))
(assert (and (= x8_58 ((_ sign_extend 1) ((_ extract 63 1) x8_57))) (= dc_237 ((_ zero_extend 63) ((_ extract 0 0) x8_57)))))
(assert true)
(assert (= x10_57 (ite (= ne_28 #b1) x7_32 #x0000000000000000)))
(assert (and (= ge_82 ((_ extract 63 63) x3_55)) (= dc_238 ((_ extract 62 0) x3_55))))
(assert (= ge_83 (bvnot ge_82)))
(assert (= ge_84 (ite (= ne_28 #b1) ge_83 #b0)))
(assert (and (= dc_239 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_55))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_28 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_55))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_56 (ite (= ge_84 #b1) x3_neg_28 x3_55)))
(assert (and (= dc_240 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_57))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_28 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_57))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_58 (ite (= ge_84 #b1) x10_neg_28 x10_57)))
(assert (= x7_33 (ite (= ge_84 #b1) x8_58 x7_32)))
(assert (and (= dc_241 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_58) ((_ zero_extend 1) x10_58)))) (= x8_59 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_58) ((_ zero_extend 1) x10_58))))))
(assert (= x3_57 (bvadd x3_56 #x0000000000000002)))
(assert (and (= dc_242 ((_ extract 63 2) x8_59)) (= x8_lo_29 ((_ extract 1 0) x8_59))))
(assert (and (= x8_target_27 ((_ extract 1 1) x8_lo_29)) (= dc_243 ((_ extract 0 0) x8_lo_29))))
(assert (= ne_29 (bvand x8_target_27 #b1)))
(assert (and (= x8_60 ((_ sign_extend 1) ((_ extract 63 1) x8_59))) (= dc_244 ((_ zero_extend 63) ((_ extract 0 0) x8_59)))))
(assert true)
(assert (= x10_59 (ite (= ne_29 #b1) x7_33 #x0000000000000000)))
(assert (and (= ge_85 ((_ extract 63 63) x3_57)) (= dc_245 ((_ extract 62 0) x3_57))))
(assert (= ge_86 (bvnot ge_85)))
(assert (= ge_87 (ite (= ne_29 #b1) ge_86 #b0)))
(assert (and (= dc_246 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_57))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_29 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_57))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_58 (ite (= ge_87 #b1) x3_neg_29 x3_57)))
(assert (and (= dc_247 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_59))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_29 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_59))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_60 (ite (= ge_87 #b1) x10_neg_29 x10_59)))
(assert (= x7_34 (ite (= ge_87 #b1) x8_60 x7_33)))
(assert (and (= dc_248 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_60) ((_ zero_extend 1) x10_60)))) (= x8_61 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_60) ((_ zero_extend 1) x10_60))))))
(assert (= x3_59 (bvadd x3_58 #x0000000000000002)))
(assert (and (= dc_249 ((_ extract 63 2) x8_61)) (= x8_lo_30 ((_ extract 1 0) x8_61))))
(assert (and (= x8_target_28 ((_ extract 1 1) x8_lo_30)) (= dc_250 ((_ extract 0 0) x8_lo_30))))
(assert (= ne_30 (bvand x8_target_28 #b1)))
(assert (and (= x8_62 ((_ sign_extend 1) ((_ extract 63 1) x8_61))) (= dc_251 ((_ zero_extend 63) ((_ extract 0 0) x8_61)))))
(assert true)
(assert (= x10_61 (ite (= ne_30 #b1) x7_34 #x0000000000000000)))
(assert (and (= ge_88 ((_ extract 63 63) x3_59)) (= dc_252 ((_ extract 62 0) x3_59))))
(assert (= ge_89 (bvnot ge_88)))
(assert (= ge_90 (ite (= ne_30 #b1) ge_89 #b0)))
(assert (and (= dc_253 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_59))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_30 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_59))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_60 (ite (= ge_90 #b1) x3_neg_30 x3_59)))
(assert (and (= dc_254 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_61))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_30 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_61))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_62 (ite (= ge_90 #b1) x10_neg_30 x10_61)))
(assert (= x7_35 (ite (= ge_90 #b1) x8_62 x7_34)))
(assert (and (= dc_255 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_62) ((_ zero_extend 1) x10_62)))) (= x8_63 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_62) ((_ zero_extend 1) x10_62))))))
(assert (= x3_61 (bvadd x3_60 #x0000000000000002)))
(assert (and (= dc_256 ((_ extract 63 2) x8_63)) (= x8_lo_31 ((_ extract 1 0) x8_63))))
(assert (and (= x8_target_29 ((_ extract 1 1) x8_lo_31)) (= dc_257 ((_ extract 0 0) x8_lo_31))))
(assert (= ne_31 (bvand x8_target_29 #b1)))
(assert (and (= x8_64 ((_ sign_extend 1) ((_ extract 63 1) x8_63))) (= dc_258 ((_ zero_extend 63) ((_ extract 0 0) x8_63)))))
(assert true)
(assert (= x10_63 (ite (= ne_31 #b1) x7_35 #x0000000000000000)))
(assert (and (= ge_91 ((_ extract 63 63) x3_61)) (= dc_259 ((_ extract 62 0) x3_61))))
(assert (= ge_92 (bvnot ge_91)))
(assert (= ge_93 (ite (= ne_31 #b1) ge_92 #b0)))
(assert (and (= dc_260 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_61))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_31 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_61))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_62 (ite (= ge_93 #b1) x3_neg_31 x3_61)))
(assert (and (= dc_261 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_63))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_31 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_63))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_64 (ite (= ge_93 #b1) x10_neg_31 x10_63)))
(assert (= x7_36 (ite (= ge_93 #b1) x8_64 x7_35)))
(assert (and (= dc_262 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_64) ((_ zero_extend 1) x10_64)))) (= x8_65 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_64) ((_ zero_extend 1) x10_64))))))
(assert (= x3_63 (bvadd x3_62 #x0000000000000002)))
(assert (and (= dc_263 ((_ extract 63 2) x8_65)) (= x8_lo_32 ((_ extract 1 0) x8_65))))
(assert (and (= x8_target_30 ((_ extract 1 1) x8_lo_32)) (= dc_264 ((_ extract 0 0) x8_lo_32))))
(assert (= ne_32 (bvand x8_target_30 #b1)))
(assert (and (= x8_66 ((_ sign_extend 1) ((_ extract 63 1) x8_65))) (= dc_265 ((_ zero_extend 63) ((_ extract 0 0) x8_65)))))
(assert true)
(assert (= x10_65 (ite (= ne_32 #b1) x7_36 #x0000000000000000)))
(assert (and (= ge_94 ((_ extract 63 63) x3_63)) (= dc_266 ((_ extract 62 0) x3_63))))
(assert (= ge_95 (bvnot ge_94)))
(assert (= ge_96 (ite (= ne_32 #b1) ge_95 #b0)))
(assert (and (= dc_267 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_63))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_32 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_63))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_64 (ite (= ge_96 #b1) x3_neg_32 x3_63)))
(assert (and (= dc_268 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_65))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_32 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_65))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_66 (ite (= ge_96 #b1) x10_neg_32 x10_65)))
(assert (= x7_37 (ite (= ge_96 #b1) x8_66 x7_36)))
(assert (and (= dc_269 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_66) ((_ zero_extend 1) x10_66)))) (= x8_67 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_66) ((_ zero_extend 1) x10_66))))))
(assert (= x3_65 (bvadd x3_64 #x0000000000000002)))
(assert (and (= dc_270 ((_ extract 63 2) x8_67)) (= x8_lo_33 ((_ extract 1 0) x8_67))))
(assert (and (= x8_target_31 ((_ extract 1 1) x8_lo_33)) (= dc_271 ((_ extract 0 0) x8_lo_33))))
(assert (= ne_33 (bvand x8_target_31 #b1)))
(assert (and (= x8_68 ((_ sign_extend 1) ((_ extract 63 1) x8_67))) (= dc_272 ((_ zero_extend 63) ((_ extract 0 0) x8_67)))))
(assert true)
(assert (= x10_67 (ite (= ne_33 #b1) x7_37 #x0000000000000000)))
(assert (and (= ge_97 ((_ extract 63 63) x3_65)) (= dc_273 ((_ extract 62 0) x3_65))))
(assert (= ge_98 (bvnot ge_97)))
(assert (= ge_99 (ite (= ne_33 #b1) ge_98 #b0)))
(assert (and (= dc_274 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_65))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_33 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_65))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_66 (ite (= ge_99 #b1) x3_neg_33 x3_65)))
(assert (and (= dc_275 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_67))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_33 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_67))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_68 (ite (= ge_99 #b1) x10_neg_33 x10_67)))
(assert (= x7_38 (ite (= ge_99 #b1) x8_68 x7_37)))
(assert (and (= dc_276 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_68) ((_ zero_extend 1) x10_68)))) (= x8_69 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_68) ((_ zero_extend 1) x10_68))))))
(assert (= x3_67 (bvadd x3_66 #x0000000000000002)))
(assert (and (= dc_277 ((_ extract 63 2) x8_69)) (= x8_lo_34 ((_ extract 1 0) x8_69))))
(assert (and (= x8_target_32 ((_ extract 1 1) x8_lo_34)) (= dc_278 ((_ extract 0 0) x8_lo_34))))
(assert (= ne_34 (bvand x8_target_32 #b1)))
(assert (and (= x8_70 ((_ sign_extend 1) ((_ extract 63 1) x8_69))) (= dc_279 ((_ zero_extend 63) ((_ extract 0 0) x8_69)))))
(assert true)
(assert (= x10_69 (ite (= ne_34 #b1) x7_38 #x0000000000000000)))
(assert (and (= ge_100 ((_ extract 63 63) x3_67)) (= dc_280 ((_ extract 62 0) x3_67))))
(assert (= ge_101 (bvnot ge_100)))
(assert (= ge_102 (ite (= ne_34 #b1) ge_101 #b0)))
(assert (and (= dc_281 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_67))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_34 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_67))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_68 (ite (= ge_102 #b1) x3_neg_34 x3_67)))
(assert (and (= dc_282 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_69))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_34 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_69))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_70 (ite (= ge_102 #b1) x10_neg_34 x10_69)))
(assert (= x7_39 (ite (= ge_102 #b1) x8_70 x7_38)))
(assert (and (= dc_283 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_70) ((_ zero_extend 1) x10_70)))) (= x8_71 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_70) ((_ zero_extend 1) x10_70))))))
(assert (= x3_69 (bvadd x3_68 #x0000000000000002)))
(assert (and (= dc_284 ((_ extract 63 2) x8_71)) (= x8_lo_35 ((_ extract 1 0) x8_71))))
(assert (and (= x8_target_33 ((_ extract 1 1) x8_lo_35)) (= dc_285 ((_ extract 0 0) x8_lo_35))))
(assert (= ne_35 (bvand x8_target_33 #b1)))
(assert (and (= x8_72 ((_ sign_extend 1) ((_ extract 63 1) x8_71))) (= dc_286 ((_ zero_extend 63) ((_ extract 0 0) x8_71)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_70) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_39 x7_38)) (= (bvmul x8_72 #x0000000000000002) x8_70)) (= x3_69 (bvadd #x0000000000000002 x3_67))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_70) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_67 #x0000000000000000)) (= x7_39 x7_38)) (= (bvmul x8_72 #x0000000000000002) (bvadd x8_70 x7_38))) (= x3_69 (bvadd #x0000000000000002 x3_67)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_70) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_67 #x0000000000000000)) (= x7_39 x8_70)) (= (bvmul x8_72 #x0000000000000002) (bvsub x8_70 x7_38))) (= x3_69 (bvsub #x0000000000000002 x3_67))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_31fe04.smt2
Execution time of boolector: 1.2269 seconds
OUTPUT FROM boolector:
unsat

=== Cut #6 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #6
; Range assertion #55: or [and [smod (sub (uext x8_74 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_41 = x7_40, mul x8_76 2@64 = x8_74, x3_73 = add 2@64 x3_71], and [smod (sub (uext x8_74 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_71 <s 0@64, x7_41 = x7_40, mul x8_76 2@64 = add x8_74 x7_40, x3_73 = add 2@64 x3_71], and [smod (sub (uext x8_74 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_71 >=s 0@64, x7_41 = x8_74, mul x8_76 2@64 = sub x8_74 x7_40, x3_73 = sub 2@64 x3_71]]
; Range condition: ((x8_74@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_41 = x7_40 /\ x8_76 * 2 = x8_74 /\ x3_73 = 2 + x3_71 \/ ((x8_74@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_71 <s 0 /\ x7_41 = x7_40 /\ x8_76 * 2 = x8_74 + x7_40 /\ x3_73 = 2 + x3_71 \/ ((x8_74@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_71 >=s 0 /\ x7_41 = x8_74 /\ x8_76 * 2 = x8_74 - x7_40 /\ x3_73 = 2 - x3_71
; Output file: /tmp/outputqfbv_673b0a.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_35 () (_ BitVec 1))
(declare-fun x8_target_34 () (_ BitVec 1))
(declare-fun x8_target_33 () (_ BitVec 1))
(declare-fun x8_target_32 () (_ BitVec 1))
(declare-fun x8_target_31 () (_ BitVec 1))
(declare-fun x8_target_30 () (_ BitVec 1))
(declare-fun x8_target_29 () (_ BitVec 1))
(declare-fun x8_target_28 () (_ BitVec 1))
(declare-fun x8_target_27 () (_ BitVec 1))
(declare-fun x8_target_26 () (_ BitVec 1))
(declare-fun x8_target_25 () (_ BitVec 1))
(declare-fun x8_target_24 () (_ BitVec 1))
(declare-fun x8_target_23 () (_ BitVec 1))
(declare-fun x8_target_22 () (_ BitVec 1))
(declare-fun x8_target_21 () (_ BitVec 1))
(declare-fun x8_target_20 () (_ BitVec 1))
(declare-fun x8_lo_37 () (_ BitVec 2))
(declare-fun x8_lo_36 () (_ BitVec 2))
(declare-fun x8_lo_35 () (_ BitVec 2))
(declare-fun x8_lo_34 () (_ BitVec 2))
(declare-fun x8_lo_33 () (_ BitVec 2))
(declare-fun x8_lo_32 () (_ BitVec 2))
(declare-fun x8_lo_31 () (_ BitVec 2))
(declare-fun x8_lo_30 () (_ BitVec 2))
(declare-fun x8_lo_29 () (_ BitVec 2))
(declare-fun x8_lo_28 () (_ BitVec 2))
(declare-fun x8_lo_27 () (_ BitVec 2))
(declare-fun x8_lo_26 () (_ BitVec 2))
(declare-fun x8_lo_25 () (_ BitVec 2))
(declare-fun x8_lo_24 () (_ BitVec 2))
(declare-fun x8_lo_23 () (_ BitVec 2))
(declare-fun x8_lo_22 () (_ BitVec 2))
(declare-fun x8_lo_21 () (_ BitVec 1))
(declare-fun x8_76 () (_ BitVec 64))
(declare-fun x8_75 () (_ BitVec 64))
(declare-fun x8_74 () (_ BitVec 64))
(declare-fun x8_73 () (_ BitVec 64))
(declare-fun x8_72 () (_ BitVec 64))
(declare-fun x8_71 () (_ BitVec 64))
(declare-fun x8_70 () (_ BitVec 64))
(declare-fun x8_69 () (_ BitVec 64))
(declare-fun x8_68 () (_ BitVec 64))
(declare-fun x8_67 () (_ BitVec 64))
(declare-fun x8_66 () (_ BitVec 64))
(declare-fun x8_65 () (_ BitVec 64))
(declare-fun x8_64 () (_ BitVec 64))
(declare-fun x8_63 () (_ BitVec 64))
(declare-fun x8_62 () (_ BitVec 64))
(declare-fun x8_61 () (_ BitVec 64))
(declare-fun x8_60 () (_ BitVec 64))
(declare-fun x8_59 () (_ BitVec 64))
(declare-fun x8_58 () (_ BitVec 64))
(declare-fun x8_57 () (_ BitVec 64))
(declare-fun x8_56 () (_ BitVec 64))
(declare-fun x8_55 () (_ BitVec 64))
(declare-fun x8_54 () (_ BitVec 64))
(declare-fun x8_53 () (_ BitVec 64))
(declare-fun x8_52 () (_ BitVec 64))
(declare-fun x8_51 () (_ BitVec 64))
(declare-fun x8_50 () (_ BitVec 64))
(declare-fun x8_49 () (_ BitVec 64))
(declare-fun x8_48 () (_ BitVec 64))
(declare-fun x8_47 () (_ BitVec 64))
(declare-fun x8_46 () (_ BitVec 64))
(declare-fun x8_45 () (_ BitVec 64))
(declare-fun x8_44 () (_ BitVec 64))
(declare-fun x7_41 () (_ BitVec 64))
(declare-fun x7_40 () (_ BitVec 64))
(declare-fun x7_39 () (_ BitVec 64))
(declare-fun x7_38 () (_ BitVec 64))
(declare-fun x7_37 () (_ BitVec 64))
(declare-fun x7_36 () (_ BitVec 64))
(declare-fun x7_35 () (_ BitVec 64))
(declare-fun x7_34 () (_ BitVec 64))
(declare-fun x7_33 () (_ BitVec 64))
(declare-fun x7_32 () (_ BitVec 64))
(declare-fun x7_31 () (_ BitVec 64))
(declare-fun x7_30 () (_ BitVec 64))
(declare-fun x7_29 () (_ BitVec 64))
(declare-fun x7_28 () (_ BitVec 64))
(declare-fun x7_27 () (_ BitVec 64))
(declare-fun x7_26 () (_ BitVec 64))
(declare-fun x7_25 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_36 () (_ BitVec 64))
(declare-fun x3_neg_35 () (_ BitVec 64))
(declare-fun x3_neg_34 () (_ BitVec 64))
(declare-fun x3_neg_33 () (_ BitVec 64))
(declare-fun x3_neg_32 () (_ BitVec 64))
(declare-fun x3_neg_31 () (_ BitVec 64))
(declare-fun x3_neg_30 () (_ BitVec 64))
(declare-fun x3_neg_29 () (_ BitVec 64))
(declare-fun x3_neg_28 () (_ BitVec 64))
(declare-fun x3_neg_27 () (_ BitVec 64))
(declare-fun x3_neg_26 () (_ BitVec 64))
(declare-fun x3_neg_25 () (_ BitVec 64))
(declare-fun x3_neg_24 () (_ BitVec 64))
(declare-fun x3_neg_23 () (_ BitVec 64))
(declare-fun x3_neg_22 () (_ BitVec 64))
(declare-fun x3_neg_21 () (_ BitVec 64))
(declare-fun x3_73 () (_ BitVec 64))
(declare-fun x3_72 () (_ BitVec 64))
(declare-fun x3_71 () (_ BitVec 64))
(declare-fun x3_70 () (_ BitVec 64))
(declare-fun x3_69 () (_ BitVec 64))
(declare-fun x3_68 () (_ BitVec 64))
(declare-fun x3_67 () (_ BitVec 64))
(declare-fun x3_66 () (_ BitVec 64))
(declare-fun x3_65 () (_ BitVec 64))
(declare-fun x3_64 () (_ BitVec 64))
(declare-fun x3_63 () (_ BitVec 64))
(declare-fun x3_62 () (_ BitVec 64))
(declare-fun x3_61 () (_ BitVec 64))
(declare-fun x3_60 () (_ BitVec 64))
(declare-fun x3_59 () (_ BitVec 64))
(declare-fun x3_58 () (_ BitVec 64))
(declare-fun x3_57 () (_ BitVec 64))
(declare-fun x3_56 () (_ BitVec 64))
(declare-fun x3_55 () (_ BitVec 64))
(declare-fun x3_54 () (_ BitVec 64))
(declare-fun x3_53 () (_ BitVec 64))
(declare-fun x3_52 () (_ BitVec 64))
(declare-fun x3_51 () (_ BitVec 64))
(declare-fun x3_50 () (_ BitVec 64))
(declare-fun x3_49 () (_ BitVec 64))
(declare-fun x3_48 () (_ BitVec 64))
(declare-fun x3_47 () (_ BitVec 64))
(declare-fun x3_46 () (_ BitVec 64))
(declare-fun x3_45 () (_ BitVec 64))
(declare-fun x3_44 () (_ BitVec 64))
(declare-fun x3_43 () (_ BitVec 64))
(declare-fun x3_42 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x10_neg_36 () (_ BitVec 64))
(declare-fun x10_neg_35 () (_ BitVec 64))
(declare-fun x10_neg_34 () (_ BitVec 64))
(declare-fun x10_neg_33 () (_ BitVec 64))
(declare-fun x10_neg_32 () (_ BitVec 64))
(declare-fun x10_neg_31 () (_ BitVec 64))
(declare-fun x10_neg_30 () (_ BitVec 64))
(declare-fun x10_neg_29 () (_ BitVec 64))
(declare-fun x10_neg_28 () (_ BitVec 64))
(declare-fun x10_neg_27 () (_ BitVec 64))
(declare-fun x10_neg_26 () (_ BitVec 64))
(declare-fun x10_neg_25 () (_ BitVec 64))
(declare-fun x10_neg_24 () (_ BitVec 64))
(declare-fun x10_neg_23 () (_ BitVec 64))
(declare-fun x10_neg_22 () (_ BitVec 64))
(declare-fun x10_neg_21 () (_ BitVec 64))
(declare-fun x10_74 () (_ BitVec 64))
(declare-fun x10_73 () (_ BitVec 64))
(declare-fun x10_72 () (_ BitVec 64))
(declare-fun x10_71 () (_ BitVec 64))
(declare-fun x10_70 () (_ BitVec 64))
(declare-fun x10_69 () (_ BitVec 64))
(declare-fun x10_68 () (_ BitVec 64))
(declare-fun x10_67 () (_ BitVec 64))
(declare-fun x10_66 () (_ BitVec 64))
(declare-fun x10_65 () (_ BitVec 64))
(declare-fun x10_64 () (_ BitVec 64))
(declare-fun x10_63 () (_ BitVec 64))
(declare-fun x10_62 () (_ BitVec 64))
(declare-fun x10_61 () (_ BitVec 64))
(declare-fun x10_60 () (_ BitVec 64))
(declare-fun x10_59 () (_ BitVec 64))
(declare-fun x10_58 () (_ BitVec 64))
(declare-fun x10_57 () (_ BitVec 64))
(declare-fun x10_56 () (_ BitVec 64))
(declare-fun x10_55 () (_ BitVec 64))
(declare-fun x10_54 () (_ BitVec 64))
(declare-fun x10_53 () (_ BitVec 64))
(declare-fun x10_52 () (_ BitVec 64))
(declare-fun x10_51 () (_ BitVec 64))
(declare-fun x10_50 () (_ BitVec 64))
(declare-fun x10_49 () (_ BitVec 64))
(declare-fun x10_48 () (_ BitVec 64))
(declare-fun x10_47 () (_ BitVec 64))
(declare-fun x10_46 () (_ BitVec 64))
(declare-fun x10_45 () (_ BitVec 64))
(declare-fun x10_44 () (_ BitVec 64))
(declare-fun x10_43 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun ne_37 () (_ BitVec 1))
(declare-fun ne_36 () (_ BitVec 1))
(declare-fun ne_35 () (_ BitVec 1))
(declare-fun ne_34 () (_ BitVec 1))
(declare-fun ne_33 () (_ BitVec 1))
(declare-fun ne_32 () (_ BitVec 1))
(declare-fun ne_31 () (_ BitVec 1))
(declare-fun ne_30 () (_ BitVec 1))
(declare-fun ne_29 () (_ BitVec 1))
(declare-fun ne_28 () (_ BitVec 1))
(declare-fun ne_27 () (_ BitVec 1))
(declare-fun ne_26 () (_ BitVec 1))
(declare-fun ne_25 () (_ BitVec 1))
(declare-fun ne_24 () (_ BitVec 1))
(declare-fun ne_23 () (_ BitVec 1))
(declare-fun ne_22 () (_ BitVec 1))
(declare-fun ne_21 () (_ BitVec 1))
(declare-fun ge_108 () (_ BitVec 1))
(declare-fun ge_107 () (_ BitVec 1))
(declare-fun ge_106 () (_ BitVec 1))
(declare-fun ge_105 () (_ BitVec 1))
(declare-fun ge_104 () (_ BitVec 1))
(declare-fun ge_103 () (_ BitVec 1))
(declare-fun ge_102 () (_ BitVec 1))
(declare-fun ge_101 () (_ BitVec 1))
(declare-fun ge_100 () (_ BitVec 1))
(declare-fun ge_99 () (_ BitVec 1))
(declare-fun ge_98 () (_ BitVec 1))
(declare-fun ge_97 () (_ BitVec 1))
(declare-fun ge_96 () (_ BitVec 1))
(declare-fun ge_95 () (_ BitVec 1))
(declare-fun ge_94 () (_ BitVec 1))
(declare-fun ge_93 () (_ BitVec 1))
(declare-fun ge_92 () (_ BitVec 1))
(declare-fun ge_91 () (_ BitVec 1))
(declare-fun ge_90 () (_ BitVec 1))
(declare-fun ge_89 () (_ BitVec 1))
(declare-fun ge_88 () (_ BitVec 1))
(declare-fun ge_87 () (_ BitVec 1))
(declare-fun ge_86 () (_ BitVec 1))
(declare-fun ge_85 () (_ BitVec 1))
(declare-fun ge_84 () (_ BitVec 1))
(declare-fun ge_83 () (_ BitVec 1))
(declare-fun ge_82 () (_ BitVec 1))
(declare-fun ge_81 () (_ BitVec 1))
(declare-fun ge_80 () (_ BitVec 1))
(declare-fun ge_79 () (_ BitVec 1))
(declare-fun ge_78 () (_ BitVec 1))
(declare-fun ge_77 () (_ BitVec 1))
(declare-fun ge_76 () (_ BitVec 1))
(declare-fun ge_75 () (_ BitVec 1))
(declare-fun ge_74 () (_ BitVec 1))
(declare-fun ge_73 () (_ BitVec 1))
(declare-fun ge_72 () (_ BitVec 1))
(declare-fun ge_71 () (_ BitVec 1))
(declare-fun ge_70 () (_ BitVec 1))
(declare-fun ge_69 () (_ BitVec 1))
(declare-fun ge_68 () (_ BitVec 1))
(declare-fun ge_67 () (_ BitVec 1))
(declare-fun ge_66 () (_ BitVec 1))
(declare-fun ge_65 () (_ BitVec 1))
(declare-fun ge_64 () (_ BitVec 1))
(declare-fun ge_63 () (_ BitVec 1))
(declare-fun ge_62 () (_ BitVec 1))
(declare-fun ge_61 () (_ BitVec 1))
(declare-fun dc_300 () (_ BitVec 64))
(declare-fun dc_299 () (_ BitVec 1))
(declare-fun dc_298 () (_ BitVec 62))
(declare-fun dc_297 () (_ BitVec 1))
(declare-fun dc_296 () (_ BitVec 1))
(declare-fun dc_295 () (_ BitVec 1))
(declare-fun dc_294 () (_ BitVec 63))
(declare-fun dc_293 () (_ BitVec 64))
(declare-fun dc_292 () (_ BitVec 1))
(declare-fun dc_291 () (_ BitVec 62))
(declare-fun dc_290 () (_ BitVec 1))
(declare-fun dc_289 () (_ BitVec 1))
(declare-fun dc_288 () (_ BitVec 1))
(declare-fun dc_287 () (_ BitVec 63))
(declare-fun dc_286 () (_ BitVec 64))
(declare-fun dc_285 () (_ BitVec 1))
(declare-fun dc_284 () (_ BitVec 62))
(declare-fun dc_283 () (_ BitVec 1))
(declare-fun dc_282 () (_ BitVec 1))
(declare-fun dc_281 () (_ BitVec 1))
(declare-fun dc_280 () (_ BitVec 63))
(declare-fun dc_279 () (_ BitVec 64))
(declare-fun dc_278 () (_ BitVec 1))
(declare-fun dc_277 () (_ BitVec 62))
(declare-fun dc_276 () (_ BitVec 1))
(declare-fun dc_275 () (_ BitVec 1))
(declare-fun dc_274 () (_ BitVec 1))
(declare-fun dc_273 () (_ BitVec 63))
(declare-fun dc_272 () (_ BitVec 64))
(declare-fun dc_271 () (_ BitVec 1))
(declare-fun dc_270 () (_ BitVec 62))
(declare-fun dc_269 () (_ BitVec 1))
(declare-fun dc_268 () (_ BitVec 1))
(declare-fun dc_267 () (_ BitVec 1))
(declare-fun dc_266 () (_ BitVec 63))
(declare-fun dc_265 () (_ BitVec 64))
(declare-fun dc_264 () (_ BitVec 1))
(declare-fun dc_263 () (_ BitVec 62))
(declare-fun dc_262 () (_ BitVec 1))
(declare-fun dc_261 () (_ BitVec 1))
(declare-fun dc_260 () (_ BitVec 1))
(declare-fun dc_259 () (_ BitVec 63))
(declare-fun dc_258 () (_ BitVec 64))
(declare-fun dc_257 () (_ BitVec 1))
(declare-fun dc_256 () (_ BitVec 62))
(declare-fun dc_255 () (_ BitVec 1))
(declare-fun dc_254 () (_ BitVec 1))
(declare-fun dc_253 () (_ BitVec 1))
(declare-fun dc_252 () (_ BitVec 63))
(declare-fun dc_251 () (_ BitVec 64))
(declare-fun dc_250 () (_ BitVec 1))
(declare-fun dc_249 () (_ BitVec 62))
(declare-fun dc_248 () (_ BitVec 1))
(declare-fun dc_247 () (_ BitVec 1))
(declare-fun dc_246 () (_ BitVec 1))
(declare-fun dc_245 () (_ BitVec 63))
(declare-fun dc_244 () (_ BitVec 64))
(declare-fun dc_243 () (_ BitVec 1))
(declare-fun dc_242 () (_ BitVec 62))
(declare-fun dc_241 () (_ BitVec 1))
(declare-fun dc_240 () (_ BitVec 1))
(declare-fun dc_239 () (_ BitVec 1))
(declare-fun dc_238 () (_ BitVec 63))
(declare-fun dc_237 () (_ BitVec 64))
(declare-fun dc_236 () (_ BitVec 1))
(declare-fun dc_235 () (_ BitVec 62))
(declare-fun dc_234 () (_ BitVec 1))
(declare-fun dc_233 () (_ BitVec 1))
(declare-fun dc_232 () (_ BitVec 1))
(declare-fun dc_231 () (_ BitVec 63))
(declare-fun dc_230 () (_ BitVec 64))
(declare-fun dc_229 () (_ BitVec 1))
(declare-fun dc_228 () (_ BitVec 62))
(declare-fun dc_227 () (_ BitVec 1))
(declare-fun dc_226 () (_ BitVec 1))
(declare-fun dc_225 () (_ BitVec 1))
(declare-fun dc_224 () (_ BitVec 63))
(declare-fun dc_223 () (_ BitVec 64))
(declare-fun dc_222 () (_ BitVec 1))
(declare-fun dc_221 () (_ BitVec 62))
(declare-fun dc_220 () (_ BitVec 1))
(declare-fun dc_219 () (_ BitVec 1))
(declare-fun dc_218 () (_ BitVec 1))
(declare-fun dc_217 () (_ BitVec 63))
(declare-fun dc_216 () (_ BitVec 64))
(declare-fun dc_215 () (_ BitVec 1))
(declare-fun dc_214 () (_ BitVec 62))
(declare-fun dc_213 () (_ BitVec 1))
(declare-fun dc_212 () (_ BitVec 1))
(declare-fun dc_211 () (_ BitVec 1))
(declare-fun dc_210 () (_ BitVec 63))
(declare-fun dc_209 () (_ BitVec 64))
(declare-fun dc_208 () (_ BitVec 1))
(declare-fun dc_207 () (_ BitVec 62))
(declare-fun dc_206 () (_ BitVec 1))
(declare-fun dc_205 () (_ BitVec 1))
(declare-fun dc_204 () (_ BitVec 1))
(declare-fun dc_203 () (_ BitVec 63))
(declare-fun dc_202 () (_ BitVec 64))
(declare-fun dc_201 () (_ BitVec 1))
(declare-fun dc_200 () (_ BitVec 62))
(declare-fun dc_199 () (_ BitVec 1))
(declare-fun dc_198 () (_ BitVec 1))
(declare-fun dc_197 () (_ BitVec 1))
(declare-fun dc_196 () (_ BitVec 63))
(declare-fun dc_195 () (_ BitVec 64))
(declare-fun dc_194 () (_ BitVec 1))
(declare-fun dc_193 () (_ BitVec 62))
(declare-fun dc_192 () (_ BitVec 1))
(declare-fun dc_191 () (_ BitVec 1))
(declare-fun dc_190 () (_ BitVec 1))
(declare-fun dc_189 () (_ BitVec 63))
(declare-fun dc_188 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_25 (bvadd (bvadd neg_f_0_low60_20_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_44 (bvadd (bvadd neg_g_0_low60_20_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_0_1)) (bvsle neg_f_0_low60_20_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_0_1)) (bvsle neg_g_0_low60_20_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_25) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_188 ((_ extract 63 1) x8_44)) (= x8_lo_21 ((_ extract 0 0) x8_44))))
(assert (= ne_21 (bvand x8_lo_21 #b1)))
(assert (= x10_43 (ite (= ne_21 #b1) x7_25 #x0000000000000000)))
(assert (and (= ge_61 ((_ extract 63 63) x3_41)) (= dc_189 ((_ extract 62 0) x3_41))))
(assert (= ge_62 (bvnot ge_61)))
(assert (= ge_63 (ite (= ne_21 #b1) ge_62 #b0)))
(assert (and (= dc_190 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_42 (ite (= ge_63 #b1) x3_neg_21 x3_41)))
(assert (and (= dc_191 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_44 (ite (= ge_63 #b1) x10_neg_21 x10_43)))
(assert (= x7_26 (ite (= ge_63 #b1) x8_44 x7_25)))
(assert (and (= dc_192 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44)))) (= x8_45 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44))))))
(assert (= x3_43 (bvadd x3_42 #x0000000000000002)))
(assert (and (= dc_193 ((_ extract 63 2) x8_45)) (= x8_lo_22 ((_ extract 1 0) x8_45))))
(assert (and (= x8_target_20 ((_ extract 1 1) x8_lo_22)) (= dc_194 ((_ extract 0 0) x8_lo_22))))
(assert (= ne_22 (bvand x8_target_20 #b1)))
(assert (and (= x8_46 ((_ sign_extend 1) ((_ extract 63 1) x8_45))) (= dc_195 ((_ zero_extend 63) ((_ extract 0 0) x8_45)))))
(assert true)
(assert (= x10_45 (ite (= ne_22 #b1) x7_26 #x0000000000000000)))
(assert (and (= ge_64 ((_ extract 63 63) x3_43)) (= dc_196 ((_ extract 62 0) x3_43))))
(assert (= ge_65 (bvnot ge_64)))
(assert (= ge_66 (ite (= ne_22 #b1) ge_65 #b0)))
(assert (and (= dc_197 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_44 (ite (= ge_66 #b1) x3_neg_22 x3_43)))
(assert (and (= dc_198 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_46 (ite (= ge_66 #b1) x10_neg_22 x10_45)))
(assert (= x7_27 (ite (= ge_66 #b1) x8_46 x7_26)))
(assert (and (= dc_199 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46)))) (= x8_47 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46))))))
(assert (= x3_45 (bvadd x3_44 #x0000000000000002)))
(assert (and (= dc_200 ((_ extract 63 2) x8_47)) (= x8_lo_23 ((_ extract 1 0) x8_47))))
(assert (and (= x8_target_21 ((_ extract 1 1) x8_lo_23)) (= dc_201 ((_ extract 0 0) x8_lo_23))))
(assert (= ne_23 (bvand x8_target_21 #b1)))
(assert (and (= x8_48 ((_ sign_extend 1) ((_ extract 63 1) x8_47))) (= dc_202 ((_ zero_extend 63) ((_ extract 0 0) x8_47)))))
(assert true)
(assert (= x10_47 (ite (= ne_23 #b1) x7_27 #x0000000000000000)))
(assert (and (= ge_67 ((_ extract 63 63) x3_45)) (= dc_203 ((_ extract 62 0) x3_45))))
(assert (= ge_68 (bvnot ge_67)))
(assert (= ge_69 (ite (= ne_23 #b1) ge_68 #b0)))
(assert (and (= dc_204 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_46 (ite (= ge_69 #b1) x3_neg_23 x3_45)))
(assert (and (= dc_205 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_48 (ite (= ge_69 #b1) x10_neg_23 x10_47)))
(assert (= x7_28 (ite (= ge_69 #b1) x8_48 x7_27)))
(assert (and (= dc_206 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48)))) (= x8_49 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48))))))
(assert (= x3_47 (bvadd x3_46 #x0000000000000002)))
(assert (and (= dc_207 ((_ extract 63 2) x8_49)) (= x8_lo_24 ((_ extract 1 0) x8_49))))
(assert (and (= x8_target_22 ((_ extract 1 1) x8_lo_24)) (= dc_208 ((_ extract 0 0) x8_lo_24))))
(assert (= ne_24 (bvand x8_target_22 #b1)))
(assert (and (= x8_50 ((_ sign_extend 1) ((_ extract 63 1) x8_49))) (= dc_209 ((_ zero_extend 63) ((_ extract 0 0) x8_49)))))
(assert true)
(assert (= x10_49 (ite (= ne_24 #b1) x7_28 #x0000000000000000)))
(assert (and (= ge_70 ((_ extract 63 63) x3_47)) (= dc_210 ((_ extract 62 0) x3_47))))
(assert (= ge_71 (bvnot ge_70)))
(assert (= ge_72 (ite (= ne_24 #b1) ge_71 #b0)))
(assert (and (= dc_211 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_47))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_24 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_47))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_48 (ite (= ge_72 #b1) x3_neg_24 x3_47)))
(assert (and (= dc_212 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_49))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_24 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_49))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_50 (ite (= ge_72 #b1) x10_neg_24 x10_49)))
(assert (= x7_29 (ite (= ge_72 #b1) x8_50 x7_28)))
(assert (and (= dc_213 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_50) ((_ zero_extend 1) x10_50)))) (= x8_51 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_50) ((_ zero_extend 1) x10_50))))))
(assert (= x3_49 (bvadd x3_48 #x0000000000000002)))
(assert (and (= dc_214 ((_ extract 63 2) x8_51)) (= x8_lo_25 ((_ extract 1 0) x8_51))))
(assert (and (= x8_target_23 ((_ extract 1 1) x8_lo_25)) (= dc_215 ((_ extract 0 0) x8_lo_25))))
(assert (= ne_25 (bvand x8_target_23 #b1)))
(assert (and (= x8_52 ((_ sign_extend 1) ((_ extract 63 1) x8_51))) (= dc_216 ((_ zero_extend 63) ((_ extract 0 0) x8_51)))))
(assert true)
(assert (= x10_51 (ite (= ne_25 #b1) x7_29 #x0000000000000000)))
(assert (and (= ge_73 ((_ extract 63 63) x3_49)) (= dc_217 ((_ extract 62 0) x3_49))))
(assert (= ge_74 (bvnot ge_73)))
(assert (= ge_75 (ite (= ne_25 #b1) ge_74 #b0)))
(assert (and (= dc_218 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_49))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_25 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_49))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_50 (ite (= ge_75 #b1) x3_neg_25 x3_49)))
(assert (and (= dc_219 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_51))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_25 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_51))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_52 (ite (= ge_75 #b1) x10_neg_25 x10_51)))
(assert (= x7_30 (ite (= ge_75 #b1) x8_52 x7_29)))
(assert (and (= dc_220 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_52) ((_ zero_extend 1) x10_52)))) (= x8_53 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_52) ((_ zero_extend 1) x10_52))))))
(assert (= x3_51 (bvadd x3_50 #x0000000000000002)))
(assert (and (= dc_221 ((_ extract 63 2) x8_53)) (= x8_lo_26 ((_ extract 1 0) x8_53))))
(assert (and (= x8_target_24 ((_ extract 1 1) x8_lo_26)) (= dc_222 ((_ extract 0 0) x8_lo_26))))
(assert (= ne_26 (bvand x8_target_24 #b1)))
(assert (and (= x8_54 ((_ sign_extend 1) ((_ extract 63 1) x8_53))) (= dc_223 ((_ zero_extend 63) ((_ extract 0 0) x8_53)))))
(assert true)
(assert (= x10_53 (ite (= ne_26 #b1) x7_30 #x0000000000000000)))
(assert (and (= ge_76 ((_ extract 63 63) x3_51)) (= dc_224 ((_ extract 62 0) x3_51))))
(assert (= ge_77 (bvnot ge_76)))
(assert (= ge_78 (ite (= ne_26 #b1) ge_77 #b0)))
(assert (and (= dc_225 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_51))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_26 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_51))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_52 (ite (= ge_78 #b1) x3_neg_26 x3_51)))
(assert (and (= dc_226 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_53))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_26 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_53))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_54 (ite (= ge_78 #b1) x10_neg_26 x10_53)))
(assert (= x7_31 (ite (= ge_78 #b1) x8_54 x7_30)))
(assert (and (= dc_227 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_54) ((_ zero_extend 1) x10_54)))) (= x8_55 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_54) ((_ zero_extend 1) x10_54))))))
(assert (= x3_53 (bvadd x3_52 #x0000000000000002)))
(assert (and (= dc_228 ((_ extract 63 2) x8_55)) (= x8_lo_27 ((_ extract 1 0) x8_55))))
(assert (and (= x8_target_25 ((_ extract 1 1) x8_lo_27)) (= dc_229 ((_ extract 0 0) x8_lo_27))))
(assert (= ne_27 (bvand x8_target_25 #b1)))
(assert (and (= x8_56 ((_ sign_extend 1) ((_ extract 63 1) x8_55))) (= dc_230 ((_ zero_extend 63) ((_ extract 0 0) x8_55)))))
(assert true)
(assert (= x10_55 (ite (= ne_27 #b1) x7_31 #x0000000000000000)))
(assert (and (= ge_79 ((_ extract 63 63) x3_53)) (= dc_231 ((_ extract 62 0) x3_53))))
(assert (= ge_80 (bvnot ge_79)))
(assert (= ge_81 (ite (= ne_27 #b1) ge_80 #b0)))
(assert (and (= dc_232 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_53))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_27 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_53))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_54 (ite (= ge_81 #b1) x3_neg_27 x3_53)))
(assert (and (= dc_233 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_55))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_27 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_55))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_56 (ite (= ge_81 #b1) x10_neg_27 x10_55)))
(assert (= x7_32 (ite (= ge_81 #b1) x8_56 x7_31)))
(assert (and (= dc_234 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_56) ((_ zero_extend 1) x10_56)))) (= x8_57 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_56) ((_ zero_extend 1) x10_56))))))
(assert (= x3_55 (bvadd x3_54 #x0000000000000002)))
(assert (and (= dc_235 ((_ extract 63 2) x8_57)) (= x8_lo_28 ((_ extract 1 0) x8_57))))
(assert (and (= x8_target_26 ((_ extract 1 1) x8_lo_28)) (= dc_236 ((_ extract 0 0) x8_lo_28))))
(assert (= ne_28 (bvand x8_target_26 #b1)))
(assert (and (= x8_58 ((_ sign_extend 1) ((_ extract 63 1) x8_57))) (= dc_237 ((_ zero_extend 63) ((_ extract 0 0) x8_57)))))
(assert true)
(assert (= x10_57 (ite (= ne_28 #b1) x7_32 #x0000000000000000)))
(assert (and (= ge_82 ((_ extract 63 63) x3_55)) (= dc_238 ((_ extract 62 0) x3_55))))
(assert (= ge_83 (bvnot ge_82)))
(assert (= ge_84 (ite (= ne_28 #b1) ge_83 #b0)))
(assert (and (= dc_239 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_55))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_28 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_55))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_56 (ite (= ge_84 #b1) x3_neg_28 x3_55)))
(assert (and (= dc_240 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_57))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_28 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_57))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_58 (ite (= ge_84 #b1) x10_neg_28 x10_57)))
(assert (= x7_33 (ite (= ge_84 #b1) x8_58 x7_32)))
(assert (and (= dc_241 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_58) ((_ zero_extend 1) x10_58)))) (= x8_59 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_58) ((_ zero_extend 1) x10_58))))))
(assert (= x3_57 (bvadd x3_56 #x0000000000000002)))
(assert (and (= dc_242 ((_ extract 63 2) x8_59)) (= x8_lo_29 ((_ extract 1 0) x8_59))))
(assert (and (= x8_target_27 ((_ extract 1 1) x8_lo_29)) (= dc_243 ((_ extract 0 0) x8_lo_29))))
(assert (= ne_29 (bvand x8_target_27 #b1)))
(assert (and (= x8_60 ((_ sign_extend 1) ((_ extract 63 1) x8_59))) (= dc_244 ((_ zero_extend 63) ((_ extract 0 0) x8_59)))))
(assert true)
(assert (= x10_59 (ite (= ne_29 #b1) x7_33 #x0000000000000000)))
(assert (and (= ge_85 ((_ extract 63 63) x3_57)) (= dc_245 ((_ extract 62 0) x3_57))))
(assert (= ge_86 (bvnot ge_85)))
(assert (= ge_87 (ite (= ne_29 #b1) ge_86 #b0)))
(assert (and (= dc_246 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_57))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_29 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_57))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_58 (ite (= ge_87 #b1) x3_neg_29 x3_57)))
(assert (and (= dc_247 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_59))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_29 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_59))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_60 (ite (= ge_87 #b1) x10_neg_29 x10_59)))
(assert (= x7_34 (ite (= ge_87 #b1) x8_60 x7_33)))
(assert (and (= dc_248 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_60) ((_ zero_extend 1) x10_60)))) (= x8_61 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_60) ((_ zero_extend 1) x10_60))))))
(assert (= x3_59 (bvadd x3_58 #x0000000000000002)))
(assert (and (= dc_249 ((_ extract 63 2) x8_61)) (= x8_lo_30 ((_ extract 1 0) x8_61))))
(assert (and (= x8_target_28 ((_ extract 1 1) x8_lo_30)) (= dc_250 ((_ extract 0 0) x8_lo_30))))
(assert (= ne_30 (bvand x8_target_28 #b1)))
(assert (and (= x8_62 ((_ sign_extend 1) ((_ extract 63 1) x8_61))) (= dc_251 ((_ zero_extend 63) ((_ extract 0 0) x8_61)))))
(assert true)
(assert (= x10_61 (ite (= ne_30 #b1) x7_34 #x0000000000000000)))
(assert (and (= ge_88 ((_ extract 63 63) x3_59)) (= dc_252 ((_ extract 62 0) x3_59))))
(assert (= ge_89 (bvnot ge_88)))
(assert (= ge_90 (ite (= ne_30 #b1) ge_89 #b0)))
(assert (and (= dc_253 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_59))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_30 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_59))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_60 (ite (= ge_90 #b1) x3_neg_30 x3_59)))
(assert (and (= dc_254 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_61))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_30 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_61))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_62 (ite (= ge_90 #b1) x10_neg_30 x10_61)))
(assert (= x7_35 (ite (= ge_90 #b1) x8_62 x7_34)))
(assert (and (= dc_255 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_62) ((_ zero_extend 1) x10_62)))) (= x8_63 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_62) ((_ zero_extend 1) x10_62))))))
(assert (= x3_61 (bvadd x3_60 #x0000000000000002)))
(assert (and (= dc_256 ((_ extract 63 2) x8_63)) (= x8_lo_31 ((_ extract 1 0) x8_63))))
(assert (and (= x8_target_29 ((_ extract 1 1) x8_lo_31)) (= dc_257 ((_ extract 0 0) x8_lo_31))))
(assert (= ne_31 (bvand x8_target_29 #b1)))
(assert (and (= x8_64 ((_ sign_extend 1) ((_ extract 63 1) x8_63))) (= dc_258 ((_ zero_extend 63) ((_ extract 0 0) x8_63)))))
(assert true)
(assert (= x10_63 (ite (= ne_31 #b1) x7_35 #x0000000000000000)))
(assert (and (= ge_91 ((_ extract 63 63) x3_61)) (= dc_259 ((_ extract 62 0) x3_61))))
(assert (= ge_92 (bvnot ge_91)))
(assert (= ge_93 (ite (= ne_31 #b1) ge_92 #b0)))
(assert (and (= dc_260 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_61))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_31 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_61))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_62 (ite (= ge_93 #b1) x3_neg_31 x3_61)))
(assert (and (= dc_261 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_63))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_31 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_63))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_64 (ite (= ge_93 #b1) x10_neg_31 x10_63)))
(assert (= x7_36 (ite (= ge_93 #b1) x8_64 x7_35)))
(assert (and (= dc_262 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_64) ((_ zero_extend 1) x10_64)))) (= x8_65 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_64) ((_ zero_extend 1) x10_64))))))
(assert (= x3_63 (bvadd x3_62 #x0000000000000002)))
(assert (and (= dc_263 ((_ extract 63 2) x8_65)) (= x8_lo_32 ((_ extract 1 0) x8_65))))
(assert (and (= x8_target_30 ((_ extract 1 1) x8_lo_32)) (= dc_264 ((_ extract 0 0) x8_lo_32))))
(assert (= ne_32 (bvand x8_target_30 #b1)))
(assert (and (= x8_66 ((_ sign_extend 1) ((_ extract 63 1) x8_65))) (= dc_265 ((_ zero_extend 63) ((_ extract 0 0) x8_65)))))
(assert true)
(assert (= x10_65 (ite (= ne_32 #b1) x7_36 #x0000000000000000)))
(assert (and (= ge_94 ((_ extract 63 63) x3_63)) (= dc_266 ((_ extract 62 0) x3_63))))
(assert (= ge_95 (bvnot ge_94)))
(assert (= ge_96 (ite (= ne_32 #b1) ge_95 #b0)))
(assert (and (= dc_267 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_63))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_32 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_63))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_64 (ite (= ge_96 #b1) x3_neg_32 x3_63)))
(assert (and (= dc_268 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_65))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_32 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_65))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_66 (ite (= ge_96 #b1) x10_neg_32 x10_65)))
(assert (= x7_37 (ite (= ge_96 #b1) x8_66 x7_36)))
(assert (and (= dc_269 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_66) ((_ zero_extend 1) x10_66)))) (= x8_67 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_66) ((_ zero_extend 1) x10_66))))))
(assert (= x3_65 (bvadd x3_64 #x0000000000000002)))
(assert (and (= dc_270 ((_ extract 63 2) x8_67)) (= x8_lo_33 ((_ extract 1 0) x8_67))))
(assert (and (= x8_target_31 ((_ extract 1 1) x8_lo_33)) (= dc_271 ((_ extract 0 0) x8_lo_33))))
(assert (= ne_33 (bvand x8_target_31 #b1)))
(assert (and (= x8_68 ((_ sign_extend 1) ((_ extract 63 1) x8_67))) (= dc_272 ((_ zero_extend 63) ((_ extract 0 0) x8_67)))))
(assert true)
(assert (= x10_67 (ite (= ne_33 #b1) x7_37 #x0000000000000000)))
(assert (and (= ge_97 ((_ extract 63 63) x3_65)) (= dc_273 ((_ extract 62 0) x3_65))))
(assert (= ge_98 (bvnot ge_97)))
(assert (= ge_99 (ite (= ne_33 #b1) ge_98 #b0)))
(assert (and (= dc_274 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_65))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_33 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_65))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_66 (ite (= ge_99 #b1) x3_neg_33 x3_65)))
(assert (and (= dc_275 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_67))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_33 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_67))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_68 (ite (= ge_99 #b1) x10_neg_33 x10_67)))
(assert (= x7_38 (ite (= ge_99 #b1) x8_68 x7_37)))
(assert (and (= dc_276 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_68) ((_ zero_extend 1) x10_68)))) (= x8_69 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_68) ((_ zero_extend 1) x10_68))))))
(assert (= x3_67 (bvadd x3_66 #x0000000000000002)))
(assert (and (= dc_277 ((_ extract 63 2) x8_69)) (= x8_lo_34 ((_ extract 1 0) x8_69))))
(assert (and (= x8_target_32 ((_ extract 1 1) x8_lo_34)) (= dc_278 ((_ extract 0 0) x8_lo_34))))
(assert (= ne_34 (bvand x8_target_32 #b1)))
(assert (and (= x8_70 ((_ sign_extend 1) ((_ extract 63 1) x8_69))) (= dc_279 ((_ zero_extend 63) ((_ extract 0 0) x8_69)))))
(assert true)
(assert (= x10_69 (ite (= ne_34 #b1) x7_38 #x0000000000000000)))
(assert (and (= ge_100 ((_ extract 63 63) x3_67)) (= dc_280 ((_ extract 62 0) x3_67))))
(assert (= ge_101 (bvnot ge_100)))
(assert (= ge_102 (ite (= ne_34 #b1) ge_101 #b0)))
(assert (and (= dc_281 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_67))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_34 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_67))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_68 (ite (= ge_102 #b1) x3_neg_34 x3_67)))
(assert (and (= dc_282 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_69))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_34 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_69))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_70 (ite (= ge_102 #b1) x10_neg_34 x10_69)))
(assert (= x7_39 (ite (= ge_102 #b1) x8_70 x7_38)))
(assert (and (= dc_283 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_70) ((_ zero_extend 1) x10_70)))) (= x8_71 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_70) ((_ zero_extend 1) x10_70))))))
(assert (= x3_69 (bvadd x3_68 #x0000000000000002)))
(assert (and (= dc_284 ((_ extract 63 2) x8_71)) (= x8_lo_35 ((_ extract 1 0) x8_71))))
(assert (and (= x8_target_33 ((_ extract 1 1) x8_lo_35)) (= dc_285 ((_ extract 0 0) x8_lo_35))))
(assert (= ne_35 (bvand x8_target_33 #b1)))
(assert (and (= x8_72 ((_ sign_extend 1) ((_ extract 63 1) x8_71))) (= dc_286 ((_ zero_extend 63) ((_ extract 0 0) x8_71)))))
(assert true)
(assert (= x10_71 (ite (= ne_35 #b1) x7_39 #x0000000000000000)))
(assert (and (= ge_103 ((_ extract 63 63) x3_69)) (= dc_287 ((_ extract 62 0) x3_69))))
(assert (= ge_104 (bvnot ge_103)))
(assert (= ge_105 (ite (= ne_35 #b1) ge_104 #b0)))
(assert (and (= dc_288 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_69))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_35 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_69))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_70 (ite (= ge_105 #b1) x3_neg_35 x3_69)))
(assert (and (= dc_289 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_71))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_35 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_71))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_72 (ite (= ge_105 #b1) x10_neg_35 x10_71)))
(assert (= x7_40 (ite (= ge_105 #b1) x8_72 x7_39)))
(assert (and (= dc_290 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_72) ((_ zero_extend 1) x10_72)))) (= x8_73 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_72) ((_ zero_extend 1) x10_72))))))
(assert (= x3_71 (bvadd x3_70 #x0000000000000002)))
(assert (and (= dc_291 ((_ extract 63 2) x8_73)) (= x8_lo_36 ((_ extract 1 0) x8_73))))
(assert (and (= x8_target_34 ((_ extract 1 1) x8_lo_36)) (= dc_292 ((_ extract 0 0) x8_lo_36))))
(assert (= ne_36 (bvand x8_target_34 #b1)))
(assert (and (= x8_74 ((_ sign_extend 1) ((_ extract 63 1) x8_73))) (= dc_293 ((_ zero_extend 63) ((_ extract 0 0) x8_73)))))
(assert true)
(assert (= x10_73 (ite (= ne_36 #b1) x7_40 #x0000000000000000)))
(assert (and (= ge_106 ((_ extract 63 63) x3_71)) (= dc_294 ((_ extract 62 0) x3_71))))
(assert (= ge_107 (bvnot ge_106)))
(assert (= ge_108 (ite (= ne_36 #b1) ge_107 #b0)))
(assert (and (= dc_295 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_71))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_36 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_71))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_72 (ite (= ge_108 #b1) x3_neg_36 x3_71)))
(assert (and (= dc_296 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_73))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_36 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_73))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_74 (ite (= ge_108 #b1) x10_neg_36 x10_73)))
(assert (= x7_41 (ite (= ge_108 #b1) x8_74 x7_40)))
(assert (and (= dc_297 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_74) ((_ zero_extend 1) x10_74)))) (= x8_75 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_74) ((_ zero_extend 1) x10_74))))))
(assert (= x3_73 (bvadd x3_72 #x0000000000000002)))
(assert (and (= dc_298 ((_ extract 63 2) x8_75)) (= x8_lo_37 ((_ extract 1 0) x8_75))))
(assert (and (= x8_target_35 ((_ extract 1 1) x8_lo_37)) (= dc_299 ((_ extract 0 0) x8_lo_37))))
(assert (= ne_37 (bvand x8_target_35 #b1)))
(assert (and (= x8_76 ((_ sign_extend 1) ((_ extract 63 1) x8_75))) (= dc_300 ((_ zero_extend 63) ((_ extract 0 0) x8_75)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_74) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_41 x7_40)) (= (bvmul x8_76 #x0000000000000002) x8_74)) (= x3_73 (bvadd #x0000000000000002 x3_71))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_74) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_71 #x0000000000000000)) (= x7_41 x7_40)) (= (bvmul x8_76 #x0000000000000002) (bvadd x8_74 x7_40))) (= x3_73 (bvadd #x0000000000000002 x3_71)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_74) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_71 #x0000000000000000)) (= x7_41 x8_74)) (= (bvmul x8_76 #x0000000000000002) (bvsub x8_74 x7_40))) (= x3_73 (bvsub #x0000000000000002 x3_71))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_f1ca9a.smt2
Execution time of boolector: 1.1056 seconds
OUTPUT FROM boolector:
unsat

=== Cut #7 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #7
; Range assertion #59: x15_5 = u_20_40_2
; Range condition: x15_5 = u_20_40_2
; Output file: /tmp/outputqfbv_334712.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_82 () (_ BitVec 64))
(declare-fun x7_44 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_79 () (_ BitVec 64))
(declare-fun x20_3 () (_ BitVec 64))
(declare-fun x20_2 () (_ BitVec 64))
(declare-fun x20_1 () (_ BitVec 64))
(declare-fun x17_5 () (_ BitVec 64))
(declare-fun x17_4 () (_ BitVec 64))
(declare-fun x17_3 () (_ BitVec 64))
(declare-fun x17_2 () (_ BitVec 64))
(declare-fun x17_1 () (_ BitVec 64))
(declare-fun x16_3 () (_ BitVec 64))
(declare-fun x16_2 () (_ BitVec 64))
(declare-fun x16_1 () (_ BitVec 64))
(declare-fun x15_5 () (_ BitVec 64))
(declare-fun x15_4 () (_ BitVec 64))
(declare-fun x15_3 () (_ BitVec 64))
(declare-fun x15_2 () (_ BitVec 64))
(declare-fun x15_1 () (_ BitVec 64))
(declare-fun v_20_40_2 () (_ BitVec 64))
(declare-fun u_20_40_2 () (_ BitVec 64))
(declare-fun s_20_40_2 () (_ BitVec 64))
(declare-fun r_20_40_2 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_20_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_40_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_20_1 () (_ BitVec 64))
(declare-fun dcH_8 () (_ BitVec 64))
(declare-fun dcH_7 () (_ BitVec 64))
(declare-fun dc_323 () (_ BitVec 64))
(declare-fun dc_322 () (_ BitVec 64))
(declare-fun dc_321 () (_ BitVec 64))
(declare-fun dc_320 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_44 (bvadd (bvadd neg_f_0_low60_20_low20_20_1 (bvmul u_20_40_2 #x0000000000200000)) (bvmul v_20_40_2 #x0000040000000000))) (= x8_82 (bvadd (bvadd neg_g_0_low60_20_low20_20_1 (bvmul r_20_40_2 #x0000000000200000)) (bvmul s_20_40_2 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_20_1)) (bvsle neg_f_0_low60_20_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_20_1)) (bvsle neg_g_0_low60_20_low20_20_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) neg_f_0_low60_40_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_79) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFB1 x3_79)) (bvsle x3_79 #x0000000000000051)) (bvsle #xFFFFFFFFFFF00000 u_20_40_2)) (bvsle u_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 v_20_40_2)) (bvsle v_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 r_20_40_2)) (bvsle r_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 s_20_40_2)) (bvsle s_20_40_2 #x00000000000FFFFF)) (= x6_2 #x0000020000100000)))
(assert (= x16_1 (bvadd x7_44 x6_2)))
(assert (= x16_2 x16_1))
(assert (and (= x16_3 ((_ sign_extend 42) ((_ extract 63 42) x16_2))) (= dc_320 ((_ zero_extend 22) ((_ extract 41 0) x16_2)))))
(assert (= x15_1 (bvadd x7_44 #x0000000000100000)))
(assert (and (= dcH_7 ((_ sign_extend 42) ((_ extract 63 42) x15_1))) (= x15_2 ((_ zero_extend 22) ((_ extract 41 0) x15_1)))))
(assert (= x15_3 (bvshl x15_2 #x0000000000000016)))
(assert (= x15_4 x15_3))
(assert (and (= x15_5 ((_ sign_extend 43) ((_ extract 63 43) x15_4))) (= dc_321 ((_ zero_extend 21) ((_ extract 42 0) x15_4)))))
(assert (= x20_1 (bvadd x8_82 x6_2)))
(assert (= x20_2 x20_1))
(assert (and (= x20_3 ((_ sign_extend 42) ((_ extract 63 42) x20_2))) (= dc_322 ((_ zero_extend 22) ((_ extract 41 0) x20_2)))))
(assert (= x17_1 (bvadd x8_82 #x0000000000100000)))
(assert (and (= dcH_8 ((_ sign_extend 42) ((_ extract 63 42) x17_1))) (= x17_2 ((_ zero_extend 22) ((_ extract 41 0) x17_1)))))
(assert (= x17_3 (bvshl x17_2 #x0000000000000016)))
(assert (= x17_4 x17_3))
(assert (and (= x17_5 ((_ sign_extend 43) ((_ extract 63 43) x17_4))) (= dc_323 ((_ zero_extend 21) ((_ extract 42 0) x17_4)))))
(assert (not (= x15_5 u_20_40_2)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_7040c4.smt2
Execution time of boolector: 0.0046 seconds
OUTPUT FROM boolector:
unsat

=== Cut #7 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #7
; Range assertion #60: x16_3 = v_20_40_2
; Range condition: x16_3 = v_20_40_2
; Output file: /tmp/outputqfbv_ac7d8b.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_82 () (_ BitVec 64))
(declare-fun x7_44 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_79 () (_ BitVec 64))
(declare-fun x20_3 () (_ BitVec 64))
(declare-fun x20_2 () (_ BitVec 64))
(declare-fun x20_1 () (_ BitVec 64))
(declare-fun x17_5 () (_ BitVec 64))
(declare-fun x17_4 () (_ BitVec 64))
(declare-fun x17_3 () (_ BitVec 64))
(declare-fun x17_2 () (_ BitVec 64))
(declare-fun x17_1 () (_ BitVec 64))
(declare-fun x16_3 () (_ BitVec 64))
(declare-fun x16_2 () (_ BitVec 64))
(declare-fun x16_1 () (_ BitVec 64))
(declare-fun x15_5 () (_ BitVec 64))
(declare-fun x15_4 () (_ BitVec 64))
(declare-fun x15_3 () (_ BitVec 64))
(declare-fun x15_2 () (_ BitVec 64))
(declare-fun x15_1 () (_ BitVec 64))
(declare-fun v_20_40_2 () (_ BitVec 64))
(declare-fun u_20_40_2 () (_ BitVec 64))
(declare-fun s_20_40_2 () (_ BitVec 64))
(declare-fun r_20_40_2 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_20_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_40_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_20_1 () (_ BitVec 64))
(declare-fun dcH_8 () (_ BitVec 64))
(declare-fun dcH_7 () (_ BitVec 64))
(declare-fun dc_323 () (_ BitVec 64))
(declare-fun dc_322 () (_ BitVec 64))
(declare-fun dc_321 () (_ BitVec 64))
(declare-fun dc_320 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_44 (bvadd (bvadd neg_f_0_low60_20_low20_20_1 (bvmul u_20_40_2 #x0000000000200000)) (bvmul v_20_40_2 #x0000040000000000))) (= x8_82 (bvadd (bvadd neg_g_0_low60_20_low20_20_1 (bvmul r_20_40_2 #x0000000000200000)) (bvmul s_20_40_2 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_20_1)) (bvsle neg_f_0_low60_20_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_20_1)) (bvsle neg_g_0_low60_20_low20_20_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) neg_f_0_low60_40_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_79) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFB1 x3_79)) (bvsle x3_79 #x0000000000000051)) (bvsle #xFFFFFFFFFFF00000 u_20_40_2)) (bvsle u_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 v_20_40_2)) (bvsle v_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 r_20_40_2)) (bvsle r_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 s_20_40_2)) (bvsle s_20_40_2 #x00000000000FFFFF)) (= x6_2 #x0000020000100000)))
(assert (= x16_1 (bvadd x7_44 x6_2)))
(assert (= x16_2 x16_1))
(assert (and (= x16_3 ((_ sign_extend 42) ((_ extract 63 42) x16_2))) (= dc_320 ((_ zero_extend 22) ((_ extract 41 0) x16_2)))))
(assert (= x15_1 (bvadd x7_44 #x0000000000100000)))
(assert (and (= dcH_7 ((_ sign_extend 42) ((_ extract 63 42) x15_1))) (= x15_2 ((_ zero_extend 22) ((_ extract 41 0) x15_1)))))
(assert (= x15_3 (bvshl x15_2 #x0000000000000016)))
(assert (= x15_4 x15_3))
(assert (and (= x15_5 ((_ sign_extend 43) ((_ extract 63 43) x15_4))) (= dc_321 ((_ zero_extend 21) ((_ extract 42 0) x15_4)))))
(assert (= x20_1 (bvadd x8_82 x6_2)))
(assert (= x20_2 x20_1))
(assert (and (= x20_3 ((_ sign_extend 42) ((_ extract 63 42) x20_2))) (= dc_322 ((_ zero_extend 22) ((_ extract 41 0) x20_2)))))
(assert (= x17_1 (bvadd x8_82 #x0000000000100000)))
(assert (and (= dcH_8 ((_ sign_extend 42) ((_ extract 63 42) x17_1))) (= x17_2 ((_ zero_extend 22) ((_ extract 41 0) x17_1)))))
(assert (= x17_3 (bvshl x17_2 #x0000000000000016)))
(assert (= x17_4 x17_3))
(assert (and (= x17_5 ((_ sign_extend 43) ((_ extract 63 43) x17_4))) (= dc_323 ((_ zero_extend 21) ((_ extract 42 0) x17_4)))))
(assert true)
(assert (not (= x16_3 v_20_40_2)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_cb22af.smt2
Execution time of boolector: 0.0055 seconds
OUTPUT FROM boolector:
unsat

=== Cut #7 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #7
; Range assertion #61: x17_5 = r_20_40_2
; Range condition: x17_5 = r_20_40_2
; Output file: /tmp/outputqfbv_61afc8.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_82 () (_ BitVec 64))
(declare-fun x7_44 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_79 () (_ BitVec 64))
(declare-fun x20_3 () (_ BitVec 64))
(declare-fun x20_2 () (_ BitVec 64))
(declare-fun x20_1 () (_ BitVec 64))
(declare-fun x17_5 () (_ BitVec 64))
(declare-fun x17_4 () (_ BitVec 64))
(declare-fun x17_3 () (_ BitVec 64))
(declare-fun x17_2 () (_ BitVec 64))
(declare-fun x17_1 () (_ BitVec 64))
(declare-fun x16_3 () (_ BitVec 64))
(declare-fun x16_2 () (_ BitVec 64))
(declare-fun x16_1 () (_ BitVec 64))
(declare-fun x15_5 () (_ BitVec 64))
(declare-fun x15_4 () (_ BitVec 64))
(declare-fun x15_3 () (_ BitVec 64))
(declare-fun x15_2 () (_ BitVec 64))
(declare-fun x15_1 () (_ BitVec 64))
(declare-fun v_20_40_2 () (_ BitVec 64))
(declare-fun u_20_40_2 () (_ BitVec 64))
(declare-fun s_20_40_2 () (_ BitVec 64))
(declare-fun r_20_40_2 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_20_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_40_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_20_1 () (_ BitVec 64))
(declare-fun dcH_8 () (_ BitVec 64))
(declare-fun dcH_7 () (_ BitVec 64))
(declare-fun dc_323 () (_ BitVec 64))
(declare-fun dc_322 () (_ BitVec 64))
(declare-fun dc_321 () (_ BitVec 64))
(declare-fun dc_320 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_44 (bvadd (bvadd neg_f_0_low60_20_low20_20_1 (bvmul u_20_40_2 #x0000000000200000)) (bvmul v_20_40_2 #x0000040000000000))) (= x8_82 (bvadd (bvadd neg_g_0_low60_20_low20_20_1 (bvmul r_20_40_2 #x0000000000200000)) (bvmul s_20_40_2 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_20_1)) (bvsle neg_f_0_low60_20_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_20_1)) (bvsle neg_g_0_low60_20_low20_20_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) neg_f_0_low60_40_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_79) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFB1 x3_79)) (bvsle x3_79 #x0000000000000051)) (bvsle #xFFFFFFFFFFF00000 u_20_40_2)) (bvsle u_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 v_20_40_2)) (bvsle v_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 r_20_40_2)) (bvsle r_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 s_20_40_2)) (bvsle s_20_40_2 #x00000000000FFFFF)) (= x6_2 #x0000020000100000)))
(assert (= x16_1 (bvadd x7_44 x6_2)))
(assert (= x16_2 x16_1))
(assert (and (= x16_3 ((_ sign_extend 42) ((_ extract 63 42) x16_2))) (= dc_320 ((_ zero_extend 22) ((_ extract 41 0) x16_2)))))
(assert (= x15_1 (bvadd x7_44 #x0000000000100000)))
(assert (and (= dcH_7 ((_ sign_extend 42) ((_ extract 63 42) x15_1))) (= x15_2 ((_ zero_extend 22) ((_ extract 41 0) x15_1)))))
(assert (= x15_3 (bvshl x15_2 #x0000000000000016)))
(assert (= x15_4 x15_3))
(assert (and (= x15_5 ((_ sign_extend 43) ((_ extract 63 43) x15_4))) (= dc_321 ((_ zero_extend 21) ((_ extract 42 0) x15_4)))))
(assert (= x20_1 (bvadd x8_82 x6_2)))
(assert (= x20_2 x20_1))
(assert (and (= x20_3 ((_ sign_extend 42) ((_ extract 63 42) x20_2))) (= dc_322 ((_ zero_extend 22) ((_ extract 41 0) x20_2)))))
(assert (= x17_1 (bvadd x8_82 #x0000000000100000)))
(assert (and (= dcH_8 ((_ sign_extend 42) ((_ extract 63 42) x17_1))) (= x17_2 ((_ zero_extend 22) ((_ extract 41 0) x17_1)))))
(assert (= x17_3 (bvshl x17_2 #x0000000000000016)))
(assert (= x17_4 x17_3))
(assert (and (= x17_5 ((_ sign_extend 43) ((_ extract 63 43) x17_4))) (= dc_323 ((_ zero_extend 21) ((_ extract 42 0) x17_4)))))
(assert true)
(assert true)
(assert (not (= x17_5 r_20_40_2)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_89af41.smt2
Execution time of boolector: 0.0050 seconds
OUTPUT FROM boolector:
unsat

=== Cut #7 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #7
; Range assertion #62: x20_3 = s_20_40_2
; Range condition: x20_3 = s_20_40_2
; Output file: /tmp/outputqfbv_48ee58.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_82 () (_ BitVec 64))
(declare-fun x7_44 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_79 () (_ BitVec 64))
(declare-fun x20_3 () (_ BitVec 64))
(declare-fun x20_2 () (_ BitVec 64))
(declare-fun x20_1 () (_ BitVec 64))
(declare-fun x17_5 () (_ BitVec 64))
(declare-fun x17_4 () (_ BitVec 64))
(declare-fun x17_3 () (_ BitVec 64))
(declare-fun x17_2 () (_ BitVec 64))
(declare-fun x17_1 () (_ BitVec 64))
(declare-fun x16_3 () (_ BitVec 64))
(declare-fun x16_2 () (_ BitVec 64))
(declare-fun x16_1 () (_ BitVec 64))
(declare-fun x15_5 () (_ BitVec 64))
(declare-fun x15_4 () (_ BitVec 64))
(declare-fun x15_3 () (_ BitVec 64))
(declare-fun x15_2 () (_ BitVec 64))
(declare-fun x15_1 () (_ BitVec 64))
(declare-fun v_20_40_2 () (_ BitVec 64))
(declare-fun u_20_40_2 () (_ BitVec 64))
(declare-fun s_20_40_2 () (_ BitVec 64))
(declare-fun r_20_40_2 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_20_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_40_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_20_1 () (_ BitVec 64))
(declare-fun dcH_8 () (_ BitVec 64))
(declare-fun dcH_7 () (_ BitVec 64))
(declare-fun dc_323 () (_ BitVec 64))
(declare-fun dc_322 () (_ BitVec 64))
(declare-fun dc_321 () (_ BitVec 64))
(declare-fun dc_320 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_44 (bvadd (bvadd neg_f_0_low60_20_low20_20_1 (bvmul u_20_40_2 #x0000000000200000)) (bvmul v_20_40_2 #x0000040000000000))) (= x8_82 (bvadd (bvadd neg_g_0_low60_20_low20_20_1 (bvmul r_20_40_2 #x0000000000200000)) (bvmul s_20_40_2 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_20_1)) (bvsle neg_f_0_low60_20_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_20_1)) (bvsle neg_g_0_low60_20_low20_20_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) neg_f_0_low60_40_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_79) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFB1 x3_79)) (bvsle x3_79 #x0000000000000051)) (bvsle #xFFFFFFFFFFF00000 u_20_40_2)) (bvsle u_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 v_20_40_2)) (bvsle v_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 r_20_40_2)) (bvsle r_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 s_20_40_2)) (bvsle s_20_40_2 #x00000000000FFFFF)) (= x6_2 #x0000020000100000)))
(assert (= x16_1 (bvadd x7_44 x6_2)))
(assert (= x16_2 x16_1))
(assert (and (= x16_3 ((_ sign_extend 42) ((_ extract 63 42) x16_2))) (= dc_320 ((_ zero_extend 22) ((_ extract 41 0) x16_2)))))
(assert (= x15_1 (bvadd x7_44 #x0000000000100000)))
(assert (and (= dcH_7 ((_ sign_extend 42) ((_ extract 63 42) x15_1))) (= x15_2 ((_ zero_extend 22) ((_ extract 41 0) x15_1)))))
(assert (= x15_3 (bvshl x15_2 #x0000000000000016)))
(assert (= x15_4 x15_3))
(assert (and (= x15_5 ((_ sign_extend 43) ((_ extract 63 43) x15_4))) (= dc_321 ((_ zero_extend 21) ((_ extract 42 0) x15_4)))))
(assert (= x20_1 (bvadd x8_82 x6_2)))
(assert (= x20_2 x20_1))
(assert (and (= x20_3 ((_ sign_extend 42) ((_ extract 63 42) x20_2))) (= dc_322 ((_ zero_extend 22) ((_ extract 41 0) x20_2)))))
(assert (= x17_1 (bvadd x8_82 #x0000000000100000)))
(assert (and (= dcH_8 ((_ sign_extend 42) ((_ extract 63 42) x17_1))) (= x17_2 ((_ zero_extend 22) ((_ extract 41 0) x17_1)))))
(assert (= x17_3 (bvshl x17_2 #x0000000000000016)))
(assert (= x17_4 x17_3))
(assert (and (= x17_5 ((_ sign_extend 43) ((_ extract 63 43) x17_4))) (= dc_323 ((_ zero_extend 21) ((_ extract 42 0) x17_4)))))
(assert true)
(assert true)
(assert true)
(assert (not (= x20_3 s_20_40_2)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_c0b560.smt2
Execution time of boolector: 0.0055 seconds
OUTPUT FROM boolector:
unsat

=== Cut #8 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #8
; Range assertion #64: mul x9_6 1048576@64 = mul (mul (-1)@64 1048576@64) neg_f_0_low60_40_1
; Range condition: x9_6 * 1048576 = (-1 * 1048576) * neg_f_0_low60_40_1
; Output file: /tmp/outputqfbv_21aabb.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x9_6 () (_ BitVec 64))
(declare-fun x9_5 () (_ BitVec 64))
(declare-fun x9_4 () (_ BitVec 64))
(declare-fun x9_3 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_79 () (_ BitVec 64))
(declare-fun x20_3 () (_ BitVec 64))
(declare-fun x2_9 () (_ BitVec 64))
(declare-fun x2_7 () (_ BitVec 64))
(declare-fun x17_5 () (_ BitVec 64))
(declare-fun x16_3 () (_ BitVec 64))
(declare-fun x15_5 () (_ BitVec 64))
(declare-fun x1_5 () (_ BitVec 64))
(declare-fun tmp_3 () (_ BitVec 64))
(declare-fun neg_f_0_low60_40_1 () (_ BitVec 64))
(declare-fun dcH_11 () (_ BitVec 64))
(declare-fun dcH_10 () (_ BitVec 64))
(declare-fun dc_325 () (_ BitVec 64))
(declare-fun dc_324 () (_ BitVec 1))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) neg_f_0_low60_40_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= (bvsmod (bvsub ((_ zero_extend 1) x3_79) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFB1 x3_79)) (bvsle x3_79 #x0000000000000051)) (bvsle #xFFFFFFFFFFF00000 x15_5)) (bvsle x15_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x16_3)) (bvsle x16_3 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x17_5)) (bvsle x17_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x20_3)) (bvsle x20_3 #x00000000000FFFFF)) (= x6_2 #x0000020000100000)))
(assert (= x1_5 x9_3))
(assert (= x2_9 x2_7))
(assert true)
(assert (and (= dcH_10 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x15_5) ((_ sign_extend 64) x1_5)))) (= x9_4 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x15_5) ((_ sign_extend 64) x1_5))))))
(assert (and (= dcH_11 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_9) ((_ sign_extend 64) x16_3)))) (= tmp_3 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_9) ((_ sign_extend 64) x16_3))))))
(assert (and (= dc_324 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x9_4) ((_ zero_extend 1) tmp_3)))) (= x9_5 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x9_4) ((_ zero_extend 1) tmp_3))))))
(assert true)
(assert (and (= x9_5 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) neg_f_0_low60_40_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x9_5) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x9_6 ((_ zero_extend 20) ((_ extract 63 20) x9_5))) (= dc_325 ((_ zero_extend 44) ((_ extract 19 0) x9_5)))))
(assert (not (= (bvmul x9_6 #x0000000000100000) (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) neg_f_0_low60_40_1))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_edaf97.smt2
Execution time of boolector: 0.0552 seconds
OUTPUT FROM boolector:
unsat

=== Cut #8 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #8
; Range assertion #65: smod (sub (uext x9_6 1) (uext (mul (-1)@64 neg_f_0_low60_40_1) 1)) (uext 17592186044416@64 1) = 0@65
; Range condition: ((x9_6@e1) - ((-1 * neg_f_0_low60_40_1)@e1)) smod (17592186044416@e1) = 0
; Output file: /tmp/outputqfbv_ea7a41.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x9_6 () (_ BitVec 64))
(declare-fun x9_5 () (_ BitVec 64))
(declare-fun x9_4 () (_ BitVec 64))
(declare-fun x9_3 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_79 () (_ BitVec 64))
(declare-fun x20_3 () (_ BitVec 64))
(declare-fun x2_9 () (_ BitVec 64))
(declare-fun x2_7 () (_ BitVec 64))
(declare-fun x17_5 () (_ BitVec 64))
(declare-fun x16_3 () (_ BitVec 64))
(declare-fun x15_5 () (_ BitVec 64))
(declare-fun x1_5 () (_ BitVec 64))
(declare-fun tmp_3 () (_ BitVec 64))
(declare-fun neg_f_0_low60_40_1 () (_ BitVec 64))
(declare-fun dcH_11 () (_ BitVec 64))
(declare-fun dcH_10 () (_ BitVec 64))
(declare-fun dc_325 () (_ BitVec 64))
(declare-fun dc_324 () (_ BitVec 1))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) neg_f_0_low60_40_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= (bvsmod (bvsub ((_ zero_extend 1) x3_79) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFB1 x3_79)) (bvsle x3_79 #x0000000000000051)) (bvsle #xFFFFFFFFFFF00000 x15_5)) (bvsle x15_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x16_3)) (bvsle x16_3 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x17_5)) (bvsle x17_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x20_3)) (bvsle x20_3 #x00000000000FFFFF)) (= x6_2 #x0000020000100000)))
(assert (= x1_5 x9_3))
(assert (= x2_9 x2_7))
(assert true)
(assert (and (= dcH_10 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x15_5) ((_ sign_extend 64) x1_5)))) (= x9_4 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x15_5) ((_ sign_extend 64) x1_5))))))
(assert (and (= dcH_11 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_9) ((_ sign_extend 64) x16_3)))) (= tmp_3 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_9) ((_ sign_extend 64) x16_3))))))
(assert (and (= dc_324 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x9_4) ((_ zero_extend 1) tmp_3)))) (= x9_5 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x9_4) ((_ zero_extend 1) tmp_3))))))
(assert true)
(assert (and (= x9_5 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) neg_f_0_low60_40_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x9_5) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x9_6 ((_ zero_extend 20) ((_ extract 63 20) x9_5))) (= dc_325 ((_ zero_extend 44) ((_ extract 19 0) x9_5)))))
(assert true)
(assert (not (= (bvsmod (bvsub ((_ zero_extend 1) x9_6) ((_ zero_extend 1) (bvmul #xFFFFFFFFFFFFFFFF neg_f_0_low60_40_1))) ((_ zero_extend 1) #x0000100000000000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_475377.smt2
Execution time of boolector: 0.0666 seconds
OUTPUT FROM boolector:
unsat

=== Cut #8 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #8
; Range assertion #67: mul x2_10 1048576@64 = mul (mul (-1)@64 1048576@64) neg_g_0_low60_40_1
; Range condition: x2_10 * 1048576 = (-1 * 1048576) * neg_g_0_low60_40_1
; Output file: /tmp/outputqfbv_180268.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x9_6 () (_ BitVec 64))
(declare-fun x9_5 () (_ BitVec 64))
(declare-fun x9_4 () (_ BitVec 64))
(declare-fun x9_3 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_79 () (_ BitVec 64))
(declare-fun x20_3 () (_ BitVec 64))
(declare-fun x2_10 () (_ BitVec 64))
(declare-fun x2_9 () (_ BitVec 64))
(declare-fun x2_7 () (_ BitVec 64))
(declare-fun x17_5 () (_ BitVec 64))
(declare-fun x16_3 () (_ BitVec 64))
(declare-fun x15_5 () (_ BitVec 64))
(declare-fun x10_82 () (_ BitVec 64))
(declare-fun x10_81 () (_ BitVec 64))
(declare-fun x1_5 () (_ BitVec 64))
(declare-fun tmp_4 () (_ BitVec 64))
(declare-fun tmp_3 () (_ BitVec 64))
(declare-fun neg_g_0_low60_40_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_40_1 () (_ BitVec 64))
(declare-fun dcH_13 () (_ BitVec 64))
(declare-fun dcH_12 () (_ BitVec 64))
(declare-fun dcH_11 () (_ BitVec 64))
(declare-fun dcH_10 () (_ BitVec 64))
(declare-fun dc_327 () (_ BitVec 64))
(declare-fun dc_326 () (_ BitVec 1))
(declare-fun dc_325 () (_ BitVec 64))
(declare-fun dc_324 () (_ BitVec 1))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) neg_f_0_low60_40_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= (bvsmod (bvsub ((_ zero_extend 1) x3_79) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFB1 x3_79)) (bvsle x3_79 #x0000000000000051)) (bvsle #xFFFFFFFFFFF00000 x15_5)) (bvsle x15_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x16_3)) (bvsle x16_3 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x17_5)) (bvsle x17_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x20_3)) (bvsle x20_3 #x00000000000FFFFF)) (= x6_2 #x0000020000100000)))
(assert (= x1_5 x9_3))
(assert (= x2_9 x2_7))
(assert true)
(assert (and (= dcH_10 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x15_5) ((_ sign_extend 64) x1_5)))) (= x9_4 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x15_5) ((_ sign_extend 64) x1_5))))))
(assert (and (= dcH_11 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_9) ((_ sign_extend 64) x16_3)))) (= tmp_3 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_9) ((_ sign_extend 64) x16_3))))))
(assert (and (= dc_324 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x9_4) ((_ zero_extend 1) tmp_3)))) (= x9_5 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x9_4) ((_ zero_extend 1) tmp_3))))))
(assert true)
(assert (and (= x9_5 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) neg_f_0_low60_40_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x9_5) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x9_6 ((_ zero_extend 20) ((_ extract 63 20) x9_5))) (= dc_325 ((_ zero_extend 44) ((_ extract 19 0) x9_5)))))
(assert true)
(assert true)
(assert (and (= dcH_12 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x17_5) ((_ sign_extend 64) x1_5)))) (= x10_81 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x17_5) ((_ sign_extend 64) x1_5))))))
(assert (and (= dcH_13 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_9) ((_ sign_extend 64) x20_3)))) (= tmp_4 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_9) ((_ sign_extend 64) x20_3))))))
(assert (and (= dc_326 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x10_81) ((_ zero_extend 1) tmp_4)))) (= x10_82 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x10_81) ((_ zero_extend 1) tmp_4))))))
(assert true)
(assert (and (= x10_82 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) neg_g_0_low60_40_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x10_82) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x2_10 ((_ zero_extend 20) ((_ extract 63 20) x10_82))) (= dc_327 ((_ zero_extend 44) ((_ extract 19 0) x10_82)))))
(assert (not (= (bvmul x2_10 #x0000000000100000) (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) neg_g_0_low60_40_1))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_9b9ba4.smt2
Execution time of boolector: 0.1327 seconds
OUTPUT FROM boolector:
unsat

=== Cut #6 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #6
; Range assertion #56: or [and [smod (sub (uext x8_76 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_42 = x7_41, mul x8_78 2@64 = x8_76, x3_75 = add 2@64 x3_73], and [smod (sub (uext x8_76 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_73 <s 0@64, x7_42 = x7_41, mul x8_78 2@64 = add x8_76 x7_41, x3_75 = add 2@64 x3_73], and [smod (sub (uext x8_76 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_73 >=s 0@64, x7_42 = x8_76, mul x8_78 2@64 = sub x8_76 x7_41, x3_75 = sub 2@64 x3_73]]
; Range condition: ((x8_76@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_42 = x7_41 /\ x8_78 * 2 = x8_76 /\ x3_75 = 2 + x3_73 \/ ((x8_76@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_73 <s 0 /\ x7_42 = x7_41 /\ x8_78 * 2 = x8_76 + x7_41 /\ x3_75 = 2 + x3_73 \/ ((x8_76@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_73 >=s 0 /\ x7_42 = x8_76 /\ x8_78 * 2 = x8_76 - x7_41 /\ x3_75 = 2 - x3_73
; Output file: /tmp/outputqfbv_f360ad.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_36 () (_ BitVec 1))
(declare-fun x8_target_35 () (_ BitVec 1))
(declare-fun x8_target_34 () (_ BitVec 1))
(declare-fun x8_target_33 () (_ BitVec 1))
(declare-fun x8_target_32 () (_ BitVec 1))
(declare-fun x8_target_31 () (_ BitVec 1))
(declare-fun x8_target_30 () (_ BitVec 1))
(declare-fun x8_target_29 () (_ BitVec 1))
(declare-fun x8_target_28 () (_ BitVec 1))
(declare-fun x8_target_27 () (_ BitVec 1))
(declare-fun x8_target_26 () (_ BitVec 1))
(declare-fun x8_target_25 () (_ BitVec 1))
(declare-fun x8_target_24 () (_ BitVec 1))
(declare-fun x8_target_23 () (_ BitVec 1))
(declare-fun x8_target_22 () (_ BitVec 1))
(declare-fun x8_target_21 () (_ BitVec 1))
(declare-fun x8_target_20 () (_ BitVec 1))
(declare-fun x8_lo_38 () (_ BitVec 2))
(declare-fun x8_lo_37 () (_ BitVec 2))
(declare-fun x8_lo_36 () (_ BitVec 2))
(declare-fun x8_lo_35 () (_ BitVec 2))
(declare-fun x8_lo_34 () (_ BitVec 2))
(declare-fun x8_lo_33 () (_ BitVec 2))
(declare-fun x8_lo_32 () (_ BitVec 2))
(declare-fun x8_lo_31 () (_ BitVec 2))
(declare-fun x8_lo_30 () (_ BitVec 2))
(declare-fun x8_lo_29 () (_ BitVec 2))
(declare-fun x8_lo_28 () (_ BitVec 2))
(declare-fun x8_lo_27 () (_ BitVec 2))
(declare-fun x8_lo_26 () (_ BitVec 2))
(declare-fun x8_lo_25 () (_ BitVec 2))
(declare-fun x8_lo_24 () (_ BitVec 2))
(declare-fun x8_lo_23 () (_ BitVec 2))
(declare-fun x8_lo_22 () (_ BitVec 2))
(declare-fun x8_lo_21 () (_ BitVec 1))
(declare-fun x8_78 () (_ BitVec 64))
(declare-fun x8_77 () (_ BitVec 64))
(declare-fun x8_76 () (_ BitVec 64))
(declare-fun x8_75 () (_ BitVec 64))
(declare-fun x8_74 () (_ BitVec 64))
(declare-fun x8_73 () (_ BitVec 64))
(declare-fun x8_72 () (_ BitVec 64))
(declare-fun x8_71 () (_ BitVec 64))
(declare-fun x8_70 () (_ BitVec 64))
(declare-fun x8_69 () (_ BitVec 64))
(declare-fun x8_68 () (_ BitVec 64))
(declare-fun x8_67 () (_ BitVec 64))
(declare-fun x8_66 () (_ BitVec 64))
(declare-fun x8_65 () (_ BitVec 64))
(declare-fun x8_64 () (_ BitVec 64))
(declare-fun x8_63 () (_ BitVec 64))
(declare-fun x8_62 () (_ BitVec 64))
(declare-fun x8_61 () (_ BitVec 64))
(declare-fun x8_60 () (_ BitVec 64))
(declare-fun x8_59 () (_ BitVec 64))
(declare-fun x8_58 () (_ BitVec 64))
(declare-fun x8_57 () (_ BitVec 64))
(declare-fun x8_56 () (_ BitVec 64))
(declare-fun x8_55 () (_ BitVec 64))
(declare-fun x8_54 () (_ BitVec 64))
(declare-fun x8_53 () (_ BitVec 64))
(declare-fun x8_52 () (_ BitVec 64))
(declare-fun x8_51 () (_ BitVec 64))
(declare-fun x8_50 () (_ BitVec 64))
(declare-fun x8_49 () (_ BitVec 64))
(declare-fun x8_48 () (_ BitVec 64))
(declare-fun x8_47 () (_ BitVec 64))
(declare-fun x8_46 () (_ BitVec 64))
(declare-fun x8_45 () (_ BitVec 64))
(declare-fun x8_44 () (_ BitVec 64))
(declare-fun x7_42 () (_ BitVec 64))
(declare-fun x7_41 () (_ BitVec 64))
(declare-fun x7_40 () (_ BitVec 64))
(declare-fun x7_39 () (_ BitVec 64))
(declare-fun x7_38 () (_ BitVec 64))
(declare-fun x7_37 () (_ BitVec 64))
(declare-fun x7_36 () (_ BitVec 64))
(declare-fun x7_35 () (_ BitVec 64))
(declare-fun x7_34 () (_ BitVec 64))
(declare-fun x7_33 () (_ BitVec 64))
(declare-fun x7_32 () (_ BitVec 64))
(declare-fun x7_31 () (_ BitVec 64))
(declare-fun x7_30 () (_ BitVec 64))
(declare-fun x7_29 () (_ BitVec 64))
(declare-fun x7_28 () (_ BitVec 64))
(declare-fun x7_27 () (_ BitVec 64))
(declare-fun x7_26 () (_ BitVec 64))
(declare-fun x7_25 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_37 () (_ BitVec 64))
(declare-fun x3_neg_36 () (_ BitVec 64))
(declare-fun x3_neg_35 () (_ BitVec 64))
(declare-fun x3_neg_34 () (_ BitVec 64))
(declare-fun x3_neg_33 () (_ BitVec 64))
(declare-fun x3_neg_32 () (_ BitVec 64))
(declare-fun x3_neg_31 () (_ BitVec 64))
(declare-fun x3_neg_30 () (_ BitVec 64))
(declare-fun x3_neg_29 () (_ BitVec 64))
(declare-fun x3_neg_28 () (_ BitVec 64))
(declare-fun x3_neg_27 () (_ BitVec 64))
(declare-fun x3_neg_26 () (_ BitVec 64))
(declare-fun x3_neg_25 () (_ BitVec 64))
(declare-fun x3_neg_24 () (_ BitVec 64))
(declare-fun x3_neg_23 () (_ BitVec 64))
(declare-fun x3_neg_22 () (_ BitVec 64))
(declare-fun x3_neg_21 () (_ BitVec 64))
(declare-fun x3_75 () (_ BitVec 64))
(declare-fun x3_74 () (_ BitVec 64))
(declare-fun x3_73 () (_ BitVec 64))
(declare-fun x3_72 () (_ BitVec 64))
(declare-fun x3_71 () (_ BitVec 64))
(declare-fun x3_70 () (_ BitVec 64))
(declare-fun x3_69 () (_ BitVec 64))
(declare-fun x3_68 () (_ BitVec 64))
(declare-fun x3_67 () (_ BitVec 64))
(declare-fun x3_66 () (_ BitVec 64))
(declare-fun x3_65 () (_ BitVec 64))
(declare-fun x3_64 () (_ BitVec 64))
(declare-fun x3_63 () (_ BitVec 64))
(declare-fun x3_62 () (_ BitVec 64))
(declare-fun x3_61 () (_ BitVec 64))
(declare-fun x3_60 () (_ BitVec 64))
(declare-fun x3_59 () (_ BitVec 64))
(declare-fun x3_58 () (_ BitVec 64))
(declare-fun x3_57 () (_ BitVec 64))
(declare-fun x3_56 () (_ BitVec 64))
(declare-fun x3_55 () (_ BitVec 64))
(declare-fun x3_54 () (_ BitVec 64))
(declare-fun x3_53 () (_ BitVec 64))
(declare-fun x3_52 () (_ BitVec 64))
(declare-fun x3_51 () (_ BitVec 64))
(declare-fun x3_50 () (_ BitVec 64))
(declare-fun x3_49 () (_ BitVec 64))
(declare-fun x3_48 () (_ BitVec 64))
(declare-fun x3_47 () (_ BitVec 64))
(declare-fun x3_46 () (_ BitVec 64))
(declare-fun x3_45 () (_ BitVec 64))
(declare-fun x3_44 () (_ BitVec 64))
(declare-fun x3_43 () (_ BitVec 64))
(declare-fun x3_42 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x10_neg_37 () (_ BitVec 64))
(declare-fun x10_neg_36 () (_ BitVec 64))
(declare-fun x10_neg_35 () (_ BitVec 64))
(declare-fun x10_neg_34 () (_ BitVec 64))
(declare-fun x10_neg_33 () (_ BitVec 64))
(declare-fun x10_neg_32 () (_ BitVec 64))
(declare-fun x10_neg_31 () (_ BitVec 64))
(declare-fun x10_neg_30 () (_ BitVec 64))
(declare-fun x10_neg_29 () (_ BitVec 64))
(declare-fun x10_neg_28 () (_ BitVec 64))
(declare-fun x10_neg_27 () (_ BitVec 64))
(declare-fun x10_neg_26 () (_ BitVec 64))
(declare-fun x10_neg_25 () (_ BitVec 64))
(declare-fun x10_neg_24 () (_ BitVec 64))
(declare-fun x10_neg_23 () (_ BitVec 64))
(declare-fun x10_neg_22 () (_ BitVec 64))
(declare-fun x10_neg_21 () (_ BitVec 64))
(declare-fun x10_76 () (_ BitVec 64))
(declare-fun x10_75 () (_ BitVec 64))
(declare-fun x10_74 () (_ BitVec 64))
(declare-fun x10_73 () (_ BitVec 64))
(declare-fun x10_72 () (_ BitVec 64))
(declare-fun x10_71 () (_ BitVec 64))
(declare-fun x10_70 () (_ BitVec 64))
(declare-fun x10_69 () (_ BitVec 64))
(declare-fun x10_68 () (_ BitVec 64))
(declare-fun x10_67 () (_ BitVec 64))
(declare-fun x10_66 () (_ BitVec 64))
(declare-fun x10_65 () (_ BitVec 64))
(declare-fun x10_64 () (_ BitVec 64))
(declare-fun x10_63 () (_ BitVec 64))
(declare-fun x10_62 () (_ BitVec 64))
(declare-fun x10_61 () (_ BitVec 64))
(declare-fun x10_60 () (_ BitVec 64))
(declare-fun x10_59 () (_ BitVec 64))
(declare-fun x10_58 () (_ BitVec 64))
(declare-fun x10_57 () (_ BitVec 64))
(declare-fun x10_56 () (_ BitVec 64))
(declare-fun x10_55 () (_ BitVec 64))
(declare-fun x10_54 () (_ BitVec 64))
(declare-fun x10_53 () (_ BitVec 64))
(declare-fun x10_52 () (_ BitVec 64))
(declare-fun x10_51 () (_ BitVec 64))
(declare-fun x10_50 () (_ BitVec 64))
(declare-fun x10_49 () (_ BitVec 64))
(declare-fun x10_48 () (_ BitVec 64))
(declare-fun x10_47 () (_ BitVec 64))
(declare-fun x10_46 () (_ BitVec 64))
(declare-fun x10_45 () (_ BitVec 64))
(declare-fun x10_44 () (_ BitVec 64))
(declare-fun x10_43 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun ne_38 () (_ BitVec 1))
(declare-fun ne_37 () (_ BitVec 1))
(declare-fun ne_36 () (_ BitVec 1))
(declare-fun ne_35 () (_ BitVec 1))
(declare-fun ne_34 () (_ BitVec 1))
(declare-fun ne_33 () (_ BitVec 1))
(declare-fun ne_32 () (_ BitVec 1))
(declare-fun ne_31 () (_ BitVec 1))
(declare-fun ne_30 () (_ BitVec 1))
(declare-fun ne_29 () (_ BitVec 1))
(declare-fun ne_28 () (_ BitVec 1))
(declare-fun ne_27 () (_ BitVec 1))
(declare-fun ne_26 () (_ BitVec 1))
(declare-fun ne_25 () (_ BitVec 1))
(declare-fun ne_24 () (_ BitVec 1))
(declare-fun ne_23 () (_ BitVec 1))
(declare-fun ne_22 () (_ BitVec 1))
(declare-fun ne_21 () (_ BitVec 1))
(declare-fun ge_111 () (_ BitVec 1))
(declare-fun ge_110 () (_ BitVec 1))
(declare-fun ge_109 () (_ BitVec 1))
(declare-fun ge_108 () (_ BitVec 1))
(declare-fun ge_107 () (_ BitVec 1))
(declare-fun ge_106 () (_ BitVec 1))
(declare-fun ge_105 () (_ BitVec 1))
(declare-fun ge_104 () (_ BitVec 1))
(declare-fun ge_103 () (_ BitVec 1))
(declare-fun ge_102 () (_ BitVec 1))
(declare-fun ge_101 () (_ BitVec 1))
(declare-fun ge_100 () (_ BitVec 1))
(declare-fun ge_99 () (_ BitVec 1))
(declare-fun ge_98 () (_ BitVec 1))
(declare-fun ge_97 () (_ BitVec 1))
(declare-fun ge_96 () (_ BitVec 1))
(declare-fun ge_95 () (_ BitVec 1))
(declare-fun ge_94 () (_ BitVec 1))
(declare-fun ge_93 () (_ BitVec 1))
(declare-fun ge_92 () (_ BitVec 1))
(declare-fun ge_91 () (_ BitVec 1))
(declare-fun ge_90 () (_ BitVec 1))
(declare-fun ge_89 () (_ BitVec 1))
(declare-fun ge_88 () (_ BitVec 1))
(declare-fun ge_87 () (_ BitVec 1))
(declare-fun ge_86 () (_ BitVec 1))
(declare-fun ge_85 () (_ BitVec 1))
(declare-fun ge_84 () (_ BitVec 1))
(declare-fun ge_83 () (_ BitVec 1))
(declare-fun ge_82 () (_ BitVec 1))
(declare-fun ge_81 () (_ BitVec 1))
(declare-fun ge_80 () (_ BitVec 1))
(declare-fun ge_79 () (_ BitVec 1))
(declare-fun ge_78 () (_ BitVec 1))
(declare-fun ge_77 () (_ BitVec 1))
(declare-fun ge_76 () (_ BitVec 1))
(declare-fun ge_75 () (_ BitVec 1))
(declare-fun ge_74 () (_ BitVec 1))
(declare-fun ge_73 () (_ BitVec 1))
(declare-fun ge_72 () (_ BitVec 1))
(declare-fun ge_71 () (_ BitVec 1))
(declare-fun ge_70 () (_ BitVec 1))
(declare-fun ge_69 () (_ BitVec 1))
(declare-fun ge_68 () (_ BitVec 1))
(declare-fun ge_67 () (_ BitVec 1))
(declare-fun ge_66 () (_ BitVec 1))
(declare-fun ge_65 () (_ BitVec 1))
(declare-fun ge_64 () (_ BitVec 1))
(declare-fun ge_63 () (_ BitVec 1))
(declare-fun ge_62 () (_ BitVec 1))
(declare-fun ge_61 () (_ BitVec 1))
(declare-fun dc_307 () (_ BitVec 64))
(declare-fun dc_306 () (_ BitVec 1))
(declare-fun dc_305 () (_ BitVec 62))
(declare-fun dc_304 () (_ BitVec 1))
(declare-fun dc_303 () (_ BitVec 1))
(declare-fun dc_302 () (_ BitVec 1))
(declare-fun dc_301 () (_ BitVec 63))
(declare-fun dc_300 () (_ BitVec 64))
(declare-fun dc_299 () (_ BitVec 1))
(declare-fun dc_298 () (_ BitVec 62))
(declare-fun dc_297 () (_ BitVec 1))
(declare-fun dc_296 () (_ BitVec 1))
(declare-fun dc_295 () (_ BitVec 1))
(declare-fun dc_294 () (_ BitVec 63))
(declare-fun dc_293 () (_ BitVec 64))
(declare-fun dc_292 () (_ BitVec 1))
(declare-fun dc_291 () (_ BitVec 62))
(declare-fun dc_290 () (_ BitVec 1))
(declare-fun dc_289 () (_ BitVec 1))
(declare-fun dc_288 () (_ BitVec 1))
(declare-fun dc_287 () (_ BitVec 63))
(declare-fun dc_286 () (_ BitVec 64))
(declare-fun dc_285 () (_ BitVec 1))
(declare-fun dc_284 () (_ BitVec 62))
(declare-fun dc_283 () (_ BitVec 1))
(declare-fun dc_282 () (_ BitVec 1))
(declare-fun dc_281 () (_ BitVec 1))
(declare-fun dc_280 () (_ BitVec 63))
(declare-fun dc_279 () (_ BitVec 64))
(declare-fun dc_278 () (_ BitVec 1))
(declare-fun dc_277 () (_ BitVec 62))
(declare-fun dc_276 () (_ BitVec 1))
(declare-fun dc_275 () (_ BitVec 1))
(declare-fun dc_274 () (_ BitVec 1))
(declare-fun dc_273 () (_ BitVec 63))
(declare-fun dc_272 () (_ BitVec 64))
(declare-fun dc_271 () (_ BitVec 1))
(declare-fun dc_270 () (_ BitVec 62))
(declare-fun dc_269 () (_ BitVec 1))
(declare-fun dc_268 () (_ BitVec 1))
(declare-fun dc_267 () (_ BitVec 1))
(declare-fun dc_266 () (_ BitVec 63))
(declare-fun dc_265 () (_ BitVec 64))
(declare-fun dc_264 () (_ BitVec 1))
(declare-fun dc_263 () (_ BitVec 62))
(declare-fun dc_262 () (_ BitVec 1))
(declare-fun dc_261 () (_ BitVec 1))
(declare-fun dc_260 () (_ BitVec 1))
(declare-fun dc_259 () (_ BitVec 63))
(declare-fun dc_258 () (_ BitVec 64))
(declare-fun dc_257 () (_ BitVec 1))
(declare-fun dc_256 () (_ BitVec 62))
(declare-fun dc_255 () (_ BitVec 1))
(declare-fun dc_254 () (_ BitVec 1))
(declare-fun dc_253 () (_ BitVec 1))
(declare-fun dc_252 () (_ BitVec 63))
(declare-fun dc_251 () (_ BitVec 64))
(declare-fun dc_250 () (_ BitVec 1))
(declare-fun dc_249 () (_ BitVec 62))
(declare-fun dc_248 () (_ BitVec 1))
(declare-fun dc_247 () (_ BitVec 1))
(declare-fun dc_246 () (_ BitVec 1))
(declare-fun dc_245 () (_ BitVec 63))
(declare-fun dc_244 () (_ BitVec 64))
(declare-fun dc_243 () (_ BitVec 1))
(declare-fun dc_242 () (_ BitVec 62))
(declare-fun dc_241 () (_ BitVec 1))
(declare-fun dc_240 () (_ BitVec 1))
(declare-fun dc_239 () (_ BitVec 1))
(declare-fun dc_238 () (_ BitVec 63))
(declare-fun dc_237 () (_ BitVec 64))
(declare-fun dc_236 () (_ BitVec 1))
(declare-fun dc_235 () (_ BitVec 62))
(declare-fun dc_234 () (_ BitVec 1))
(declare-fun dc_233 () (_ BitVec 1))
(declare-fun dc_232 () (_ BitVec 1))
(declare-fun dc_231 () (_ BitVec 63))
(declare-fun dc_230 () (_ BitVec 64))
(declare-fun dc_229 () (_ BitVec 1))
(declare-fun dc_228 () (_ BitVec 62))
(declare-fun dc_227 () (_ BitVec 1))
(declare-fun dc_226 () (_ BitVec 1))
(declare-fun dc_225 () (_ BitVec 1))
(declare-fun dc_224 () (_ BitVec 63))
(declare-fun dc_223 () (_ BitVec 64))
(declare-fun dc_222 () (_ BitVec 1))
(declare-fun dc_221 () (_ BitVec 62))
(declare-fun dc_220 () (_ BitVec 1))
(declare-fun dc_219 () (_ BitVec 1))
(declare-fun dc_218 () (_ BitVec 1))
(declare-fun dc_217 () (_ BitVec 63))
(declare-fun dc_216 () (_ BitVec 64))
(declare-fun dc_215 () (_ BitVec 1))
(declare-fun dc_214 () (_ BitVec 62))
(declare-fun dc_213 () (_ BitVec 1))
(declare-fun dc_212 () (_ BitVec 1))
(declare-fun dc_211 () (_ BitVec 1))
(declare-fun dc_210 () (_ BitVec 63))
(declare-fun dc_209 () (_ BitVec 64))
(declare-fun dc_208 () (_ BitVec 1))
(declare-fun dc_207 () (_ BitVec 62))
(declare-fun dc_206 () (_ BitVec 1))
(declare-fun dc_205 () (_ BitVec 1))
(declare-fun dc_204 () (_ BitVec 1))
(declare-fun dc_203 () (_ BitVec 63))
(declare-fun dc_202 () (_ BitVec 64))
(declare-fun dc_201 () (_ BitVec 1))
(declare-fun dc_200 () (_ BitVec 62))
(declare-fun dc_199 () (_ BitVec 1))
(declare-fun dc_198 () (_ BitVec 1))
(declare-fun dc_197 () (_ BitVec 1))
(declare-fun dc_196 () (_ BitVec 63))
(declare-fun dc_195 () (_ BitVec 64))
(declare-fun dc_194 () (_ BitVec 1))
(declare-fun dc_193 () (_ BitVec 62))
(declare-fun dc_192 () (_ BitVec 1))
(declare-fun dc_191 () (_ BitVec 1))
(declare-fun dc_190 () (_ BitVec 1))
(declare-fun dc_189 () (_ BitVec 63))
(declare-fun dc_188 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_25 (bvadd (bvadd neg_f_0_low60_20_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_44 (bvadd (bvadd neg_g_0_low60_20_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_0_1)) (bvsle neg_f_0_low60_20_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_0_1)) (bvsle neg_g_0_low60_20_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_25) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_188 ((_ extract 63 1) x8_44)) (= x8_lo_21 ((_ extract 0 0) x8_44))))
(assert (= ne_21 (bvand x8_lo_21 #b1)))
(assert (= x10_43 (ite (= ne_21 #b1) x7_25 #x0000000000000000)))
(assert (and (= ge_61 ((_ extract 63 63) x3_41)) (= dc_189 ((_ extract 62 0) x3_41))))
(assert (= ge_62 (bvnot ge_61)))
(assert (= ge_63 (ite (= ne_21 #b1) ge_62 #b0)))
(assert (and (= dc_190 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_42 (ite (= ge_63 #b1) x3_neg_21 x3_41)))
(assert (and (= dc_191 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_44 (ite (= ge_63 #b1) x10_neg_21 x10_43)))
(assert (= x7_26 (ite (= ge_63 #b1) x8_44 x7_25)))
(assert (and (= dc_192 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44)))) (= x8_45 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44))))))
(assert (= x3_43 (bvadd x3_42 #x0000000000000002)))
(assert (and (= dc_193 ((_ extract 63 2) x8_45)) (= x8_lo_22 ((_ extract 1 0) x8_45))))
(assert (and (= x8_target_20 ((_ extract 1 1) x8_lo_22)) (= dc_194 ((_ extract 0 0) x8_lo_22))))
(assert (= ne_22 (bvand x8_target_20 #b1)))
(assert (and (= x8_46 ((_ sign_extend 1) ((_ extract 63 1) x8_45))) (= dc_195 ((_ zero_extend 63) ((_ extract 0 0) x8_45)))))
(assert true)
(assert (= x10_45 (ite (= ne_22 #b1) x7_26 #x0000000000000000)))
(assert (and (= ge_64 ((_ extract 63 63) x3_43)) (= dc_196 ((_ extract 62 0) x3_43))))
(assert (= ge_65 (bvnot ge_64)))
(assert (= ge_66 (ite (= ne_22 #b1) ge_65 #b0)))
(assert (and (= dc_197 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_44 (ite (= ge_66 #b1) x3_neg_22 x3_43)))
(assert (and (= dc_198 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_46 (ite (= ge_66 #b1) x10_neg_22 x10_45)))
(assert (= x7_27 (ite (= ge_66 #b1) x8_46 x7_26)))
(assert (and (= dc_199 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46)))) (= x8_47 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46))))))
(assert (= x3_45 (bvadd x3_44 #x0000000000000002)))
(assert (and (= dc_200 ((_ extract 63 2) x8_47)) (= x8_lo_23 ((_ extract 1 0) x8_47))))
(assert (and (= x8_target_21 ((_ extract 1 1) x8_lo_23)) (= dc_201 ((_ extract 0 0) x8_lo_23))))
(assert (= ne_23 (bvand x8_target_21 #b1)))
(assert (and (= x8_48 ((_ sign_extend 1) ((_ extract 63 1) x8_47))) (= dc_202 ((_ zero_extend 63) ((_ extract 0 0) x8_47)))))
(assert true)
(assert (= x10_47 (ite (= ne_23 #b1) x7_27 #x0000000000000000)))
(assert (and (= ge_67 ((_ extract 63 63) x3_45)) (= dc_203 ((_ extract 62 0) x3_45))))
(assert (= ge_68 (bvnot ge_67)))
(assert (= ge_69 (ite (= ne_23 #b1) ge_68 #b0)))
(assert (and (= dc_204 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_46 (ite (= ge_69 #b1) x3_neg_23 x3_45)))
(assert (and (= dc_205 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_48 (ite (= ge_69 #b1) x10_neg_23 x10_47)))
(assert (= x7_28 (ite (= ge_69 #b1) x8_48 x7_27)))
(assert (and (= dc_206 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48)))) (= x8_49 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48))))))
(assert (= x3_47 (bvadd x3_46 #x0000000000000002)))
(assert (and (= dc_207 ((_ extract 63 2) x8_49)) (= x8_lo_24 ((_ extract 1 0) x8_49))))
(assert (and (= x8_target_22 ((_ extract 1 1) x8_lo_24)) (= dc_208 ((_ extract 0 0) x8_lo_24))))
(assert (= ne_24 (bvand x8_target_22 #b1)))
(assert (and (= x8_50 ((_ sign_extend 1) ((_ extract 63 1) x8_49))) (= dc_209 ((_ zero_extend 63) ((_ extract 0 0) x8_49)))))
(assert true)
(assert (= x10_49 (ite (= ne_24 #b1) x7_28 #x0000000000000000)))
(assert (and (= ge_70 ((_ extract 63 63) x3_47)) (= dc_210 ((_ extract 62 0) x3_47))))
(assert (= ge_71 (bvnot ge_70)))
(assert (= ge_72 (ite (= ne_24 #b1) ge_71 #b0)))
(assert (and (= dc_211 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_47))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_24 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_47))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_48 (ite (= ge_72 #b1) x3_neg_24 x3_47)))
(assert (and (= dc_212 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_49))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_24 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_49))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_50 (ite (= ge_72 #b1) x10_neg_24 x10_49)))
(assert (= x7_29 (ite (= ge_72 #b1) x8_50 x7_28)))
(assert (and (= dc_213 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_50) ((_ zero_extend 1) x10_50)))) (= x8_51 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_50) ((_ zero_extend 1) x10_50))))))
(assert (= x3_49 (bvadd x3_48 #x0000000000000002)))
(assert (and (= dc_214 ((_ extract 63 2) x8_51)) (= x8_lo_25 ((_ extract 1 0) x8_51))))
(assert (and (= x8_target_23 ((_ extract 1 1) x8_lo_25)) (= dc_215 ((_ extract 0 0) x8_lo_25))))
(assert (= ne_25 (bvand x8_target_23 #b1)))
(assert (and (= x8_52 ((_ sign_extend 1) ((_ extract 63 1) x8_51))) (= dc_216 ((_ zero_extend 63) ((_ extract 0 0) x8_51)))))
(assert true)
(assert (= x10_51 (ite (= ne_25 #b1) x7_29 #x0000000000000000)))
(assert (and (= ge_73 ((_ extract 63 63) x3_49)) (= dc_217 ((_ extract 62 0) x3_49))))
(assert (= ge_74 (bvnot ge_73)))
(assert (= ge_75 (ite (= ne_25 #b1) ge_74 #b0)))
(assert (and (= dc_218 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_49))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_25 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_49))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_50 (ite (= ge_75 #b1) x3_neg_25 x3_49)))
(assert (and (= dc_219 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_51))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_25 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_51))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_52 (ite (= ge_75 #b1) x10_neg_25 x10_51)))
(assert (= x7_30 (ite (= ge_75 #b1) x8_52 x7_29)))
(assert (and (= dc_220 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_52) ((_ zero_extend 1) x10_52)))) (= x8_53 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_52) ((_ zero_extend 1) x10_52))))))
(assert (= x3_51 (bvadd x3_50 #x0000000000000002)))
(assert (and (= dc_221 ((_ extract 63 2) x8_53)) (= x8_lo_26 ((_ extract 1 0) x8_53))))
(assert (and (= x8_target_24 ((_ extract 1 1) x8_lo_26)) (= dc_222 ((_ extract 0 0) x8_lo_26))))
(assert (= ne_26 (bvand x8_target_24 #b1)))
(assert (and (= x8_54 ((_ sign_extend 1) ((_ extract 63 1) x8_53))) (= dc_223 ((_ zero_extend 63) ((_ extract 0 0) x8_53)))))
(assert true)
(assert (= x10_53 (ite (= ne_26 #b1) x7_30 #x0000000000000000)))
(assert (and (= ge_76 ((_ extract 63 63) x3_51)) (= dc_224 ((_ extract 62 0) x3_51))))
(assert (= ge_77 (bvnot ge_76)))
(assert (= ge_78 (ite (= ne_26 #b1) ge_77 #b0)))
(assert (and (= dc_225 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_51))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_26 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_51))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_52 (ite (= ge_78 #b1) x3_neg_26 x3_51)))
(assert (and (= dc_226 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_53))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_26 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_53))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_54 (ite (= ge_78 #b1) x10_neg_26 x10_53)))
(assert (= x7_31 (ite (= ge_78 #b1) x8_54 x7_30)))
(assert (and (= dc_227 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_54) ((_ zero_extend 1) x10_54)))) (= x8_55 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_54) ((_ zero_extend 1) x10_54))))))
(assert (= x3_53 (bvadd x3_52 #x0000000000000002)))
(assert (and (= dc_228 ((_ extract 63 2) x8_55)) (= x8_lo_27 ((_ extract 1 0) x8_55))))
(assert (and (= x8_target_25 ((_ extract 1 1) x8_lo_27)) (= dc_229 ((_ extract 0 0) x8_lo_27))))
(assert (= ne_27 (bvand x8_target_25 #b1)))
(assert (and (= x8_56 ((_ sign_extend 1) ((_ extract 63 1) x8_55))) (= dc_230 ((_ zero_extend 63) ((_ extract 0 0) x8_55)))))
(assert true)
(assert (= x10_55 (ite (= ne_27 #b1) x7_31 #x0000000000000000)))
(assert (and (= ge_79 ((_ extract 63 63) x3_53)) (= dc_231 ((_ extract 62 0) x3_53))))
(assert (= ge_80 (bvnot ge_79)))
(assert (= ge_81 (ite (= ne_27 #b1) ge_80 #b0)))
(assert (and (= dc_232 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_53))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_27 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_53))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_54 (ite (= ge_81 #b1) x3_neg_27 x3_53)))
(assert (and (= dc_233 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_55))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_27 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_55))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_56 (ite (= ge_81 #b1) x10_neg_27 x10_55)))
(assert (= x7_32 (ite (= ge_81 #b1) x8_56 x7_31)))
(assert (and (= dc_234 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_56) ((_ zero_extend 1) x10_56)))) (= x8_57 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_56) ((_ zero_extend 1) x10_56))))))
(assert (= x3_55 (bvadd x3_54 #x0000000000000002)))
(assert (and (= dc_235 ((_ extract 63 2) x8_57)) (= x8_lo_28 ((_ extract 1 0) x8_57))))
(assert (and (= x8_target_26 ((_ extract 1 1) x8_lo_28)) (= dc_236 ((_ extract 0 0) x8_lo_28))))
(assert (= ne_28 (bvand x8_target_26 #b1)))
(assert (and (= x8_58 ((_ sign_extend 1) ((_ extract 63 1) x8_57))) (= dc_237 ((_ zero_extend 63) ((_ extract 0 0) x8_57)))))
(assert true)
(assert (= x10_57 (ite (= ne_28 #b1) x7_32 #x0000000000000000)))
(assert (and (= ge_82 ((_ extract 63 63) x3_55)) (= dc_238 ((_ extract 62 0) x3_55))))
(assert (= ge_83 (bvnot ge_82)))
(assert (= ge_84 (ite (= ne_28 #b1) ge_83 #b0)))
(assert (and (= dc_239 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_55))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_28 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_55))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_56 (ite (= ge_84 #b1) x3_neg_28 x3_55)))
(assert (and (= dc_240 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_57))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_28 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_57))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_58 (ite (= ge_84 #b1) x10_neg_28 x10_57)))
(assert (= x7_33 (ite (= ge_84 #b1) x8_58 x7_32)))
(assert (and (= dc_241 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_58) ((_ zero_extend 1) x10_58)))) (= x8_59 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_58) ((_ zero_extend 1) x10_58))))))
(assert (= x3_57 (bvadd x3_56 #x0000000000000002)))
(assert (and (= dc_242 ((_ extract 63 2) x8_59)) (= x8_lo_29 ((_ extract 1 0) x8_59))))
(assert (and (= x8_target_27 ((_ extract 1 1) x8_lo_29)) (= dc_243 ((_ extract 0 0) x8_lo_29))))
(assert (= ne_29 (bvand x8_target_27 #b1)))
(assert (and (= x8_60 ((_ sign_extend 1) ((_ extract 63 1) x8_59))) (= dc_244 ((_ zero_extend 63) ((_ extract 0 0) x8_59)))))
(assert true)
(assert (= x10_59 (ite (= ne_29 #b1) x7_33 #x0000000000000000)))
(assert (and (= ge_85 ((_ extract 63 63) x3_57)) (= dc_245 ((_ extract 62 0) x3_57))))
(assert (= ge_86 (bvnot ge_85)))
(assert (= ge_87 (ite (= ne_29 #b1) ge_86 #b0)))
(assert (and (= dc_246 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_57))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_29 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_57))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_58 (ite (= ge_87 #b1) x3_neg_29 x3_57)))
(assert (and (= dc_247 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_59))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_29 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_59))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_60 (ite (= ge_87 #b1) x10_neg_29 x10_59)))
(assert (= x7_34 (ite (= ge_87 #b1) x8_60 x7_33)))
(assert (and (= dc_248 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_60) ((_ zero_extend 1) x10_60)))) (= x8_61 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_60) ((_ zero_extend 1) x10_60))))))
(assert (= x3_59 (bvadd x3_58 #x0000000000000002)))
(assert (and (= dc_249 ((_ extract 63 2) x8_61)) (= x8_lo_30 ((_ extract 1 0) x8_61))))
(assert (and (= x8_target_28 ((_ extract 1 1) x8_lo_30)) (= dc_250 ((_ extract 0 0) x8_lo_30))))
(assert (= ne_30 (bvand x8_target_28 #b1)))
(assert (and (= x8_62 ((_ sign_extend 1) ((_ extract 63 1) x8_61))) (= dc_251 ((_ zero_extend 63) ((_ extract 0 0) x8_61)))))
(assert true)
(assert (= x10_61 (ite (= ne_30 #b1) x7_34 #x0000000000000000)))
(assert (and (= ge_88 ((_ extract 63 63) x3_59)) (= dc_252 ((_ extract 62 0) x3_59))))
(assert (= ge_89 (bvnot ge_88)))
(assert (= ge_90 (ite (= ne_30 #b1) ge_89 #b0)))
(assert (and (= dc_253 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_59))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_30 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_59))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_60 (ite (= ge_90 #b1) x3_neg_30 x3_59)))
(assert (and (= dc_254 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_61))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_30 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_61))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_62 (ite (= ge_90 #b1) x10_neg_30 x10_61)))
(assert (= x7_35 (ite (= ge_90 #b1) x8_62 x7_34)))
(assert (and (= dc_255 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_62) ((_ zero_extend 1) x10_62)))) (= x8_63 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_62) ((_ zero_extend 1) x10_62))))))
(assert (= x3_61 (bvadd x3_60 #x0000000000000002)))
(assert (and (= dc_256 ((_ extract 63 2) x8_63)) (= x8_lo_31 ((_ extract 1 0) x8_63))))
(assert (and (= x8_target_29 ((_ extract 1 1) x8_lo_31)) (= dc_257 ((_ extract 0 0) x8_lo_31))))
(assert (= ne_31 (bvand x8_target_29 #b1)))
(assert (and (= x8_64 ((_ sign_extend 1) ((_ extract 63 1) x8_63))) (= dc_258 ((_ zero_extend 63) ((_ extract 0 0) x8_63)))))
(assert true)
(assert (= x10_63 (ite (= ne_31 #b1) x7_35 #x0000000000000000)))
(assert (and (= ge_91 ((_ extract 63 63) x3_61)) (= dc_259 ((_ extract 62 0) x3_61))))
(assert (= ge_92 (bvnot ge_91)))
(assert (= ge_93 (ite (= ne_31 #b1) ge_92 #b0)))
(assert (and (= dc_260 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_61))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_31 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_61))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_62 (ite (= ge_93 #b1) x3_neg_31 x3_61)))
(assert (and (= dc_261 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_63))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_31 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_63))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_64 (ite (= ge_93 #b1) x10_neg_31 x10_63)))
(assert (= x7_36 (ite (= ge_93 #b1) x8_64 x7_35)))
(assert (and (= dc_262 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_64) ((_ zero_extend 1) x10_64)))) (= x8_65 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_64) ((_ zero_extend 1) x10_64))))))
(assert (= x3_63 (bvadd x3_62 #x0000000000000002)))
(assert (and (= dc_263 ((_ extract 63 2) x8_65)) (= x8_lo_32 ((_ extract 1 0) x8_65))))
(assert (and (= x8_target_30 ((_ extract 1 1) x8_lo_32)) (= dc_264 ((_ extract 0 0) x8_lo_32))))
(assert (= ne_32 (bvand x8_target_30 #b1)))
(assert (and (= x8_66 ((_ sign_extend 1) ((_ extract 63 1) x8_65))) (= dc_265 ((_ zero_extend 63) ((_ extract 0 0) x8_65)))))
(assert true)
(assert (= x10_65 (ite (= ne_32 #b1) x7_36 #x0000000000000000)))
(assert (and (= ge_94 ((_ extract 63 63) x3_63)) (= dc_266 ((_ extract 62 0) x3_63))))
(assert (= ge_95 (bvnot ge_94)))
(assert (= ge_96 (ite (= ne_32 #b1) ge_95 #b0)))
(assert (and (= dc_267 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_63))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_32 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_63))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_64 (ite (= ge_96 #b1) x3_neg_32 x3_63)))
(assert (and (= dc_268 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_65))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_32 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_65))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_66 (ite (= ge_96 #b1) x10_neg_32 x10_65)))
(assert (= x7_37 (ite (= ge_96 #b1) x8_66 x7_36)))
(assert (and (= dc_269 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_66) ((_ zero_extend 1) x10_66)))) (= x8_67 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_66) ((_ zero_extend 1) x10_66))))))
(assert (= x3_65 (bvadd x3_64 #x0000000000000002)))
(assert (and (= dc_270 ((_ extract 63 2) x8_67)) (= x8_lo_33 ((_ extract 1 0) x8_67))))
(assert (and (= x8_target_31 ((_ extract 1 1) x8_lo_33)) (= dc_271 ((_ extract 0 0) x8_lo_33))))
(assert (= ne_33 (bvand x8_target_31 #b1)))
(assert (and (= x8_68 ((_ sign_extend 1) ((_ extract 63 1) x8_67))) (= dc_272 ((_ zero_extend 63) ((_ extract 0 0) x8_67)))))
(assert true)
(assert (= x10_67 (ite (= ne_33 #b1) x7_37 #x0000000000000000)))
(assert (and (= ge_97 ((_ extract 63 63) x3_65)) (= dc_273 ((_ extract 62 0) x3_65))))
(assert (= ge_98 (bvnot ge_97)))
(assert (= ge_99 (ite (= ne_33 #b1) ge_98 #b0)))
(assert (and (= dc_274 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_65))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_33 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_65))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_66 (ite (= ge_99 #b1) x3_neg_33 x3_65)))
(assert (and (= dc_275 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_67))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_33 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_67))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_68 (ite (= ge_99 #b1) x10_neg_33 x10_67)))
(assert (= x7_38 (ite (= ge_99 #b1) x8_68 x7_37)))
(assert (and (= dc_276 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_68) ((_ zero_extend 1) x10_68)))) (= x8_69 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_68) ((_ zero_extend 1) x10_68))))))
(assert (= x3_67 (bvadd x3_66 #x0000000000000002)))
(assert (and (= dc_277 ((_ extract 63 2) x8_69)) (= x8_lo_34 ((_ extract 1 0) x8_69))))
(assert (and (= x8_target_32 ((_ extract 1 1) x8_lo_34)) (= dc_278 ((_ extract 0 0) x8_lo_34))))
(assert (= ne_34 (bvand x8_target_32 #b1)))
(assert (and (= x8_70 ((_ sign_extend 1) ((_ extract 63 1) x8_69))) (= dc_279 ((_ zero_extend 63) ((_ extract 0 0) x8_69)))))
(assert true)
(assert (= x10_69 (ite (= ne_34 #b1) x7_38 #x0000000000000000)))
(assert (and (= ge_100 ((_ extract 63 63) x3_67)) (= dc_280 ((_ extract 62 0) x3_67))))
(assert (= ge_101 (bvnot ge_100)))
(assert (= ge_102 (ite (= ne_34 #b1) ge_101 #b0)))
(assert (and (= dc_281 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_67))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_34 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_67))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_68 (ite (= ge_102 #b1) x3_neg_34 x3_67)))
(assert (and (= dc_282 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_69))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_34 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_69))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_70 (ite (= ge_102 #b1) x10_neg_34 x10_69)))
(assert (= x7_39 (ite (= ge_102 #b1) x8_70 x7_38)))
(assert (and (= dc_283 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_70) ((_ zero_extend 1) x10_70)))) (= x8_71 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_70) ((_ zero_extend 1) x10_70))))))
(assert (= x3_69 (bvadd x3_68 #x0000000000000002)))
(assert (and (= dc_284 ((_ extract 63 2) x8_71)) (= x8_lo_35 ((_ extract 1 0) x8_71))))
(assert (and (= x8_target_33 ((_ extract 1 1) x8_lo_35)) (= dc_285 ((_ extract 0 0) x8_lo_35))))
(assert (= ne_35 (bvand x8_target_33 #b1)))
(assert (and (= x8_72 ((_ sign_extend 1) ((_ extract 63 1) x8_71))) (= dc_286 ((_ zero_extend 63) ((_ extract 0 0) x8_71)))))
(assert true)
(assert (= x10_71 (ite (= ne_35 #b1) x7_39 #x0000000000000000)))
(assert (and (= ge_103 ((_ extract 63 63) x3_69)) (= dc_287 ((_ extract 62 0) x3_69))))
(assert (= ge_104 (bvnot ge_103)))
(assert (= ge_105 (ite (= ne_35 #b1) ge_104 #b0)))
(assert (and (= dc_288 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_69))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_35 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_69))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_70 (ite (= ge_105 #b1) x3_neg_35 x3_69)))
(assert (and (= dc_289 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_71))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_35 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_71))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_72 (ite (= ge_105 #b1) x10_neg_35 x10_71)))
(assert (= x7_40 (ite (= ge_105 #b1) x8_72 x7_39)))
(assert (and (= dc_290 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_72) ((_ zero_extend 1) x10_72)))) (= x8_73 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_72) ((_ zero_extend 1) x10_72))))))
(assert (= x3_71 (bvadd x3_70 #x0000000000000002)))
(assert (and (= dc_291 ((_ extract 63 2) x8_73)) (= x8_lo_36 ((_ extract 1 0) x8_73))))
(assert (and (= x8_target_34 ((_ extract 1 1) x8_lo_36)) (= dc_292 ((_ extract 0 0) x8_lo_36))))
(assert (= ne_36 (bvand x8_target_34 #b1)))
(assert (and (= x8_74 ((_ sign_extend 1) ((_ extract 63 1) x8_73))) (= dc_293 ((_ zero_extend 63) ((_ extract 0 0) x8_73)))))
(assert true)
(assert (= x10_73 (ite (= ne_36 #b1) x7_40 #x0000000000000000)))
(assert (and (= ge_106 ((_ extract 63 63) x3_71)) (= dc_294 ((_ extract 62 0) x3_71))))
(assert (= ge_107 (bvnot ge_106)))
(assert (= ge_108 (ite (= ne_36 #b1) ge_107 #b0)))
(assert (and (= dc_295 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_71))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_36 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_71))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_72 (ite (= ge_108 #b1) x3_neg_36 x3_71)))
(assert (and (= dc_296 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_73))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_36 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_73))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_74 (ite (= ge_108 #b1) x10_neg_36 x10_73)))
(assert (= x7_41 (ite (= ge_108 #b1) x8_74 x7_40)))
(assert (and (= dc_297 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_74) ((_ zero_extend 1) x10_74)))) (= x8_75 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_74) ((_ zero_extend 1) x10_74))))))
(assert (= x3_73 (bvadd x3_72 #x0000000000000002)))
(assert (and (= dc_298 ((_ extract 63 2) x8_75)) (= x8_lo_37 ((_ extract 1 0) x8_75))))
(assert (and (= x8_target_35 ((_ extract 1 1) x8_lo_37)) (= dc_299 ((_ extract 0 0) x8_lo_37))))
(assert (= ne_37 (bvand x8_target_35 #b1)))
(assert (and (= x8_76 ((_ sign_extend 1) ((_ extract 63 1) x8_75))) (= dc_300 ((_ zero_extend 63) ((_ extract 0 0) x8_75)))))
(assert true)
(assert (= x10_75 (ite (= ne_37 #b1) x7_41 #x0000000000000000)))
(assert (and (= ge_109 ((_ extract 63 63) x3_73)) (= dc_301 ((_ extract 62 0) x3_73))))
(assert (= ge_110 (bvnot ge_109)))
(assert (= ge_111 (ite (= ne_37 #b1) ge_110 #b0)))
(assert (and (= dc_302 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_73))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_37 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_73))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_74 (ite (= ge_111 #b1) x3_neg_37 x3_73)))
(assert (and (= dc_303 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_75))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_37 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_75))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_76 (ite (= ge_111 #b1) x10_neg_37 x10_75)))
(assert (= x7_42 (ite (= ge_111 #b1) x8_76 x7_41)))
(assert (and (= dc_304 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_76) ((_ zero_extend 1) x10_76)))) (= x8_77 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_76) ((_ zero_extend 1) x10_76))))))
(assert (= x3_75 (bvadd x3_74 #x0000000000000002)))
(assert (and (= dc_305 ((_ extract 63 2) x8_77)) (= x8_lo_38 ((_ extract 1 0) x8_77))))
(assert (and (= x8_target_36 ((_ extract 1 1) x8_lo_38)) (= dc_306 ((_ extract 0 0) x8_lo_38))))
(assert (= ne_38 (bvand x8_target_36 #b1)))
(assert (and (= x8_78 ((_ sign_extend 1) ((_ extract 63 1) x8_77))) (= dc_307 ((_ zero_extend 63) ((_ extract 0 0) x8_77)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_76) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_42 x7_41)) (= (bvmul x8_78 #x0000000000000002) x8_76)) (= x3_75 (bvadd #x0000000000000002 x3_73))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_76) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_73 #x0000000000000000)) (= x7_42 x7_41)) (= (bvmul x8_78 #x0000000000000002) (bvadd x8_76 x7_41))) (= x3_75 (bvadd #x0000000000000002 x3_73)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_76) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_73 #x0000000000000000)) (= x7_42 x8_76)) (= (bvmul x8_78 #x0000000000000002) (bvsub x8_76 x7_41))) (= x3_75 (bvsub #x0000000000000002 x3_73))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_451b76.smt2
Execution time of boolector: 1.3503 seconds
OUTPUT FROM boolector:
unsat

=== Cut #8 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #8
; Range assertion #68: smod (sub (uext x2_10 1) (uext (mul (-1)@64 neg_g_0_low60_40_1) 1)) (uext 17592186044416@64 1) = 0@65
; Range condition: ((x2_10@e1) - ((-1 * neg_g_0_low60_40_1)@e1)) smod (17592186044416@e1) = 0
; Output file: /tmp/outputqfbv_b8e2fa.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x9_6 () (_ BitVec 64))
(declare-fun x9_5 () (_ BitVec 64))
(declare-fun x9_4 () (_ BitVec 64))
(declare-fun x9_3 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_79 () (_ BitVec 64))
(declare-fun x20_3 () (_ BitVec 64))
(declare-fun x2_10 () (_ BitVec 64))
(declare-fun x2_9 () (_ BitVec 64))
(declare-fun x2_7 () (_ BitVec 64))
(declare-fun x17_5 () (_ BitVec 64))
(declare-fun x16_3 () (_ BitVec 64))
(declare-fun x15_5 () (_ BitVec 64))
(declare-fun x10_82 () (_ BitVec 64))
(declare-fun x10_81 () (_ BitVec 64))
(declare-fun x1_5 () (_ BitVec 64))
(declare-fun tmp_4 () (_ BitVec 64))
(declare-fun tmp_3 () (_ BitVec 64))
(declare-fun neg_g_0_low60_40_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_40_1 () (_ BitVec 64))
(declare-fun dcH_13 () (_ BitVec 64))
(declare-fun dcH_12 () (_ BitVec 64))
(declare-fun dcH_11 () (_ BitVec 64))
(declare-fun dcH_10 () (_ BitVec 64))
(declare-fun dc_327 () (_ BitVec 64))
(declare-fun dc_326 () (_ BitVec 1))
(declare-fun dc_325 () (_ BitVec 64))
(declare-fun dc_324 () (_ BitVec 1))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) neg_f_0_low60_40_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= (bvsmod (bvsub ((_ zero_extend 1) x3_79) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFB1 x3_79)) (bvsle x3_79 #x0000000000000051)) (bvsle #xFFFFFFFFFFF00000 x15_5)) (bvsle x15_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x16_3)) (bvsle x16_3 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x17_5)) (bvsle x17_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x20_3)) (bvsle x20_3 #x00000000000FFFFF)) (= x6_2 #x0000020000100000)))
(assert (= x1_5 x9_3))
(assert (= x2_9 x2_7))
(assert true)
(assert (and (= dcH_10 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x15_5) ((_ sign_extend 64) x1_5)))) (= x9_4 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x15_5) ((_ sign_extend 64) x1_5))))))
(assert (and (= dcH_11 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_9) ((_ sign_extend 64) x16_3)))) (= tmp_3 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_9) ((_ sign_extend 64) x16_3))))))
(assert (and (= dc_324 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x9_4) ((_ zero_extend 1) tmp_3)))) (= x9_5 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x9_4) ((_ zero_extend 1) tmp_3))))))
(assert true)
(assert (and (= x9_5 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) neg_f_0_low60_40_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x9_5) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x9_6 ((_ zero_extend 20) ((_ extract 63 20) x9_5))) (= dc_325 ((_ zero_extend 44) ((_ extract 19 0) x9_5)))))
(assert true)
(assert true)
(assert (and (= dcH_12 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x17_5) ((_ sign_extend 64) x1_5)))) (= x10_81 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x17_5) ((_ sign_extend 64) x1_5))))))
(assert (and (= dcH_13 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_9) ((_ sign_extend 64) x20_3)))) (= tmp_4 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_9) ((_ sign_extend 64) x20_3))))))
(assert (and (= dc_326 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x10_81) ((_ zero_extend 1) tmp_4)))) (= x10_82 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x10_81) ((_ zero_extend 1) tmp_4))))))
(assert true)
(assert (and (= x10_82 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) neg_g_0_low60_40_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x10_82) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x2_10 ((_ zero_extend 20) ((_ extract 63 20) x10_82))) (= dc_327 ((_ zero_extend 44) ((_ extract 19 0) x10_82)))))
(assert true)
(assert (not (= (bvsmod (bvsub ((_ zero_extend 1) x2_10) ((_ zero_extend 1) (bvmul #xFFFFFFFFFFFFFFFF neg_g_0_low60_40_1))) ((_ zero_extend 1) #x0000100000000000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_df9e6d.smt2
Execution time of boolector: 0.1445 seconds
OUTPUT FROM boolector:
unsat

=== Cut #8 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #8
; Range assertion #69: smod (sub (uext x9_6 1) (uext (mul (-1)@64 neg_f_0_low60_40_1) 1)) (uext 17592186044416@64 1) = 0@65
; Range condition: ((x9_6@e1) - ((-1 * neg_f_0_low60_40_1)@e1)) smod (17592186044416@e1) = 0
; Output file: /tmp/outputqfbv_b6ca9e.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x9_6 () (_ BitVec 64))
(declare-fun x9_5 () (_ BitVec 64))
(declare-fun x9_4 () (_ BitVec 64))
(declare-fun x9_3 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_79 () (_ BitVec 64))
(declare-fun x20_3 () (_ BitVec 64))
(declare-fun x2_10 () (_ BitVec 64))
(declare-fun x2_9 () (_ BitVec 64))
(declare-fun x2_7 () (_ BitVec 64))
(declare-fun x17_5 () (_ BitVec 64))
(declare-fun x16_3 () (_ BitVec 64))
(declare-fun x15_5 () (_ BitVec 64))
(declare-fun x10_82 () (_ BitVec 64))
(declare-fun x10_81 () (_ BitVec 64))
(declare-fun x1_5 () (_ BitVec 64))
(declare-fun tmp_4 () (_ BitVec 64))
(declare-fun tmp_3 () (_ BitVec 64))
(declare-fun neg_g_0_low60_40_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_40_1 () (_ BitVec 64))
(declare-fun dcH_13 () (_ BitVec 64))
(declare-fun dcH_12 () (_ BitVec 64))
(declare-fun dcH_11 () (_ BitVec 64))
(declare-fun dcH_10 () (_ BitVec 64))
(declare-fun dc_327 () (_ BitVec 64))
(declare-fun dc_326 () (_ BitVec 1))
(declare-fun dc_325 () (_ BitVec 64))
(declare-fun dc_324 () (_ BitVec 1))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) neg_f_0_low60_40_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= (bvsmod (bvsub ((_ zero_extend 1) x3_79) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFB1 x3_79)) (bvsle x3_79 #x0000000000000051)) (bvsle #xFFFFFFFFFFF00000 x15_5)) (bvsle x15_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x16_3)) (bvsle x16_3 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x17_5)) (bvsle x17_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x20_3)) (bvsle x20_3 #x00000000000FFFFF)) (= x6_2 #x0000020000100000)))
(assert (= x1_5 x9_3))
(assert (= x2_9 x2_7))
(assert true)
(assert (and (= dcH_10 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x15_5) ((_ sign_extend 64) x1_5)))) (= x9_4 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x15_5) ((_ sign_extend 64) x1_5))))))
(assert (and (= dcH_11 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_9) ((_ sign_extend 64) x16_3)))) (= tmp_3 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_9) ((_ sign_extend 64) x16_3))))))
(assert (and (= dc_324 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x9_4) ((_ zero_extend 1) tmp_3)))) (= x9_5 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x9_4) ((_ zero_extend 1) tmp_3))))))
(assert true)
(assert (and (= x9_5 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) neg_f_0_low60_40_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x9_5) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x9_6 ((_ zero_extend 20) ((_ extract 63 20) x9_5))) (= dc_325 ((_ zero_extend 44) ((_ extract 19 0) x9_5)))))
(assert true)
(assert true)
(assert (and (= dcH_12 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x17_5) ((_ sign_extend 64) x1_5)))) (= x10_81 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x17_5) ((_ sign_extend 64) x1_5))))))
(assert (and (= dcH_13 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_9) ((_ sign_extend 64) x20_3)))) (= tmp_4 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_9) ((_ sign_extend 64) x20_3))))))
(assert (and (= dc_326 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x10_81) ((_ zero_extend 1) tmp_4)))) (= x10_82 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x10_81) ((_ zero_extend 1) tmp_4))))))
(assert true)
(assert (and (= x10_82 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) neg_g_0_low60_40_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x10_82) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x2_10 ((_ zero_extend 20) ((_ extract 63 20) x10_82))) (= dc_327 ((_ zero_extend 44) ((_ extract 19 0) x10_82)))))
(assert true)
(assert true)
(assert (not (= (bvsmod (bvsub ((_ zero_extend 1) x9_6) ((_ zero_extend 1) (bvmul #xFFFFFFFFFFFFFFFF neg_f_0_low60_40_1))) ((_ zero_extend 1) #x0000100000000000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_87672c.smt2
Execution time of boolector: 0.1171 seconds
OUTPUT FROM boolector:
unsat

=== Cut #8 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #8
; Range assertion #70: smod (sub (uext x2_10 1) (uext (mul (-1)@64 neg_g_0_low60_40_1) 1)) (uext 17592186044416@64 1) = 0@65
; Range condition: ((x2_10@e1) - ((-1 * neg_g_0_low60_40_1)@e1)) smod (17592186044416@e1) = 0
; Output file: /tmp/outputqfbv_f49ac4.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x9_6 () (_ BitVec 64))
(declare-fun x9_5 () (_ BitVec 64))
(declare-fun x9_4 () (_ BitVec 64))
(declare-fun x9_3 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_79 () (_ BitVec 64))
(declare-fun x20_3 () (_ BitVec 64))
(declare-fun x2_10 () (_ BitVec 64))
(declare-fun x2_9 () (_ BitVec 64))
(declare-fun x2_7 () (_ BitVec 64))
(declare-fun x17_5 () (_ BitVec 64))
(declare-fun x16_3 () (_ BitVec 64))
(declare-fun x15_5 () (_ BitVec 64))
(declare-fun x10_82 () (_ BitVec 64))
(declare-fun x10_81 () (_ BitVec 64))
(declare-fun x1_5 () (_ BitVec 64))
(declare-fun tmp_4 () (_ BitVec 64))
(declare-fun tmp_3 () (_ BitVec 64))
(declare-fun neg_g_0_low60_40_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_40_1 () (_ BitVec 64))
(declare-fun dcH_13 () (_ BitVec 64))
(declare-fun dcH_12 () (_ BitVec 64))
(declare-fun dcH_11 () (_ BitVec 64))
(declare-fun dcH_10 () (_ BitVec 64))
(declare-fun dc_327 () (_ BitVec 64))
(declare-fun dc_326 () (_ BitVec 1))
(declare-fun dc_325 () (_ BitVec 64))
(declare-fun dc_324 () (_ BitVec 1))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) neg_f_0_low60_40_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= (bvsmod (bvsub ((_ zero_extend 1) x3_79) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFB1 x3_79)) (bvsle x3_79 #x0000000000000051)) (bvsle #xFFFFFFFFFFF00000 x15_5)) (bvsle x15_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x16_3)) (bvsle x16_3 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x17_5)) (bvsle x17_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x20_3)) (bvsle x20_3 #x00000000000FFFFF)) (= x6_2 #x0000020000100000)))
(assert (= x1_5 x9_3))
(assert (= x2_9 x2_7))
(assert true)
(assert (and (= dcH_10 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x15_5) ((_ sign_extend 64) x1_5)))) (= x9_4 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x15_5) ((_ sign_extend 64) x1_5))))))
(assert (and (= dcH_11 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_9) ((_ sign_extend 64) x16_3)))) (= tmp_3 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_9) ((_ sign_extend 64) x16_3))))))
(assert (and (= dc_324 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x9_4) ((_ zero_extend 1) tmp_3)))) (= x9_5 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x9_4) ((_ zero_extend 1) tmp_3))))))
(assert true)
(assert (and (= x9_5 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) neg_f_0_low60_40_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x9_5) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x9_6 ((_ zero_extend 20) ((_ extract 63 20) x9_5))) (= dc_325 ((_ zero_extend 44) ((_ extract 19 0) x9_5)))))
(assert true)
(assert true)
(assert (and (= dcH_12 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x17_5) ((_ sign_extend 64) x1_5)))) (= x10_81 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x17_5) ((_ sign_extend 64) x1_5))))))
(assert (and (= dcH_13 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_9) ((_ sign_extend 64) x20_3)))) (= tmp_4 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_9) ((_ sign_extend 64) x20_3))))))
(assert (and (= dc_326 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x10_81) ((_ zero_extend 1) tmp_4)))) (= x10_82 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x10_81) ((_ zero_extend 1) tmp_4))))))
(assert true)
(assert (and (= x10_82 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) neg_g_0_low60_40_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x10_82) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x2_10 ((_ zero_extend 20) ((_ extract 63 20) x10_82))) (= dc_327 ((_ zero_extend 44) ((_ extract 19 0) x10_82)))))
(assert true)
(assert true)
(assert true)
(assert (not (= (bvsmod (bvsub ((_ zero_extend 1) x2_10) ((_ zero_extend 1) (bvmul #xFFFFFFFFFFFFFFFF neg_g_0_low60_40_1))) ((_ zero_extend 1) #x0000100000000000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_a2beaa.smt2
Execution time of boolector: 0.1357 seconds
OUTPUT FROM boolector:
unsat

=== Cut #6 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #6
; Range assertion #57: or [and [smod (sub (uext x8_78 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_43 = x7_42, mul x8_80 2@64 = x8_78, x3_77 = add 2@64 x3_75], and [smod (sub (uext x8_78 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_75 <s 0@64, x7_43 = x7_42, mul x8_80 2@64 = add x8_78 x7_42, x3_77 = add 2@64 x3_75], and [smod (sub (uext x8_78 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_75 >=s 0@64, x7_43 = x8_78, mul x8_80 2@64 = sub x8_78 x7_42, x3_77 = sub 2@64 x3_75]]
; Range condition: ((x8_78@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_43 = x7_42 /\ x8_80 * 2 = x8_78 /\ x3_77 = 2 + x3_75 \/ ((x8_78@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_75 <s 0 /\ x7_43 = x7_42 /\ x8_80 * 2 = x8_78 + x7_42 /\ x3_77 = 2 + x3_75 \/ ((x8_78@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_75 >=s 0 /\ x7_43 = x8_78 /\ x8_80 * 2 = x8_78 - x7_42 /\ x3_77 = 2 - x3_75
; Output file: /tmp/outputqfbv_0dbd83.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_37 () (_ BitVec 1))
(declare-fun x8_target_36 () (_ BitVec 1))
(declare-fun x8_target_35 () (_ BitVec 1))
(declare-fun x8_target_34 () (_ BitVec 1))
(declare-fun x8_target_33 () (_ BitVec 1))
(declare-fun x8_target_32 () (_ BitVec 1))
(declare-fun x8_target_31 () (_ BitVec 1))
(declare-fun x8_target_30 () (_ BitVec 1))
(declare-fun x8_target_29 () (_ BitVec 1))
(declare-fun x8_target_28 () (_ BitVec 1))
(declare-fun x8_target_27 () (_ BitVec 1))
(declare-fun x8_target_26 () (_ BitVec 1))
(declare-fun x8_target_25 () (_ BitVec 1))
(declare-fun x8_target_24 () (_ BitVec 1))
(declare-fun x8_target_23 () (_ BitVec 1))
(declare-fun x8_target_22 () (_ BitVec 1))
(declare-fun x8_target_21 () (_ BitVec 1))
(declare-fun x8_target_20 () (_ BitVec 1))
(declare-fun x8_lo_39 () (_ BitVec 2))
(declare-fun x8_lo_38 () (_ BitVec 2))
(declare-fun x8_lo_37 () (_ BitVec 2))
(declare-fun x8_lo_36 () (_ BitVec 2))
(declare-fun x8_lo_35 () (_ BitVec 2))
(declare-fun x8_lo_34 () (_ BitVec 2))
(declare-fun x8_lo_33 () (_ BitVec 2))
(declare-fun x8_lo_32 () (_ BitVec 2))
(declare-fun x8_lo_31 () (_ BitVec 2))
(declare-fun x8_lo_30 () (_ BitVec 2))
(declare-fun x8_lo_29 () (_ BitVec 2))
(declare-fun x8_lo_28 () (_ BitVec 2))
(declare-fun x8_lo_27 () (_ BitVec 2))
(declare-fun x8_lo_26 () (_ BitVec 2))
(declare-fun x8_lo_25 () (_ BitVec 2))
(declare-fun x8_lo_24 () (_ BitVec 2))
(declare-fun x8_lo_23 () (_ BitVec 2))
(declare-fun x8_lo_22 () (_ BitVec 2))
(declare-fun x8_lo_21 () (_ BitVec 1))
(declare-fun x8_80 () (_ BitVec 64))
(declare-fun x8_79 () (_ BitVec 64))
(declare-fun x8_78 () (_ BitVec 64))
(declare-fun x8_77 () (_ BitVec 64))
(declare-fun x8_76 () (_ BitVec 64))
(declare-fun x8_75 () (_ BitVec 64))
(declare-fun x8_74 () (_ BitVec 64))
(declare-fun x8_73 () (_ BitVec 64))
(declare-fun x8_72 () (_ BitVec 64))
(declare-fun x8_71 () (_ BitVec 64))
(declare-fun x8_70 () (_ BitVec 64))
(declare-fun x8_69 () (_ BitVec 64))
(declare-fun x8_68 () (_ BitVec 64))
(declare-fun x8_67 () (_ BitVec 64))
(declare-fun x8_66 () (_ BitVec 64))
(declare-fun x8_65 () (_ BitVec 64))
(declare-fun x8_64 () (_ BitVec 64))
(declare-fun x8_63 () (_ BitVec 64))
(declare-fun x8_62 () (_ BitVec 64))
(declare-fun x8_61 () (_ BitVec 64))
(declare-fun x8_60 () (_ BitVec 64))
(declare-fun x8_59 () (_ BitVec 64))
(declare-fun x8_58 () (_ BitVec 64))
(declare-fun x8_57 () (_ BitVec 64))
(declare-fun x8_56 () (_ BitVec 64))
(declare-fun x8_55 () (_ BitVec 64))
(declare-fun x8_54 () (_ BitVec 64))
(declare-fun x8_53 () (_ BitVec 64))
(declare-fun x8_52 () (_ BitVec 64))
(declare-fun x8_51 () (_ BitVec 64))
(declare-fun x8_50 () (_ BitVec 64))
(declare-fun x8_49 () (_ BitVec 64))
(declare-fun x8_48 () (_ BitVec 64))
(declare-fun x8_47 () (_ BitVec 64))
(declare-fun x8_46 () (_ BitVec 64))
(declare-fun x8_45 () (_ BitVec 64))
(declare-fun x8_44 () (_ BitVec 64))
(declare-fun x7_43 () (_ BitVec 64))
(declare-fun x7_42 () (_ BitVec 64))
(declare-fun x7_41 () (_ BitVec 64))
(declare-fun x7_40 () (_ BitVec 64))
(declare-fun x7_39 () (_ BitVec 64))
(declare-fun x7_38 () (_ BitVec 64))
(declare-fun x7_37 () (_ BitVec 64))
(declare-fun x7_36 () (_ BitVec 64))
(declare-fun x7_35 () (_ BitVec 64))
(declare-fun x7_34 () (_ BitVec 64))
(declare-fun x7_33 () (_ BitVec 64))
(declare-fun x7_32 () (_ BitVec 64))
(declare-fun x7_31 () (_ BitVec 64))
(declare-fun x7_30 () (_ BitVec 64))
(declare-fun x7_29 () (_ BitVec 64))
(declare-fun x7_28 () (_ BitVec 64))
(declare-fun x7_27 () (_ BitVec 64))
(declare-fun x7_26 () (_ BitVec 64))
(declare-fun x7_25 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_38 () (_ BitVec 64))
(declare-fun x3_neg_37 () (_ BitVec 64))
(declare-fun x3_neg_36 () (_ BitVec 64))
(declare-fun x3_neg_35 () (_ BitVec 64))
(declare-fun x3_neg_34 () (_ BitVec 64))
(declare-fun x3_neg_33 () (_ BitVec 64))
(declare-fun x3_neg_32 () (_ BitVec 64))
(declare-fun x3_neg_31 () (_ BitVec 64))
(declare-fun x3_neg_30 () (_ BitVec 64))
(declare-fun x3_neg_29 () (_ BitVec 64))
(declare-fun x3_neg_28 () (_ BitVec 64))
(declare-fun x3_neg_27 () (_ BitVec 64))
(declare-fun x3_neg_26 () (_ BitVec 64))
(declare-fun x3_neg_25 () (_ BitVec 64))
(declare-fun x3_neg_24 () (_ BitVec 64))
(declare-fun x3_neg_23 () (_ BitVec 64))
(declare-fun x3_neg_22 () (_ BitVec 64))
(declare-fun x3_neg_21 () (_ BitVec 64))
(declare-fun x3_77 () (_ BitVec 64))
(declare-fun x3_76 () (_ BitVec 64))
(declare-fun x3_75 () (_ BitVec 64))
(declare-fun x3_74 () (_ BitVec 64))
(declare-fun x3_73 () (_ BitVec 64))
(declare-fun x3_72 () (_ BitVec 64))
(declare-fun x3_71 () (_ BitVec 64))
(declare-fun x3_70 () (_ BitVec 64))
(declare-fun x3_69 () (_ BitVec 64))
(declare-fun x3_68 () (_ BitVec 64))
(declare-fun x3_67 () (_ BitVec 64))
(declare-fun x3_66 () (_ BitVec 64))
(declare-fun x3_65 () (_ BitVec 64))
(declare-fun x3_64 () (_ BitVec 64))
(declare-fun x3_63 () (_ BitVec 64))
(declare-fun x3_62 () (_ BitVec 64))
(declare-fun x3_61 () (_ BitVec 64))
(declare-fun x3_60 () (_ BitVec 64))
(declare-fun x3_59 () (_ BitVec 64))
(declare-fun x3_58 () (_ BitVec 64))
(declare-fun x3_57 () (_ BitVec 64))
(declare-fun x3_56 () (_ BitVec 64))
(declare-fun x3_55 () (_ BitVec 64))
(declare-fun x3_54 () (_ BitVec 64))
(declare-fun x3_53 () (_ BitVec 64))
(declare-fun x3_52 () (_ BitVec 64))
(declare-fun x3_51 () (_ BitVec 64))
(declare-fun x3_50 () (_ BitVec 64))
(declare-fun x3_49 () (_ BitVec 64))
(declare-fun x3_48 () (_ BitVec 64))
(declare-fun x3_47 () (_ BitVec 64))
(declare-fun x3_46 () (_ BitVec 64))
(declare-fun x3_45 () (_ BitVec 64))
(declare-fun x3_44 () (_ BitVec 64))
(declare-fun x3_43 () (_ BitVec 64))
(declare-fun x3_42 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x10_neg_38 () (_ BitVec 64))
(declare-fun x10_neg_37 () (_ BitVec 64))
(declare-fun x10_neg_36 () (_ BitVec 64))
(declare-fun x10_neg_35 () (_ BitVec 64))
(declare-fun x10_neg_34 () (_ BitVec 64))
(declare-fun x10_neg_33 () (_ BitVec 64))
(declare-fun x10_neg_32 () (_ BitVec 64))
(declare-fun x10_neg_31 () (_ BitVec 64))
(declare-fun x10_neg_30 () (_ BitVec 64))
(declare-fun x10_neg_29 () (_ BitVec 64))
(declare-fun x10_neg_28 () (_ BitVec 64))
(declare-fun x10_neg_27 () (_ BitVec 64))
(declare-fun x10_neg_26 () (_ BitVec 64))
(declare-fun x10_neg_25 () (_ BitVec 64))
(declare-fun x10_neg_24 () (_ BitVec 64))
(declare-fun x10_neg_23 () (_ BitVec 64))
(declare-fun x10_neg_22 () (_ BitVec 64))
(declare-fun x10_neg_21 () (_ BitVec 64))
(declare-fun x10_78 () (_ BitVec 64))
(declare-fun x10_77 () (_ BitVec 64))
(declare-fun x10_76 () (_ BitVec 64))
(declare-fun x10_75 () (_ BitVec 64))
(declare-fun x10_74 () (_ BitVec 64))
(declare-fun x10_73 () (_ BitVec 64))
(declare-fun x10_72 () (_ BitVec 64))
(declare-fun x10_71 () (_ BitVec 64))
(declare-fun x10_70 () (_ BitVec 64))
(declare-fun x10_69 () (_ BitVec 64))
(declare-fun x10_68 () (_ BitVec 64))
(declare-fun x10_67 () (_ BitVec 64))
(declare-fun x10_66 () (_ BitVec 64))
(declare-fun x10_65 () (_ BitVec 64))
(declare-fun x10_64 () (_ BitVec 64))
(declare-fun x10_63 () (_ BitVec 64))
(declare-fun x10_62 () (_ BitVec 64))
(declare-fun x10_61 () (_ BitVec 64))
(declare-fun x10_60 () (_ BitVec 64))
(declare-fun x10_59 () (_ BitVec 64))
(declare-fun x10_58 () (_ BitVec 64))
(declare-fun x10_57 () (_ BitVec 64))
(declare-fun x10_56 () (_ BitVec 64))
(declare-fun x10_55 () (_ BitVec 64))
(declare-fun x10_54 () (_ BitVec 64))
(declare-fun x10_53 () (_ BitVec 64))
(declare-fun x10_52 () (_ BitVec 64))
(declare-fun x10_51 () (_ BitVec 64))
(declare-fun x10_50 () (_ BitVec 64))
(declare-fun x10_49 () (_ BitVec 64))
(declare-fun x10_48 () (_ BitVec 64))
(declare-fun x10_47 () (_ BitVec 64))
(declare-fun x10_46 () (_ BitVec 64))
(declare-fun x10_45 () (_ BitVec 64))
(declare-fun x10_44 () (_ BitVec 64))
(declare-fun x10_43 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun ne_39 () (_ BitVec 1))
(declare-fun ne_38 () (_ BitVec 1))
(declare-fun ne_37 () (_ BitVec 1))
(declare-fun ne_36 () (_ BitVec 1))
(declare-fun ne_35 () (_ BitVec 1))
(declare-fun ne_34 () (_ BitVec 1))
(declare-fun ne_33 () (_ BitVec 1))
(declare-fun ne_32 () (_ BitVec 1))
(declare-fun ne_31 () (_ BitVec 1))
(declare-fun ne_30 () (_ BitVec 1))
(declare-fun ne_29 () (_ BitVec 1))
(declare-fun ne_28 () (_ BitVec 1))
(declare-fun ne_27 () (_ BitVec 1))
(declare-fun ne_26 () (_ BitVec 1))
(declare-fun ne_25 () (_ BitVec 1))
(declare-fun ne_24 () (_ BitVec 1))
(declare-fun ne_23 () (_ BitVec 1))
(declare-fun ne_22 () (_ BitVec 1))
(declare-fun ne_21 () (_ BitVec 1))
(declare-fun ge_114 () (_ BitVec 1))
(declare-fun ge_113 () (_ BitVec 1))
(declare-fun ge_112 () (_ BitVec 1))
(declare-fun ge_111 () (_ BitVec 1))
(declare-fun ge_110 () (_ BitVec 1))
(declare-fun ge_109 () (_ BitVec 1))
(declare-fun ge_108 () (_ BitVec 1))
(declare-fun ge_107 () (_ BitVec 1))
(declare-fun ge_106 () (_ BitVec 1))
(declare-fun ge_105 () (_ BitVec 1))
(declare-fun ge_104 () (_ BitVec 1))
(declare-fun ge_103 () (_ BitVec 1))
(declare-fun ge_102 () (_ BitVec 1))
(declare-fun ge_101 () (_ BitVec 1))
(declare-fun ge_100 () (_ BitVec 1))
(declare-fun ge_99 () (_ BitVec 1))
(declare-fun ge_98 () (_ BitVec 1))
(declare-fun ge_97 () (_ BitVec 1))
(declare-fun ge_96 () (_ BitVec 1))
(declare-fun ge_95 () (_ BitVec 1))
(declare-fun ge_94 () (_ BitVec 1))
(declare-fun ge_93 () (_ BitVec 1))
(declare-fun ge_92 () (_ BitVec 1))
(declare-fun ge_91 () (_ BitVec 1))
(declare-fun ge_90 () (_ BitVec 1))
(declare-fun ge_89 () (_ BitVec 1))
(declare-fun ge_88 () (_ BitVec 1))
(declare-fun ge_87 () (_ BitVec 1))
(declare-fun ge_86 () (_ BitVec 1))
(declare-fun ge_85 () (_ BitVec 1))
(declare-fun ge_84 () (_ BitVec 1))
(declare-fun ge_83 () (_ BitVec 1))
(declare-fun ge_82 () (_ BitVec 1))
(declare-fun ge_81 () (_ BitVec 1))
(declare-fun ge_80 () (_ BitVec 1))
(declare-fun ge_79 () (_ BitVec 1))
(declare-fun ge_78 () (_ BitVec 1))
(declare-fun ge_77 () (_ BitVec 1))
(declare-fun ge_76 () (_ BitVec 1))
(declare-fun ge_75 () (_ BitVec 1))
(declare-fun ge_74 () (_ BitVec 1))
(declare-fun ge_73 () (_ BitVec 1))
(declare-fun ge_72 () (_ BitVec 1))
(declare-fun ge_71 () (_ BitVec 1))
(declare-fun ge_70 () (_ BitVec 1))
(declare-fun ge_69 () (_ BitVec 1))
(declare-fun ge_68 () (_ BitVec 1))
(declare-fun ge_67 () (_ BitVec 1))
(declare-fun ge_66 () (_ BitVec 1))
(declare-fun ge_65 () (_ BitVec 1))
(declare-fun ge_64 () (_ BitVec 1))
(declare-fun ge_63 () (_ BitVec 1))
(declare-fun ge_62 () (_ BitVec 1))
(declare-fun ge_61 () (_ BitVec 1))
(declare-fun dc_314 () (_ BitVec 64))
(declare-fun dc_313 () (_ BitVec 1))
(declare-fun dc_312 () (_ BitVec 62))
(declare-fun dc_311 () (_ BitVec 1))
(declare-fun dc_310 () (_ BitVec 1))
(declare-fun dc_309 () (_ BitVec 1))
(declare-fun dc_308 () (_ BitVec 63))
(declare-fun dc_307 () (_ BitVec 64))
(declare-fun dc_306 () (_ BitVec 1))
(declare-fun dc_305 () (_ BitVec 62))
(declare-fun dc_304 () (_ BitVec 1))
(declare-fun dc_303 () (_ BitVec 1))
(declare-fun dc_302 () (_ BitVec 1))
(declare-fun dc_301 () (_ BitVec 63))
(declare-fun dc_300 () (_ BitVec 64))
(declare-fun dc_299 () (_ BitVec 1))
(declare-fun dc_298 () (_ BitVec 62))
(declare-fun dc_297 () (_ BitVec 1))
(declare-fun dc_296 () (_ BitVec 1))
(declare-fun dc_295 () (_ BitVec 1))
(declare-fun dc_294 () (_ BitVec 63))
(declare-fun dc_293 () (_ BitVec 64))
(declare-fun dc_292 () (_ BitVec 1))
(declare-fun dc_291 () (_ BitVec 62))
(declare-fun dc_290 () (_ BitVec 1))
(declare-fun dc_289 () (_ BitVec 1))
(declare-fun dc_288 () (_ BitVec 1))
(declare-fun dc_287 () (_ BitVec 63))
(declare-fun dc_286 () (_ BitVec 64))
(declare-fun dc_285 () (_ BitVec 1))
(declare-fun dc_284 () (_ BitVec 62))
(declare-fun dc_283 () (_ BitVec 1))
(declare-fun dc_282 () (_ BitVec 1))
(declare-fun dc_281 () (_ BitVec 1))
(declare-fun dc_280 () (_ BitVec 63))
(declare-fun dc_279 () (_ BitVec 64))
(declare-fun dc_278 () (_ BitVec 1))
(declare-fun dc_277 () (_ BitVec 62))
(declare-fun dc_276 () (_ BitVec 1))
(declare-fun dc_275 () (_ BitVec 1))
(declare-fun dc_274 () (_ BitVec 1))
(declare-fun dc_273 () (_ BitVec 63))
(declare-fun dc_272 () (_ BitVec 64))
(declare-fun dc_271 () (_ BitVec 1))
(declare-fun dc_270 () (_ BitVec 62))
(declare-fun dc_269 () (_ BitVec 1))
(declare-fun dc_268 () (_ BitVec 1))
(declare-fun dc_267 () (_ BitVec 1))
(declare-fun dc_266 () (_ BitVec 63))
(declare-fun dc_265 () (_ BitVec 64))
(declare-fun dc_264 () (_ BitVec 1))
(declare-fun dc_263 () (_ BitVec 62))
(declare-fun dc_262 () (_ BitVec 1))
(declare-fun dc_261 () (_ BitVec 1))
(declare-fun dc_260 () (_ BitVec 1))
(declare-fun dc_259 () (_ BitVec 63))
(declare-fun dc_258 () (_ BitVec 64))
(declare-fun dc_257 () (_ BitVec 1))
(declare-fun dc_256 () (_ BitVec 62))
(declare-fun dc_255 () (_ BitVec 1))
(declare-fun dc_254 () (_ BitVec 1))
(declare-fun dc_253 () (_ BitVec 1))
(declare-fun dc_252 () (_ BitVec 63))
(declare-fun dc_251 () (_ BitVec 64))
(declare-fun dc_250 () (_ BitVec 1))
(declare-fun dc_249 () (_ BitVec 62))
(declare-fun dc_248 () (_ BitVec 1))
(declare-fun dc_247 () (_ BitVec 1))
(declare-fun dc_246 () (_ BitVec 1))
(declare-fun dc_245 () (_ BitVec 63))
(declare-fun dc_244 () (_ BitVec 64))
(declare-fun dc_243 () (_ BitVec 1))
(declare-fun dc_242 () (_ BitVec 62))
(declare-fun dc_241 () (_ BitVec 1))
(declare-fun dc_240 () (_ BitVec 1))
(declare-fun dc_239 () (_ BitVec 1))
(declare-fun dc_238 () (_ BitVec 63))
(declare-fun dc_237 () (_ BitVec 64))
(declare-fun dc_236 () (_ BitVec 1))
(declare-fun dc_235 () (_ BitVec 62))
(declare-fun dc_234 () (_ BitVec 1))
(declare-fun dc_233 () (_ BitVec 1))
(declare-fun dc_232 () (_ BitVec 1))
(declare-fun dc_231 () (_ BitVec 63))
(declare-fun dc_230 () (_ BitVec 64))
(declare-fun dc_229 () (_ BitVec 1))
(declare-fun dc_228 () (_ BitVec 62))
(declare-fun dc_227 () (_ BitVec 1))
(declare-fun dc_226 () (_ BitVec 1))
(declare-fun dc_225 () (_ BitVec 1))
(declare-fun dc_224 () (_ BitVec 63))
(declare-fun dc_223 () (_ BitVec 64))
(declare-fun dc_222 () (_ BitVec 1))
(declare-fun dc_221 () (_ BitVec 62))
(declare-fun dc_220 () (_ BitVec 1))
(declare-fun dc_219 () (_ BitVec 1))
(declare-fun dc_218 () (_ BitVec 1))
(declare-fun dc_217 () (_ BitVec 63))
(declare-fun dc_216 () (_ BitVec 64))
(declare-fun dc_215 () (_ BitVec 1))
(declare-fun dc_214 () (_ BitVec 62))
(declare-fun dc_213 () (_ BitVec 1))
(declare-fun dc_212 () (_ BitVec 1))
(declare-fun dc_211 () (_ BitVec 1))
(declare-fun dc_210 () (_ BitVec 63))
(declare-fun dc_209 () (_ BitVec 64))
(declare-fun dc_208 () (_ BitVec 1))
(declare-fun dc_207 () (_ BitVec 62))
(declare-fun dc_206 () (_ BitVec 1))
(declare-fun dc_205 () (_ BitVec 1))
(declare-fun dc_204 () (_ BitVec 1))
(declare-fun dc_203 () (_ BitVec 63))
(declare-fun dc_202 () (_ BitVec 64))
(declare-fun dc_201 () (_ BitVec 1))
(declare-fun dc_200 () (_ BitVec 62))
(declare-fun dc_199 () (_ BitVec 1))
(declare-fun dc_198 () (_ BitVec 1))
(declare-fun dc_197 () (_ BitVec 1))
(declare-fun dc_196 () (_ BitVec 63))
(declare-fun dc_195 () (_ BitVec 64))
(declare-fun dc_194 () (_ BitVec 1))
(declare-fun dc_193 () (_ BitVec 62))
(declare-fun dc_192 () (_ BitVec 1))
(declare-fun dc_191 () (_ BitVec 1))
(declare-fun dc_190 () (_ BitVec 1))
(declare-fun dc_189 () (_ BitVec 63))
(declare-fun dc_188 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_25 (bvadd (bvadd neg_f_0_low60_20_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_44 (bvadd (bvadd neg_g_0_low60_20_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_0_1)) (bvsle neg_f_0_low60_20_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_0_1)) (bvsle neg_g_0_low60_20_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_25) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_188 ((_ extract 63 1) x8_44)) (= x8_lo_21 ((_ extract 0 0) x8_44))))
(assert (= ne_21 (bvand x8_lo_21 #b1)))
(assert (= x10_43 (ite (= ne_21 #b1) x7_25 #x0000000000000000)))
(assert (and (= ge_61 ((_ extract 63 63) x3_41)) (= dc_189 ((_ extract 62 0) x3_41))))
(assert (= ge_62 (bvnot ge_61)))
(assert (= ge_63 (ite (= ne_21 #b1) ge_62 #b0)))
(assert (and (= dc_190 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_42 (ite (= ge_63 #b1) x3_neg_21 x3_41)))
(assert (and (= dc_191 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_44 (ite (= ge_63 #b1) x10_neg_21 x10_43)))
(assert (= x7_26 (ite (= ge_63 #b1) x8_44 x7_25)))
(assert (and (= dc_192 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44)))) (= x8_45 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44))))))
(assert (= x3_43 (bvadd x3_42 #x0000000000000002)))
(assert (and (= dc_193 ((_ extract 63 2) x8_45)) (= x8_lo_22 ((_ extract 1 0) x8_45))))
(assert (and (= x8_target_20 ((_ extract 1 1) x8_lo_22)) (= dc_194 ((_ extract 0 0) x8_lo_22))))
(assert (= ne_22 (bvand x8_target_20 #b1)))
(assert (and (= x8_46 ((_ sign_extend 1) ((_ extract 63 1) x8_45))) (= dc_195 ((_ zero_extend 63) ((_ extract 0 0) x8_45)))))
(assert true)
(assert (= x10_45 (ite (= ne_22 #b1) x7_26 #x0000000000000000)))
(assert (and (= ge_64 ((_ extract 63 63) x3_43)) (= dc_196 ((_ extract 62 0) x3_43))))
(assert (= ge_65 (bvnot ge_64)))
(assert (= ge_66 (ite (= ne_22 #b1) ge_65 #b0)))
(assert (and (= dc_197 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_44 (ite (= ge_66 #b1) x3_neg_22 x3_43)))
(assert (and (= dc_198 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_46 (ite (= ge_66 #b1) x10_neg_22 x10_45)))
(assert (= x7_27 (ite (= ge_66 #b1) x8_46 x7_26)))
(assert (and (= dc_199 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46)))) (= x8_47 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46))))))
(assert (= x3_45 (bvadd x3_44 #x0000000000000002)))
(assert (and (= dc_200 ((_ extract 63 2) x8_47)) (= x8_lo_23 ((_ extract 1 0) x8_47))))
(assert (and (= x8_target_21 ((_ extract 1 1) x8_lo_23)) (= dc_201 ((_ extract 0 0) x8_lo_23))))
(assert (= ne_23 (bvand x8_target_21 #b1)))
(assert (and (= x8_48 ((_ sign_extend 1) ((_ extract 63 1) x8_47))) (= dc_202 ((_ zero_extend 63) ((_ extract 0 0) x8_47)))))
(assert true)
(assert (= x10_47 (ite (= ne_23 #b1) x7_27 #x0000000000000000)))
(assert (and (= ge_67 ((_ extract 63 63) x3_45)) (= dc_203 ((_ extract 62 0) x3_45))))
(assert (= ge_68 (bvnot ge_67)))
(assert (= ge_69 (ite (= ne_23 #b1) ge_68 #b0)))
(assert (and (= dc_204 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_46 (ite (= ge_69 #b1) x3_neg_23 x3_45)))
(assert (and (= dc_205 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_48 (ite (= ge_69 #b1) x10_neg_23 x10_47)))
(assert (= x7_28 (ite (= ge_69 #b1) x8_48 x7_27)))
(assert (and (= dc_206 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48)))) (= x8_49 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48))))))
(assert (= x3_47 (bvadd x3_46 #x0000000000000002)))
(assert (and (= dc_207 ((_ extract 63 2) x8_49)) (= x8_lo_24 ((_ extract 1 0) x8_49))))
(assert (and (= x8_target_22 ((_ extract 1 1) x8_lo_24)) (= dc_208 ((_ extract 0 0) x8_lo_24))))
(assert (= ne_24 (bvand x8_target_22 #b1)))
(assert (and (= x8_50 ((_ sign_extend 1) ((_ extract 63 1) x8_49))) (= dc_209 ((_ zero_extend 63) ((_ extract 0 0) x8_49)))))
(assert true)
(assert (= x10_49 (ite (= ne_24 #b1) x7_28 #x0000000000000000)))
(assert (and (= ge_70 ((_ extract 63 63) x3_47)) (= dc_210 ((_ extract 62 0) x3_47))))
(assert (= ge_71 (bvnot ge_70)))
(assert (= ge_72 (ite (= ne_24 #b1) ge_71 #b0)))
(assert (and (= dc_211 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_47))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_24 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_47))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_48 (ite (= ge_72 #b1) x3_neg_24 x3_47)))
(assert (and (= dc_212 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_49))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_24 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_49))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_50 (ite (= ge_72 #b1) x10_neg_24 x10_49)))
(assert (= x7_29 (ite (= ge_72 #b1) x8_50 x7_28)))
(assert (and (= dc_213 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_50) ((_ zero_extend 1) x10_50)))) (= x8_51 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_50) ((_ zero_extend 1) x10_50))))))
(assert (= x3_49 (bvadd x3_48 #x0000000000000002)))
(assert (and (= dc_214 ((_ extract 63 2) x8_51)) (= x8_lo_25 ((_ extract 1 0) x8_51))))
(assert (and (= x8_target_23 ((_ extract 1 1) x8_lo_25)) (= dc_215 ((_ extract 0 0) x8_lo_25))))
(assert (= ne_25 (bvand x8_target_23 #b1)))
(assert (and (= x8_52 ((_ sign_extend 1) ((_ extract 63 1) x8_51))) (= dc_216 ((_ zero_extend 63) ((_ extract 0 0) x8_51)))))
(assert true)
(assert (= x10_51 (ite (= ne_25 #b1) x7_29 #x0000000000000000)))
(assert (and (= ge_73 ((_ extract 63 63) x3_49)) (= dc_217 ((_ extract 62 0) x3_49))))
(assert (= ge_74 (bvnot ge_73)))
(assert (= ge_75 (ite (= ne_25 #b1) ge_74 #b0)))
(assert (and (= dc_218 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_49))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_25 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_49))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_50 (ite (= ge_75 #b1) x3_neg_25 x3_49)))
(assert (and (= dc_219 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_51))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_25 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_51))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_52 (ite (= ge_75 #b1) x10_neg_25 x10_51)))
(assert (= x7_30 (ite (= ge_75 #b1) x8_52 x7_29)))
(assert (and (= dc_220 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_52) ((_ zero_extend 1) x10_52)))) (= x8_53 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_52) ((_ zero_extend 1) x10_52))))))
(assert (= x3_51 (bvadd x3_50 #x0000000000000002)))
(assert (and (= dc_221 ((_ extract 63 2) x8_53)) (= x8_lo_26 ((_ extract 1 0) x8_53))))
(assert (and (= x8_target_24 ((_ extract 1 1) x8_lo_26)) (= dc_222 ((_ extract 0 0) x8_lo_26))))
(assert (= ne_26 (bvand x8_target_24 #b1)))
(assert (and (= x8_54 ((_ sign_extend 1) ((_ extract 63 1) x8_53))) (= dc_223 ((_ zero_extend 63) ((_ extract 0 0) x8_53)))))
(assert true)
(assert (= x10_53 (ite (= ne_26 #b1) x7_30 #x0000000000000000)))
(assert (and (= ge_76 ((_ extract 63 63) x3_51)) (= dc_224 ((_ extract 62 0) x3_51))))
(assert (= ge_77 (bvnot ge_76)))
(assert (= ge_78 (ite (= ne_26 #b1) ge_77 #b0)))
(assert (and (= dc_225 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_51))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_26 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_51))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_52 (ite (= ge_78 #b1) x3_neg_26 x3_51)))
(assert (and (= dc_226 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_53))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_26 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_53))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_54 (ite (= ge_78 #b1) x10_neg_26 x10_53)))
(assert (= x7_31 (ite (= ge_78 #b1) x8_54 x7_30)))
(assert (and (= dc_227 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_54) ((_ zero_extend 1) x10_54)))) (= x8_55 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_54) ((_ zero_extend 1) x10_54))))))
(assert (= x3_53 (bvadd x3_52 #x0000000000000002)))
(assert (and (= dc_228 ((_ extract 63 2) x8_55)) (= x8_lo_27 ((_ extract 1 0) x8_55))))
(assert (and (= x8_target_25 ((_ extract 1 1) x8_lo_27)) (= dc_229 ((_ extract 0 0) x8_lo_27))))
(assert (= ne_27 (bvand x8_target_25 #b1)))
(assert (and (= x8_56 ((_ sign_extend 1) ((_ extract 63 1) x8_55))) (= dc_230 ((_ zero_extend 63) ((_ extract 0 0) x8_55)))))
(assert true)
(assert (= x10_55 (ite (= ne_27 #b1) x7_31 #x0000000000000000)))
(assert (and (= ge_79 ((_ extract 63 63) x3_53)) (= dc_231 ((_ extract 62 0) x3_53))))
(assert (= ge_80 (bvnot ge_79)))
(assert (= ge_81 (ite (= ne_27 #b1) ge_80 #b0)))
(assert (and (= dc_232 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_53))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_27 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_53))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_54 (ite (= ge_81 #b1) x3_neg_27 x3_53)))
(assert (and (= dc_233 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_55))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_27 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_55))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_56 (ite (= ge_81 #b1) x10_neg_27 x10_55)))
(assert (= x7_32 (ite (= ge_81 #b1) x8_56 x7_31)))
(assert (and (= dc_234 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_56) ((_ zero_extend 1) x10_56)))) (= x8_57 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_56) ((_ zero_extend 1) x10_56))))))
(assert (= x3_55 (bvadd x3_54 #x0000000000000002)))
(assert (and (= dc_235 ((_ extract 63 2) x8_57)) (= x8_lo_28 ((_ extract 1 0) x8_57))))
(assert (and (= x8_target_26 ((_ extract 1 1) x8_lo_28)) (= dc_236 ((_ extract 0 0) x8_lo_28))))
(assert (= ne_28 (bvand x8_target_26 #b1)))
(assert (and (= x8_58 ((_ sign_extend 1) ((_ extract 63 1) x8_57))) (= dc_237 ((_ zero_extend 63) ((_ extract 0 0) x8_57)))))
(assert true)
(assert (= x10_57 (ite (= ne_28 #b1) x7_32 #x0000000000000000)))
(assert (and (= ge_82 ((_ extract 63 63) x3_55)) (= dc_238 ((_ extract 62 0) x3_55))))
(assert (= ge_83 (bvnot ge_82)))
(assert (= ge_84 (ite (= ne_28 #b1) ge_83 #b0)))
(assert (and (= dc_239 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_55))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_28 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_55))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_56 (ite (= ge_84 #b1) x3_neg_28 x3_55)))
(assert (and (= dc_240 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_57))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_28 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_57))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_58 (ite (= ge_84 #b1) x10_neg_28 x10_57)))
(assert (= x7_33 (ite (= ge_84 #b1) x8_58 x7_32)))
(assert (and (= dc_241 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_58) ((_ zero_extend 1) x10_58)))) (= x8_59 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_58) ((_ zero_extend 1) x10_58))))))
(assert (= x3_57 (bvadd x3_56 #x0000000000000002)))
(assert (and (= dc_242 ((_ extract 63 2) x8_59)) (= x8_lo_29 ((_ extract 1 0) x8_59))))
(assert (and (= x8_target_27 ((_ extract 1 1) x8_lo_29)) (= dc_243 ((_ extract 0 0) x8_lo_29))))
(assert (= ne_29 (bvand x8_target_27 #b1)))
(assert (and (= x8_60 ((_ sign_extend 1) ((_ extract 63 1) x8_59))) (= dc_244 ((_ zero_extend 63) ((_ extract 0 0) x8_59)))))
(assert true)
(assert (= x10_59 (ite (= ne_29 #b1) x7_33 #x0000000000000000)))
(assert (and (= ge_85 ((_ extract 63 63) x3_57)) (= dc_245 ((_ extract 62 0) x3_57))))
(assert (= ge_86 (bvnot ge_85)))
(assert (= ge_87 (ite (= ne_29 #b1) ge_86 #b0)))
(assert (and (= dc_246 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_57))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_29 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_57))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_58 (ite (= ge_87 #b1) x3_neg_29 x3_57)))
(assert (and (= dc_247 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_59))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_29 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_59))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_60 (ite (= ge_87 #b1) x10_neg_29 x10_59)))
(assert (= x7_34 (ite (= ge_87 #b1) x8_60 x7_33)))
(assert (and (= dc_248 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_60) ((_ zero_extend 1) x10_60)))) (= x8_61 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_60) ((_ zero_extend 1) x10_60))))))
(assert (= x3_59 (bvadd x3_58 #x0000000000000002)))
(assert (and (= dc_249 ((_ extract 63 2) x8_61)) (= x8_lo_30 ((_ extract 1 0) x8_61))))
(assert (and (= x8_target_28 ((_ extract 1 1) x8_lo_30)) (= dc_250 ((_ extract 0 0) x8_lo_30))))
(assert (= ne_30 (bvand x8_target_28 #b1)))
(assert (and (= x8_62 ((_ sign_extend 1) ((_ extract 63 1) x8_61))) (= dc_251 ((_ zero_extend 63) ((_ extract 0 0) x8_61)))))
(assert true)
(assert (= x10_61 (ite (= ne_30 #b1) x7_34 #x0000000000000000)))
(assert (and (= ge_88 ((_ extract 63 63) x3_59)) (= dc_252 ((_ extract 62 0) x3_59))))
(assert (= ge_89 (bvnot ge_88)))
(assert (= ge_90 (ite (= ne_30 #b1) ge_89 #b0)))
(assert (and (= dc_253 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_59))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_30 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_59))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_60 (ite (= ge_90 #b1) x3_neg_30 x3_59)))
(assert (and (= dc_254 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_61))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_30 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_61))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_62 (ite (= ge_90 #b1) x10_neg_30 x10_61)))
(assert (= x7_35 (ite (= ge_90 #b1) x8_62 x7_34)))
(assert (and (= dc_255 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_62) ((_ zero_extend 1) x10_62)))) (= x8_63 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_62) ((_ zero_extend 1) x10_62))))))
(assert (= x3_61 (bvadd x3_60 #x0000000000000002)))
(assert (and (= dc_256 ((_ extract 63 2) x8_63)) (= x8_lo_31 ((_ extract 1 0) x8_63))))
(assert (and (= x8_target_29 ((_ extract 1 1) x8_lo_31)) (= dc_257 ((_ extract 0 0) x8_lo_31))))
(assert (= ne_31 (bvand x8_target_29 #b1)))
(assert (and (= x8_64 ((_ sign_extend 1) ((_ extract 63 1) x8_63))) (= dc_258 ((_ zero_extend 63) ((_ extract 0 0) x8_63)))))
(assert true)
(assert (= x10_63 (ite (= ne_31 #b1) x7_35 #x0000000000000000)))
(assert (and (= ge_91 ((_ extract 63 63) x3_61)) (= dc_259 ((_ extract 62 0) x3_61))))
(assert (= ge_92 (bvnot ge_91)))
(assert (= ge_93 (ite (= ne_31 #b1) ge_92 #b0)))
(assert (and (= dc_260 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_61))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_31 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_61))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_62 (ite (= ge_93 #b1) x3_neg_31 x3_61)))
(assert (and (= dc_261 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_63))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_31 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_63))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_64 (ite (= ge_93 #b1) x10_neg_31 x10_63)))
(assert (= x7_36 (ite (= ge_93 #b1) x8_64 x7_35)))
(assert (and (= dc_262 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_64) ((_ zero_extend 1) x10_64)))) (= x8_65 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_64) ((_ zero_extend 1) x10_64))))))
(assert (= x3_63 (bvadd x3_62 #x0000000000000002)))
(assert (and (= dc_263 ((_ extract 63 2) x8_65)) (= x8_lo_32 ((_ extract 1 0) x8_65))))
(assert (and (= x8_target_30 ((_ extract 1 1) x8_lo_32)) (= dc_264 ((_ extract 0 0) x8_lo_32))))
(assert (= ne_32 (bvand x8_target_30 #b1)))
(assert (and (= x8_66 ((_ sign_extend 1) ((_ extract 63 1) x8_65))) (= dc_265 ((_ zero_extend 63) ((_ extract 0 0) x8_65)))))
(assert true)
(assert (= x10_65 (ite (= ne_32 #b1) x7_36 #x0000000000000000)))
(assert (and (= ge_94 ((_ extract 63 63) x3_63)) (= dc_266 ((_ extract 62 0) x3_63))))
(assert (= ge_95 (bvnot ge_94)))
(assert (= ge_96 (ite (= ne_32 #b1) ge_95 #b0)))
(assert (and (= dc_267 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_63))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_32 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_63))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_64 (ite (= ge_96 #b1) x3_neg_32 x3_63)))
(assert (and (= dc_268 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_65))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_32 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_65))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_66 (ite (= ge_96 #b1) x10_neg_32 x10_65)))
(assert (= x7_37 (ite (= ge_96 #b1) x8_66 x7_36)))
(assert (and (= dc_269 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_66) ((_ zero_extend 1) x10_66)))) (= x8_67 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_66) ((_ zero_extend 1) x10_66))))))
(assert (= x3_65 (bvadd x3_64 #x0000000000000002)))
(assert (and (= dc_270 ((_ extract 63 2) x8_67)) (= x8_lo_33 ((_ extract 1 0) x8_67))))
(assert (and (= x8_target_31 ((_ extract 1 1) x8_lo_33)) (= dc_271 ((_ extract 0 0) x8_lo_33))))
(assert (= ne_33 (bvand x8_target_31 #b1)))
(assert (and (= x8_68 ((_ sign_extend 1) ((_ extract 63 1) x8_67))) (= dc_272 ((_ zero_extend 63) ((_ extract 0 0) x8_67)))))
(assert true)
(assert (= x10_67 (ite (= ne_33 #b1) x7_37 #x0000000000000000)))
(assert (and (= ge_97 ((_ extract 63 63) x3_65)) (= dc_273 ((_ extract 62 0) x3_65))))
(assert (= ge_98 (bvnot ge_97)))
(assert (= ge_99 (ite (= ne_33 #b1) ge_98 #b0)))
(assert (and (= dc_274 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_65))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_33 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_65))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_66 (ite (= ge_99 #b1) x3_neg_33 x3_65)))
(assert (and (= dc_275 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_67))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_33 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_67))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_68 (ite (= ge_99 #b1) x10_neg_33 x10_67)))
(assert (= x7_38 (ite (= ge_99 #b1) x8_68 x7_37)))
(assert (and (= dc_276 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_68) ((_ zero_extend 1) x10_68)))) (= x8_69 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_68) ((_ zero_extend 1) x10_68))))))
(assert (= x3_67 (bvadd x3_66 #x0000000000000002)))
(assert (and (= dc_277 ((_ extract 63 2) x8_69)) (= x8_lo_34 ((_ extract 1 0) x8_69))))
(assert (and (= x8_target_32 ((_ extract 1 1) x8_lo_34)) (= dc_278 ((_ extract 0 0) x8_lo_34))))
(assert (= ne_34 (bvand x8_target_32 #b1)))
(assert (and (= x8_70 ((_ sign_extend 1) ((_ extract 63 1) x8_69))) (= dc_279 ((_ zero_extend 63) ((_ extract 0 0) x8_69)))))
(assert true)
(assert (= x10_69 (ite (= ne_34 #b1) x7_38 #x0000000000000000)))
(assert (and (= ge_100 ((_ extract 63 63) x3_67)) (= dc_280 ((_ extract 62 0) x3_67))))
(assert (= ge_101 (bvnot ge_100)))
(assert (= ge_102 (ite (= ne_34 #b1) ge_101 #b0)))
(assert (and (= dc_281 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_67))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_34 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_67))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_68 (ite (= ge_102 #b1) x3_neg_34 x3_67)))
(assert (and (= dc_282 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_69))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_34 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_69))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_70 (ite (= ge_102 #b1) x10_neg_34 x10_69)))
(assert (= x7_39 (ite (= ge_102 #b1) x8_70 x7_38)))
(assert (and (= dc_283 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_70) ((_ zero_extend 1) x10_70)))) (= x8_71 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_70) ((_ zero_extend 1) x10_70))))))
(assert (= x3_69 (bvadd x3_68 #x0000000000000002)))
(assert (and (= dc_284 ((_ extract 63 2) x8_71)) (= x8_lo_35 ((_ extract 1 0) x8_71))))
(assert (and (= x8_target_33 ((_ extract 1 1) x8_lo_35)) (= dc_285 ((_ extract 0 0) x8_lo_35))))
(assert (= ne_35 (bvand x8_target_33 #b1)))
(assert (and (= x8_72 ((_ sign_extend 1) ((_ extract 63 1) x8_71))) (= dc_286 ((_ zero_extend 63) ((_ extract 0 0) x8_71)))))
(assert true)
(assert (= x10_71 (ite (= ne_35 #b1) x7_39 #x0000000000000000)))
(assert (and (= ge_103 ((_ extract 63 63) x3_69)) (= dc_287 ((_ extract 62 0) x3_69))))
(assert (= ge_104 (bvnot ge_103)))
(assert (= ge_105 (ite (= ne_35 #b1) ge_104 #b0)))
(assert (and (= dc_288 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_69))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_35 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_69))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_70 (ite (= ge_105 #b1) x3_neg_35 x3_69)))
(assert (and (= dc_289 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_71))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_35 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_71))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_72 (ite (= ge_105 #b1) x10_neg_35 x10_71)))
(assert (= x7_40 (ite (= ge_105 #b1) x8_72 x7_39)))
(assert (and (= dc_290 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_72) ((_ zero_extend 1) x10_72)))) (= x8_73 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_72) ((_ zero_extend 1) x10_72))))))
(assert (= x3_71 (bvadd x3_70 #x0000000000000002)))
(assert (and (= dc_291 ((_ extract 63 2) x8_73)) (= x8_lo_36 ((_ extract 1 0) x8_73))))
(assert (and (= x8_target_34 ((_ extract 1 1) x8_lo_36)) (= dc_292 ((_ extract 0 0) x8_lo_36))))
(assert (= ne_36 (bvand x8_target_34 #b1)))
(assert (and (= x8_74 ((_ sign_extend 1) ((_ extract 63 1) x8_73))) (= dc_293 ((_ zero_extend 63) ((_ extract 0 0) x8_73)))))
(assert true)
(assert (= x10_73 (ite (= ne_36 #b1) x7_40 #x0000000000000000)))
(assert (and (= ge_106 ((_ extract 63 63) x3_71)) (= dc_294 ((_ extract 62 0) x3_71))))
(assert (= ge_107 (bvnot ge_106)))
(assert (= ge_108 (ite (= ne_36 #b1) ge_107 #b0)))
(assert (and (= dc_295 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_71))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_36 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_71))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_72 (ite (= ge_108 #b1) x3_neg_36 x3_71)))
(assert (and (= dc_296 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_73))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_36 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_73))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_74 (ite (= ge_108 #b1) x10_neg_36 x10_73)))
(assert (= x7_41 (ite (= ge_108 #b1) x8_74 x7_40)))
(assert (and (= dc_297 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_74) ((_ zero_extend 1) x10_74)))) (= x8_75 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_74) ((_ zero_extend 1) x10_74))))))
(assert (= x3_73 (bvadd x3_72 #x0000000000000002)))
(assert (and (= dc_298 ((_ extract 63 2) x8_75)) (= x8_lo_37 ((_ extract 1 0) x8_75))))
(assert (and (= x8_target_35 ((_ extract 1 1) x8_lo_37)) (= dc_299 ((_ extract 0 0) x8_lo_37))))
(assert (= ne_37 (bvand x8_target_35 #b1)))
(assert (and (= x8_76 ((_ sign_extend 1) ((_ extract 63 1) x8_75))) (= dc_300 ((_ zero_extend 63) ((_ extract 0 0) x8_75)))))
(assert true)
(assert (= x10_75 (ite (= ne_37 #b1) x7_41 #x0000000000000000)))
(assert (and (= ge_109 ((_ extract 63 63) x3_73)) (= dc_301 ((_ extract 62 0) x3_73))))
(assert (= ge_110 (bvnot ge_109)))
(assert (= ge_111 (ite (= ne_37 #b1) ge_110 #b0)))
(assert (and (= dc_302 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_73))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_37 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_73))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_74 (ite (= ge_111 #b1) x3_neg_37 x3_73)))
(assert (and (= dc_303 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_75))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_37 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_75))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_76 (ite (= ge_111 #b1) x10_neg_37 x10_75)))
(assert (= x7_42 (ite (= ge_111 #b1) x8_76 x7_41)))
(assert (and (= dc_304 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_76) ((_ zero_extend 1) x10_76)))) (= x8_77 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_76) ((_ zero_extend 1) x10_76))))))
(assert (= x3_75 (bvadd x3_74 #x0000000000000002)))
(assert (and (= dc_305 ((_ extract 63 2) x8_77)) (= x8_lo_38 ((_ extract 1 0) x8_77))))
(assert (and (= x8_target_36 ((_ extract 1 1) x8_lo_38)) (= dc_306 ((_ extract 0 0) x8_lo_38))))
(assert (= ne_38 (bvand x8_target_36 #b1)))
(assert (and (= x8_78 ((_ sign_extend 1) ((_ extract 63 1) x8_77))) (= dc_307 ((_ zero_extend 63) ((_ extract 0 0) x8_77)))))
(assert true)
(assert (= x10_77 (ite (= ne_38 #b1) x7_42 #x0000000000000000)))
(assert (and (= ge_112 ((_ extract 63 63) x3_75)) (= dc_308 ((_ extract 62 0) x3_75))))
(assert (= ge_113 (bvnot ge_112)))
(assert (= ge_114 (ite (= ne_38 #b1) ge_113 #b0)))
(assert (and (= dc_309 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_75))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_38 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_75))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_76 (ite (= ge_114 #b1) x3_neg_38 x3_75)))
(assert (and (= dc_310 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_77))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_38 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_77))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_78 (ite (= ge_114 #b1) x10_neg_38 x10_77)))
(assert (= x7_43 (ite (= ge_114 #b1) x8_78 x7_42)))
(assert (and (= dc_311 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_78) ((_ zero_extend 1) x10_78)))) (= x8_79 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_78) ((_ zero_extend 1) x10_78))))))
(assert (= x3_77 (bvadd x3_76 #x0000000000000002)))
(assert (and (= dc_312 ((_ extract 63 2) x8_79)) (= x8_lo_39 ((_ extract 1 0) x8_79))))
(assert (and (= x8_target_37 ((_ extract 1 1) x8_lo_39)) (= dc_313 ((_ extract 0 0) x8_lo_39))))
(assert (= ne_39 (bvand x8_target_37 #b1)))
(assert (and (= x8_80 ((_ sign_extend 1) ((_ extract 63 1) x8_79))) (= dc_314 ((_ zero_extend 63) ((_ extract 0 0) x8_79)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_78) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_43 x7_42)) (= (bvmul x8_80 #x0000000000000002) x8_78)) (= x3_77 (bvadd #x0000000000000002 x3_75))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_78) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_75 #x0000000000000000)) (= x7_43 x7_42)) (= (bvmul x8_80 #x0000000000000002) (bvadd x8_78 x7_42))) (= x3_77 (bvadd #x0000000000000002 x3_75)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_78) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_75 #x0000000000000000)) (= x7_43 x8_78)) (= (bvmul x8_80 #x0000000000000002) (bvsub x8_78 x7_42))) (= x3_77 (bvsub #x0000000000000002 x3_75))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_159105.smt2
Execution time of boolector: 1.4424 seconds
OUTPUT FROM boolector:
unsat

=== Cut #6 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range assertions
; Track: default
; Cut: #6
; Range assertion #58: or [and [smod (sub (uext x8_80 1) (uext 0@64 1)) (uext 2@64 1) = 0@65, x7_44 = x7_43, mul x8_82 2@64 = x8_80, x3_79 = add 2@64 x3_77], and [smod (sub (uext x8_80 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_77 <s 0@64, x7_44 = x7_43, mul x8_82 2@64 = add x8_80 x7_43, x3_79 = add 2@64 x3_77], and [smod (sub (uext x8_80 1) (uext 1@64 1)) (uext 2@64 1) = 0@65, x3_77 >=s 0@64, x7_44 = x8_80, mul x8_82 2@64 = sub x8_80 x7_43, x3_79 = sub 2@64 x3_77]]
; Range condition: ((x8_80@e1) - (0@e1)) smod (2@e1) = 0 /\ x7_44 = x7_43 /\ x8_82 * 2 = x8_80 /\ x3_79 = 2 + x3_77 \/ ((x8_80@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_77 <s 0 /\ x7_44 = x7_43 /\ x8_82 * 2 = x8_80 + x7_43 /\ x3_79 = 2 + x3_77 \/ ((x8_80@e1) - (1@e1)) smod (2@e1) = 0 /\ x3_77 >=s 0 /\ x7_44 = x8_80 /\ x8_82 * 2 = x8_80 - x7_43 /\ x3_79 = 2 - x3_77
; Output file: /tmp/outputqfbv_279af7.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_37 () (_ BitVec 1))
(declare-fun x8_target_36 () (_ BitVec 1))
(declare-fun x8_target_35 () (_ BitVec 1))
(declare-fun x8_target_34 () (_ BitVec 1))
(declare-fun x8_target_33 () (_ BitVec 1))
(declare-fun x8_target_32 () (_ BitVec 1))
(declare-fun x8_target_31 () (_ BitVec 1))
(declare-fun x8_target_30 () (_ BitVec 1))
(declare-fun x8_target_29 () (_ BitVec 1))
(declare-fun x8_target_28 () (_ BitVec 1))
(declare-fun x8_target_27 () (_ BitVec 1))
(declare-fun x8_target_26 () (_ BitVec 1))
(declare-fun x8_target_25 () (_ BitVec 1))
(declare-fun x8_target_24 () (_ BitVec 1))
(declare-fun x8_target_23 () (_ BitVec 1))
(declare-fun x8_target_22 () (_ BitVec 1))
(declare-fun x8_target_21 () (_ BitVec 1))
(declare-fun x8_target_20 () (_ BitVec 1))
(declare-fun x8_lo_39 () (_ BitVec 2))
(declare-fun x8_lo_38 () (_ BitVec 2))
(declare-fun x8_lo_37 () (_ BitVec 2))
(declare-fun x8_lo_36 () (_ BitVec 2))
(declare-fun x8_lo_35 () (_ BitVec 2))
(declare-fun x8_lo_34 () (_ BitVec 2))
(declare-fun x8_lo_33 () (_ BitVec 2))
(declare-fun x8_lo_32 () (_ BitVec 2))
(declare-fun x8_lo_31 () (_ BitVec 2))
(declare-fun x8_lo_30 () (_ BitVec 2))
(declare-fun x8_lo_29 () (_ BitVec 2))
(declare-fun x8_lo_28 () (_ BitVec 2))
(declare-fun x8_lo_27 () (_ BitVec 2))
(declare-fun x8_lo_26 () (_ BitVec 2))
(declare-fun x8_lo_25 () (_ BitVec 2))
(declare-fun x8_lo_24 () (_ BitVec 2))
(declare-fun x8_lo_23 () (_ BitVec 2))
(declare-fun x8_lo_22 () (_ BitVec 2))
(declare-fun x8_lo_21 () (_ BitVec 1))
(declare-fun x8_82 () (_ BitVec 64))
(declare-fun x8_81 () (_ BitVec 64))
(declare-fun x8_80 () (_ BitVec 64))
(declare-fun x8_79 () (_ BitVec 64))
(declare-fun x8_78 () (_ BitVec 64))
(declare-fun x8_77 () (_ BitVec 64))
(declare-fun x8_76 () (_ BitVec 64))
(declare-fun x8_75 () (_ BitVec 64))
(declare-fun x8_74 () (_ BitVec 64))
(declare-fun x8_73 () (_ BitVec 64))
(declare-fun x8_72 () (_ BitVec 64))
(declare-fun x8_71 () (_ BitVec 64))
(declare-fun x8_70 () (_ BitVec 64))
(declare-fun x8_69 () (_ BitVec 64))
(declare-fun x8_68 () (_ BitVec 64))
(declare-fun x8_67 () (_ BitVec 64))
(declare-fun x8_66 () (_ BitVec 64))
(declare-fun x8_65 () (_ BitVec 64))
(declare-fun x8_64 () (_ BitVec 64))
(declare-fun x8_63 () (_ BitVec 64))
(declare-fun x8_62 () (_ BitVec 64))
(declare-fun x8_61 () (_ BitVec 64))
(declare-fun x8_60 () (_ BitVec 64))
(declare-fun x8_59 () (_ BitVec 64))
(declare-fun x8_58 () (_ BitVec 64))
(declare-fun x8_57 () (_ BitVec 64))
(declare-fun x8_56 () (_ BitVec 64))
(declare-fun x8_55 () (_ BitVec 64))
(declare-fun x8_54 () (_ BitVec 64))
(declare-fun x8_53 () (_ BitVec 64))
(declare-fun x8_52 () (_ BitVec 64))
(declare-fun x8_51 () (_ BitVec 64))
(declare-fun x8_50 () (_ BitVec 64))
(declare-fun x8_49 () (_ BitVec 64))
(declare-fun x8_48 () (_ BitVec 64))
(declare-fun x8_47 () (_ BitVec 64))
(declare-fun x8_46 () (_ BitVec 64))
(declare-fun x8_45 () (_ BitVec 64))
(declare-fun x8_44 () (_ BitVec 64))
(declare-fun x7_44 () (_ BitVec 64))
(declare-fun x7_43 () (_ BitVec 64))
(declare-fun x7_42 () (_ BitVec 64))
(declare-fun x7_41 () (_ BitVec 64))
(declare-fun x7_40 () (_ BitVec 64))
(declare-fun x7_39 () (_ BitVec 64))
(declare-fun x7_38 () (_ BitVec 64))
(declare-fun x7_37 () (_ BitVec 64))
(declare-fun x7_36 () (_ BitVec 64))
(declare-fun x7_35 () (_ BitVec 64))
(declare-fun x7_34 () (_ BitVec 64))
(declare-fun x7_33 () (_ BitVec 64))
(declare-fun x7_32 () (_ BitVec 64))
(declare-fun x7_31 () (_ BitVec 64))
(declare-fun x7_30 () (_ BitVec 64))
(declare-fun x7_29 () (_ BitVec 64))
(declare-fun x7_28 () (_ BitVec 64))
(declare-fun x7_27 () (_ BitVec 64))
(declare-fun x7_26 () (_ BitVec 64))
(declare-fun x7_25 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_39 () (_ BitVec 64))
(declare-fun x3_neg_38 () (_ BitVec 64))
(declare-fun x3_neg_37 () (_ BitVec 64))
(declare-fun x3_neg_36 () (_ BitVec 64))
(declare-fun x3_neg_35 () (_ BitVec 64))
(declare-fun x3_neg_34 () (_ BitVec 64))
(declare-fun x3_neg_33 () (_ BitVec 64))
(declare-fun x3_neg_32 () (_ BitVec 64))
(declare-fun x3_neg_31 () (_ BitVec 64))
(declare-fun x3_neg_30 () (_ BitVec 64))
(declare-fun x3_neg_29 () (_ BitVec 64))
(declare-fun x3_neg_28 () (_ BitVec 64))
(declare-fun x3_neg_27 () (_ BitVec 64))
(declare-fun x3_neg_26 () (_ BitVec 64))
(declare-fun x3_neg_25 () (_ BitVec 64))
(declare-fun x3_neg_24 () (_ BitVec 64))
(declare-fun x3_neg_23 () (_ BitVec 64))
(declare-fun x3_neg_22 () (_ BitVec 64))
(declare-fun x3_neg_21 () (_ BitVec 64))
(declare-fun x3_79 () (_ BitVec 64))
(declare-fun x3_78 () (_ BitVec 64))
(declare-fun x3_77 () (_ BitVec 64))
(declare-fun x3_76 () (_ BitVec 64))
(declare-fun x3_75 () (_ BitVec 64))
(declare-fun x3_74 () (_ BitVec 64))
(declare-fun x3_73 () (_ BitVec 64))
(declare-fun x3_72 () (_ BitVec 64))
(declare-fun x3_71 () (_ BitVec 64))
(declare-fun x3_70 () (_ BitVec 64))
(declare-fun x3_69 () (_ BitVec 64))
(declare-fun x3_68 () (_ BitVec 64))
(declare-fun x3_67 () (_ BitVec 64))
(declare-fun x3_66 () (_ BitVec 64))
(declare-fun x3_65 () (_ BitVec 64))
(declare-fun x3_64 () (_ BitVec 64))
(declare-fun x3_63 () (_ BitVec 64))
(declare-fun x3_62 () (_ BitVec 64))
(declare-fun x3_61 () (_ BitVec 64))
(declare-fun x3_60 () (_ BitVec 64))
(declare-fun x3_59 () (_ BitVec 64))
(declare-fun x3_58 () (_ BitVec 64))
(declare-fun x3_57 () (_ BitVec 64))
(declare-fun x3_56 () (_ BitVec 64))
(declare-fun x3_55 () (_ BitVec 64))
(declare-fun x3_54 () (_ BitVec 64))
(declare-fun x3_53 () (_ BitVec 64))
(declare-fun x3_52 () (_ BitVec 64))
(declare-fun x3_51 () (_ BitVec 64))
(declare-fun x3_50 () (_ BitVec 64))
(declare-fun x3_49 () (_ BitVec 64))
(declare-fun x3_48 () (_ BitVec 64))
(declare-fun x3_47 () (_ BitVec 64))
(declare-fun x3_46 () (_ BitVec 64))
(declare-fun x3_45 () (_ BitVec 64))
(declare-fun x3_44 () (_ BitVec 64))
(declare-fun x3_43 () (_ BitVec 64))
(declare-fun x3_42 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x10_neg_39 () (_ BitVec 64))
(declare-fun x10_neg_38 () (_ BitVec 64))
(declare-fun x10_neg_37 () (_ BitVec 64))
(declare-fun x10_neg_36 () (_ BitVec 64))
(declare-fun x10_neg_35 () (_ BitVec 64))
(declare-fun x10_neg_34 () (_ BitVec 64))
(declare-fun x10_neg_33 () (_ BitVec 64))
(declare-fun x10_neg_32 () (_ BitVec 64))
(declare-fun x10_neg_31 () (_ BitVec 64))
(declare-fun x10_neg_30 () (_ BitVec 64))
(declare-fun x10_neg_29 () (_ BitVec 64))
(declare-fun x10_neg_28 () (_ BitVec 64))
(declare-fun x10_neg_27 () (_ BitVec 64))
(declare-fun x10_neg_26 () (_ BitVec 64))
(declare-fun x10_neg_25 () (_ BitVec 64))
(declare-fun x10_neg_24 () (_ BitVec 64))
(declare-fun x10_neg_23 () (_ BitVec 64))
(declare-fun x10_neg_22 () (_ BitVec 64))
(declare-fun x10_neg_21 () (_ BitVec 64))
(declare-fun x10_80 () (_ BitVec 64))
(declare-fun x10_79 () (_ BitVec 64))
(declare-fun x10_78 () (_ BitVec 64))
(declare-fun x10_77 () (_ BitVec 64))
(declare-fun x10_76 () (_ BitVec 64))
(declare-fun x10_75 () (_ BitVec 64))
(declare-fun x10_74 () (_ BitVec 64))
(declare-fun x10_73 () (_ BitVec 64))
(declare-fun x10_72 () (_ BitVec 64))
(declare-fun x10_71 () (_ BitVec 64))
(declare-fun x10_70 () (_ BitVec 64))
(declare-fun x10_69 () (_ BitVec 64))
(declare-fun x10_68 () (_ BitVec 64))
(declare-fun x10_67 () (_ BitVec 64))
(declare-fun x10_66 () (_ BitVec 64))
(declare-fun x10_65 () (_ BitVec 64))
(declare-fun x10_64 () (_ BitVec 64))
(declare-fun x10_63 () (_ BitVec 64))
(declare-fun x10_62 () (_ BitVec 64))
(declare-fun x10_61 () (_ BitVec 64))
(declare-fun x10_60 () (_ BitVec 64))
(declare-fun x10_59 () (_ BitVec 64))
(declare-fun x10_58 () (_ BitVec 64))
(declare-fun x10_57 () (_ BitVec 64))
(declare-fun x10_56 () (_ BitVec 64))
(declare-fun x10_55 () (_ BitVec 64))
(declare-fun x10_54 () (_ BitVec 64))
(declare-fun x10_53 () (_ BitVec 64))
(declare-fun x10_52 () (_ BitVec 64))
(declare-fun x10_51 () (_ BitVec 64))
(declare-fun x10_50 () (_ BitVec 64))
(declare-fun x10_49 () (_ BitVec 64))
(declare-fun x10_48 () (_ BitVec 64))
(declare-fun x10_47 () (_ BitVec 64))
(declare-fun x10_46 () (_ BitVec 64))
(declare-fun x10_45 () (_ BitVec 64))
(declare-fun x10_44 () (_ BitVec 64))
(declare-fun x10_43 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun ne_39 () (_ BitVec 1))
(declare-fun ne_38 () (_ BitVec 1))
(declare-fun ne_37 () (_ BitVec 1))
(declare-fun ne_36 () (_ BitVec 1))
(declare-fun ne_35 () (_ BitVec 1))
(declare-fun ne_34 () (_ BitVec 1))
(declare-fun ne_33 () (_ BitVec 1))
(declare-fun ne_32 () (_ BitVec 1))
(declare-fun ne_31 () (_ BitVec 1))
(declare-fun ne_30 () (_ BitVec 1))
(declare-fun ne_29 () (_ BitVec 1))
(declare-fun ne_28 () (_ BitVec 1))
(declare-fun ne_27 () (_ BitVec 1))
(declare-fun ne_26 () (_ BitVec 1))
(declare-fun ne_25 () (_ BitVec 1))
(declare-fun ne_24 () (_ BitVec 1))
(declare-fun ne_23 () (_ BitVec 1))
(declare-fun ne_22 () (_ BitVec 1))
(declare-fun ne_21 () (_ BitVec 1))
(declare-fun ge_117 () (_ BitVec 1))
(declare-fun ge_116 () (_ BitVec 1))
(declare-fun ge_115 () (_ BitVec 1))
(declare-fun ge_114 () (_ BitVec 1))
(declare-fun ge_113 () (_ BitVec 1))
(declare-fun ge_112 () (_ BitVec 1))
(declare-fun ge_111 () (_ BitVec 1))
(declare-fun ge_110 () (_ BitVec 1))
(declare-fun ge_109 () (_ BitVec 1))
(declare-fun ge_108 () (_ BitVec 1))
(declare-fun ge_107 () (_ BitVec 1))
(declare-fun ge_106 () (_ BitVec 1))
(declare-fun ge_105 () (_ BitVec 1))
(declare-fun ge_104 () (_ BitVec 1))
(declare-fun ge_103 () (_ BitVec 1))
(declare-fun ge_102 () (_ BitVec 1))
(declare-fun ge_101 () (_ BitVec 1))
(declare-fun ge_100 () (_ BitVec 1))
(declare-fun ge_99 () (_ BitVec 1))
(declare-fun ge_98 () (_ BitVec 1))
(declare-fun ge_97 () (_ BitVec 1))
(declare-fun ge_96 () (_ BitVec 1))
(declare-fun ge_95 () (_ BitVec 1))
(declare-fun ge_94 () (_ BitVec 1))
(declare-fun ge_93 () (_ BitVec 1))
(declare-fun ge_92 () (_ BitVec 1))
(declare-fun ge_91 () (_ BitVec 1))
(declare-fun ge_90 () (_ BitVec 1))
(declare-fun ge_89 () (_ BitVec 1))
(declare-fun ge_88 () (_ BitVec 1))
(declare-fun ge_87 () (_ BitVec 1))
(declare-fun ge_86 () (_ BitVec 1))
(declare-fun ge_85 () (_ BitVec 1))
(declare-fun ge_84 () (_ BitVec 1))
(declare-fun ge_83 () (_ BitVec 1))
(declare-fun ge_82 () (_ BitVec 1))
(declare-fun ge_81 () (_ BitVec 1))
(declare-fun ge_80 () (_ BitVec 1))
(declare-fun ge_79 () (_ BitVec 1))
(declare-fun ge_78 () (_ BitVec 1))
(declare-fun ge_77 () (_ BitVec 1))
(declare-fun ge_76 () (_ BitVec 1))
(declare-fun ge_75 () (_ BitVec 1))
(declare-fun ge_74 () (_ BitVec 1))
(declare-fun ge_73 () (_ BitVec 1))
(declare-fun ge_72 () (_ BitVec 1))
(declare-fun ge_71 () (_ BitVec 1))
(declare-fun ge_70 () (_ BitVec 1))
(declare-fun ge_69 () (_ BitVec 1))
(declare-fun ge_68 () (_ BitVec 1))
(declare-fun ge_67 () (_ BitVec 1))
(declare-fun ge_66 () (_ BitVec 1))
(declare-fun ge_65 () (_ BitVec 1))
(declare-fun ge_64 () (_ BitVec 1))
(declare-fun ge_63 () (_ BitVec 1))
(declare-fun ge_62 () (_ BitVec 1))
(declare-fun ge_61 () (_ BitVec 1))
(declare-fun dc_319 () (_ BitVec 64))
(declare-fun dc_318 () (_ BitVec 1))
(declare-fun dc_317 () (_ BitVec 1))
(declare-fun dc_316 () (_ BitVec 1))
(declare-fun dc_315 () (_ BitVec 63))
(declare-fun dc_314 () (_ BitVec 64))
(declare-fun dc_313 () (_ BitVec 1))
(declare-fun dc_312 () (_ BitVec 62))
(declare-fun dc_311 () (_ BitVec 1))
(declare-fun dc_310 () (_ BitVec 1))
(declare-fun dc_309 () (_ BitVec 1))
(declare-fun dc_308 () (_ BitVec 63))
(declare-fun dc_307 () (_ BitVec 64))
(declare-fun dc_306 () (_ BitVec 1))
(declare-fun dc_305 () (_ BitVec 62))
(declare-fun dc_304 () (_ BitVec 1))
(declare-fun dc_303 () (_ BitVec 1))
(declare-fun dc_302 () (_ BitVec 1))
(declare-fun dc_301 () (_ BitVec 63))
(declare-fun dc_300 () (_ BitVec 64))
(declare-fun dc_299 () (_ BitVec 1))
(declare-fun dc_298 () (_ BitVec 62))
(declare-fun dc_297 () (_ BitVec 1))
(declare-fun dc_296 () (_ BitVec 1))
(declare-fun dc_295 () (_ BitVec 1))
(declare-fun dc_294 () (_ BitVec 63))
(declare-fun dc_293 () (_ BitVec 64))
(declare-fun dc_292 () (_ BitVec 1))
(declare-fun dc_291 () (_ BitVec 62))
(declare-fun dc_290 () (_ BitVec 1))
(declare-fun dc_289 () (_ BitVec 1))
(declare-fun dc_288 () (_ BitVec 1))
(declare-fun dc_287 () (_ BitVec 63))
(declare-fun dc_286 () (_ BitVec 64))
(declare-fun dc_285 () (_ BitVec 1))
(declare-fun dc_284 () (_ BitVec 62))
(declare-fun dc_283 () (_ BitVec 1))
(declare-fun dc_282 () (_ BitVec 1))
(declare-fun dc_281 () (_ BitVec 1))
(declare-fun dc_280 () (_ BitVec 63))
(declare-fun dc_279 () (_ BitVec 64))
(declare-fun dc_278 () (_ BitVec 1))
(declare-fun dc_277 () (_ BitVec 62))
(declare-fun dc_276 () (_ BitVec 1))
(declare-fun dc_275 () (_ BitVec 1))
(declare-fun dc_274 () (_ BitVec 1))
(declare-fun dc_273 () (_ BitVec 63))
(declare-fun dc_272 () (_ BitVec 64))
(declare-fun dc_271 () (_ BitVec 1))
(declare-fun dc_270 () (_ BitVec 62))
(declare-fun dc_269 () (_ BitVec 1))
(declare-fun dc_268 () (_ BitVec 1))
(declare-fun dc_267 () (_ BitVec 1))
(declare-fun dc_266 () (_ BitVec 63))
(declare-fun dc_265 () (_ BitVec 64))
(declare-fun dc_264 () (_ BitVec 1))
(declare-fun dc_263 () (_ BitVec 62))
(declare-fun dc_262 () (_ BitVec 1))
(declare-fun dc_261 () (_ BitVec 1))
(declare-fun dc_260 () (_ BitVec 1))
(declare-fun dc_259 () (_ BitVec 63))
(declare-fun dc_258 () (_ BitVec 64))
(declare-fun dc_257 () (_ BitVec 1))
(declare-fun dc_256 () (_ BitVec 62))
(declare-fun dc_255 () (_ BitVec 1))
(declare-fun dc_254 () (_ BitVec 1))
(declare-fun dc_253 () (_ BitVec 1))
(declare-fun dc_252 () (_ BitVec 63))
(declare-fun dc_251 () (_ BitVec 64))
(declare-fun dc_250 () (_ BitVec 1))
(declare-fun dc_249 () (_ BitVec 62))
(declare-fun dc_248 () (_ BitVec 1))
(declare-fun dc_247 () (_ BitVec 1))
(declare-fun dc_246 () (_ BitVec 1))
(declare-fun dc_245 () (_ BitVec 63))
(declare-fun dc_244 () (_ BitVec 64))
(declare-fun dc_243 () (_ BitVec 1))
(declare-fun dc_242 () (_ BitVec 62))
(declare-fun dc_241 () (_ BitVec 1))
(declare-fun dc_240 () (_ BitVec 1))
(declare-fun dc_239 () (_ BitVec 1))
(declare-fun dc_238 () (_ BitVec 63))
(declare-fun dc_237 () (_ BitVec 64))
(declare-fun dc_236 () (_ BitVec 1))
(declare-fun dc_235 () (_ BitVec 62))
(declare-fun dc_234 () (_ BitVec 1))
(declare-fun dc_233 () (_ BitVec 1))
(declare-fun dc_232 () (_ BitVec 1))
(declare-fun dc_231 () (_ BitVec 63))
(declare-fun dc_230 () (_ BitVec 64))
(declare-fun dc_229 () (_ BitVec 1))
(declare-fun dc_228 () (_ BitVec 62))
(declare-fun dc_227 () (_ BitVec 1))
(declare-fun dc_226 () (_ BitVec 1))
(declare-fun dc_225 () (_ BitVec 1))
(declare-fun dc_224 () (_ BitVec 63))
(declare-fun dc_223 () (_ BitVec 64))
(declare-fun dc_222 () (_ BitVec 1))
(declare-fun dc_221 () (_ BitVec 62))
(declare-fun dc_220 () (_ BitVec 1))
(declare-fun dc_219 () (_ BitVec 1))
(declare-fun dc_218 () (_ BitVec 1))
(declare-fun dc_217 () (_ BitVec 63))
(declare-fun dc_216 () (_ BitVec 64))
(declare-fun dc_215 () (_ BitVec 1))
(declare-fun dc_214 () (_ BitVec 62))
(declare-fun dc_213 () (_ BitVec 1))
(declare-fun dc_212 () (_ BitVec 1))
(declare-fun dc_211 () (_ BitVec 1))
(declare-fun dc_210 () (_ BitVec 63))
(declare-fun dc_209 () (_ BitVec 64))
(declare-fun dc_208 () (_ BitVec 1))
(declare-fun dc_207 () (_ BitVec 62))
(declare-fun dc_206 () (_ BitVec 1))
(declare-fun dc_205 () (_ BitVec 1))
(declare-fun dc_204 () (_ BitVec 1))
(declare-fun dc_203 () (_ BitVec 63))
(declare-fun dc_202 () (_ BitVec 64))
(declare-fun dc_201 () (_ BitVec 1))
(declare-fun dc_200 () (_ BitVec 62))
(declare-fun dc_199 () (_ BitVec 1))
(declare-fun dc_198 () (_ BitVec 1))
(declare-fun dc_197 () (_ BitVec 1))
(declare-fun dc_196 () (_ BitVec 63))
(declare-fun dc_195 () (_ BitVec 64))
(declare-fun dc_194 () (_ BitVec 1))
(declare-fun dc_193 () (_ BitVec 62))
(declare-fun dc_192 () (_ BitVec 1))
(declare-fun dc_191 () (_ BitVec 1))
(declare-fun dc_190 () (_ BitVec 1))
(declare-fun dc_189 () (_ BitVec 63))
(declare-fun dc_188 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_25 (bvadd (bvadd neg_f_0_low60_20_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_44 (bvadd (bvadd neg_g_0_low60_20_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_0_1)) (bvsle neg_f_0_low60_20_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_0_1)) (bvsle neg_g_0_low60_20_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_25) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_188 ((_ extract 63 1) x8_44)) (= x8_lo_21 ((_ extract 0 0) x8_44))))
(assert (= ne_21 (bvand x8_lo_21 #b1)))
(assert (= x10_43 (ite (= ne_21 #b1) x7_25 #x0000000000000000)))
(assert (and (= ge_61 ((_ extract 63 63) x3_41)) (= dc_189 ((_ extract 62 0) x3_41))))
(assert (= ge_62 (bvnot ge_61)))
(assert (= ge_63 (ite (= ne_21 #b1) ge_62 #b0)))
(assert (and (= dc_190 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_42 (ite (= ge_63 #b1) x3_neg_21 x3_41)))
(assert (and (= dc_191 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_44 (ite (= ge_63 #b1) x10_neg_21 x10_43)))
(assert (= x7_26 (ite (= ge_63 #b1) x8_44 x7_25)))
(assert (and (= dc_192 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44)))) (= x8_45 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44))))))
(assert (= x3_43 (bvadd x3_42 #x0000000000000002)))
(assert (and (= dc_193 ((_ extract 63 2) x8_45)) (= x8_lo_22 ((_ extract 1 0) x8_45))))
(assert (and (= x8_target_20 ((_ extract 1 1) x8_lo_22)) (= dc_194 ((_ extract 0 0) x8_lo_22))))
(assert (= ne_22 (bvand x8_target_20 #b1)))
(assert (and (= x8_46 ((_ sign_extend 1) ((_ extract 63 1) x8_45))) (= dc_195 ((_ zero_extend 63) ((_ extract 0 0) x8_45)))))
(assert true)
(assert (= x10_45 (ite (= ne_22 #b1) x7_26 #x0000000000000000)))
(assert (and (= ge_64 ((_ extract 63 63) x3_43)) (= dc_196 ((_ extract 62 0) x3_43))))
(assert (= ge_65 (bvnot ge_64)))
(assert (= ge_66 (ite (= ne_22 #b1) ge_65 #b0)))
(assert (and (= dc_197 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_44 (ite (= ge_66 #b1) x3_neg_22 x3_43)))
(assert (and (= dc_198 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_46 (ite (= ge_66 #b1) x10_neg_22 x10_45)))
(assert (= x7_27 (ite (= ge_66 #b1) x8_46 x7_26)))
(assert (and (= dc_199 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46)))) (= x8_47 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46))))))
(assert (= x3_45 (bvadd x3_44 #x0000000000000002)))
(assert (and (= dc_200 ((_ extract 63 2) x8_47)) (= x8_lo_23 ((_ extract 1 0) x8_47))))
(assert (and (= x8_target_21 ((_ extract 1 1) x8_lo_23)) (= dc_201 ((_ extract 0 0) x8_lo_23))))
(assert (= ne_23 (bvand x8_target_21 #b1)))
(assert (and (= x8_48 ((_ sign_extend 1) ((_ extract 63 1) x8_47))) (= dc_202 ((_ zero_extend 63) ((_ extract 0 0) x8_47)))))
(assert true)
(assert (= x10_47 (ite (= ne_23 #b1) x7_27 #x0000000000000000)))
(assert (and (= ge_67 ((_ extract 63 63) x3_45)) (= dc_203 ((_ extract 62 0) x3_45))))
(assert (= ge_68 (bvnot ge_67)))
(assert (= ge_69 (ite (= ne_23 #b1) ge_68 #b0)))
(assert (and (= dc_204 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_46 (ite (= ge_69 #b1) x3_neg_23 x3_45)))
(assert (and (= dc_205 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_48 (ite (= ge_69 #b1) x10_neg_23 x10_47)))
(assert (= x7_28 (ite (= ge_69 #b1) x8_48 x7_27)))
(assert (and (= dc_206 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48)))) (= x8_49 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48))))))
(assert (= x3_47 (bvadd x3_46 #x0000000000000002)))
(assert (and (= dc_207 ((_ extract 63 2) x8_49)) (= x8_lo_24 ((_ extract 1 0) x8_49))))
(assert (and (= x8_target_22 ((_ extract 1 1) x8_lo_24)) (= dc_208 ((_ extract 0 0) x8_lo_24))))
(assert (= ne_24 (bvand x8_target_22 #b1)))
(assert (and (= x8_50 ((_ sign_extend 1) ((_ extract 63 1) x8_49))) (= dc_209 ((_ zero_extend 63) ((_ extract 0 0) x8_49)))))
(assert true)
(assert (= x10_49 (ite (= ne_24 #b1) x7_28 #x0000000000000000)))
(assert (and (= ge_70 ((_ extract 63 63) x3_47)) (= dc_210 ((_ extract 62 0) x3_47))))
(assert (= ge_71 (bvnot ge_70)))
(assert (= ge_72 (ite (= ne_24 #b1) ge_71 #b0)))
(assert (and (= dc_211 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_47))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_24 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_47))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_48 (ite (= ge_72 #b1) x3_neg_24 x3_47)))
(assert (and (= dc_212 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_49))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_24 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_49))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_50 (ite (= ge_72 #b1) x10_neg_24 x10_49)))
(assert (= x7_29 (ite (= ge_72 #b1) x8_50 x7_28)))
(assert (and (= dc_213 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_50) ((_ zero_extend 1) x10_50)))) (= x8_51 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_50) ((_ zero_extend 1) x10_50))))))
(assert (= x3_49 (bvadd x3_48 #x0000000000000002)))
(assert (and (= dc_214 ((_ extract 63 2) x8_51)) (= x8_lo_25 ((_ extract 1 0) x8_51))))
(assert (and (= x8_target_23 ((_ extract 1 1) x8_lo_25)) (= dc_215 ((_ extract 0 0) x8_lo_25))))
(assert (= ne_25 (bvand x8_target_23 #b1)))
(assert (and (= x8_52 ((_ sign_extend 1) ((_ extract 63 1) x8_51))) (= dc_216 ((_ zero_extend 63) ((_ extract 0 0) x8_51)))))
(assert true)
(assert (= x10_51 (ite (= ne_25 #b1) x7_29 #x0000000000000000)))
(assert (and (= ge_73 ((_ extract 63 63) x3_49)) (= dc_217 ((_ extract 62 0) x3_49))))
(assert (= ge_74 (bvnot ge_73)))
(assert (= ge_75 (ite (= ne_25 #b1) ge_74 #b0)))
(assert (and (= dc_218 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_49))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_25 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_49))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_50 (ite (= ge_75 #b1) x3_neg_25 x3_49)))
(assert (and (= dc_219 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_51))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_25 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_51))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_52 (ite (= ge_75 #b1) x10_neg_25 x10_51)))
(assert (= x7_30 (ite (= ge_75 #b1) x8_52 x7_29)))
(assert (and (= dc_220 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_52) ((_ zero_extend 1) x10_52)))) (= x8_53 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_52) ((_ zero_extend 1) x10_52))))))
(assert (= x3_51 (bvadd x3_50 #x0000000000000002)))
(assert (and (= dc_221 ((_ extract 63 2) x8_53)) (= x8_lo_26 ((_ extract 1 0) x8_53))))
(assert (and (= x8_target_24 ((_ extract 1 1) x8_lo_26)) (= dc_222 ((_ extract 0 0) x8_lo_26))))
(assert (= ne_26 (bvand x8_target_24 #b1)))
(assert (and (= x8_54 ((_ sign_extend 1) ((_ extract 63 1) x8_53))) (= dc_223 ((_ zero_extend 63) ((_ extract 0 0) x8_53)))))
(assert true)
(assert (= x10_53 (ite (= ne_26 #b1) x7_30 #x0000000000000000)))
(assert (and (= ge_76 ((_ extract 63 63) x3_51)) (= dc_224 ((_ extract 62 0) x3_51))))
(assert (= ge_77 (bvnot ge_76)))
(assert (= ge_78 (ite (= ne_26 #b1) ge_77 #b0)))
(assert (and (= dc_225 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_51))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_26 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_51))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_52 (ite (= ge_78 #b1) x3_neg_26 x3_51)))
(assert (and (= dc_226 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_53))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_26 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_53))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_54 (ite (= ge_78 #b1) x10_neg_26 x10_53)))
(assert (= x7_31 (ite (= ge_78 #b1) x8_54 x7_30)))
(assert (and (= dc_227 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_54) ((_ zero_extend 1) x10_54)))) (= x8_55 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_54) ((_ zero_extend 1) x10_54))))))
(assert (= x3_53 (bvadd x3_52 #x0000000000000002)))
(assert (and (= dc_228 ((_ extract 63 2) x8_55)) (= x8_lo_27 ((_ extract 1 0) x8_55))))
(assert (and (= x8_target_25 ((_ extract 1 1) x8_lo_27)) (= dc_229 ((_ extract 0 0) x8_lo_27))))
(assert (= ne_27 (bvand x8_target_25 #b1)))
(assert (and (= x8_56 ((_ sign_extend 1) ((_ extract 63 1) x8_55))) (= dc_230 ((_ zero_extend 63) ((_ extract 0 0) x8_55)))))
(assert true)
(assert (= x10_55 (ite (= ne_27 #b1) x7_31 #x0000000000000000)))
(assert (and (= ge_79 ((_ extract 63 63) x3_53)) (= dc_231 ((_ extract 62 0) x3_53))))
(assert (= ge_80 (bvnot ge_79)))
(assert (= ge_81 (ite (= ne_27 #b1) ge_80 #b0)))
(assert (and (= dc_232 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_53))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_27 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_53))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_54 (ite (= ge_81 #b1) x3_neg_27 x3_53)))
(assert (and (= dc_233 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_55))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_27 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_55))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_56 (ite (= ge_81 #b1) x10_neg_27 x10_55)))
(assert (= x7_32 (ite (= ge_81 #b1) x8_56 x7_31)))
(assert (and (= dc_234 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_56) ((_ zero_extend 1) x10_56)))) (= x8_57 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_56) ((_ zero_extend 1) x10_56))))))
(assert (= x3_55 (bvadd x3_54 #x0000000000000002)))
(assert (and (= dc_235 ((_ extract 63 2) x8_57)) (= x8_lo_28 ((_ extract 1 0) x8_57))))
(assert (and (= x8_target_26 ((_ extract 1 1) x8_lo_28)) (= dc_236 ((_ extract 0 0) x8_lo_28))))
(assert (= ne_28 (bvand x8_target_26 #b1)))
(assert (and (= x8_58 ((_ sign_extend 1) ((_ extract 63 1) x8_57))) (= dc_237 ((_ zero_extend 63) ((_ extract 0 0) x8_57)))))
(assert true)
(assert (= x10_57 (ite (= ne_28 #b1) x7_32 #x0000000000000000)))
(assert (and (= ge_82 ((_ extract 63 63) x3_55)) (= dc_238 ((_ extract 62 0) x3_55))))
(assert (= ge_83 (bvnot ge_82)))
(assert (= ge_84 (ite (= ne_28 #b1) ge_83 #b0)))
(assert (and (= dc_239 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_55))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_28 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_55))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_56 (ite (= ge_84 #b1) x3_neg_28 x3_55)))
(assert (and (= dc_240 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_57))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_28 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_57))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_58 (ite (= ge_84 #b1) x10_neg_28 x10_57)))
(assert (= x7_33 (ite (= ge_84 #b1) x8_58 x7_32)))
(assert (and (= dc_241 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_58) ((_ zero_extend 1) x10_58)))) (= x8_59 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_58) ((_ zero_extend 1) x10_58))))))
(assert (= x3_57 (bvadd x3_56 #x0000000000000002)))
(assert (and (= dc_242 ((_ extract 63 2) x8_59)) (= x8_lo_29 ((_ extract 1 0) x8_59))))
(assert (and (= x8_target_27 ((_ extract 1 1) x8_lo_29)) (= dc_243 ((_ extract 0 0) x8_lo_29))))
(assert (= ne_29 (bvand x8_target_27 #b1)))
(assert (and (= x8_60 ((_ sign_extend 1) ((_ extract 63 1) x8_59))) (= dc_244 ((_ zero_extend 63) ((_ extract 0 0) x8_59)))))
(assert true)
(assert (= x10_59 (ite (= ne_29 #b1) x7_33 #x0000000000000000)))
(assert (and (= ge_85 ((_ extract 63 63) x3_57)) (= dc_245 ((_ extract 62 0) x3_57))))
(assert (= ge_86 (bvnot ge_85)))
(assert (= ge_87 (ite (= ne_29 #b1) ge_86 #b0)))
(assert (and (= dc_246 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_57))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_29 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_57))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_58 (ite (= ge_87 #b1) x3_neg_29 x3_57)))
(assert (and (= dc_247 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_59))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_29 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_59))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_60 (ite (= ge_87 #b1) x10_neg_29 x10_59)))
(assert (= x7_34 (ite (= ge_87 #b1) x8_60 x7_33)))
(assert (and (= dc_248 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_60) ((_ zero_extend 1) x10_60)))) (= x8_61 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_60) ((_ zero_extend 1) x10_60))))))
(assert (= x3_59 (bvadd x3_58 #x0000000000000002)))
(assert (and (= dc_249 ((_ extract 63 2) x8_61)) (= x8_lo_30 ((_ extract 1 0) x8_61))))
(assert (and (= x8_target_28 ((_ extract 1 1) x8_lo_30)) (= dc_250 ((_ extract 0 0) x8_lo_30))))
(assert (= ne_30 (bvand x8_target_28 #b1)))
(assert (and (= x8_62 ((_ sign_extend 1) ((_ extract 63 1) x8_61))) (= dc_251 ((_ zero_extend 63) ((_ extract 0 0) x8_61)))))
(assert true)
(assert (= x10_61 (ite (= ne_30 #b1) x7_34 #x0000000000000000)))
(assert (and (= ge_88 ((_ extract 63 63) x3_59)) (= dc_252 ((_ extract 62 0) x3_59))))
(assert (= ge_89 (bvnot ge_88)))
(assert (= ge_90 (ite (= ne_30 #b1) ge_89 #b0)))
(assert (and (= dc_253 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_59))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_30 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_59))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_60 (ite (= ge_90 #b1) x3_neg_30 x3_59)))
(assert (and (= dc_254 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_61))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_30 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_61))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_62 (ite (= ge_90 #b1) x10_neg_30 x10_61)))
(assert (= x7_35 (ite (= ge_90 #b1) x8_62 x7_34)))
(assert (and (= dc_255 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_62) ((_ zero_extend 1) x10_62)))) (= x8_63 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_62) ((_ zero_extend 1) x10_62))))))
(assert (= x3_61 (bvadd x3_60 #x0000000000000002)))
(assert (and (= dc_256 ((_ extract 63 2) x8_63)) (= x8_lo_31 ((_ extract 1 0) x8_63))))
(assert (and (= x8_target_29 ((_ extract 1 1) x8_lo_31)) (= dc_257 ((_ extract 0 0) x8_lo_31))))
(assert (= ne_31 (bvand x8_target_29 #b1)))
(assert (and (= x8_64 ((_ sign_extend 1) ((_ extract 63 1) x8_63))) (= dc_258 ((_ zero_extend 63) ((_ extract 0 0) x8_63)))))
(assert true)
(assert (= x10_63 (ite (= ne_31 #b1) x7_35 #x0000000000000000)))
(assert (and (= ge_91 ((_ extract 63 63) x3_61)) (= dc_259 ((_ extract 62 0) x3_61))))
(assert (= ge_92 (bvnot ge_91)))
(assert (= ge_93 (ite (= ne_31 #b1) ge_92 #b0)))
(assert (and (= dc_260 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_61))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_31 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_61))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_62 (ite (= ge_93 #b1) x3_neg_31 x3_61)))
(assert (and (= dc_261 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_63))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_31 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_63))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_64 (ite (= ge_93 #b1) x10_neg_31 x10_63)))
(assert (= x7_36 (ite (= ge_93 #b1) x8_64 x7_35)))
(assert (and (= dc_262 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_64) ((_ zero_extend 1) x10_64)))) (= x8_65 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_64) ((_ zero_extend 1) x10_64))))))
(assert (= x3_63 (bvadd x3_62 #x0000000000000002)))
(assert (and (= dc_263 ((_ extract 63 2) x8_65)) (= x8_lo_32 ((_ extract 1 0) x8_65))))
(assert (and (= x8_target_30 ((_ extract 1 1) x8_lo_32)) (= dc_264 ((_ extract 0 0) x8_lo_32))))
(assert (= ne_32 (bvand x8_target_30 #b1)))
(assert (and (= x8_66 ((_ sign_extend 1) ((_ extract 63 1) x8_65))) (= dc_265 ((_ zero_extend 63) ((_ extract 0 0) x8_65)))))
(assert true)
(assert (= x10_65 (ite (= ne_32 #b1) x7_36 #x0000000000000000)))
(assert (and (= ge_94 ((_ extract 63 63) x3_63)) (= dc_266 ((_ extract 62 0) x3_63))))
(assert (= ge_95 (bvnot ge_94)))
(assert (= ge_96 (ite (= ne_32 #b1) ge_95 #b0)))
(assert (and (= dc_267 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_63))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_32 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_63))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_64 (ite (= ge_96 #b1) x3_neg_32 x3_63)))
(assert (and (= dc_268 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_65))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_32 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_65))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_66 (ite (= ge_96 #b1) x10_neg_32 x10_65)))
(assert (= x7_37 (ite (= ge_96 #b1) x8_66 x7_36)))
(assert (and (= dc_269 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_66) ((_ zero_extend 1) x10_66)))) (= x8_67 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_66) ((_ zero_extend 1) x10_66))))))
(assert (= x3_65 (bvadd x3_64 #x0000000000000002)))
(assert (and (= dc_270 ((_ extract 63 2) x8_67)) (= x8_lo_33 ((_ extract 1 0) x8_67))))
(assert (and (= x8_target_31 ((_ extract 1 1) x8_lo_33)) (= dc_271 ((_ extract 0 0) x8_lo_33))))
(assert (= ne_33 (bvand x8_target_31 #b1)))
(assert (and (= x8_68 ((_ sign_extend 1) ((_ extract 63 1) x8_67))) (= dc_272 ((_ zero_extend 63) ((_ extract 0 0) x8_67)))))
(assert true)
(assert (= x10_67 (ite (= ne_33 #b1) x7_37 #x0000000000000000)))
(assert (and (= ge_97 ((_ extract 63 63) x3_65)) (= dc_273 ((_ extract 62 0) x3_65))))
(assert (= ge_98 (bvnot ge_97)))
(assert (= ge_99 (ite (= ne_33 #b1) ge_98 #b0)))
(assert (and (= dc_274 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_65))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_33 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_65))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_66 (ite (= ge_99 #b1) x3_neg_33 x3_65)))
(assert (and (= dc_275 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_67))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_33 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_67))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_68 (ite (= ge_99 #b1) x10_neg_33 x10_67)))
(assert (= x7_38 (ite (= ge_99 #b1) x8_68 x7_37)))
(assert (and (= dc_276 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_68) ((_ zero_extend 1) x10_68)))) (= x8_69 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_68) ((_ zero_extend 1) x10_68))))))
(assert (= x3_67 (bvadd x3_66 #x0000000000000002)))
(assert (and (= dc_277 ((_ extract 63 2) x8_69)) (= x8_lo_34 ((_ extract 1 0) x8_69))))
(assert (and (= x8_target_32 ((_ extract 1 1) x8_lo_34)) (= dc_278 ((_ extract 0 0) x8_lo_34))))
(assert (= ne_34 (bvand x8_target_32 #b1)))
(assert (and (= x8_70 ((_ sign_extend 1) ((_ extract 63 1) x8_69))) (= dc_279 ((_ zero_extend 63) ((_ extract 0 0) x8_69)))))
(assert true)
(assert (= x10_69 (ite (= ne_34 #b1) x7_38 #x0000000000000000)))
(assert (and (= ge_100 ((_ extract 63 63) x3_67)) (= dc_280 ((_ extract 62 0) x3_67))))
(assert (= ge_101 (bvnot ge_100)))
(assert (= ge_102 (ite (= ne_34 #b1) ge_101 #b0)))
(assert (and (= dc_281 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_67))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_34 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_67))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_68 (ite (= ge_102 #b1) x3_neg_34 x3_67)))
(assert (and (= dc_282 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_69))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_34 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_69))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_70 (ite (= ge_102 #b1) x10_neg_34 x10_69)))
(assert (= x7_39 (ite (= ge_102 #b1) x8_70 x7_38)))
(assert (and (= dc_283 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_70) ((_ zero_extend 1) x10_70)))) (= x8_71 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_70) ((_ zero_extend 1) x10_70))))))
(assert (= x3_69 (bvadd x3_68 #x0000000000000002)))
(assert (and (= dc_284 ((_ extract 63 2) x8_71)) (= x8_lo_35 ((_ extract 1 0) x8_71))))
(assert (and (= x8_target_33 ((_ extract 1 1) x8_lo_35)) (= dc_285 ((_ extract 0 0) x8_lo_35))))
(assert (= ne_35 (bvand x8_target_33 #b1)))
(assert (and (= x8_72 ((_ sign_extend 1) ((_ extract 63 1) x8_71))) (= dc_286 ((_ zero_extend 63) ((_ extract 0 0) x8_71)))))
(assert true)
(assert (= x10_71 (ite (= ne_35 #b1) x7_39 #x0000000000000000)))
(assert (and (= ge_103 ((_ extract 63 63) x3_69)) (= dc_287 ((_ extract 62 0) x3_69))))
(assert (= ge_104 (bvnot ge_103)))
(assert (= ge_105 (ite (= ne_35 #b1) ge_104 #b0)))
(assert (and (= dc_288 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_69))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_35 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_69))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_70 (ite (= ge_105 #b1) x3_neg_35 x3_69)))
(assert (and (= dc_289 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_71))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_35 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_71))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_72 (ite (= ge_105 #b1) x10_neg_35 x10_71)))
(assert (= x7_40 (ite (= ge_105 #b1) x8_72 x7_39)))
(assert (and (= dc_290 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_72) ((_ zero_extend 1) x10_72)))) (= x8_73 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_72) ((_ zero_extend 1) x10_72))))))
(assert (= x3_71 (bvadd x3_70 #x0000000000000002)))
(assert (and (= dc_291 ((_ extract 63 2) x8_73)) (= x8_lo_36 ((_ extract 1 0) x8_73))))
(assert (and (= x8_target_34 ((_ extract 1 1) x8_lo_36)) (= dc_292 ((_ extract 0 0) x8_lo_36))))
(assert (= ne_36 (bvand x8_target_34 #b1)))
(assert (and (= x8_74 ((_ sign_extend 1) ((_ extract 63 1) x8_73))) (= dc_293 ((_ zero_extend 63) ((_ extract 0 0) x8_73)))))
(assert true)
(assert (= x10_73 (ite (= ne_36 #b1) x7_40 #x0000000000000000)))
(assert (and (= ge_106 ((_ extract 63 63) x3_71)) (= dc_294 ((_ extract 62 0) x3_71))))
(assert (= ge_107 (bvnot ge_106)))
(assert (= ge_108 (ite (= ne_36 #b1) ge_107 #b0)))
(assert (and (= dc_295 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_71))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_36 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_71))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_72 (ite (= ge_108 #b1) x3_neg_36 x3_71)))
(assert (and (= dc_296 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_73))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_36 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_73))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_74 (ite (= ge_108 #b1) x10_neg_36 x10_73)))
(assert (= x7_41 (ite (= ge_108 #b1) x8_74 x7_40)))
(assert (and (= dc_297 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_74) ((_ zero_extend 1) x10_74)))) (= x8_75 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_74) ((_ zero_extend 1) x10_74))))))
(assert (= x3_73 (bvadd x3_72 #x0000000000000002)))
(assert (and (= dc_298 ((_ extract 63 2) x8_75)) (= x8_lo_37 ((_ extract 1 0) x8_75))))
(assert (and (= x8_target_35 ((_ extract 1 1) x8_lo_37)) (= dc_299 ((_ extract 0 0) x8_lo_37))))
(assert (= ne_37 (bvand x8_target_35 #b1)))
(assert (and (= x8_76 ((_ sign_extend 1) ((_ extract 63 1) x8_75))) (= dc_300 ((_ zero_extend 63) ((_ extract 0 0) x8_75)))))
(assert true)
(assert (= x10_75 (ite (= ne_37 #b1) x7_41 #x0000000000000000)))
(assert (and (= ge_109 ((_ extract 63 63) x3_73)) (= dc_301 ((_ extract 62 0) x3_73))))
(assert (= ge_110 (bvnot ge_109)))
(assert (= ge_111 (ite (= ne_37 #b1) ge_110 #b0)))
(assert (and (= dc_302 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_73))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_37 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_73))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_74 (ite (= ge_111 #b1) x3_neg_37 x3_73)))
(assert (and (= dc_303 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_75))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_37 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_75))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_76 (ite (= ge_111 #b1) x10_neg_37 x10_75)))
(assert (= x7_42 (ite (= ge_111 #b1) x8_76 x7_41)))
(assert (and (= dc_304 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_76) ((_ zero_extend 1) x10_76)))) (= x8_77 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_76) ((_ zero_extend 1) x10_76))))))
(assert (= x3_75 (bvadd x3_74 #x0000000000000002)))
(assert (and (= dc_305 ((_ extract 63 2) x8_77)) (= x8_lo_38 ((_ extract 1 0) x8_77))))
(assert (and (= x8_target_36 ((_ extract 1 1) x8_lo_38)) (= dc_306 ((_ extract 0 0) x8_lo_38))))
(assert (= ne_38 (bvand x8_target_36 #b1)))
(assert (and (= x8_78 ((_ sign_extend 1) ((_ extract 63 1) x8_77))) (= dc_307 ((_ zero_extend 63) ((_ extract 0 0) x8_77)))))
(assert true)
(assert (= x10_77 (ite (= ne_38 #b1) x7_42 #x0000000000000000)))
(assert (and (= ge_112 ((_ extract 63 63) x3_75)) (= dc_308 ((_ extract 62 0) x3_75))))
(assert (= ge_113 (bvnot ge_112)))
(assert (= ge_114 (ite (= ne_38 #b1) ge_113 #b0)))
(assert (and (= dc_309 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_75))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_38 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_75))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_76 (ite (= ge_114 #b1) x3_neg_38 x3_75)))
(assert (and (= dc_310 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_77))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_38 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_77))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_78 (ite (= ge_114 #b1) x10_neg_38 x10_77)))
(assert (= x7_43 (ite (= ge_114 #b1) x8_78 x7_42)))
(assert (and (= dc_311 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_78) ((_ zero_extend 1) x10_78)))) (= x8_79 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_78) ((_ zero_extend 1) x10_78))))))
(assert (= x3_77 (bvadd x3_76 #x0000000000000002)))
(assert (and (= dc_312 ((_ extract 63 2) x8_79)) (= x8_lo_39 ((_ extract 1 0) x8_79))))
(assert (and (= x8_target_37 ((_ extract 1 1) x8_lo_39)) (= dc_313 ((_ extract 0 0) x8_lo_39))))
(assert (= ne_39 (bvand x8_target_37 #b1)))
(assert (and (= x8_80 ((_ sign_extend 1) ((_ extract 63 1) x8_79))) (= dc_314 ((_ zero_extend 63) ((_ extract 0 0) x8_79)))))
(assert true)
(assert (= x10_79 (ite (= ne_39 #b1) x7_43 #x0000000000000000)))
(assert (and (= ge_115 ((_ extract 63 63) x3_77)) (= dc_315 ((_ extract 62 0) x3_77))))
(assert (= ge_116 (bvnot ge_115)))
(assert (= ge_117 (ite (= ne_39 #b1) ge_116 #b0)))
(assert (and (= dc_316 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_77))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_39 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_77))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_78 (ite (= ge_117 #b1) x3_neg_39 x3_77)))
(assert (and (= dc_317 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_79))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_39 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_79))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_80 (ite (= ge_117 #b1) x10_neg_39 x10_79)))
(assert (= x7_44 (ite (= ge_117 #b1) x8_80 x7_43)))
(assert (and (= dc_318 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_80) ((_ zero_extend 1) x10_80)))) (= x8_81 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_80) ((_ zero_extend 1) x10_80))))))
(assert (= x3_79 (bvadd x3_78 #x0000000000000002)))
(assert (and (= x8_82 ((_ sign_extend 1) ((_ extract 63 1) x8_81))) (= dc_319 ((_ zero_extend 63) ((_ extract 0 0) x8_81)))))
(assert (not (or (or (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_80) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= x7_44 x7_43)) (= (bvmul x8_82 #x0000000000000002) x8_80)) (= x3_79 (bvadd #x0000000000000002 x3_77))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_80) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvslt x3_77 #x0000000000000000)) (= x7_44 x7_43)) (= (bvmul x8_82 #x0000000000000002) (bvadd x8_80 x7_43))) (= x3_79 (bvadd #x0000000000000002 x3_77)))) (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) x8_80) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (bvsge x3_77 #x0000000000000000)) (= x7_44 x8_80)) (= (bvmul x8_82 #x0000000000000002) (bvsub x8_80 x7_43))) (= x3_79 (bvsub #x0000000000000002 x3_77))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_7b470e.smt2
Execution time of boolector: 2.5050 seconds
OUTPUT FROM boolector:
unsat

===== Verifying range specifications =====
=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s v3_sint32_0_1
; Output file: /tmp/outputqfbv_771d0d.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 v3_sint32_0_1)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_159f6e.smt2
Execution time of boolector: 0.0012 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: v3_sint32_0_1 <=s 1073741823
; Output file: /tmp/outputqfbv_c4dfae.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle v3_sint32_0_1 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_c436a1.smt2
Execution time of boolector: 0.0013 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s v3_sint32_1_1
; Output file: /tmp/outputqfbv_bbad5b.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 v3_sint32_1_1)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_471af8.smt2
Execution time of boolector: 0.0012 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: v3_sint32_1_1 <=s 1073741823
; Output file: /tmp/outputqfbv_e16d0a.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle v3_sint32_1_1 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_853893.smt2
Execution time of boolector: 0.0012 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s v4_sint32_0_1
; Output file: /tmp/outputqfbv_df7a23.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 v4_sint32_0_1)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_3c18dd.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: v4_sint32_0_1 <=s 1073741823
; Output file: /tmp/outputqfbv_8c6edb.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle v4_sint32_0_1 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_afee5b.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s v4_sint32_1_1
; Output file: /tmp/outputqfbv_b12cac.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 v4_sint32_1_1)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_ac11bd.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: v4_sint32_1_1 <=s 1073741823
; Output file: /tmp/outputqfbv_5ae579.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle v4_sint32_1_1 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_a5faf5.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s v5_sint32_0_1
; Output file: /tmp/outputqfbv_f7a7f4.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 v5_sint32_0_1)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_a0d36c.smt2
Execution time of boolector: 0.0012 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: v5_sint32_0_1 <=s 1073741823
; Output file: /tmp/outputqfbv_6de14f.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle v5_sint32_0_1 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_928ed5.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s v5_sint32_1_1
; Output file: /tmp/outputqfbv_9f4ecc.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 v5_sint32_1_1)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_2028b2.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: v5_sint32_1_1 <=s 1073741823
; Output file: /tmp/outputqfbv_84ec19.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle v5_sint32_1_1 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_c4d3b7.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s v6_sint32_0_1
; Output file: /tmp/outputqfbv_34ca8d.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 v6_sint32_0_1)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_0faa69.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: v6_sint32_0_1 <=s 1073741823
; Output file: /tmp/outputqfbv_cc8c01.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle v6_sint32_0_1 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_f91519.smt2
Execution time of boolector: 0.0010 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s v6_sint32_1_1
; Output file: /tmp/outputqfbv_d7b488.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 v6_sint32_1_1)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_0d4685.smt2
Execution time of boolector: 0.0010 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: v6_sint32_1_1 <=s 1073741823
; Output file: /tmp/outputqfbv_8f8cd6.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle v6_sint32_1_1 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_48a3c8.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s v7_sint32_0_1
; Output file: /tmp/outputqfbv_3378e3.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 v7_sint32_0_1)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_89dfa5.smt2
Execution time of boolector: 0.0010 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: v7_sint32_0_1 <=s 32767
; Output file: /tmp/outputqfbv_48b9b4.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle v7_sint32_0_1 #x00007FFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_83e713.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s v3_sint32_2_1
; Output file: /tmp/outputqfbv_b672eb.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 v3_sint32_2_1)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_117259.smt2
Execution time of boolector: 0.0012 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: v3_sint32_2_1 <=s 1073741823
; Output file: /tmp/outputqfbv_56c582.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle v3_sint32_2_1 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_62968f.smt2
Execution time of boolector: 0.0012 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s v3_sint32_3_1
; Output file: /tmp/outputqfbv_6743af.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 v3_sint32_3_1)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_6d0b08.smt2
Execution time of boolector: 0.0010 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: v3_sint32_3_1 <=s 1073741823
; Output file: /tmp/outputqfbv_4a0c42.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle v3_sint32_3_1 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_02d599.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s v4_sint32_2_1
; Output file: /tmp/outputqfbv_4bc331.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 v4_sint32_2_1)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_955974.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: v4_sint32_2_1 <=s 1073741823
; Output file: /tmp/outputqfbv_a9035b.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle v4_sint32_2_1 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_663dc6.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s v4_sint32_3_1
; Output file: /tmp/outputqfbv_b9583e.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 v4_sint32_3_1)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_a9c252.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: v4_sint32_3_1 <=s 1073741823
; Output file: /tmp/outputqfbv_ee9eb8.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle v4_sint32_3_1 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_1d3c96.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s v5_sint32_2_1
; Output file: /tmp/outputqfbv_2ab31c.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 v5_sint32_2_1)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_25cfc5.smt2
Execution time of boolector: 0.0012 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: v5_sint32_2_1 <=s 1073741823
; Output file: /tmp/outputqfbv_1675e0.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle v5_sint32_2_1 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_5208fa.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s v5_sint32_3_1
; Output file: /tmp/outputqfbv_319afd.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 v5_sint32_3_1)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_f098c4.smt2
Execution time of boolector: 0.0010 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: v5_sint32_3_1 <=s 1073741823
; Output file: /tmp/outputqfbv_276a32.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle v5_sint32_3_1 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_4791d6.smt2
Execution time of boolector: 0.0012 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s v6_sint32_2_1
; Output file: /tmp/outputqfbv_7cb56e.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 v6_sint32_2_1)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_408efa.smt2
Execution time of boolector: 0.0012 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: v6_sint32_2_1 <=s 1073741823
; Output file: /tmp/outputqfbv_fbeaaf.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle v6_sint32_2_1 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_385426.smt2
Execution time of boolector: 0.0012 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s v6_sint32_3_1
; Output file: /tmp/outputqfbv_a2a009.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 v6_sint32_3_1)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_32407e.smt2
Execution time of boolector: 0.0010 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: v6_sint32_3_1 <=s 1073741823
; Output file: /tmp/outputqfbv_aee187.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle v6_sint32_3_1 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_0bc15d.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s v7_sint32_2_1
; Output file: /tmp/outputqfbv_33a20b.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 v7_sint32_2_1)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_9e4caa.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: v7_sint32_2_1 <=s 65535
; Output file: /tmp/outputqfbv_a123a1.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle v7_sint32_2_1 #x0000FFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_f0d870.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s 0
; Output file: /tmp/outputqfbv_37421e.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 #x00000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_39f27b.smt2
Execution time of boolector: 0.0010 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s 1073741823
; Output file: /tmp/outputqfbv_b49f8e.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_99e5cb.smt2
Execution time of boolector: 0.0010 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s 0
; Output file: /tmp/outputqfbv_5da3d6.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 #x00000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_e95c1f.smt2
Execution time of boolector: 0.0306 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s 1073741823
; Output file: /tmp/outputqfbv_4a6767.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_b0bde3.smt2
Execution time of boolector: 0.0043 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s 0
; Output file: /tmp/outputqfbv_d5e86d.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 #x00000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_420ac4.smt2
Execution time of boolector: 0.0028 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s 1073741823
; Output file: /tmp/outputqfbv_9e9200.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_b05301.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s 0
; Output file: /tmp/outputqfbv_dc02d3.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 #x00000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_6f931e.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s 1073741823
; Output file: /tmp/outputqfbv_28fde2.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_ac58f9.smt2
Execution time of boolector: 0.0009 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s 0
; Output file: /tmp/outputqfbv_c41c7a.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 #x00000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_230273.smt2
Execution time of boolector: 0.0009 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s 1073741823
; Output file: /tmp/outputqfbv_42e161.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_17f1ed.smt2
Execution time of boolector: 0.0009 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s 0
; Output file: /tmp/outputqfbv_2a8b3f.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 #x00000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_edf37f.smt2
Execution time of boolector: 0.0009 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s 1073741823
; Output file: /tmp/outputqfbv_e17791.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_36e7dd.smt2
Execution time of boolector: 0.0009 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s 0
; Output file: /tmp/outputqfbv_29eb11.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 #x00000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_48ecfb.smt2
Execution time of boolector: 0.0009 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s 1073741823
; Output file: /tmp/outputqfbv_e9121c.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_34ecec.smt2
Execution time of boolector: 0.0009 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s 0
; Output file: /tmp/outputqfbv_744b30.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 #x00000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_880ece.smt2
Execution time of boolector: 0.0010 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s 1073741823
; Output file: /tmp/outputqfbv_bc1452.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_ebf057.smt2
Execution time of boolector: 0.0009 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s 0
; Output file: /tmp/outputqfbv_0ddfc1.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 #x00000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_dd7e2e.smt2
Execution time of boolector: 0.0009 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s 65535
; Output file: /tmp/outputqfbv_9d3177.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 #x0000FFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_48c95c.smt2
Execution time of boolector: 0.0009 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s v8_sint32_2_2
; Output file: /tmp/outputqfbv_5cf4d5.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 v8_sint32_2_2)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_d4d8ac.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: v8_sint32_2_2 <=s 1073741823
; Output file: /tmp/outputqfbv_b1d7cb.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle v8_sint32_2_2 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_3f7b15.smt2
Execution time of boolector: 0.0010 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s 0
; Output file: /tmp/outputqfbv_d74f8a.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 #x00000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_24d503.smt2
Execution time of boolector: 0.0009 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s 1073741823
; Output file: /tmp/outputqfbv_e7a5cc.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_01bba9.smt2
Execution time of boolector: 0.0009 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s 0
; Output file: /tmp/outputqfbv_8af7cf.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 #x00000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_4d804c.smt2
Execution time of boolector: 0.0009 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s 1073741823
; Output file: /tmp/outputqfbv_e53fee.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_a2d1eb.smt2
Execution time of boolector: 0.0008 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s 0
; Output file: /tmp/outputqfbv_f7a1d0.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 #x00000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_eb4021.smt2
Execution time of boolector: 0.0009 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s 1073741823
; Output file: /tmp/outputqfbv_98494c.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_d480ca.smt2
Execution time of boolector: 0.0009 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s 0
; Output file: /tmp/outputqfbv_0080a0.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 #x00000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_eaf3a9.smt2
Execution time of boolector: 0.0009 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s 1073741823
; Output file: /tmp/outputqfbv_60bb43.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_6df9f5.smt2
Execution time of boolector: 0.0009 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s 0
; Output file: /tmp/outputqfbv_c2cc27.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 #x00000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_81bb1a.smt2
Execution time of boolector: 0.0009 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s 1073741823
; Output file: /tmp/outputqfbv_7662f3.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_643b87.smt2
Execution time of boolector: 0.0009 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s 0
; Output file: /tmp/outputqfbv_6dc1fd.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 #x00000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_d38a91.smt2
Execution time of boolector: 0.0008 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s 1073741823
; Output file: /tmp/outputqfbv_36a8a1.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_628845.smt2
Execution time of boolector: 0.0009 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s 0
; Output file: /tmp/outputqfbv_d58f1e.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 #x00000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_72311f.smt2
Execution time of boolector: 0.0009 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s 1073741823
; Output file: /tmp/outputqfbv_8ec22b.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 #x3FFFFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_785c00.smt2
Execution time of boolector: 0.0009 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s 0
; Output file: /tmp/outputqfbv_c8be58.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 #x00000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_d517ba.smt2
Execution time of boolector: 0.0009 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 0 <=s 65535
; Output file: /tmp/outputqfbv_1d4a16.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (bvsle #x00000000 #x0000FFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_5ff2f6.smt2
Execution time of boolector: 0.0010 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: ((v3_sint32_0_1@e240) * 1) + (((v3_sint32_1_1@e240) * 1073741824) + (((v4_sint32_0_1@e240) * 1152921504606846976) + (((v4_sint32_1_1@e240) * 1237940039285380274899124224) + (((v5_sint32_0_1@e240) * 1329227995784915872903807060280344576) + (((v5_sint32_1_1@e240) * 1427247692705959881058285969449495136382746624) + (((v6_sint32_0_1@e240) * 1532495540865888858358347027150309183618739122183602176) + (((v6_sint32_1_1@e240) * 1645504557321206042154969182557350504982735865633579863348609024) + ((v7_sint32_0_1@s240) * 1766847064778384329583297500742918515827483896875618958121606201292619776)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949
; Output file: /tmp/outputqfbv_bfcc5b.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (= (bvadd (bvmul ((_ zero_extend 240) v3_sint32_0_1) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) v3_sint32_1_1) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_0_1) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_1_1) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_0_1) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_1_1) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_0_1) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_1_1) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) v7_sint32_0_1) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00007FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_af33bb.smt2
Execution time of boolector: 0.0012 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: ((0@e240) * 1) + (((0@e240) * 1073741824) + (((0@e240) * 1152921504606846976) + (((0@e240) * 1237940039285380274899124224) + (((0@e240) * 1329227995784915872903807060280344576) + (((0@e240) * 1427247692705959881058285969449495136382746624) + (((0@e240) * 1532495540865888858358347027150309183618739122183602176) + (((0@e240) * 1645504557321206042154969182557350504982735865633579863348609024) + ((0@s240) * 1766847064778384329583297500742918515827483896875618958121606201292619776)))))))) = 0
; Output file: /tmp/outputqfbv_a6902a.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (= (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) #x00000000) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00000000000000000000000000000000000000000000000000000000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_d793dd.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: ((v8_sint32_2_2@e240) * 1) + (((0@e240) * 1073741824) + (((0@e240) * 1152921504606846976) + (((0@e240) * 1237940039285380274899124224) + (((0@e240) * 1329227995784915872903807060280344576) + (((0@e240) * 1427247692705959881058285969449495136382746624) + (((0@e240) * 1532495540865888858358347027150309183618739122183602176) + (((0@e240) * 1645504557321206042154969182557350504982735865633579863348609024) + ((0@s240) * 1766847064778384329583297500742918515827483896875618958121606201292619776)))))))) = 1
; Output file: /tmp/outputqfbv_65f73b.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (= (bvadd (bvmul ((_ zero_extend 240) v8_sint32_2_2) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) #x00000000) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00000000000000000000000000000000000000000000000000000000000000000001)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_0faf13.smt2
Execution time of boolector: 0.0010 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: (((x1_2@e192)@e1) - (57896044618658097711785492504343953926634992332820282019728792003956564819949@e1)) smod (1152921504606846976@e1) = 0
; Output file: /tmp/outputqfbv_210ae9.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 192) x1_2)) ((_ zero_extend 1) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) ((_ zero_extend 1) #x0000000000000000000000000000000000000000000000001000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_bf2e6d.smt2
Execution time of boolector: 0.0012 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: ((v3_sint32_2_1@e240) * 1) + (((v3_sint32_3_1@e240) * 1073741824) + (((v4_sint32_2_1@e240) * 1152921504606846976) + (((v4_sint32_3_1@e240) * 1237940039285380274899124224) + (((v5_sint32_2_1@e240) * 1329227995784915872903807060280344576) + (((v5_sint32_3_1@e240) * 1427247692705959881058285969449495136382746624) + (((v6_sint32_2_1@e240) * 1532495540865888858358347027150309183618739122183602176) + (((v6_sint32_3_1@e240) * 1645504557321206042154969182557350504982735865633579863348609024) + ((v7_sint32_2_1@s240) * 1766847064778384329583297500742918515827483896875618958121606201292619776)))))))) = (((op_x0_0@e192) * 1) + (((op_x1_0@e192) * 18446744073709551616) + (((op_x2_0@e192) * 340282366920938463463374607431768211456) + ((op_x3_0@e192) * 6277101735386680763835789423207666416102355444464034512896))))@e16
; Output file: /tmp/outputqfbv_ad750c.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (= (bvadd (bvmul ((_ zero_extend 240) v3_sint32_2_1) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) v3_sint32_3_1) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_2_1) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_3_1) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_2_1) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_3_1) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_2_1) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_3_1) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) v7_sint32_2_1) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) ((_ zero_extend 16) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000))))))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_cd5ab6.smt2
Execution time of boolector: 0.0176 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: 1 = 1
; Output file: /tmp/outputqfbv_5d714f.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (= #x0000000000000001 #x0000000000000001)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_585c13.smt2
Execution time of boolector: 0.0009 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: ((((((18446744073709551597@e64) * 1) + ((18446744073709551615@e64) * 18446744073709551616))@e128)@e1) - (57896044618658097711785492504343953926634992332820282019728792003956564819949@e1)) smod (340282366920938463463374607431768211456@e1) = 0
; Output file: /tmp/outputqfbv_4cdcd8.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 128) (bvadd (bvmul ((_ zero_extend 64) #xFFFFFFFFFFFFFFED) #x00000000000000000000000000000001) (bvmul ((_ zero_extend 64) #xFFFFFFFFFFFFFFFF) #x00000000000000010000000000000000)))) ((_ zero_extend 1) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) ((_ zero_extend 1) #x0000000000000000000000000000000100000000000000000000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_4f90e9.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: (((x2_6@e192)@e1) - ((((op_x0_0@e192) * 1) + (((op_x1_0@e192) * 18446744073709551616) + (((op_x2_0@e192) * 340282366920938463463374607431768211456) + ((op_x3_0@e192) * 6277101735386680763835789423207666416102355444464034512896))))@e1)) smod (1152921504606846976@e1) = 0
; Output file: /tmp/outputqfbv_055a3e.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 192) x2_6)) ((_ zero_extend 1) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))))) ((_ zero_extend 1) #x0000000000000000000000000000000000000000000000001000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_010e15.smt2
Execution time of boolector: 0.0154 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: x6_2 = 2199024304128
; Output file: /tmp/outputqfbv_cdece5.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (= x6_2 #x0000020000100000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_d77db5.smt2
Execution time of boolector: 0.0010 seconds
OUTPUT FROM boolector:
unsat

=== Cut #0 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #0
; Range specification #0: and [0@32 <=s v3_sint32_0_1, v3_sint32_0_1 <=s 1073741823@32, 0@32 <=s v3_sint32_1_1, v3_sint32_1_1 <=s 1073741823@32, 0@32 <=s v4_sint32_0_1, v4_sint32_0_1 <=s 1073741823@32, 0@32 <=s v4_sint32_1_1, v4_sint32_1_1 <=s 1073741823@32, 0@32 <=s v5_sint32_0_1, v5_sint32_0_1 <=s 1073741823@32, 0@32 <=s v5_sint32_1_1, v5_sint32_1_1 <=s 1073741823@32, 0@32 <=s v6_sint32_0_1, v6_sint32_0_1 <=s 1073741823@32, 0@32 <=s v6_sint32_1_1, v6_sint32_1_1 <=s 1073741823@32, 0@32 <=s v7_sint32_0_1, v7_sint32_0_1 <=s 32767@32, 0@32 <=s v3_sint32_2_1, v3_sint32_2_1 <=s 1073741823@32, 0@32 <=s v3_sint32_3_1, v3_sint32_3_1 <=s 1073741823@32, 0@32 <=s v4_sint32_2_1, v4_sint32_2_1 <=s 1073741823@32, 0@32 <=s v4_sint32_3_1, v4_sint32_3_1 <=s 1073741823@32, 0@32 <=s v5_sint32_2_1, v5_sint32_2_1 <=s 1073741823@32, 0@32 <=s v5_sint32_3_1, v5_sint32_3_1 <=s 1073741823@32, 0@32 <=s v6_sint32_2_1, v6_sint32_2_1 <=s 1073741823@32, 0@32 <=s v6_sint32_3_1, v6_sint32_3_1 <=s 1073741823@32, 0@32 <=s v7_sint32_2_1, v7_sint32_2_1 <=s 65535@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, 0@32 <=s v8_sint32_2_2, v8_sint32_2_2 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 1073741823@32, 0@32 <=s 0@32, 0@32 <=s 65535@32, add (mul (uext v3_sint32_0_1 240) 1@272) (add (mul (uext v3_sint32_1_1 240) 1073741824@272) (add (mul (uext v4_sint32_0_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_1_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_0_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_1_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_0_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_1_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_0_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 57896044618658097711785492504343953926634992332820282019728792003956564819949@272, add (mul (uext v3_sint32_2_1 240) 1@272) (add (mul (uext v3_sint32_3_1 240) 1073741824@272) (add (mul (uext v4_sint32_2_1 240) 1152921504606846976@272) (add (mul (uext v4_sint32_3_1 240) 1237940039285380274899124224@272) (add (mul (uext v5_sint32_2_1 240) 1329227995784915872903807060280344576@272) (add (mul (uext v5_sint32_3_1 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext v6_sint32_2_1 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext v6_sint32_3_1 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext v7_sint32_2_1 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 16, add (mul (uext 0@32 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 0@272, add (mul (uext v8_sint32_2_2 240) 1@272) (add (mul (uext 0@32 240) 1073741824@272) (add (mul (uext 0@32 240) 1152921504606846976@272) (add (mul (uext 0@32 240) 1237940039285380274899124224@272) (add (mul (uext 0@32 240) 1329227995784915872903807060280344576@272) (add (mul (uext 0@32 240) 1427247692705959881058285969449495136382746624@272) (add (mul (uext 0@32 240) 1532495540865888858358347027150309183618739122183602176@272) (add (mul (uext 0@32 240) 1645504557321206042154969182557350504982735865633579863348609024@272) (mul (sext 0@32 240) 1766847064778384329583297500742918515827483896875618958121606201292619776@272)))))))) = 1@272, smod (sub (uext (uext x1_2 192) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 1152921504606846976@256 1) = 0@257, smod (sub (uext (uext x2_6 192) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 1152921504606846976@256 1) = 0@257, 1@64 = 1@64, smod (sub (uext (uext (add (mul (uext 18446744073709551597@64 64) 1@128) (mul (uext 18446744073709551615@64 64) 18446744073709551616@128)) 128) 1) (uext 57896044618658097711785492504343953926634992332820282019728792003956564819949@256 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, smod (sub (uext (uext (add (mul (uext op_x0_0 64) 1@128) (mul (uext op_x1_0 64) 18446744073709551616@128)) 128) 1) (uext (add (mul (uext op_x0_0 192) 1@256) (add (mul (uext op_x1_0 192) 18446744073709551616@256) (add (mul (uext op_x2_0 192) 340282366920938463463374607431768211456@256) (mul (uext op_x3_0 192) 6277101735386680763835789423207666416102355444464034512896@256)))) 1)) (uext 340282366920938463463374607431768211456@256 1) = 0@257, x6_2 = 2199024304128@64]
; Range condition: ((((((op_x0_0@e64) * 1) + ((op_x1_0@e64) * 18446744073709551616))@e128)@e1) - ((((op_x0_0@e192) * 1) + (((op_x1_0@e192) * 18446744073709551616) + (((op_x2_0@e192) * 340282366920938463463374607431768211456) + ((op_x3_0@e192) * 6277101735386680763835789423207666416102355444464034512896))))@e1)) smod (340282366920938463463374607431768211456@e1) = 0
; Output file: /tmp/outputqfbv_c00b78.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x2_2 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun w7_1 () (_ BitVec 32))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_uint64_1_1 () (_ BitVec 64))
(declare-fun v7_uint64_0_1 () (_ BitVec 64))
(declare-fun v7_sint32_3_1 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_1_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_uint64_1_3 () (_ BitVec 64))
(declare-fun v6_uint64_1_2 () (_ BitVec 64))
(declare-fun v6_uint64_0_3 () (_ BitVec 64))
(declare-fun v6_uint64_0_2 () (_ BitVec 64))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_uint64_1_3 () (_ BitVec 64))
(declare-fun v5_uint64_1_2 () (_ BitVec 64))
(declare-fun v5_uint64_0_3 () (_ BitVec 64))
(declare-fun v5_uint64_0_2 () (_ BitVec 64))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_uint64_1_3 () (_ BitVec 64))
(declare-fun v4_uint64_1_2 () (_ BitVec 64))
(declare-fun v4_uint64_0_3 () (_ BitVec 64))
(declare-fun v4_uint64_0_2 () (_ BitVec 64))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_uint64_1_2 () (_ BitVec 64))
(declare-fun v3_uint64_0_2 () (_ BitVec 64))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun v1_uint64_1_1 () (_ BitVec 64))
(declare-fun v1_uint64_0_1 () (_ BitVec 64))
(declare-fun v1_uint32_3_1 () (_ BitVec 32))
(declare-fun v1_uint32_2_1 () (_ BitVec 32))
(declare-fun v1_uint32_1_1 () (_ BitVec 32))
(declare-fun v1_uint32_0_1 () (_ BitVec 32))
(declare-fun v12_uint64_1_14 () (_ BitVec 64))
(declare-fun v12_uint64_1_13 () (_ BitVec 64))
(declare-fun v12_uint64_1_12 () (_ BitVec 64))
(declare-fun v12_uint64_1_11 () (_ BitVec 64))
(declare-fun v12_uint64_1_10 () (_ BitVec 64))
(declare-fun v12_uint64_1_9 () (_ BitVec 64))
(declare-fun v12_uint64_1_8 () (_ BitVec 64))
(declare-fun v12_uint64_1_7 () (_ BitVec 64))
(declare-fun v12_uint64_1_6 () (_ BitVec 64))
(declare-fun v12_uint64_1_5 () (_ BitVec 64))
(declare-fun v12_uint64_1_4 () (_ BitVec 64))
(declare-fun v12_uint64_1_3 () (_ BitVec 64))
(declare-fun v12_uint64_1_2 () (_ BitVec 64))
(declare-fun v12_uint64_1_1 () (_ BitVec 64))
(declare-fun v12_uint64_0_14 () (_ BitVec 64))
(declare-fun v12_uint64_0_13 () (_ BitVec 64))
(declare-fun v12_uint64_0_12 () (_ BitVec 64))
(declare-fun v12_uint64_0_11 () (_ BitVec 64))
(declare-fun v12_uint64_0_10 () (_ BitVec 64))
(declare-fun v12_uint64_0_9 () (_ BitVec 64))
(declare-fun v12_uint64_0_8 () (_ BitVec 64))
(declare-fun v12_uint64_0_7 () (_ BitVec 64))
(declare-fun v12_uint64_0_6 () (_ BitVec 64))
(declare-fun v12_uint64_0_5 () (_ BitVec 64))
(declare-fun v12_uint64_0_4 () (_ BitVec 64))
(declare-fun v12_uint64_0_3 () (_ BitVec 64))
(declare-fun v12_uint64_0_2 () (_ BitVec 64))
(declare-fun v12_uint64_0_1 () (_ BitVec 64))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun dcL_1 () (_ BitVec 64))
(declare-fun dc_40 () (_ BitVec 48))
(declare-fun dc_39 () (_ BitVec 48))
(declare-fun dc_38 () (_ BitVec 64))
(declare-fun dc_37 () (_ BitVec 64))
(declare-fun dc_36 () (_ BitVec 18))
(declare-fun dc_35 () (_ BitVec 18))
(declare-fun dc_34 () (_ BitVec 64))
(declare-fun dc_33 () (_ BitVec 64))
(declare-fun dc_32 () (_ BitVec 12))
(declare-fun dc_31 () (_ BitVec 12))
(declare-fun dc_30 () (_ BitVec 52))
(declare-fun dc_29 () (_ BitVec 52))
(declare-fun dc_28 () (_ BitVec 64))
(declare-fun dc_27 () (_ BitVec 64))
(declare-fun dc_26 () (_ BitVec 22))
(declare-fun dc_25 () (_ BitVec 22))
(declare-fun dc_24 () (_ BitVec 64))
(declare-fun dc_23 () (_ BitVec 64))
(declare-fun dc_22 () (_ BitVec 8))
(declare-fun dc_21 () (_ BitVec 8))
(declare-fun dc_20 () (_ BitVec 56))
(declare-fun dc_19 () (_ BitVec 56))
(declare-fun dc_18 () (_ BitVec 64))
(declare-fun dc_17 () (_ BitVec 64))
(declare-fun dc_16 () (_ BitVec 26))
(declare-fun dc_15 () (_ BitVec 26))
(declare-fun dc_14 () (_ BitVec 64))
(declare-fun dc_13 () (_ BitVec 64))
(declare-fun dc_12 () (_ BitVec 4))
(declare-fun dc_11 () (_ BitVec 4))
(declare-fun dc_10 () (_ BitVec 60))
(declare-fun dc_9 () (_ BitVec 60))
(declare-fun dc_8 () (_ BitVec 64))
(declare-fun dc_7 () (_ BitVec 64))
(declare-fun dc_6 () (_ BitVec 30))
(declare-fun dc_5 () (_ BitVec 30))
(declare-fun dc_4 () (_ BitVec 64))
(declare-fun dc_3 () (_ BitVec 64))
(declare-fun dc_2 () (_ BitVec 34))
(declare-fun dc_1 () (_ BitVec 34))
(assert true)
(assert (and (= x2_2 ((_ zero_extend 1) ((_ extract 63 1) #xFFFFFFFFFFFFFFFF))) (= dcL_1 ((_ zero_extend 63) ((_ extract 0 0) #xFFFFFFFFFFFFFFFF)))))
(assert (and (= v1_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_1 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v1_uint64_1_1 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000022)) (= dc_2 ((_ extract 33 0) #xFFFFFFFFFFFFFFFF))))
(assert true)
(assert (and (= dc_3 ((_ zero_extend 30) ((_ extract 63 30) #xFFFFFFFFFFFFFFED))) (= v3_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) #xFFFFFFFFFFFFFFED)))))
(assert (and (= dc_4 ((_ zero_extend 30) ((_ extract 63 30) op_x0_0))) (= v3_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) op_x0_0)))))
(assert (and (= v12_uint64_0_1 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000001E)) (= dc_5 ((_ extract 29 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v12_uint64_1_1 (bvlshr op_x0_0 #x000000000000001E)) (= dc_6 ((_ extract 29 0) op_x0_0))))
(assert true)
(assert (and (= dc_7 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_1))) (= v12_uint64_0_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_1)))))
(assert (and (= dc_8 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_1))) (= v12_uint64_1_2 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_1)))))
(assert (= v3_sint32_0_1 ((_ extract 31 0) v3_uint64_0_2)))
(assert (= v3_sint32_2_1 ((_ extract 31 0) v3_uint64_1_2)))
(assert (= v3_sint32_1_1 ((_ extract 31 0) v12_uint64_0_2)))
(assert (= v3_sint32_3_1 ((_ extract 31 0) v12_uint64_1_2)))
(assert true)
(assert (and (= v4_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFED #x000000000000003C)) (= dc_9 ((_ extract 59 0) #xFFFFFFFFFFFFFFED))))
(assert (and (= v4_uint64_1_2 (bvlshr op_x0_0 #x000000000000003C)) (= dc_10 ((_ extract 59 0) op_x0_0))))
(assert (and (= dc_11 ((_ extract 63 60) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_3 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000004))))
(assert (and (= dc_12 ((_ extract 63 60) op_x1_0)) (= v12_uint64_1_3 (bvshl op_x1_0 #x0000000000000004))))
(assert (and (= dc_13 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_3))) (= v12_uint64_0_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_3)))))
(assert (and (= dc_14 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_3))) (= v12_uint64_1_4 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_3)))))
(assert (= v4_uint64_0_3 (bvor v4_uint64_0_2 v12_uint64_0_4)))
(assert (= v4_uint64_1_3 (bvor v4_uint64_1_2 v12_uint64_1_4)))
(assert (and (= v12_uint64_0_5 (bvlshr #xFFFFFFFFFFFFFFFF #x000000000000001A)) (= dc_15 ((_ extract 25 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_5 (bvlshr op_x1_0 #x000000000000001A)) (= dc_16 ((_ extract 25 0) op_x1_0))))
(assert (and (= dc_17 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_5))) (= v12_uint64_0_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_5)))))
(assert (and (= dc_18 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_5))) (= v12_uint64_1_6 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_5)))))
(assert (= v4_sint32_0_1 ((_ extract 31 0) v4_uint64_0_3)))
(assert (= v4_sint32_2_1 ((_ extract 31 0) v4_uint64_1_3)))
(assert (= v4_sint32_1_1 ((_ extract 31 0) v12_uint64_0_6)))
(assert (= v4_sint32_3_1 ((_ extract 31 0) v12_uint64_1_6)))
(assert (and (= v5_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000038)) (= dc_19 ((_ extract 55 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v5_uint64_1_2 (bvlshr op_x1_0 #x0000000000000038)) (= dc_20 ((_ extract 55 0) op_x1_0))))
(assert (and (= dc_21 ((_ extract 63 56) #xFFFFFFFFFFFFFFFF)) (= v12_uint64_0_7 (bvshl #xFFFFFFFFFFFFFFFF #x0000000000000008))))
(assert (and (= dc_22 ((_ extract 63 56) op_x2_0)) (= v12_uint64_1_7 (bvshl op_x2_0 #x0000000000000008))))
(assert (and (= dc_23 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_7))) (= v12_uint64_0_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_7)))))
(assert (and (= dc_24 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_7))) (= v12_uint64_1_8 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_7)))))
(assert (= v5_uint64_0_3 (bvor v5_uint64_0_2 v12_uint64_0_8)))
(assert (= v5_uint64_1_3 (bvor v5_uint64_1_2 v12_uint64_1_8)))
(assert (and (= v12_uint64_0_9 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000016)) (= dc_25 ((_ extract 21 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v12_uint64_1_9 (bvlshr op_x2_0 #x0000000000000016)) (= dc_26 ((_ extract 21 0) op_x2_0))))
(assert (and (= dc_27 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_9))) (= v12_uint64_0_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_9)))))
(assert (and (= dc_28 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_9))) (= v12_uint64_1_10 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_9)))))
(assert (= v5_sint32_0_1 ((_ extract 31 0) v5_uint64_0_3)))
(assert (= v5_sint32_2_1 ((_ extract 31 0) v5_uint64_1_3)))
(assert (= v5_sint32_1_1 ((_ extract 31 0) v12_uint64_0_10)))
(assert (= v5_sint32_3_1 ((_ extract 31 0) v12_uint64_1_10)))
(assert (and (= v6_uint64_0_2 (bvlshr #xFFFFFFFFFFFFFFFF #x0000000000000034)) (= dc_29 ((_ extract 51 0) #xFFFFFFFFFFFFFFFF))))
(assert (and (= v6_uint64_1_2 (bvlshr op_x2_0 #x0000000000000034)) (= dc_30 ((_ extract 51 0) op_x2_0))))
(assert (and (= dc_31 ((_ extract 63 52) x2_2)) (= v12_uint64_0_11 (bvshl x2_2 #x000000000000000C))))
(assert (and (= dc_32 ((_ extract 63 52) op_x3_0)) (= v12_uint64_1_11 (bvshl op_x3_0 #x000000000000000C))))
(assert (and (= dc_33 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_11))) (= v12_uint64_0_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_11)))))
(assert (and (= dc_34 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_11))) (= v12_uint64_1_12 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_11)))))
(assert (= v6_uint64_0_3 (bvor v6_uint64_0_2 v12_uint64_0_12)))
(assert (= v6_uint64_1_3 (bvor v6_uint64_1_2 v12_uint64_1_12)))
(assert (and (= v12_uint64_0_13 (bvlshr x2_2 #x0000000000000012)) (= dc_35 ((_ extract 17 0) x2_2))))
(assert (and (= v12_uint64_1_13 (bvlshr op_x3_0 #x0000000000000012)) (= dc_36 ((_ extract 17 0) op_x3_0))))
(assert (and (= dc_37 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_0_13))) (= v12_uint64_0_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_0_13)))))
(assert (and (= dc_38 ((_ zero_extend 30) ((_ extract 63 30) v12_uint64_1_13))) (= v12_uint64_1_14 ((_ zero_extend 34) ((_ extract 29 0) v12_uint64_1_13)))))
(assert (= v6_sint32_0_1 ((_ extract 31 0) v6_uint64_0_3)))
(assert (= v6_sint32_2_1 ((_ extract 31 0) v6_uint64_1_3)))
(assert (= v6_sint32_1_1 ((_ extract 31 0) v12_uint64_0_14)))
(assert (= v6_sint32_3_1 ((_ extract 31 0) v12_uint64_1_14)))
(assert (and (= v7_uint64_0_1 (bvlshr x2_2 #x0000000000000030)) (= dc_39 ((_ extract 47 0) x2_2))))
(assert (and (= v7_uint64_1_1 (bvlshr op_x3_0 #x0000000000000030)) (= dc_40 ((_ extract 47 0) op_x3_0))))
(assert (and (= v7_sint32_1_1 ((_ extract 63 32) v7_uint64_0_1)) (= v7_sint32_0_1 ((_ extract 31 0) v7_uint64_0_1))))
(assert (and (= v7_sint32_3_1 ((_ extract 63 32) v7_uint64_1_1)) (= v7_sint32_2_1 ((_ extract 31 0) v7_uint64_1_1))))
(assert (= v8_sint32_2_2 ((_ extract 31 0) #x0000000000000001)))
(assert (and (= v1_uint32_1_1 ((_ extract 63 32) v1_uint64_0_1)) (= v1_uint32_0_1 ((_ extract 31 0) v1_uint64_0_1))))
(assert (and (= v1_uint32_3_1 ((_ extract 63 32) v1_uint64_1_1)) (= v1_uint32_2_1 ((_ extract 31 0) v1_uint64_1_1))))
(assert (= x1_2 #xFFFFFFFFFFFFFFED))
(assert (= x2_6 op_x0_0))
(assert (= x6_2 (bvadd #x0000020000000000 #x0000000000100000)))
(assert (= w7_1 ((_ extract 31 0) #x00000000286BCA1B)))
(assert (not (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 128) (bvadd (bvmul ((_ zero_extend 64) op_x0_0) #x00000000000000000000000000000001) (bvmul ((_ zero_extend 64) op_x1_0) #x00000000000000010000000000000000)))) ((_ zero_extend 1) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))))) ((_ zero_extend 1) #x0000000000000000000000000000000100000000000000000000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_866686.smt2
Execution time of boolector: 0.0177 seconds
OUTPUT FROM boolector:
unsat

=== Cut #1 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #1
; Range specification #3: (-1048575)@64 <=s f_0_low60_0_low20_0_1
; Range condition: -1048575 <=s f_0_low60_0_low20_0_1
; Output file: /tmp/outputqfbv_ab1e66.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_2 () (_ BitVec 64))
(declare-fun x8_1 () (_ BitVec 64))
(declare-fun x7_3 () (_ BitVec 64))
(declare-fun x7_2 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun g_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_0_1 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (bvsle #x00000000 v3_sint32_0_1) (bvsle v3_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v3_sint32_1_1)) (bvsle v3_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_0_1)) (bvsle v4_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_1_1)) (bvsle v4_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_0_1)) (bvsle v5_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_1_1)) (bvsle v5_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_0_1)) (bvsle v6_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_1_1)) (bvsle v6_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v7_sint32_0_1)) (bvsle v7_sint32_0_1 #x00007FFF)) (bvsle #x00000000 v3_sint32_2_1)) (bvsle v3_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v3_sint32_3_1)) (bvsle v3_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_2_1)) (bvsle v4_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_3_1)) (bvsle v4_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_2_1)) (bvsle v5_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_3_1)) (bvsle v5_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_2_1)) (bvsle v6_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_3_1)) (bvsle v6_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v7_sint32_2_1)) (bvsle v7_sint32_2_1 #x0000FFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x0000FFFF)) (bvsle #x00000000 v8_sint32_2_2)) (bvsle v8_sint32_2_2 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x0000FFFF)) (= (bvadd (bvmul ((_ zero_extend 240) v3_sint32_0_1) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) v3_sint32_1_1) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_0_1) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_1_1) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_0_1) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_1_1) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_0_1) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_1_1) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) v7_sint32_0_1) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00007FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) (= (bvadd (bvmul ((_ zero_extend 240) v3_sint32_2_1) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) v3_sint32_3_1) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_2_1) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_3_1) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_2_1) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_3_1) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_2_1) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_3_1) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) v7_sint32_2_1) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) ((_ zero_extend 16) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000))))))) (= (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) #x00000000) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00000000000000000000000000000000000000000000000000000000000000000000)) (= (bvadd (bvmul ((_ zero_extend 240) v8_sint32_2_2) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) #x00000000) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00000000000000000000000000000000000000000000000000000000000000000001)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 192) x1_2)) ((_ zero_extend 1) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) ((_ zero_extend 1) #x0000000000000000000000000000000000000000000000001000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 192) x2_6)) ((_ zero_extend 1) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))))) ((_ zero_extend 1) #x0000000000000000000000000000000000000000000000001000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= #x0000000000000001 #x0000000000000001)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 128) (bvadd (bvmul ((_ zero_extend 64) #xFFFFFFFFFFFFFFED) #x00000000000000000000000000000001) (bvmul ((_ zero_extend 64) #xFFFFFFFFFFFFFFFF) #x00000000000000010000000000000000)))) ((_ zero_extend 1) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) ((_ zero_extend 1) #x0000000000000000000000000000000100000000000000000000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 128) (bvadd (bvmul ((_ zero_extend 64) op_x0_0) #x00000000000000000000000000000001) (bvmul ((_ zero_extend 64) op_x1_0) #x00000000000000010000000000000000)))) ((_ zero_extend 1) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))))) ((_ zero_extend 1) #x0000000000000000000000000000000100000000000000000000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= x6_2 #x0000020000100000)))
(assert (= x7_2 (bvand x1_2 #x00000000000FFFFF)))
(assert (= x8_1 (bvand x2_6 #x00000000000FFFFF)))
(assert (= x7_3 (bvor x7_2 #xFFFFFE0000000000)))
(assert (= x8_2 (bvor x8_1 #xC000000000000000)))
(assert (= f_0_low60_0_low20_0_1 (bvand x1_2 #x00000000000FFFFF)))
(assert (= g_0_low60_0_low20_0_1 (bvand x2_6 #x00000000000FFFFF)))
(assert (not (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_0_1)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_a5e272.smt2
Execution time of boolector: 0.0013 seconds
OUTPUT FROM boolector:
unsat

=== Cut #1 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #1
; Range specification #1: x7_3 = add (add f_0_low60_0_low20_0_1 (mul (-1048576)@64 2097152@64)) (mul 0@64 4398046511104@64)
; Range condition: x7_3 = (f_0_low60_0_low20_0_1 + (-1048576 * 2097152)) + (0 * 4398046511104)
; Output file: /tmp/outputqfbv_30eecd.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_2 () (_ BitVec 64))
(declare-fun x8_1 () (_ BitVec 64))
(declare-fun x7_3 () (_ BitVec 64))
(declare-fun x7_2 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun g_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_0_1 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (bvsle #x00000000 v3_sint32_0_1) (bvsle v3_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v3_sint32_1_1)) (bvsle v3_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_0_1)) (bvsle v4_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_1_1)) (bvsle v4_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_0_1)) (bvsle v5_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_1_1)) (bvsle v5_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_0_1)) (bvsle v6_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_1_1)) (bvsle v6_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v7_sint32_0_1)) (bvsle v7_sint32_0_1 #x00007FFF)) (bvsle #x00000000 v3_sint32_2_1)) (bvsle v3_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v3_sint32_3_1)) (bvsle v3_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_2_1)) (bvsle v4_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_3_1)) (bvsle v4_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_2_1)) (bvsle v5_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_3_1)) (bvsle v5_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_2_1)) (bvsle v6_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_3_1)) (bvsle v6_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v7_sint32_2_1)) (bvsle v7_sint32_2_1 #x0000FFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x0000FFFF)) (bvsle #x00000000 v8_sint32_2_2)) (bvsle v8_sint32_2_2 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x0000FFFF)) (= (bvadd (bvmul ((_ zero_extend 240) v3_sint32_0_1) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) v3_sint32_1_1) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_0_1) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_1_1) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_0_1) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_1_1) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_0_1) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_1_1) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) v7_sint32_0_1) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00007FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) (= (bvadd (bvmul ((_ zero_extend 240) v3_sint32_2_1) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) v3_sint32_3_1) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_2_1) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_3_1) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_2_1) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_3_1) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_2_1) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_3_1) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) v7_sint32_2_1) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) ((_ zero_extend 16) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000))))))) (= (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) #x00000000) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00000000000000000000000000000000000000000000000000000000000000000000)) (= (bvadd (bvmul ((_ zero_extend 240) v8_sint32_2_2) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) #x00000000) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00000000000000000000000000000000000000000000000000000000000000000001)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 192) x1_2)) ((_ zero_extend 1) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) ((_ zero_extend 1) #x0000000000000000000000000000000000000000000000001000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 192) x2_6)) ((_ zero_extend 1) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))))) ((_ zero_extend 1) #x0000000000000000000000000000000000000000000000001000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= #x0000000000000001 #x0000000000000001)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 128) (bvadd (bvmul ((_ zero_extend 64) #xFFFFFFFFFFFFFFED) #x00000000000000000000000000000001) (bvmul ((_ zero_extend 64) #xFFFFFFFFFFFFFFFF) #x00000000000000010000000000000000)))) ((_ zero_extend 1) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) ((_ zero_extend 1) #x0000000000000000000000000000000100000000000000000000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 128) (bvadd (bvmul ((_ zero_extend 64) op_x0_0) #x00000000000000000000000000000001) (bvmul ((_ zero_extend 64) op_x1_0) #x00000000000000010000000000000000)))) ((_ zero_extend 1) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))))) ((_ zero_extend 1) #x0000000000000000000000000000000100000000000000000000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= x6_2 #x0000020000100000)))
(assert (= x7_2 (bvand x1_2 #x00000000000FFFFF)))
(assert (= x8_1 (bvand x2_6 #x00000000000FFFFF)))
(assert (= x7_3 (bvor x7_2 #xFFFFFE0000000000)))
(assert (= x8_2 (bvor x8_1 #xC000000000000000)))
(assert (= f_0_low60_0_low20_0_1 (bvand x1_2 #x00000000000FFFFF)))
(assert (= g_0_low60_0_low20_0_1 (bvand x2_6 #x00000000000FFFFF)))
(assert (not (= x7_3 (bvadd (bvadd f_0_low60_0_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000)))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_158d9f.smt2
Execution time of boolector: 0.0223 seconds
OUTPUT FROM boolector:
unsat

=== Cut #1 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #1
; Range specification #5: (-1048575)@64 <=s g_0_low60_0_low20_0_1
; Range condition: -1048575 <=s g_0_low60_0_low20_0_1
; Output file: /tmp/outputqfbv_315f7e.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_2 () (_ BitVec 64))
(declare-fun x8_1 () (_ BitVec 64))
(declare-fun x7_3 () (_ BitVec 64))
(declare-fun x7_2 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun g_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_0_1 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (bvsle #x00000000 v3_sint32_0_1) (bvsle v3_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v3_sint32_1_1)) (bvsle v3_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_0_1)) (bvsle v4_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_1_1)) (bvsle v4_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_0_1)) (bvsle v5_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_1_1)) (bvsle v5_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_0_1)) (bvsle v6_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_1_1)) (bvsle v6_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v7_sint32_0_1)) (bvsle v7_sint32_0_1 #x00007FFF)) (bvsle #x00000000 v3_sint32_2_1)) (bvsle v3_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v3_sint32_3_1)) (bvsle v3_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_2_1)) (bvsle v4_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_3_1)) (bvsle v4_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_2_1)) (bvsle v5_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_3_1)) (bvsle v5_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_2_1)) (bvsle v6_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_3_1)) (bvsle v6_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v7_sint32_2_1)) (bvsle v7_sint32_2_1 #x0000FFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x0000FFFF)) (bvsle #x00000000 v8_sint32_2_2)) (bvsle v8_sint32_2_2 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x0000FFFF)) (= (bvadd (bvmul ((_ zero_extend 240) v3_sint32_0_1) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) v3_sint32_1_1) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_0_1) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_1_1) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_0_1) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_1_1) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_0_1) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_1_1) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) v7_sint32_0_1) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00007FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) (= (bvadd (bvmul ((_ zero_extend 240) v3_sint32_2_1) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) v3_sint32_3_1) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_2_1) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_3_1) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_2_1) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_3_1) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_2_1) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_3_1) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) v7_sint32_2_1) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) ((_ zero_extend 16) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000))))))) (= (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) #x00000000) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00000000000000000000000000000000000000000000000000000000000000000000)) (= (bvadd (bvmul ((_ zero_extend 240) v8_sint32_2_2) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) #x00000000) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00000000000000000000000000000000000000000000000000000000000000000001)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 192) x1_2)) ((_ zero_extend 1) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) ((_ zero_extend 1) #x0000000000000000000000000000000000000000000000001000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 192) x2_6)) ((_ zero_extend 1) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))))) ((_ zero_extend 1) #x0000000000000000000000000000000000000000000000001000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= #x0000000000000001 #x0000000000000001)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 128) (bvadd (bvmul ((_ zero_extend 64) #xFFFFFFFFFFFFFFED) #x00000000000000000000000000000001) (bvmul ((_ zero_extend 64) #xFFFFFFFFFFFFFFFF) #x00000000000000010000000000000000)))) ((_ zero_extend 1) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) ((_ zero_extend 1) #x0000000000000000000000000000000100000000000000000000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 128) (bvadd (bvmul ((_ zero_extend 64) op_x0_0) #x00000000000000000000000000000001) (bvmul ((_ zero_extend 64) op_x1_0) #x00000000000000010000000000000000)))) ((_ zero_extend 1) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))))) ((_ zero_extend 1) #x0000000000000000000000000000000100000000000000000000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= x6_2 #x0000020000100000)))
(assert (= x7_2 (bvand x1_2 #x00000000000FFFFF)))
(assert (= x8_1 (bvand x2_6 #x00000000000FFFFF)))
(assert (= x7_3 (bvor x7_2 #xFFFFFE0000000000)))
(assert (= x8_2 (bvor x8_1 #xC000000000000000)))
(assert (= f_0_low60_0_low20_0_1 (bvand x1_2 #x00000000000FFFFF)))
(assert (= g_0_low60_0_low20_0_1 (bvand x2_6 #x00000000000FFFFF)))
(assert (not (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_0_1)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_2ec0af.smt2
Execution time of boolector: 0.0013 seconds
OUTPUT FROM boolector:
unsat

=== Cut #1 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #1
; Range specification #2: x8_2 = add (add g_0_low60_0_low20_0_1 (mul 0@64 2097152@64)) (mul (-1048576)@64 4398046511104@64)
; Range condition: x8_2 = (g_0_low60_0_low20_0_1 + (0 * 2097152)) + (-1048576 * 4398046511104)
; Output file: /tmp/outputqfbv_31963d.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_2 () (_ BitVec 64))
(declare-fun x8_1 () (_ BitVec 64))
(declare-fun x7_3 () (_ BitVec 64))
(declare-fun x7_2 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun g_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_0_1 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (bvsle #x00000000 v3_sint32_0_1) (bvsle v3_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v3_sint32_1_1)) (bvsle v3_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_0_1)) (bvsle v4_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_1_1)) (bvsle v4_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_0_1)) (bvsle v5_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_1_1)) (bvsle v5_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_0_1)) (bvsle v6_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_1_1)) (bvsle v6_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v7_sint32_0_1)) (bvsle v7_sint32_0_1 #x00007FFF)) (bvsle #x00000000 v3_sint32_2_1)) (bvsle v3_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v3_sint32_3_1)) (bvsle v3_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_2_1)) (bvsle v4_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_3_1)) (bvsle v4_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_2_1)) (bvsle v5_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_3_1)) (bvsle v5_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_2_1)) (bvsle v6_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_3_1)) (bvsle v6_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v7_sint32_2_1)) (bvsle v7_sint32_2_1 #x0000FFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x0000FFFF)) (bvsle #x00000000 v8_sint32_2_2)) (bvsle v8_sint32_2_2 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x0000FFFF)) (= (bvadd (bvmul ((_ zero_extend 240) v3_sint32_0_1) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) v3_sint32_1_1) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_0_1) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_1_1) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_0_1) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_1_1) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_0_1) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_1_1) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) v7_sint32_0_1) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00007FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) (= (bvadd (bvmul ((_ zero_extend 240) v3_sint32_2_1) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) v3_sint32_3_1) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_2_1) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_3_1) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_2_1) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_3_1) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_2_1) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_3_1) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) v7_sint32_2_1) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) ((_ zero_extend 16) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000))))))) (= (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) #x00000000) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00000000000000000000000000000000000000000000000000000000000000000000)) (= (bvadd (bvmul ((_ zero_extend 240) v8_sint32_2_2) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) #x00000000) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00000000000000000000000000000000000000000000000000000000000000000001)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 192) x1_2)) ((_ zero_extend 1) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) ((_ zero_extend 1) #x0000000000000000000000000000000000000000000000001000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 192) x2_6)) ((_ zero_extend 1) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))))) ((_ zero_extend 1) #x0000000000000000000000000000000000000000000000001000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= #x0000000000000001 #x0000000000000001)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 128) (bvadd (bvmul ((_ zero_extend 64) #xFFFFFFFFFFFFFFED) #x00000000000000000000000000000001) (bvmul ((_ zero_extend 64) #xFFFFFFFFFFFFFFFF) #x00000000000000010000000000000000)))) ((_ zero_extend 1) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) ((_ zero_extend 1) #x0000000000000000000000000000000100000000000000000000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 128) (bvadd (bvmul ((_ zero_extend 64) op_x0_0) #x00000000000000000000000000000001) (bvmul ((_ zero_extend 64) op_x1_0) #x00000000000000010000000000000000)))) ((_ zero_extend 1) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))))) ((_ zero_extend 1) #x0000000000000000000000000000000100000000000000000000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= x6_2 #x0000020000100000)))
(assert (= x7_2 (bvand x1_2 #x00000000000FFFFF)))
(assert (= x8_1 (bvand x2_6 #x00000000000FFFFF)))
(assert (= x7_3 (bvor x7_2 #xFFFFFE0000000000)))
(assert (= x8_2 (bvor x8_1 #xC000000000000000)))
(assert (= f_0_low60_0_low20_0_1 (bvand x1_2 #x00000000000FFFFF)))
(assert (= g_0_low60_0_low20_0_1 (bvand x2_6 #x00000000000FFFFF)))
(assert (not (= x8_2 (bvadd (bvadd g_0_low60_0_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_e4f55e.smt2
Execution time of boolector: 0.0221 seconds
OUTPUT FROM boolector:
unsat

=== Cut #1 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #1
; Range specification #4: f_0_low60_0_low20_0_1 <=s 1048575@64
; Range condition: f_0_low60_0_low20_0_1 <=s 1048575
; Output file: /tmp/outputqfbv_723772.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_2 () (_ BitVec 64))
(declare-fun x8_1 () (_ BitVec 64))
(declare-fun x7_3 () (_ BitVec 64))
(declare-fun x7_2 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun g_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_0_1 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (bvsle #x00000000 v3_sint32_0_1) (bvsle v3_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v3_sint32_1_1)) (bvsle v3_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_0_1)) (bvsle v4_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_1_1)) (bvsle v4_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_0_1)) (bvsle v5_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_1_1)) (bvsle v5_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_0_1)) (bvsle v6_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_1_1)) (bvsle v6_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v7_sint32_0_1)) (bvsle v7_sint32_0_1 #x00007FFF)) (bvsle #x00000000 v3_sint32_2_1)) (bvsle v3_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v3_sint32_3_1)) (bvsle v3_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_2_1)) (bvsle v4_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_3_1)) (bvsle v4_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_2_1)) (bvsle v5_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_3_1)) (bvsle v5_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_2_1)) (bvsle v6_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_3_1)) (bvsle v6_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v7_sint32_2_1)) (bvsle v7_sint32_2_1 #x0000FFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x0000FFFF)) (bvsle #x00000000 v8_sint32_2_2)) (bvsle v8_sint32_2_2 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x0000FFFF)) (= (bvadd (bvmul ((_ zero_extend 240) v3_sint32_0_1) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) v3_sint32_1_1) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_0_1) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_1_1) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_0_1) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_1_1) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_0_1) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_1_1) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) v7_sint32_0_1) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00007FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) (= (bvadd (bvmul ((_ zero_extend 240) v3_sint32_2_1) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) v3_sint32_3_1) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_2_1) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_3_1) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_2_1) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_3_1) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_2_1) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_3_1) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) v7_sint32_2_1) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) ((_ zero_extend 16) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000))))))) (= (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) #x00000000) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00000000000000000000000000000000000000000000000000000000000000000000)) (= (bvadd (bvmul ((_ zero_extend 240) v8_sint32_2_2) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) #x00000000) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00000000000000000000000000000000000000000000000000000000000000000001)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 192) x1_2)) ((_ zero_extend 1) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) ((_ zero_extend 1) #x0000000000000000000000000000000000000000000000001000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 192) x2_6)) ((_ zero_extend 1) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))))) ((_ zero_extend 1) #x0000000000000000000000000000000000000000000000001000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= #x0000000000000001 #x0000000000000001)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 128) (bvadd (bvmul ((_ zero_extend 64) #xFFFFFFFFFFFFFFED) #x00000000000000000000000000000001) (bvmul ((_ zero_extend 64) #xFFFFFFFFFFFFFFFF) #x00000000000000010000000000000000)))) ((_ zero_extend 1) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) ((_ zero_extend 1) #x0000000000000000000000000000000100000000000000000000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 128) (bvadd (bvmul ((_ zero_extend 64) op_x0_0) #x00000000000000000000000000000001) (bvmul ((_ zero_extend 64) op_x1_0) #x00000000000000010000000000000000)))) ((_ zero_extend 1) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))))) ((_ zero_extend 1) #x0000000000000000000000000000000100000000000000000000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= x6_2 #x0000020000100000)))
(assert (= x7_2 (bvand x1_2 #x00000000000FFFFF)))
(assert (= x8_1 (bvand x2_6 #x00000000000FFFFF)))
(assert (= x7_3 (bvor x7_2 #xFFFFFE0000000000)))
(assert (= x8_2 (bvor x8_1 #xC000000000000000)))
(assert (= f_0_low60_0_low20_0_1 (bvand x1_2 #x00000000000FFFFF)))
(assert (= g_0_low60_0_low20_0_1 (bvand x2_6 #x00000000000FFFFF)))
(assert (not (bvsle f_0_low60_0_low20_0_1 #x00000000000FFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_9b563a.smt2
Execution time of boolector: 0.0177 seconds
OUTPUT FROM boolector:
unsat

=== Cut #1 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #1
; Range specification #9: (-1048576)@64 = (-1048576)@64
; Range condition: -1048576 = -1048576
; Output file: /tmp/outputqfbv_af83d6.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_2 () (_ BitVec 64))
(declare-fun x8_1 () (_ BitVec 64))
(declare-fun x7_3 () (_ BitVec 64))
(declare-fun x7_2 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun g_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_0_1 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (bvsle #x00000000 v3_sint32_0_1) (bvsle v3_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v3_sint32_1_1)) (bvsle v3_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_0_1)) (bvsle v4_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_1_1)) (bvsle v4_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_0_1)) (bvsle v5_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_1_1)) (bvsle v5_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_0_1)) (bvsle v6_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_1_1)) (bvsle v6_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v7_sint32_0_1)) (bvsle v7_sint32_0_1 #x00007FFF)) (bvsle #x00000000 v3_sint32_2_1)) (bvsle v3_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v3_sint32_3_1)) (bvsle v3_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_2_1)) (bvsle v4_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_3_1)) (bvsle v4_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_2_1)) (bvsle v5_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_3_1)) (bvsle v5_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_2_1)) (bvsle v6_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_3_1)) (bvsle v6_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v7_sint32_2_1)) (bvsle v7_sint32_2_1 #x0000FFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x0000FFFF)) (bvsle #x00000000 v8_sint32_2_2)) (bvsle v8_sint32_2_2 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x0000FFFF)) (= (bvadd (bvmul ((_ zero_extend 240) v3_sint32_0_1) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) v3_sint32_1_1) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_0_1) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_1_1) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_0_1) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_1_1) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_0_1) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_1_1) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) v7_sint32_0_1) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00007FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) (= (bvadd (bvmul ((_ zero_extend 240) v3_sint32_2_1) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) v3_sint32_3_1) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_2_1) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_3_1) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_2_1) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_3_1) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_2_1) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_3_1) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) v7_sint32_2_1) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) ((_ zero_extend 16) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000))))))) (= (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) #x00000000) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00000000000000000000000000000000000000000000000000000000000000000000)) (= (bvadd (bvmul ((_ zero_extend 240) v8_sint32_2_2) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) #x00000000) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00000000000000000000000000000000000000000000000000000000000000000001)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 192) x1_2)) ((_ zero_extend 1) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) ((_ zero_extend 1) #x0000000000000000000000000000000000000000000000001000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 192) x2_6)) ((_ zero_extend 1) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))))) ((_ zero_extend 1) #x0000000000000000000000000000000000000000000000001000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= #x0000000000000001 #x0000000000000001)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 128) (bvadd (bvmul ((_ zero_extend 64) #xFFFFFFFFFFFFFFED) #x00000000000000000000000000000001) (bvmul ((_ zero_extend 64) #xFFFFFFFFFFFFFFFF) #x00000000000000010000000000000000)))) ((_ zero_extend 1) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) ((_ zero_extend 1) #x0000000000000000000000000000000100000000000000000000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 128) (bvadd (bvmul ((_ zero_extend 64) op_x0_0) #x00000000000000000000000000000001) (bvmul ((_ zero_extend 64) op_x1_0) #x00000000000000010000000000000000)))) ((_ zero_extend 1) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))))) ((_ zero_extend 1) #x0000000000000000000000000000000100000000000000000000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= x6_2 #x0000020000100000)))
(assert (= x7_2 (bvand x1_2 #x00000000000FFFFF)))
(assert (= x8_1 (bvand x2_6 #x00000000000FFFFF)))
(assert (= x7_3 (bvor x7_2 #xFFFFFE0000000000)))
(assert (= x8_2 (bvor x8_1 #xC000000000000000)))
(assert (= f_0_low60_0_low20_0_1 (bvand x1_2 #x00000000000FFFFF)))
(assert (= g_0_low60_0_low20_0_1 (bvand x2_6 #x00000000000FFFFF)))
(assert (not (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_d2b270.smt2
Execution time of boolector: 0.0015 seconds
OUTPUT FROM boolector:
unsat

=== Cut #1 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #1
; Range specification #6: g_0_low60_0_low20_0_1 <=s 1048575@64
; Range condition: g_0_low60_0_low20_0_1 <=s 1048575
; Output file: /tmp/outputqfbv_796a28.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_2 () (_ BitVec 64))
(declare-fun x8_1 () (_ BitVec 64))
(declare-fun x7_3 () (_ BitVec 64))
(declare-fun x7_2 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun g_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_0_1 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (bvsle #x00000000 v3_sint32_0_1) (bvsle v3_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v3_sint32_1_1)) (bvsle v3_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_0_1)) (bvsle v4_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_1_1)) (bvsle v4_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_0_1)) (bvsle v5_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_1_1)) (bvsle v5_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_0_1)) (bvsle v6_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_1_1)) (bvsle v6_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v7_sint32_0_1)) (bvsle v7_sint32_0_1 #x00007FFF)) (bvsle #x00000000 v3_sint32_2_1)) (bvsle v3_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v3_sint32_3_1)) (bvsle v3_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_2_1)) (bvsle v4_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_3_1)) (bvsle v4_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_2_1)) (bvsle v5_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_3_1)) (bvsle v5_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_2_1)) (bvsle v6_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_3_1)) (bvsle v6_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v7_sint32_2_1)) (bvsle v7_sint32_2_1 #x0000FFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x0000FFFF)) (bvsle #x00000000 v8_sint32_2_2)) (bvsle v8_sint32_2_2 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x0000FFFF)) (= (bvadd (bvmul ((_ zero_extend 240) v3_sint32_0_1) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) v3_sint32_1_1) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_0_1) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_1_1) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_0_1) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_1_1) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_0_1) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_1_1) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) v7_sint32_0_1) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00007FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) (= (bvadd (bvmul ((_ zero_extend 240) v3_sint32_2_1) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) v3_sint32_3_1) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_2_1) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_3_1) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_2_1) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_3_1) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_2_1) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_3_1) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) v7_sint32_2_1) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) ((_ zero_extend 16) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000))))))) (= (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) #x00000000) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00000000000000000000000000000000000000000000000000000000000000000000)) (= (bvadd (bvmul ((_ zero_extend 240) v8_sint32_2_2) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) #x00000000) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00000000000000000000000000000000000000000000000000000000000000000001)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 192) x1_2)) ((_ zero_extend 1) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) ((_ zero_extend 1) #x0000000000000000000000000000000000000000000000001000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 192) x2_6)) ((_ zero_extend 1) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))))) ((_ zero_extend 1) #x0000000000000000000000000000000000000000000000001000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= #x0000000000000001 #x0000000000000001)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 128) (bvadd (bvmul ((_ zero_extend 64) #xFFFFFFFFFFFFFFED) #x00000000000000000000000000000001) (bvmul ((_ zero_extend 64) #xFFFFFFFFFFFFFFFF) #x00000000000000010000000000000000)))) ((_ zero_extend 1) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) ((_ zero_extend 1) #x0000000000000000000000000000000100000000000000000000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 128) (bvadd (bvmul ((_ zero_extend 64) op_x0_0) #x00000000000000000000000000000001) (bvmul ((_ zero_extend 64) op_x1_0) #x00000000000000010000000000000000)))) ((_ zero_extend 1) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))))) ((_ zero_extend 1) #x0000000000000000000000000000000100000000000000000000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= x6_2 #x0000020000100000)))
(assert (= x7_2 (bvand x1_2 #x00000000000FFFFF)))
(assert (= x8_1 (bvand x2_6 #x00000000000FFFFF)))
(assert (= x7_3 (bvor x7_2 #xFFFFFE0000000000)))
(assert (= x8_2 (bvor x8_1 #xC000000000000000)))
(assert (= f_0_low60_0_low20_0_1 (bvand x1_2 #x00000000000FFFFF)))
(assert (= g_0_low60_0_low20_0_1 (bvand x2_6 #x00000000000FFFFF)))
(assert (not (bvsle g_0_low60_0_low20_0_1 #x00000000000FFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_f7fcf1.smt2
Execution time of boolector: 0.0169 seconds
OUTPUT FROM boolector:
unsat

=== Cut #1 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #1
; Range specification #10: 0@64 = 0@64
; Range condition: 0 = 0
; Output file: /tmp/outputqfbv_359a26.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_2 () (_ BitVec 64))
(declare-fun x8_1 () (_ BitVec 64))
(declare-fun x7_3 () (_ BitVec 64))
(declare-fun x7_2 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun g_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_0_1 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (bvsle #x00000000 v3_sint32_0_1) (bvsle v3_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v3_sint32_1_1)) (bvsle v3_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_0_1)) (bvsle v4_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_1_1)) (bvsle v4_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_0_1)) (bvsle v5_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_1_1)) (bvsle v5_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_0_1)) (bvsle v6_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_1_1)) (bvsle v6_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v7_sint32_0_1)) (bvsle v7_sint32_0_1 #x00007FFF)) (bvsle #x00000000 v3_sint32_2_1)) (bvsle v3_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v3_sint32_3_1)) (bvsle v3_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_2_1)) (bvsle v4_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_3_1)) (bvsle v4_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_2_1)) (bvsle v5_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_3_1)) (bvsle v5_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_2_1)) (bvsle v6_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_3_1)) (bvsle v6_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v7_sint32_2_1)) (bvsle v7_sint32_2_1 #x0000FFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x0000FFFF)) (bvsle #x00000000 v8_sint32_2_2)) (bvsle v8_sint32_2_2 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x0000FFFF)) (= (bvadd (bvmul ((_ zero_extend 240) v3_sint32_0_1) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) v3_sint32_1_1) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_0_1) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_1_1) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_0_1) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_1_1) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_0_1) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_1_1) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) v7_sint32_0_1) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00007FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) (= (bvadd (bvmul ((_ zero_extend 240) v3_sint32_2_1) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) v3_sint32_3_1) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_2_1) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_3_1) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_2_1) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_3_1) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_2_1) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_3_1) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) v7_sint32_2_1) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) ((_ zero_extend 16) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000))))))) (= (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) #x00000000) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00000000000000000000000000000000000000000000000000000000000000000000)) (= (bvadd (bvmul ((_ zero_extend 240) v8_sint32_2_2) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) #x00000000) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00000000000000000000000000000000000000000000000000000000000000000001)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 192) x1_2)) ((_ zero_extend 1) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) ((_ zero_extend 1) #x0000000000000000000000000000000000000000000000001000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 192) x2_6)) ((_ zero_extend 1) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))))) ((_ zero_extend 1) #x0000000000000000000000000000000000000000000000001000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= #x0000000000000001 #x0000000000000001)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 128) (bvadd (bvmul ((_ zero_extend 64) #xFFFFFFFFFFFFFFED) #x00000000000000000000000000000001) (bvmul ((_ zero_extend 64) #xFFFFFFFFFFFFFFFF) #x00000000000000010000000000000000)))) ((_ zero_extend 1) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) ((_ zero_extend 1) #x0000000000000000000000000000000100000000000000000000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 128) (bvadd (bvmul ((_ zero_extend 64) op_x0_0) #x00000000000000000000000000000001) (bvmul ((_ zero_extend 64) op_x1_0) #x00000000000000010000000000000000)))) ((_ zero_extend 1) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))))) ((_ zero_extend 1) #x0000000000000000000000000000000100000000000000000000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= x6_2 #x0000020000100000)))
(assert (= x7_2 (bvand x1_2 #x00000000000FFFFF)))
(assert (= x8_1 (bvand x2_6 #x00000000000FFFFF)))
(assert (= x7_3 (bvor x7_2 #xFFFFFE0000000000)))
(assert (= x8_2 (bvor x8_1 #xC000000000000000)))
(assert (= f_0_low60_0_low20_0_1 (bvand x1_2 #x00000000000FFFFF)))
(assert (= g_0_low60_0_low20_0_1 (bvand x2_6 #x00000000000FFFFF)))
(assert (not (= #x0000000000000000 #x0000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_5c862b.smt2
Execution time of boolector: 0.0013 seconds
OUTPUT FROM boolector:
unsat

=== Cut #1 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #1
; Range specification #11: 0@64 = 0@64
; Range condition: 0 = 0
; Output file: /tmp/outputqfbv_a4d863.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_2 () (_ BitVec 64))
(declare-fun x8_1 () (_ BitVec 64))
(declare-fun x7_3 () (_ BitVec 64))
(declare-fun x7_2 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun g_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_0_1 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (bvsle #x00000000 v3_sint32_0_1) (bvsle v3_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v3_sint32_1_1)) (bvsle v3_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_0_1)) (bvsle v4_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_1_1)) (bvsle v4_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_0_1)) (bvsle v5_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_1_1)) (bvsle v5_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_0_1)) (bvsle v6_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_1_1)) (bvsle v6_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v7_sint32_0_1)) (bvsle v7_sint32_0_1 #x00007FFF)) (bvsle #x00000000 v3_sint32_2_1)) (bvsle v3_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v3_sint32_3_1)) (bvsle v3_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_2_1)) (bvsle v4_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_3_1)) (bvsle v4_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_2_1)) (bvsle v5_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_3_1)) (bvsle v5_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_2_1)) (bvsle v6_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_3_1)) (bvsle v6_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v7_sint32_2_1)) (bvsle v7_sint32_2_1 #x0000FFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x0000FFFF)) (bvsle #x00000000 v8_sint32_2_2)) (bvsle v8_sint32_2_2 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x0000FFFF)) (= (bvadd (bvmul ((_ zero_extend 240) v3_sint32_0_1) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) v3_sint32_1_1) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_0_1) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_1_1) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_0_1) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_1_1) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_0_1) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_1_1) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) v7_sint32_0_1) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00007FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) (= (bvadd (bvmul ((_ zero_extend 240) v3_sint32_2_1) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) v3_sint32_3_1) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_2_1) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_3_1) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_2_1) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_3_1) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_2_1) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_3_1) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) v7_sint32_2_1) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) ((_ zero_extend 16) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000))))))) (= (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) #x00000000) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00000000000000000000000000000000000000000000000000000000000000000000)) (= (bvadd (bvmul ((_ zero_extend 240) v8_sint32_2_2) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) #x00000000) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00000000000000000000000000000000000000000000000000000000000000000001)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 192) x1_2)) ((_ zero_extend 1) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) ((_ zero_extend 1) #x0000000000000000000000000000000000000000000000001000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 192) x2_6)) ((_ zero_extend 1) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))))) ((_ zero_extend 1) #x0000000000000000000000000000000000000000000000001000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= #x0000000000000001 #x0000000000000001)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 128) (bvadd (bvmul ((_ zero_extend 64) #xFFFFFFFFFFFFFFED) #x00000000000000000000000000000001) (bvmul ((_ zero_extend 64) #xFFFFFFFFFFFFFFFF) #x00000000000000010000000000000000)))) ((_ zero_extend 1) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) ((_ zero_extend 1) #x0000000000000000000000000000000100000000000000000000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 128) (bvadd (bvmul ((_ zero_extend 64) op_x0_0) #x00000000000000000000000000000001) (bvmul ((_ zero_extend 64) op_x1_0) #x00000000000000010000000000000000)))) ((_ zero_extend 1) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))))) ((_ zero_extend 1) #x0000000000000000000000000000000100000000000000000000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= x6_2 #x0000020000100000)))
(assert (= x7_2 (bvand x1_2 #x00000000000FFFFF)))
(assert (= x8_1 (bvand x2_6 #x00000000000FFFFF)))
(assert (= x7_3 (bvor x7_2 #xFFFFFE0000000000)))
(assert (= x8_2 (bvor x8_1 #xC000000000000000)))
(assert (= f_0_low60_0_low20_0_1 (bvand x1_2 #x00000000000FFFFF)))
(assert (= g_0_low60_0_low20_0_1 (bvand x2_6 #x00000000000FFFFF)))
(assert (not (= #x0000000000000000 #x0000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_26b48c.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #1 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #1
; Range specification #12: (-1048576)@64 = (-1048576)@64
; Range condition: -1048576 = -1048576
; Output file: /tmp/outputqfbv_ed216a.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_2 () (_ BitVec 64))
(declare-fun x8_1 () (_ BitVec 64))
(declare-fun x7_3 () (_ BitVec 64))
(declare-fun x7_2 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun g_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_0_1 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (bvsle #x00000000 v3_sint32_0_1) (bvsle v3_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v3_sint32_1_1)) (bvsle v3_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_0_1)) (bvsle v4_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_1_1)) (bvsle v4_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_0_1)) (bvsle v5_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_1_1)) (bvsle v5_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_0_1)) (bvsle v6_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_1_1)) (bvsle v6_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v7_sint32_0_1)) (bvsle v7_sint32_0_1 #x00007FFF)) (bvsle #x00000000 v3_sint32_2_1)) (bvsle v3_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v3_sint32_3_1)) (bvsle v3_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_2_1)) (bvsle v4_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_3_1)) (bvsle v4_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_2_1)) (bvsle v5_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_3_1)) (bvsle v5_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_2_1)) (bvsle v6_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_3_1)) (bvsle v6_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v7_sint32_2_1)) (bvsle v7_sint32_2_1 #x0000FFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x0000FFFF)) (bvsle #x00000000 v8_sint32_2_2)) (bvsle v8_sint32_2_2 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x0000FFFF)) (= (bvadd (bvmul ((_ zero_extend 240) v3_sint32_0_1) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) v3_sint32_1_1) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_0_1) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_1_1) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_0_1) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_1_1) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_0_1) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_1_1) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) v7_sint32_0_1) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00007FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) (= (bvadd (bvmul ((_ zero_extend 240) v3_sint32_2_1) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) v3_sint32_3_1) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_2_1) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_3_1) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_2_1) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_3_1) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_2_1) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_3_1) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) v7_sint32_2_1) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) ((_ zero_extend 16) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000))))))) (= (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) #x00000000) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00000000000000000000000000000000000000000000000000000000000000000000)) (= (bvadd (bvmul ((_ zero_extend 240) v8_sint32_2_2) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) #x00000000) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00000000000000000000000000000000000000000000000000000000000000000001)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 192) x1_2)) ((_ zero_extend 1) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) ((_ zero_extend 1) #x0000000000000000000000000000000000000000000000001000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 192) x2_6)) ((_ zero_extend 1) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))))) ((_ zero_extend 1) #x0000000000000000000000000000000000000000000000001000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= #x0000000000000001 #x0000000000000001)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 128) (bvadd (bvmul ((_ zero_extend 64) #xFFFFFFFFFFFFFFED) #x00000000000000000000000000000001) (bvmul ((_ zero_extend 64) #xFFFFFFFFFFFFFFFF) #x00000000000000010000000000000000)))) ((_ zero_extend 1) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) ((_ zero_extend 1) #x0000000000000000000000000000000100000000000000000000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 128) (bvadd (bvmul ((_ zero_extend 64) op_x0_0) #x00000000000000000000000000000001) (bvmul ((_ zero_extend 64) op_x1_0) #x00000000000000010000000000000000)))) ((_ zero_extend 1) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))))) ((_ zero_extend 1) #x0000000000000000000000000000000100000000000000000000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= x6_2 #x0000020000100000)))
(assert (= x7_2 (bvand x1_2 #x00000000000FFFFF)))
(assert (= x8_1 (bvand x2_6 #x00000000000FFFFF)))
(assert (= x7_3 (bvor x7_2 #xFFFFFE0000000000)))
(assert (= x8_2 (bvor x8_1 #xC000000000000000)))
(assert (= f_0_low60_0_low20_0_1 (bvand x1_2 #x00000000000FFFFF)))
(assert (= g_0_low60_0_low20_0_1 (bvand x2_6 #x00000000000FFFFF)))
(assert (not (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_90987d.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #3 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #3
; Range specification #45: (-1048576)@64 <=s x11_5
; Range condition: -1048576 <=s x11_5
; Output file: /tmp/outputqfbv_f4a476.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_42 () (_ BitVec 64))
(declare-fun x7_23 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x14_3 () (_ BitVec 64))
(declare-fun x14_2 () (_ BitVec 64))
(declare-fun x14_1 () (_ BitVec 64))
(declare-fun x13_5 () (_ BitVec 64))
(declare-fun x13_4 () (_ BitVec 64))
(declare-fun x13_3 () (_ BitVec 64))
(declare-fun x13_2 () (_ BitVec 64))
(declare-fun x13_1 () (_ BitVec 64))
(declare-fun x12_3 () (_ BitVec 64))
(declare-fun x12_2 () (_ BitVec 64))
(declare-fun x12_1 () (_ BitVec 64))
(declare-fun x11_5 () (_ BitVec 64))
(declare-fun x11_4 () (_ BitVec 64))
(declare-fun x11_3 () (_ BitVec 64))
(declare-fun x11_2 () (_ BitVec 64))
(declare-fun x11_1 () (_ BitVec 64))
(declare-fun v_0_20_2 () (_ BitVec 64))
(declare-fun u_0_20_2 () (_ BitVec 64))
(declare-fun s_0_20_2 () (_ BitVec 64))
(declare-fun r_0_20_2 () (_ BitVec 64))
(declare-fun g_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun dcH_2 () (_ BitVec 64))
(declare-fun dcH_1 () (_ BitVec 64))
(declare-fun dc_183 () (_ BitVec 64))
(declare-fun dc_182 () (_ BitVec 64))
(declare-fun dc_181 () (_ BitVec 64))
(declare-fun dc_180 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_23 (bvadd (bvadd f_0_low60_0_low20_20_1 (bvmul u_0_20_2 #x0000000000200000)) (bvmul v_0_20_2 #x0000040000000000))) (= x8_42 (bvadd (bvadd g_0_low60_0_low20_20_1 (bvmul r_0_20_2 #x0000000000200000)) (bvmul s_0_20_2 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_20_1)) (bvsle f_0_low60_0_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_20_1)) (bvsle g_0_low60_0_low20_20_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) f_0_low60_20_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (bvsle #xFFFFFFFFFFF00000 u_0_20_2)) (bvsle u_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 v_0_20_2)) (bvsle v_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 r_0_20_2)) (bvsle r_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 s_0_20_2)) (bvsle s_0_20_2 #x00000000000FFFFF)) (bvsle (bvadd u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvsub u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvadd r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvsub r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (= x6_2 #x0000020000100000)))
(assert (= x12_1 (bvadd x7_23 x6_2)))
(assert (= x12_2 x12_1))
(assert (and (= x12_3 ((_ sign_extend 42) ((_ extract 63 42) x12_2))) (= dc_180 ((_ zero_extend 22) ((_ extract 41 0) x12_2)))))
(assert (= x11_1 (bvadd x7_23 #x0000000000100000)))
(assert (and (= dcH_1 ((_ sign_extend 42) ((_ extract 63 42) x11_1))) (= x11_2 ((_ zero_extend 22) ((_ extract 41 0) x11_1)))))
(assert (= x11_3 (bvshl x11_2 #x0000000000000016)))
(assert (= x11_4 x11_3))
(assert (and (= x11_5 ((_ sign_extend 43) ((_ extract 63 43) x11_4))) (= dc_181 ((_ zero_extend 21) ((_ extract 42 0) x11_4)))))
(assert (= x14_1 (bvadd x8_42 x6_2)))
(assert (= x14_2 x14_1))
(assert (and (= x14_3 ((_ sign_extend 42) ((_ extract 63 42) x14_2))) (= dc_182 ((_ zero_extend 22) ((_ extract 41 0) x14_2)))))
(assert (= x13_1 (bvadd x8_42 #x0000000000100000)))
(assert (and (= dcH_2 ((_ sign_extend 42) ((_ extract 63 42) x13_1))) (= x13_2 ((_ zero_extend 22) ((_ extract 41 0) x13_1)))))
(assert (= x13_3 (bvshl x13_2 #x0000000000000016)))
(assert (= x13_4 x13_3))
(assert (and (= x13_5 ((_ sign_extend 43) ((_ extract 63 43) x13_4))) (= dc_183 ((_ zero_extend 21) ((_ extract 42 0) x13_4)))))
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert (not (bvsle #xFFFFFFFFFFF00000 x11_5)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_1cb425.smt2
Execution time of boolector: 0.0052 seconds
OUTPUT FROM boolector:
unsat

=== Cut #3 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #3
; Range specification #46: x11_5 <=s 1048575@64
; Range condition: x11_5 <=s 1048575
; Output file: /tmp/outputqfbv_6510e1.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_42 () (_ BitVec 64))
(declare-fun x7_23 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x14_3 () (_ BitVec 64))
(declare-fun x14_2 () (_ BitVec 64))
(declare-fun x14_1 () (_ BitVec 64))
(declare-fun x13_5 () (_ BitVec 64))
(declare-fun x13_4 () (_ BitVec 64))
(declare-fun x13_3 () (_ BitVec 64))
(declare-fun x13_2 () (_ BitVec 64))
(declare-fun x13_1 () (_ BitVec 64))
(declare-fun x12_3 () (_ BitVec 64))
(declare-fun x12_2 () (_ BitVec 64))
(declare-fun x12_1 () (_ BitVec 64))
(declare-fun x11_5 () (_ BitVec 64))
(declare-fun x11_4 () (_ BitVec 64))
(declare-fun x11_3 () (_ BitVec 64))
(declare-fun x11_2 () (_ BitVec 64))
(declare-fun x11_1 () (_ BitVec 64))
(declare-fun v_0_20_2 () (_ BitVec 64))
(declare-fun u_0_20_2 () (_ BitVec 64))
(declare-fun s_0_20_2 () (_ BitVec 64))
(declare-fun r_0_20_2 () (_ BitVec 64))
(declare-fun g_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun dcH_2 () (_ BitVec 64))
(declare-fun dcH_1 () (_ BitVec 64))
(declare-fun dc_183 () (_ BitVec 64))
(declare-fun dc_182 () (_ BitVec 64))
(declare-fun dc_181 () (_ BitVec 64))
(declare-fun dc_180 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_23 (bvadd (bvadd f_0_low60_0_low20_20_1 (bvmul u_0_20_2 #x0000000000200000)) (bvmul v_0_20_2 #x0000040000000000))) (= x8_42 (bvadd (bvadd g_0_low60_0_low20_20_1 (bvmul r_0_20_2 #x0000000000200000)) (bvmul s_0_20_2 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_20_1)) (bvsle f_0_low60_0_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_20_1)) (bvsle g_0_low60_0_low20_20_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) f_0_low60_20_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (bvsle #xFFFFFFFFFFF00000 u_0_20_2)) (bvsle u_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 v_0_20_2)) (bvsle v_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 r_0_20_2)) (bvsle r_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 s_0_20_2)) (bvsle s_0_20_2 #x00000000000FFFFF)) (bvsle (bvadd u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvsub u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvadd r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvsub r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (= x6_2 #x0000020000100000)))
(assert (= x12_1 (bvadd x7_23 x6_2)))
(assert (= x12_2 x12_1))
(assert (and (= x12_3 ((_ sign_extend 42) ((_ extract 63 42) x12_2))) (= dc_180 ((_ zero_extend 22) ((_ extract 41 0) x12_2)))))
(assert (= x11_1 (bvadd x7_23 #x0000000000100000)))
(assert (and (= dcH_1 ((_ sign_extend 42) ((_ extract 63 42) x11_1))) (= x11_2 ((_ zero_extend 22) ((_ extract 41 0) x11_1)))))
(assert (= x11_3 (bvshl x11_2 #x0000000000000016)))
(assert (= x11_4 x11_3))
(assert (and (= x11_5 ((_ sign_extend 43) ((_ extract 63 43) x11_4))) (= dc_181 ((_ zero_extend 21) ((_ extract 42 0) x11_4)))))
(assert (= x14_1 (bvadd x8_42 x6_2)))
(assert (= x14_2 x14_1))
(assert (and (= x14_3 ((_ sign_extend 42) ((_ extract 63 42) x14_2))) (= dc_182 ((_ zero_extend 22) ((_ extract 41 0) x14_2)))))
(assert (= x13_1 (bvadd x8_42 #x0000000000100000)))
(assert (and (= dcH_2 ((_ sign_extend 42) ((_ extract 63 42) x13_1))) (= x13_2 ((_ zero_extend 22) ((_ extract 41 0) x13_1)))))
(assert (= x13_3 (bvshl x13_2 #x0000000000000016)))
(assert (= x13_4 x13_3))
(assert (and (= x13_5 ((_ sign_extend 43) ((_ extract 63 43) x13_4))) (= dc_183 ((_ zero_extend 21) ((_ extract 42 0) x13_4)))))
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert (not (bvsle x11_5 #x00000000000FFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_81e0a4.smt2
Execution time of boolector: 0.0051 seconds
OUTPUT FROM boolector:
unsat

=== Cut #3 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #3
; Range specification #47: (-1048576)@64 <=s x12_3
; Range condition: -1048576 <=s x12_3
; Output file: /tmp/outputqfbv_9c6450.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_42 () (_ BitVec 64))
(declare-fun x7_23 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x14_3 () (_ BitVec 64))
(declare-fun x14_2 () (_ BitVec 64))
(declare-fun x14_1 () (_ BitVec 64))
(declare-fun x13_5 () (_ BitVec 64))
(declare-fun x13_4 () (_ BitVec 64))
(declare-fun x13_3 () (_ BitVec 64))
(declare-fun x13_2 () (_ BitVec 64))
(declare-fun x13_1 () (_ BitVec 64))
(declare-fun x12_3 () (_ BitVec 64))
(declare-fun x12_2 () (_ BitVec 64))
(declare-fun x12_1 () (_ BitVec 64))
(declare-fun x11_5 () (_ BitVec 64))
(declare-fun x11_4 () (_ BitVec 64))
(declare-fun x11_3 () (_ BitVec 64))
(declare-fun x11_2 () (_ BitVec 64))
(declare-fun x11_1 () (_ BitVec 64))
(declare-fun v_0_20_2 () (_ BitVec 64))
(declare-fun u_0_20_2 () (_ BitVec 64))
(declare-fun s_0_20_2 () (_ BitVec 64))
(declare-fun r_0_20_2 () (_ BitVec 64))
(declare-fun g_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun dcH_2 () (_ BitVec 64))
(declare-fun dcH_1 () (_ BitVec 64))
(declare-fun dc_183 () (_ BitVec 64))
(declare-fun dc_182 () (_ BitVec 64))
(declare-fun dc_181 () (_ BitVec 64))
(declare-fun dc_180 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_23 (bvadd (bvadd f_0_low60_0_low20_20_1 (bvmul u_0_20_2 #x0000000000200000)) (bvmul v_0_20_2 #x0000040000000000))) (= x8_42 (bvadd (bvadd g_0_low60_0_low20_20_1 (bvmul r_0_20_2 #x0000000000200000)) (bvmul s_0_20_2 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_20_1)) (bvsle f_0_low60_0_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_20_1)) (bvsle g_0_low60_0_low20_20_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) f_0_low60_20_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (bvsle #xFFFFFFFFFFF00000 u_0_20_2)) (bvsle u_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 v_0_20_2)) (bvsle v_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 r_0_20_2)) (bvsle r_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 s_0_20_2)) (bvsle s_0_20_2 #x00000000000FFFFF)) (bvsle (bvadd u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvsub u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvadd r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvsub r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (= x6_2 #x0000020000100000)))
(assert (= x12_1 (bvadd x7_23 x6_2)))
(assert (= x12_2 x12_1))
(assert (and (= x12_3 ((_ sign_extend 42) ((_ extract 63 42) x12_2))) (= dc_180 ((_ zero_extend 22) ((_ extract 41 0) x12_2)))))
(assert (= x11_1 (bvadd x7_23 #x0000000000100000)))
(assert (and (= dcH_1 ((_ sign_extend 42) ((_ extract 63 42) x11_1))) (= x11_2 ((_ zero_extend 22) ((_ extract 41 0) x11_1)))))
(assert (= x11_3 (bvshl x11_2 #x0000000000000016)))
(assert (= x11_4 x11_3))
(assert (and (= x11_5 ((_ sign_extend 43) ((_ extract 63 43) x11_4))) (= dc_181 ((_ zero_extend 21) ((_ extract 42 0) x11_4)))))
(assert (= x14_1 (bvadd x8_42 x6_2)))
(assert (= x14_2 x14_1))
(assert (and (= x14_3 ((_ sign_extend 42) ((_ extract 63 42) x14_2))) (= dc_182 ((_ zero_extend 22) ((_ extract 41 0) x14_2)))))
(assert (= x13_1 (bvadd x8_42 #x0000000000100000)))
(assert (and (= dcH_2 ((_ sign_extend 42) ((_ extract 63 42) x13_1))) (= x13_2 ((_ zero_extend 22) ((_ extract 41 0) x13_1)))))
(assert (= x13_3 (bvshl x13_2 #x0000000000000016)))
(assert (= x13_4 x13_3))
(assert (and (= x13_5 ((_ sign_extend 43) ((_ extract 63 43) x13_4))) (= dc_183 ((_ zero_extend 21) ((_ extract 42 0) x13_4)))))
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert (not (bvsle #xFFFFFFFFFFF00000 x12_3)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_0d0bef.smt2
Execution time of boolector: 0.0068 seconds
OUTPUT FROM boolector:
unsat

=== Cut #1 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #1
; Range specification #7: smod (sub (uext x7_3 1) (uext 1@64 1)) (uext 2@64 1) = 0@65
; Range condition: ((x7_3@e1) - (1@e1)) smod (2@e1) = 0
; Output file: /tmp/outputqfbv_2d73c6.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_2 () (_ BitVec 64))
(declare-fun x8_1 () (_ BitVec 64))
(declare-fun x7_3 () (_ BitVec 64))
(declare-fun x7_2 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun v8_sint32_2_2 () (_ BitVec 32))
(declare-fun v7_sint32_2_1 () (_ BitVec 32))
(declare-fun v7_sint32_0_1 () (_ BitVec 32))
(declare-fun v6_sint32_3_1 () (_ BitVec 32))
(declare-fun v6_sint32_2_1 () (_ BitVec 32))
(declare-fun v6_sint32_1_1 () (_ BitVec 32))
(declare-fun v6_sint32_0_1 () (_ BitVec 32))
(declare-fun v5_sint32_3_1 () (_ BitVec 32))
(declare-fun v5_sint32_2_1 () (_ BitVec 32))
(declare-fun v5_sint32_1_1 () (_ BitVec 32))
(declare-fun v5_sint32_0_1 () (_ BitVec 32))
(declare-fun v4_sint32_3_1 () (_ BitVec 32))
(declare-fun v4_sint32_2_1 () (_ BitVec 32))
(declare-fun v4_sint32_1_1 () (_ BitVec 32))
(declare-fun v4_sint32_0_1 () (_ BitVec 32))
(declare-fun v3_sint32_3_1 () (_ BitVec 32))
(declare-fun v3_sint32_2_1 () (_ BitVec 32))
(declare-fun v3_sint32_1_1 () (_ BitVec 32))
(declare-fun v3_sint32_0_1 () (_ BitVec 32))
(declare-fun op_x3_0 () (_ BitVec 64))
(declare-fun op_x2_0 () (_ BitVec 64))
(declare-fun op_x1_0 () (_ BitVec 64))
(declare-fun op_x0_0 () (_ BitVec 64))
(declare-fun g_0_low60_0_low20_0_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_0_1 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (bvsle #x00000000 v3_sint32_0_1) (bvsle v3_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v3_sint32_1_1)) (bvsle v3_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_0_1)) (bvsle v4_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_1_1)) (bvsle v4_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_0_1)) (bvsle v5_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_1_1)) (bvsle v5_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_0_1)) (bvsle v6_sint32_0_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_1_1)) (bvsle v6_sint32_1_1 #x3FFFFFFF)) (bvsle #x00000000 v7_sint32_0_1)) (bvsle v7_sint32_0_1 #x00007FFF)) (bvsle #x00000000 v3_sint32_2_1)) (bvsle v3_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v3_sint32_3_1)) (bvsle v3_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_2_1)) (bvsle v4_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v4_sint32_3_1)) (bvsle v4_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_2_1)) (bvsle v5_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v5_sint32_3_1)) (bvsle v5_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_2_1)) (bvsle v6_sint32_2_1 #x3FFFFFFF)) (bvsle #x00000000 v6_sint32_3_1)) (bvsle v6_sint32_3_1 #x3FFFFFFF)) (bvsle #x00000000 v7_sint32_2_1)) (bvsle v7_sint32_2_1 #x0000FFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x0000FFFF)) (bvsle #x00000000 v8_sint32_2_2)) (bvsle v8_sint32_2_2 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x3FFFFFFF)) (bvsle #x00000000 #x00000000)) (bvsle #x00000000 #x0000FFFF)) (= (bvadd (bvmul ((_ zero_extend 240) v3_sint32_0_1) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) v3_sint32_1_1) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_0_1) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_1_1) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_0_1) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_1_1) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_0_1) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_1_1) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) v7_sint32_0_1) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00007FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) (= (bvadd (bvmul ((_ zero_extend 240) v3_sint32_2_1) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) v3_sint32_3_1) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_2_1) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) v4_sint32_3_1) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_2_1) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v5_sint32_3_1) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_2_1) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) v6_sint32_3_1) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) v7_sint32_2_1) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) ((_ zero_extend 16) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000))))))) (= (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) #x00000000) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00000000000000000000000000000000000000000000000000000000000000000000)) (= (bvadd (bvmul ((_ zero_extend 240) v8_sint32_2_2) #x00000000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000000000000040000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000000000001000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000000000000040000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000000000001000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000000000000040000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000000000001000000000000000000000000000000000000000000000) (bvadd (bvmul ((_ zero_extend 240) #x00000000) #x00000000000000040000000000000000000000000000000000000000000000000000) (bvmul ((_ sign_extend 240) #x00000000) #x00000001000000000000000000000000000000000000000000000000000000000000))))))))) #x00000000000000000000000000000000000000000000000000000000000000000001)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 192) x1_2)) ((_ zero_extend 1) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) ((_ zero_extend 1) #x0000000000000000000000000000000000000000000000001000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 192) x2_6)) ((_ zero_extend 1) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))))) ((_ zero_extend 1) #x0000000000000000000000000000000000000000000000001000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= #x0000000000000001 #x0000000000000001)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 128) (bvadd (bvmul ((_ zero_extend 64) #xFFFFFFFFFFFFFFED) #x00000000000000000000000000000001) (bvmul ((_ zero_extend 64) #xFFFFFFFFFFFFFFFF) #x00000000000000010000000000000000)))) ((_ zero_extend 1) #x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFED)) ((_ zero_extend 1) #x0000000000000000000000000000000100000000000000000000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) ((_ zero_extend 128) (bvadd (bvmul ((_ zero_extend 64) op_x0_0) #x00000000000000000000000000000001) (bvmul ((_ zero_extend 64) op_x1_0) #x00000000000000010000000000000000)))) ((_ zero_extend 1) (bvadd (bvmul ((_ zero_extend 192) op_x0_0) #x0000000000000000000000000000000000000000000000000000000000000001) (bvadd (bvmul ((_ zero_extend 192) op_x1_0) #x0000000000000000000000000000000000000000000000010000000000000000) (bvadd (bvmul ((_ zero_extend 192) op_x2_0) #x0000000000000000000000000000000100000000000000000000000000000000) (bvmul ((_ zero_extend 192) op_x3_0) #x0000000000000001000000000000000000000000000000000000000000000000)))))) ((_ zero_extend 1) #x0000000000000000000000000000000100000000000000000000000000000000)) #b00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)) (= x6_2 #x0000020000100000)))
(assert (= x7_2 (bvand x1_2 #x00000000000FFFFF)))
(assert (= x8_1 (bvand x2_6 #x00000000000FFFFF)))
(assert (= x7_3 (bvor x7_2 #xFFFFFE0000000000)))
(assert (= x8_2 (bvor x8_1 #xC000000000000000)))
(assert (= f_0_low60_0_low20_0_1 (bvand x1_2 #x00000000000FFFFF)))
(assert (= g_0_low60_0_low20_0_1 (bvand x2_6 #x00000000000FFFFF)))
(assert (not (= (bvsmod (bvsub ((_ zero_extend 1) x7_3) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_bd3ce6.smt2
Execution time of boolector: 0.0467 seconds
OUTPUT FROM boolector:
unsat

=== Cut #3 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #3
; Range specification #48: x12_3 <=s 1048575@64
; Range condition: x12_3 <=s 1048575
; Output file: /tmp/outputqfbv_871cc0.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_42 () (_ BitVec 64))
(declare-fun x7_23 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x14_3 () (_ BitVec 64))
(declare-fun x14_2 () (_ BitVec 64))
(declare-fun x14_1 () (_ BitVec 64))
(declare-fun x13_5 () (_ BitVec 64))
(declare-fun x13_4 () (_ BitVec 64))
(declare-fun x13_3 () (_ BitVec 64))
(declare-fun x13_2 () (_ BitVec 64))
(declare-fun x13_1 () (_ BitVec 64))
(declare-fun x12_3 () (_ BitVec 64))
(declare-fun x12_2 () (_ BitVec 64))
(declare-fun x12_1 () (_ BitVec 64))
(declare-fun x11_5 () (_ BitVec 64))
(declare-fun x11_4 () (_ BitVec 64))
(declare-fun x11_3 () (_ BitVec 64))
(declare-fun x11_2 () (_ BitVec 64))
(declare-fun x11_1 () (_ BitVec 64))
(declare-fun v_0_20_2 () (_ BitVec 64))
(declare-fun u_0_20_2 () (_ BitVec 64))
(declare-fun s_0_20_2 () (_ BitVec 64))
(declare-fun r_0_20_2 () (_ BitVec 64))
(declare-fun g_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun dcH_2 () (_ BitVec 64))
(declare-fun dcH_1 () (_ BitVec 64))
(declare-fun dc_183 () (_ BitVec 64))
(declare-fun dc_182 () (_ BitVec 64))
(declare-fun dc_181 () (_ BitVec 64))
(declare-fun dc_180 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_23 (bvadd (bvadd f_0_low60_0_low20_20_1 (bvmul u_0_20_2 #x0000000000200000)) (bvmul v_0_20_2 #x0000040000000000))) (= x8_42 (bvadd (bvadd g_0_low60_0_low20_20_1 (bvmul r_0_20_2 #x0000000000200000)) (bvmul s_0_20_2 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_20_1)) (bvsle f_0_low60_0_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_20_1)) (bvsle g_0_low60_0_low20_20_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) f_0_low60_20_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (bvsle #xFFFFFFFFFFF00000 u_0_20_2)) (bvsle u_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 v_0_20_2)) (bvsle v_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 r_0_20_2)) (bvsle r_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 s_0_20_2)) (bvsle s_0_20_2 #x00000000000FFFFF)) (bvsle (bvadd u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvsub u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvadd r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvsub r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (= x6_2 #x0000020000100000)))
(assert (= x12_1 (bvadd x7_23 x6_2)))
(assert (= x12_2 x12_1))
(assert (and (= x12_3 ((_ sign_extend 42) ((_ extract 63 42) x12_2))) (= dc_180 ((_ zero_extend 22) ((_ extract 41 0) x12_2)))))
(assert (= x11_1 (bvadd x7_23 #x0000000000100000)))
(assert (and (= dcH_1 ((_ sign_extend 42) ((_ extract 63 42) x11_1))) (= x11_2 ((_ zero_extend 22) ((_ extract 41 0) x11_1)))))
(assert (= x11_3 (bvshl x11_2 #x0000000000000016)))
(assert (= x11_4 x11_3))
(assert (and (= x11_5 ((_ sign_extend 43) ((_ extract 63 43) x11_4))) (= dc_181 ((_ zero_extend 21) ((_ extract 42 0) x11_4)))))
(assert (= x14_1 (bvadd x8_42 x6_2)))
(assert (= x14_2 x14_1))
(assert (and (= x14_3 ((_ sign_extend 42) ((_ extract 63 42) x14_2))) (= dc_182 ((_ zero_extend 22) ((_ extract 41 0) x14_2)))))
(assert (= x13_1 (bvadd x8_42 #x0000000000100000)))
(assert (and (= dcH_2 ((_ sign_extend 42) ((_ extract 63 42) x13_1))) (= x13_2 ((_ zero_extend 22) ((_ extract 41 0) x13_1)))))
(assert (= x13_3 (bvshl x13_2 #x0000000000000016)))
(assert (= x13_4 x13_3))
(assert (and (= x13_5 ((_ sign_extend 43) ((_ extract 63 43) x13_4))) (= dc_183 ((_ zero_extend 21) ((_ extract 42 0) x13_4)))))
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert (not (bvsle x12_3 #x00000000000FFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_b8887d.smt2
Execution time of boolector: 0.0074 seconds
OUTPUT FROM boolector:
unsat

=== Cut #3 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #3
; Range specification #49: (-1048576)@64 <=s x13_5
; Range condition: -1048576 <=s x13_5
; Output file: /tmp/outputqfbv_478dec.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_42 () (_ BitVec 64))
(declare-fun x7_23 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x14_3 () (_ BitVec 64))
(declare-fun x14_2 () (_ BitVec 64))
(declare-fun x14_1 () (_ BitVec 64))
(declare-fun x13_5 () (_ BitVec 64))
(declare-fun x13_4 () (_ BitVec 64))
(declare-fun x13_3 () (_ BitVec 64))
(declare-fun x13_2 () (_ BitVec 64))
(declare-fun x13_1 () (_ BitVec 64))
(declare-fun x12_3 () (_ BitVec 64))
(declare-fun x12_2 () (_ BitVec 64))
(declare-fun x12_1 () (_ BitVec 64))
(declare-fun x11_5 () (_ BitVec 64))
(declare-fun x11_4 () (_ BitVec 64))
(declare-fun x11_3 () (_ BitVec 64))
(declare-fun x11_2 () (_ BitVec 64))
(declare-fun x11_1 () (_ BitVec 64))
(declare-fun v_0_20_2 () (_ BitVec 64))
(declare-fun u_0_20_2 () (_ BitVec 64))
(declare-fun s_0_20_2 () (_ BitVec 64))
(declare-fun r_0_20_2 () (_ BitVec 64))
(declare-fun g_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun dcH_2 () (_ BitVec 64))
(declare-fun dcH_1 () (_ BitVec 64))
(declare-fun dc_183 () (_ BitVec 64))
(declare-fun dc_182 () (_ BitVec 64))
(declare-fun dc_181 () (_ BitVec 64))
(declare-fun dc_180 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_23 (bvadd (bvadd f_0_low60_0_low20_20_1 (bvmul u_0_20_2 #x0000000000200000)) (bvmul v_0_20_2 #x0000040000000000))) (= x8_42 (bvadd (bvadd g_0_low60_0_low20_20_1 (bvmul r_0_20_2 #x0000000000200000)) (bvmul s_0_20_2 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_20_1)) (bvsle f_0_low60_0_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_20_1)) (bvsle g_0_low60_0_low20_20_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) f_0_low60_20_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (bvsle #xFFFFFFFFFFF00000 u_0_20_2)) (bvsle u_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 v_0_20_2)) (bvsle v_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 r_0_20_2)) (bvsle r_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 s_0_20_2)) (bvsle s_0_20_2 #x00000000000FFFFF)) (bvsle (bvadd u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvsub u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvadd r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvsub r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (= x6_2 #x0000020000100000)))
(assert (= x12_1 (bvadd x7_23 x6_2)))
(assert (= x12_2 x12_1))
(assert (and (= x12_3 ((_ sign_extend 42) ((_ extract 63 42) x12_2))) (= dc_180 ((_ zero_extend 22) ((_ extract 41 0) x12_2)))))
(assert (= x11_1 (bvadd x7_23 #x0000000000100000)))
(assert (and (= dcH_1 ((_ sign_extend 42) ((_ extract 63 42) x11_1))) (= x11_2 ((_ zero_extend 22) ((_ extract 41 0) x11_1)))))
(assert (= x11_3 (bvshl x11_2 #x0000000000000016)))
(assert (= x11_4 x11_3))
(assert (and (= x11_5 ((_ sign_extend 43) ((_ extract 63 43) x11_4))) (= dc_181 ((_ zero_extend 21) ((_ extract 42 0) x11_4)))))
(assert (= x14_1 (bvadd x8_42 x6_2)))
(assert (= x14_2 x14_1))
(assert (and (= x14_3 ((_ sign_extend 42) ((_ extract 63 42) x14_2))) (= dc_182 ((_ zero_extend 22) ((_ extract 41 0) x14_2)))))
(assert (= x13_1 (bvadd x8_42 #x0000000000100000)))
(assert (and (= dcH_2 ((_ sign_extend 42) ((_ extract 63 42) x13_1))) (= x13_2 ((_ zero_extend 22) ((_ extract 41 0) x13_1)))))
(assert (= x13_3 (bvshl x13_2 #x0000000000000016)))
(assert (= x13_4 x13_3))
(assert (and (= x13_5 ((_ sign_extend 43) ((_ extract 63 43) x13_4))) (= dc_183 ((_ zero_extend 21) ((_ extract 42 0) x13_4)))))
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert (not (bvsle #xFFFFFFFFFFF00000 x13_5)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_c3cae6.smt2
Execution time of boolector: 0.0047 seconds
OUTPUT FROM boolector:
unsat

=== Cut #3 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #3
; Range specification #50: x13_5 <=s 1048575@64
; Range condition: x13_5 <=s 1048575
; Output file: /tmp/outputqfbv_43a377.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_42 () (_ BitVec 64))
(declare-fun x7_23 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x14_3 () (_ BitVec 64))
(declare-fun x14_2 () (_ BitVec 64))
(declare-fun x14_1 () (_ BitVec 64))
(declare-fun x13_5 () (_ BitVec 64))
(declare-fun x13_4 () (_ BitVec 64))
(declare-fun x13_3 () (_ BitVec 64))
(declare-fun x13_2 () (_ BitVec 64))
(declare-fun x13_1 () (_ BitVec 64))
(declare-fun x12_3 () (_ BitVec 64))
(declare-fun x12_2 () (_ BitVec 64))
(declare-fun x12_1 () (_ BitVec 64))
(declare-fun x11_5 () (_ BitVec 64))
(declare-fun x11_4 () (_ BitVec 64))
(declare-fun x11_3 () (_ BitVec 64))
(declare-fun x11_2 () (_ BitVec 64))
(declare-fun x11_1 () (_ BitVec 64))
(declare-fun v_0_20_2 () (_ BitVec 64))
(declare-fun u_0_20_2 () (_ BitVec 64))
(declare-fun s_0_20_2 () (_ BitVec 64))
(declare-fun r_0_20_2 () (_ BitVec 64))
(declare-fun g_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun dcH_2 () (_ BitVec 64))
(declare-fun dcH_1 () (_ BitVec 64))
(declare-fun dc_183 () (_ BitVec 64))
(declare-fun dc_182 () (_ BitVec 64))
(declare-fun dc_181 () (_ BitVec 64))
(declare-fun dc_180 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_23 (bvadd (bvadd f_0_low60_0_low20_20_1 (bvmul u_0_20_2 #x0000000000200000)) (bvmul v_0_20_2 #x0000040000000000))) (= x8_42 (bvadd (bvadd g_0_low60_0_low20_20_1 (bvmul r_0_20_2 #x0000000000200000)) (bvmul s_0_20_2 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_20_1)) (bvsle f_0_low60_0_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_20_1)) (bvsle g_0_low60_0_low20_20_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) f_0_low60_20_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (bvsle #xFFFFFFFFFFF00000 u_0_20_2)) (bvsle u_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 v_0_20_2)) (bvsle v_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 r_0_20_2)) (bvsle r_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 s_0_20_2)) (bvsle s_0_20_2 #x00000000000FFFFF)) (bvsle (bvadd u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvsub u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvadd r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvsub r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (= x6_2 #x0000020000100000)))
(assert (= x12_1 (bvadd x7_23 x6_2)))
(assert (= x12_2 x12_1))
(assert (and (= x12_3 ((_ sign_extend 42) ((_ extract 63 42) x12_2))) (= dc_180 ((_ zero_extend 22) ((_ extract 41 0) x12_2)))))
(assert (= x11_1 (bvadd x7_23 #x0000000000100000)))
(assert (and (= dcH_1 ((_ sign_extend 42) ((_ extract 63 42) x11_1))) (= x11_2 ((_ zero_extend 22) ((_ extract 41 0) x11_1)))))
(assert (= x11_3 (bvshl x11_2 #x0000000000000016)))
(assert (= x11_4 x11_3))
(assert (and (= x11_5 ((_ sign_extend 43) ((_ extract 63 43) x11_4))) (= dc_181 ((_ zero_extend 21) ((_ extract 42 0) x11_4)))))
(assert (= x14_1 (bvadd x8_42 x6_2)))
(assert (= x14_2 x14_1))
(assert (and (= x14_3 ((_ sign_extend 42) ((_ extract 63 42) x14_2))) (= dc_182 ((_ zero_extend 22) ((_ extract 41 0) x14_2)))))
(assert (= x13_1 (bvadd x8_42 #x0000000000100000)))
(assert (and (= dcH_2 ((_ sign_extend 42) ((_ extract 63 42) x13_1))) (= x13_2 ((_ zero_extend 22) ((_ extract 41 0) x13_1)))))
(assert (= x13_3 (bvshl x13_2 #x0000000000000016)))
(assert (= x13_4 x13_3))
(assert (and (= x13_5 ((_ sign_extend 43) ((_ extract 63 43) x13_4))) (= dc_183 ((_ zero_extend 21) ((_ extract 42 0) x13_4)))))
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert (not (bvsle x13_5 #x00000000000FFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_bb27db.smt2
Execution time of boolector: 0.0055 seconds
OUTPUT FROM boolector:
unsat

=== Cut #3 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #3
; Range specification #51: (-1048576)@64 <=s x14_3
; Range condition: -1048576 <=s x14_3
; Output file: /tmp/outputqfbv_aa3027.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_42 () (_ BitVec 64))
(declare-fun x7_23 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x14_3 () (_ BitVec 64))
(declare-fun x14_2 () (_ BitVec 64))
(declare-fun x14_1 () (_ BitVec 64))
(declare-fun x13_5 () (_ BitVec 64))
(declare-fun x13_4 () (_ BitVec 64))
(declare-fun x13_3 () (_ BitVec 64))
(declare-fun x13_2 () (_ BitVec 64))
(declare-fun x13_1 () (_ BitVec 64))
(declare-fun x12_3 () (_ BitVec 64))
(declare-fun x12_2 () (_ BitVec 64))
(declare-fun x12_1 () (_ BitVec 64))
(declare-fun x11_5 () (_ BitVec 64))
(declare-fun x11_4 () (_ BitVec 64))
(declare-fun x11_3 () (_ BitVec 64))
(declare-fun x11_2 () (_ BitVec 64))
(declare-fun x11_1 () (_ BitVec 64))
(declare-fun v_0_20_2 () (_ BitVec 64))
(declare-fun u_0_20_2 () (_ BitVec 64))
(declare-fun s_0_20_2 () (_ BitVec 64))
(declare-fun r_0_20_2 () (_ BitVec 64))
(declare-fun g_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun dcH_2 () (_ BitVec 64))
(declare-fun dcH_1 () (_ BitVec 64))
(declare-fun dc_183 () (_ BitVec 64))
(declare-fun dc_182 () (_ BitVec 64))
(declare-fun dc_181 () (_ BitVec 64))
(declare-fun dc_180 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_23 (bvadd (bvadd f_0_low60_0_low20_20_1 (bvmul u_0_20_2 #x0000000000200000)) (bvmul v_0_20_2 #x0000040000000000))) (= x8_42 (bvadd (bvadd g_0_low60_0_low20_20_1 (bvmul r_0_20_2 #x0000000000200000)) (bvmul s_0_20_2 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_20_1)) (bvsle f_0_low60_0_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_20_1)) (bvsle g_0_low60_0_low20_20_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) f_0_low60_20_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (bvsle #xFFFFFFFFFFF00000 u_0_20_2)) (bvsle u_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 v_0_20_2)) (bvsle v_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 r_0_20_2)) (bvsle r_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 s_0_20_2)) (bvsle s_0_20_2 #x00000000000FFFFF)) (bvsle (bvadd u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvsub u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvadd r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvsub r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (= x6_2 #x0000020000100000)))
(assert (= x12_1 (bvadd x7_23 x6_2)))
(assert (= x12_2 x12_1))
(assert (and (= x12_3 ((_ sign_extend 42) ((_ extract 63 42) x12_2))) (= dc_180 ((_ zero_extend 22) ((_ extract 41 0) x12_2)))))
(assert (= x11_1 (bvadd x7_23 #x0000000000100000)))
(assert (and (= dcH_1 ((_ sign_extend 42) ((_ extract 63 42) x11_1))) (= x11_2 ((_ zero_extend 22) ((_ extract 41 0) x11_1)))))
(assert (= x11_3 (bvshl x11_2 #x0000000000000016)))
(assert (= x11_4 x11_3))
(assert (and (= x11_5 ((_ sign_extend 43) ((_ extract 63 43) x11_4))) (= dc_181 ((_ zero_extend 21) ((_ extract 42 0) x11_4)))))
(assert (= x14_1 (bvadd x8_42 x6_2)))
(assert (= x14_2 x14_1))
(assert (and (= x14_3 ((_ sign_extend 42) ((_ extract 63 42) x14_2))) (= dc_182 ((_ zero_extend 22) ((_ extract 41 0) x14_2)))))
(assert (= x13_1 (bvadd x8_42 #x0000000000100000)))
(assert (and (= dcH_2 ((_ sign_extend 42) ((_ extract 63 42) x13_1))) (= x13_2 ((_ zero_extend 22) ((_ extract 41 0) x13_1)))))
(assert (= x13_3 (bvshl x13_2 #x0000000000000016)))
(assert (= x13_4 x13_3))
(assert (and (= x13_5 ((_ sign_extend 43) ((_ extract 63 43) x13_4))) (= dc_183 ((_ zero_extend 21) ((_ extract 42 0) x13_4)))))
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert (not (bvsle #xFFFFFFFFFFF00000 x14_3)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_ef6eb8.smt2
Execution time of boolector: 0.0069 seconds
OUTPUT FROM boolector:
unsat

=== Cut #3 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #3
; Range specification #52: x14_3 <=s 1048575@64
; Range condition: x14_3 <=s 1048575
; Output file: /tmp/outputqfbv_7213b5.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_42 () (_ BitVec 64))
(declare-fun x7_23 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x14_3 () (_ BitVec 64))
(declare-fun x14_2 () (_ BitVec 64))
(declare-fun x14_1 () (_ BitVec 64))
(declare-fun x13_5 () (_ BitVec 64))
(declare-fun x13_4 () (_ BitVec 64))
(declare-fun x13_3 () (_ BitVec 64))
(declare-fun x13_2 () (_ BitVec 64))
(declare-fun x13_1 () (_ BitVec 64))
(declare-fun x12_3 () (_ BitVec 64))
(declare-fun x12_2 () (_ BitVec 64))
(declare-fun x12_1 () (_ BitVec 64))
(declare-fun x11_5 () (_ BitVec 64))
(declare-fun x11_4 () (_ BitVec 64))
(declare-fun x11_3 () (_ BitVec 64))
(declare-fun x11_2 () (_ BitVec 64))
(declare-fun x11_1 () (_ BitVec 64))
(declare-fun v_0_20_2 () (_ BitVec 64))
(declare-fun u_0_20_2 () (_ BitVec 64))
(declare-fun s_0_20_2 () (_ BitVec 64))
(declare-fun r_0_20_2 () (_ BitVec 64))
(declare-fun g_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun dcH_2 () (_ BitVec 64))
(declare-fun dcH_1 () (_ BitVec 64))
(declare-fun dc_183 () (_ BitVec 64))
(declare-fun dc_182 () (_ BitVec 64))
(declare-fun dc_181 () (_ BitVec 64))
(declare-fun dc_180 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_23 (bvadd (bvadd f_0_low60_0_low20_20_1 (bvmul u_0_20_2 #x0000000000200000)) (bvmul v_0_20_2 #x0000040000000000))) (= x8_42 (bvadd (bvadd g_0_low60_0_low20_20_1 (bvmul r_0_20_2 #x0000000000200000)) (bvmul s_0_20_2 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_20_1)) (bvsle f_0_low60_0_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_20_1)) (bvsle g_0_low60_0_low20_20_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) f_0_low60_20_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (bvsle #xFFFFFFFFFFF00000 u_0_20_2)) (bvsle u_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 v_0_20_2)) (bvsle v_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 r_0_20_2)) (bvsle r_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 s_0_20_2)) (bvsle s_0_20_2 #x00000000000FFFFF)) (bvsle (bvadd u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvsub u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvadd r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvsub r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (= x6_2 #x0000020000100000)))
(assert (= x12_1 (bvadd x7_23 x6_2)))
(assert (= x12_2 x12_1))
(assert (and (= x12_3 ((_ sign_extend 42) ((_ extract 63 42) x12_2))) (= dc_180 ((_ zero_extend 22) ((_ extract 41 0) x12_2)))))
(assert (= x11_1 (bvadd x7_23 #x0000000000100000)))
(assert (and (= dcH_1 ((_ sign_extend 42) ((_ extract 63 42) x11_1))) (= x11_2 ((_ zero_extend 22) ((_ extract 41 0) x11_1)))))
(assert (= x11_3 (bvshl x11_2 #x0000000000000016)))
(assert (= x11_4 x11_3))
(assert (and (= x11_5 ((_ sign_extend 43) ((_ extract 63 43) x11_4))) (= dc_181 ((_ zero_extend 21) ((_ extract 42 0) x11_4)))))
(assert (= x14_1 (bvadd x8_42 x6_2)))
(assert (= x14_2 x14_1))
(assert (and (= x14_3 ((_ sign_extend 42) ((_ extract 63 42) x14_2))) (= dc_182 ((_ zero_extend 22) ((_ extract 41 0) x14_2)))))
(assert (= x13_1 (bvadd x8_42 #x0000000000100000)))
(assert (and (= dcH_2 ((_ sign_extend 42) ((_ extract 63 42) x13_1))) (= x13_2 ((_ zero_extend 22) ((_ extract 41 0) x13_1)))))
(assert (= x13_3 (bvshl x13_2 #x0000000000000016)))
(assert (= x13_4 x13_3))
(assert (and (= x13_5 ((_ sign_extend 43) ((_ extract 63 43) x13_4))) (= dc_183 ((_ zero_extend 21) ((_ extract 42 0) x13_4)))))
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert (not (bvsle x14_3 #x00000000000FFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_e82c5f.smt2
Execution time of boolector: 0.0076 seconds
OUTPUT FROM boolector:
unsat

=== Cut #3 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #3
; Range specification #53: add x11_5 x12_3 <=s 1048576@64
; Range condition: x11_5 + x12_3 <=s 1048576
; Output file: /tmp/outputqfbv_0ba9e0.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_42 () (_ BitVec 64))
(declare-fun x7_23 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x14_3 () (_ BitVec 64))
(declare-fun x14_2 () (_ BitVec 64))
(declare-fun x14_1 () (_ BitVec 64))
(declare-fun x13_5 () (_ BitVec 64))
(declare-fun x13_4 () (_ BitVec 64))
(declare-fun x13_3 () (_ BitVec 64))
(declare-fun x13_2 () (_ BitVec 64))
(declare-fun x13_1 () (_ BitVec 64))
(declare-fun x12_3 () (_ BitVec 64))
(declare-fun x12_2 () (_ BitVec 64))
(declare-fun x12_1 () (_ BitVec 64))
(declare-fun x11_5 () (_ BitVec 64))
(declare-fun x11_4 () (_ BitVec 64))
(declare-fun x11_3 () (_ BitVec 64))
(declare-fun x11_2 () (_ BitVec 64))
(declare-fun x11_1 () (_ BitVec 64))
(declare-fun v_0_20_2 () (_ BitVec 64))
(declare-fun u_0_20_2 () (_ BitVec 64))
(declare-fun s_0_20_2 () (_ BitVec 64))
(declare-fun r_0_20_2 () (_ BitVec 64))
(declare-fun g_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun dcH_2 () (_ BitVec 64))
(declare-fun dcH_1 () (_ BitVec 64))
(declare-fun dc_183 () (_ BitVec 64))
(declare-fun dc_182 () (_ BitVec 64))
(declare-fun dc_181 () (_ BitVec 64))
(declare-fun dc_180 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_23 (bvadd (bvadd f_0_low60_0_low20_20_1 (bvmul u_0_20_2 #x0000000000200000)) (bvmul v_0_20_2 #x0000040000000000))) (= x8_42 (bvadd (bvadd g_0_low60_0_low20_20_1 (bvmul r_0_20_2 #x0000000000200000)) (bvmul s_0_20_2 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_20_1)) (bvsle f_0_low60_0_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_20_1)) (bvsle g_0_low60_0_low20_20_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) f_0_low60_20_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (bvsle #xFFFFFFFFFFF00000 u_0_20_2)) (bvsle u_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 v_0_20_2)) (bvsle v_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 r_0_20_2)) (bvsle r_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 s_0_20_2)) (bvsle s_0_20_2 #x00000000000FFFFF)) (bvsle (bvadd u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvsub u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvadd r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvsub r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (= x6_2 #x0000020000100000)))
(assert (= x12_1 (bvadd x7_23 x6_2)))
(assert (= x12_2 x12_1))
(assert (and (= x12_3 ((_ sign_extend 42) ((_ extract 63 42) x12_2))) (= dc_180 ((_ zero_extend 22) ((_ extract 41 0) x12_2)))))
(assert (= x11_1 (bvadd x7_23 #x0000000000100000)))
(assert (and (= dcH_1 ((_ sign_extend 42) ((_ extract 63 42) x11_1))) (= x11_2 ((_ zero_extend 22) ((_ extract 41 0) x11_1)))))
(assert (= x11_3 (bvshl x11_2 #x0000000000000016)))
(assert (= x11_4 x11_3))
(assert (and (= x11_5 ((_ sign_extend 43) ((_ extract 63 43) x11_4))) (= dc_181 ((_ zero_extend 21) ((_ extract 42 0) x11_4)))))
(assert (= x14_1 (bvadd x8_42 x6_2)))
(assert (= x14_2 x14_1))
(assert (and (= x14_3 ((_ sign_extend 42) ((_ extract 63 42) x14_2))) (= dc_182 ((_ zero_extend 22) ((_ extract 41 0) x14_2)))))
(assert (= x13_1 (bvadd x8_42 #x0000000000100000)))
(assert (and (= dcH_2 ((_ sign_extend 42) ((_ extract 63 42) x13_1))) (= x13_2 ((_ zero_extend 22) ((_ extract 41 0) x13_1)))))
(assert (= x13_3 (bvshl x13_2 #x0000000000000016)))
(assert (= x13_4 x13_3))
(assert (and (= x13_5 ((_ sign_extend 43) ((_ extract 63 43) x13_4))) (= dc_183 ((_ zero_extend 21) ((_ extract 42 0) x13_4)))))
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert (not (bvsle (bvadd x11_5 x12_3) #x0000000000100000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_02702b.smt2
Execution time of boolector: 0.0202 seconds
OUTPUT FROM boolector:
unsat

=== Cut #3 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #3
; Range specification #54: sub x11_5 x12_3 <=s 1048576@64
; Range condition: x11_5 - x12_3 <=s 1048576
; Output file: /tmp/outputqfbv_367ae9.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_42 () (_ BitVec 64))
(declare-fun x7_23 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x14_3 () (_ BitVec 64))
(declare-fun x14_2 () (_ BitVec 64))
(declare-fun x14_1 () (_ BitVec 64))
(declare-fun x13_5 () (_ BitVec 64))
(declare-fun x13_4 () (_ BitVec 64))
(declare-fun x13_3 () (_ BitVec 64))
(declare-fun x13_2 () (_ BitVec 64))
(declare-fun x13_1 () (_ BitVec 64))
(declare-fun x12_3 () (_ BitVec 64))
(declare-fun x12_2 () (_ BitVec 64))
(declare-fun x12_1 () (_ BitVec 64))
(declare-fun x11_5 () (_ BitVec 64))
(declare-fun x11_4 () (_ BitVec 64))
(declare-fun x11_3 () (_ BitVec 64))
(declare-fun x11_2 () (_ BitVec 64))
(declare-fun x11_1 () (_ BitVec 64))
(declare-fun v_0_20_2 () (_ BitVec 64))
(declare-fun u_0_20_2 () (_ BitVec 64))
(declare-fun s_0_20_2 () (_ BitVec 64))
(declare-fun r_0_20_2 () (_ BitVec 64))
(declare-fun g_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun dcH_2 () (_ BitVec 64))
(declare-fun dcH_1 () (_ BitVec 64))
(declare-fun dc_183 () (_ BitVec 64))
(declare-fun dc_182 () (_ BitVec 64))
(declare-fun dc_181 () (_ BitVec 64))
(declare-fun dc_180 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_23 (bvadd (bvadd f_0_low60_0_low20_20_1 (bvmul u_0_20_2 #x0000000000200000)) (bvmul v_0_20_2 #x0000040000000000))) (= x8_42 (bvadd (bvadd g_0_low60_0_low20_20_1 (bvmul r_0_20_2 #x0000000000200000)) (bvmul s_0_20_2 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_20_1)) (bvsle f_0_low60_0_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_20_1)) (bvsle g_0_low60_0_low20_20_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) f_0_low60_20_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (bvsle #xFFFFFFFFFFF00000 u_0_20_2)) (bvsle u_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 v_0_20_2)) (bvsle v_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 r_0_20_2)) (bvsle r_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 s_0_20_2)) (bvsle s_0_20_2 #x00000000000FFFFF)) (bvsle (bvadd u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvsub u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvadd r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvsub r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (= x6_2 #x0000020000100000)))
(assert (= x12_1 (bvadd x7_23 x6_2)))
(assert (= x12_2 x12_1))
(assert (and (= x12_3 ((_ sign_extend 42) ((_ extract 63 42) x12_2))) (= dc_180 ((_ zero_extend 22) ((_ extract 41 0) x12_2)))))
(assert (= x11_1 (bvadd x7_23 #x0000000000100000)))
(assert (and (= dcH_1 ((_ sign_extend 42) ((_ extract 63 42) x11_1))) (= x11_2 ((_ zero_extend 22) ((_ extract 41 0) x11_1)))))
(assert (= x11_3 (bvshl x11_2 #x0000000000000016)))
(assert (= x11_4 x11_3))
(assert (and (= x11_5 ((_ sign_extend 43) ((_ extract 63 43) x11_4))) (= dc_181 ((_ zero_extend 21) ((_ extract 42 0) x11_4)))))
(assert (= x14_1 (bvadd x8_42 x6_2)))
(assert (= x14_2 x14_1))
(assert (and (= x14_3 ((_ sign_extend 42) ((_ extract 63 42) x14_2))) (= dc_182 ((_ zero_extend 22) ((_ extract 41 0) x14_2)))))
(assert (= x13_1 (bvadd x8_42 #x0000000000100000)))
(assert (and (= dcH_2 ((_ sign_extend 42) ((_ extract 63 42) x13_1))) (= x13_2 ((_ zero_extend 22) ((_ extract 41 0) x13_1)))))
(assert (= x13_3 (bvshl x13_2 #x0000000000000016)))
(assert (= x13_4 x13_3))
(assert (and (= x13_5 ((_ sign_extend 43) ((_ extract 63 43) x13_4))) (= dc_183 ((_ zero_extend 21) ((_ extract 42 0) x13_4)))))
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert (not (bvsle (bvsub x11_5 x12_3) #x0000000000100000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_9f39f5.smt2
Execution time of boolector: 0.0194 seconds
OUTPUT FROM boolector:
unsat

=== Cut #3 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #3
; Range specification #55: add (sub 0@64 x11_5) x12_3 <=s 1048576@64
; Range condition: (0 - x11_5) + x12_3 <=s 1048576
; Output file: /tmp/outputqfbv_b80a4e.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_42 () (_ BitVec 64))
(declare-fun x7_23 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x14_3 () (_ BitVec 64))
(declare-fun x14_2 () (_ BitVec 64))
(declare-fun x14_1 () (_ BitVec 64))
(declare-fun x13_5 () (_ BitVec 64))
(declare-fun x13_4 () (_ BitVec 64))
(declare-fun x13_3 () (_ BitVec 64))
(declare-fun x13_2 () (_ BitVec 64))
(declare-fun x13_1 () (_ BitVec 64))
(declare-fun x12_3 () (_ BitVec 64))
(declare-fun x12_2 () (_ BitVec 64))
(declare-fun x12_1 () (_ BitVec 64))
(declare-fun x11_5 () (_ BitVec 64))
(declare-fun x11_4 () (_ BitVec 64))
(declare-fun x11_3 () (_ BitVec 64))
(declare-fun x11_2 () (_ BitVec 64))
(declare-fun x11_1 () (_ BitVec 64))
(declare-fun v_0_20_2 () (_ BitVec 64))
(declare-fun u_0_20_2 () (_ BitVec 64))
(declare-fun s_0_20_2 () (_ BitVec 64))
(declare-fun r_0_20_2 () (_ BitVec 64))
(declare-fun g_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun dcH_2 () (_ BitVec 64))
(declare-fun dcH_1 () (_ BitVec 64))
(declare-fun dc_183 () (_ BitVec 64))
(declare-fun dc_182 () (_ BitVec 64))
(declare-fun dc_181 () (_ BitVec 64))
(declare-fun dc_180 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_23 (bvadd (bvadd f_0_low60_0_low20_20_1 (bvmul u_0_20_2 #x0000000000200000)) (bvmul v_0_20_2 #x0000040000000000))) (= x8_42 (bvadd (bvadd g_0_low60_0_low20_20_1 (bvmul r_0_20_2 #x0000000000200000)) (bvmul s_0_20_2 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_20_1)) (bvsle f_0_low60_0_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_20_1)) (bvsle g_0_low60_0_low20_20_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) f_0_low60_20_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (bvsle #xFFFFFFFFFFF00000 u_0_20_2)) (bvsle u_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 v_0_20_2)) (bvsle v_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 r_0_20_2)) (bvsle r_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 s_0_20_2)) (bvsle s_0_20_2 #x00000000000FFFFF)) (bvsle (bvadd u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvsub u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvadd r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvsub r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (= x6_2 #x0000020000100000)))
(assert (= x12_1 (bvadd x7_23 x6_2)))
(assert (= x12_2 x12_1))
(assert (and (= x12_3 ((_ sign_extend 42) ((_ extract 63 42) x12_2))) (= dc_180 ((_ zero_extend 22) ((_ extract 41 0) x12_2)))))
(assert (= x11_1 (bvadd x7_23 #x0000000000100000)))
(assert (and (= dcH_1 ((_ sign_extend 42) ((_ extract 63 42) x11_1))) (= x11_2 ((_ zero_extend 22) ((_ extract 41 0) x11_1)))))
(assert (= x11_3 (bvshl x11_2 #x0000000000000016)))
(assert (= x11_4 x11_3))
(assert (and (= x11_5 ((_ sign_extend 43) ((_ extract 63 43) x11_4))) (= dc_181 ((_ zero_extend 21) ((_ extract 42 0) x11_4)))))
(assert (= x14_1 (bvadd x8_42 x6_2)))
(assert (= x14_2 x14_1))
(assert (and (= x14_3 ((_ sign_extend 42) ((_ extract 63 42) x14_2))) (= dc_182 ((_ zero_extend 22) ((_ extract 41 0) x14_2)))))
(assert (= x13_1 (bvadd x8_42 #x0000000000100000)))
(assert (and (= dcH_2 ((_ sign_extend 42) ((_ extract 63 42) x13_1))) (= x13_2 ((_ zero_extend 22) ((_ extract 41 0) x13_1)))))
(assert (= x13_3 (bvshl x13_2 #x0000000000000016)))
(assert (= x13_4 x13_3))
(assert (and (= x13_5 ((_ sign_extend 43) ((_ extract 63 43) x13_4))) (= dc_183 ((_ zero_extend 21) ((_ extract 42 0) x13_4)))))
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert (not (bvsle (bvadd (bvsub #x0000000000000000 x11_5) x12_3) #x0000000000100000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_ebd106.smt2
Execution time of boolector: 0.0348 seconds
OUTPUT FROM boolector:
unsat

=== Cut #3 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #3
; Range specification #57: add x13_5 x14_3 <=s 1048576@64
; Range condition: x13_5 + x14_3 <=s 1048576
; Output file: /tmp/outputqfbv_0508dc.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_42 () (_ BitVec 64))
(declare-fun x7_23 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x14_3 () (_ BitVec 64))
(declare-fun x14_2 () (_ BitVec 64))
(declare-fun x14_1 () (_ BitVec 64))
(declare-fun x13_5 () (_ BitVec 64))
(declare-fun x13_4 () (_ BitVec 64))
(declare-fun x13_3 () (_ BitVec 64))
(declare-fun x13_2 () (_ BitVec 64))
(declare-fun x13_1 () (_ BitVec 64))
(declare-fun x12_3 () (_ BitVec 64))
(declare-fun x12_2 () (_ BitVec 64))
(declare-fun x12_1 () (_ BitVec 64))
(declare-fun x11_5 () (_ BitVec 64))
(declare-fun x11_4 () (_ BitVec 64))
(declare-fun x11_3 () (_ BitVec 64))
(declare-fun x11_2 () (_ BitVec 64))
(declare-fun x11_1 () (_ BitVec 64))
(declare-fun v_0_20_2 () (_ BitVec 64))
(declare-fun u_0_20_2 () (_ BitVec 64))
(declare-fun s_0_20_2 () (_ BitVec 64))
(declare-fun r_0_20_2 () (_ BitVec 64))
(declare-fun g_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun dcH_2 () (_ BitVec 64))
(declare-fun dcH_1 () (_ BitVec 64))
(declare-fun dc_183 () (_ BitVec 64))
(declare-fun dc_182 () (_ BitVec 64))
(declare-fun dc_181 () (_ BitVec 64))
(declare-fun dc_180 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_23 (bvadd (bvadd f_0_low60_0_low20_20_1 (bvmul u_0_20_2 #x0000000000200000)) (bvmul v_0_20_2 #x0000040000000000))) (= x8_42 (bvadd (bvadd g_0_low60_0_low20_20_1 (bvmul r_0_20_2 #x0000000000200000)) (bvmul s_0_20_2 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_20_1)) (bvsle f_0_low60_0_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_20_1)) (bvsle g_0_low60_0_low20_20_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) f_0_low60_20_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (bvsle #xFFFFFFFFFFF00000 u_0_20_2)) (bvsle u_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 v_0_20_2)) (bvsle v_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 r_0_20_2)) (bvsle r_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 s_0_20_2)) (bvsle s_0_20_2 #x00000000000FFFFF)) (bvsle (bvadd u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvsub u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvadd r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvsub r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (= x6_2 #x0000020000100000)))
(assert (= x12_1 (bvadd x7_23 x6_2)))
(assert (= x12_2 x12_1))
(assert (and (= x12_3 ((_ sign_extend 42) ((_ extract 63 42) x12_2))) (= dc_180 ((_ zero_extend 22) ((_ extract 41 0) x12_2)))))
(assert (= x11_1 (bvadd x7_23 #x0000000000100000)))
(assert (and (= dcH_1 ((_ sign_extend 42) ((_ extract 63 42) x11_1))) (= x11_2 ((_ zero_extend 22) ((_ extract 41 0) x11_1)))))
(assert (= x11_3 (bvshl x11_2 #x0000000000000016)))
(assert (= x11_4 x11_3))
(assert (and (= x11_5 ((_ sign_extend 43) ((_ extract 63 43) x11_4))) (= dc_181 ((_ zero_extend 21) ((_ extract 42 0) x11_4)))))
(assert (= x14_1 (bvadd x8_42 x6_2)))
(assert (= x14_2 x14_1))
(assert (and (= x14_3 ((_ sign_extend 42) ((_ extract 63 42) x14_2))) (= dc_182 ((_ zero_extend 22) ((_ extract 41 0) x14_2)))))
(assert (= x13_1 (bvadd x8_42 #x0000000000100000)))
(assert (and (= dcH_2 ((_ sign_extend 42) ((_ extract 63 42) x13_1))) (= x13_2 ((_ zero_extend 22) ((_ extract 41 0) x13_1)))))
(assert (= x13_3 (bvshl x13_2 #x0000000000000016)))
(assert (= x13_4 x13_3))
(assert (and (= x13_5 ((_ sign_extend 43) ((_ extract 63 43) x13_4))) (= dc_183 ((_ zero_extend 21) ((_ extract 42 0) x13_4)))))
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert (not (bvsle (bvadd x13_5 x14_3) #x0000000000100000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_c2c333.smt2
Execution time of boolector: 0.0209 seconds
OUTPUT FROM boolector:
unsat

=== Cut #3 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #3
; Range specification #56: sub (sub 0@64 x11_5) x12_3 <=s 1048576@64
; Range condition: (0 - x11_5) - x12_3 <=s 1048576
; Output file: /tmp/outputqfbv_b0a144.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_42 () (_ BitVec 64))
(declare-fun x7_23 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x14_3 () (_ BitVec 64))
(declare-fun x14_2 () (_ BitVec 64))
(declare-fun x14_1 () (_ BitVec 64))
(declare-fun x13_5 () (_ BitVec 64))
(declare-fun x13_4 () (_ BitVec 64))
(declare-fun x13_3 () (_ BitVec 64))
(declare-fun x13_2 () (_ BitVec 64))
(declare-fun x13_1 () (_ BitVec 64))
(declare-fun x12_3 () (_ BitVec 64))
(declare-fun x12_2 () (_ BitVec 64))
(declare-fun x12_1 () (_ BitVec 64))
(declare-fun x11_5 () (_ BitVec 64))
(declare-fun x11_4 () (_ BitVec 64))
(declare-fun x11_3 () (_ BitVec 64))
(declare-fun x11_2 () (_ BitVec 64))
(declare-fun x11_1 () (_ BitVec 64))
(declare-fun v_0_20_2 () (_ BitVec 64))
(declare-fun u_0_20_2 () (_ BitVec 64))
(declare-fun s_0_20_2 () (_ BitVec 64))
(declare-fun r_0_20_2 () (_ BitVec 64))
(declare-fun g_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun dcH_2 () (_ BitVec 64))
(declare-fun dcH_1 () (_ BitVec 64))
(declare-fun dc_183 () (_ BitVec 64))
(declare-fun dc_182 () (_ BitVec 64))
(declare-fun dc_181 () (_ BitVec 64))
(declare-fun dc_180 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_23 (bvadd (bvadd f_0_low60_0_low20_20_1 (bvmul u_0_20_2 #x0000000000200000)) (bvmul v_0_20_2 #x0000040000000000))) (= x8_42 (bvadd (bvadd g_0_low60_0_low20_20_1 (bvmul r_0_20_2 #x0000000000200000)) (bvmul s_0_20_2 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_20_1)) (bvsle f_0_low60_0_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_20_1)) (bvsle g_0_low60_0_low20_20_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) f_0_low60_20_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (bvsle #xFFFFFFFFFFF00000 u_0_20_2)) (bvsle u_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 v_0_20_2)) (bvsle v_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 r_0_20_2)) (bvsle r_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 s_0_20_2)) (bvsle s_0_20_2 #x00000000000FFFFF)) (bvsle (bvadd u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvsub u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvadd r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvsub r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (= x6_2 #x0000020000100000)))
(assert (= x12_1 (bvadd x7_23 x6_2)))
(assert (= x12_2 x12_1))
(assert (and (= x12_3 ((_ sign_extend 42) ((_ extract 63 42) x12_2))) (= dc_180 ((_ zero_extend 22) ((_ extract 41 0) x12_2)))))
(assert (= x11_1 (bvadd x7_23 #x0000000000100000)))
(assert (and (= dcH_1 ((_ sign_extend 42) ((_ extract 63 42) x11_1))) (= x11_2 ((_ zero_extend 22) ((_ extract 41 0) x11_1)))))
(assert (= x11_3 (bvshl x11_2 #x0000000000000016)))
(assert (= x11_4 x11_3))
(assert (and (= x11_5 ((_ sign_extend 43) ((_ extract 63 43) x11_4))) (= dc_181 ((_ zero_extend 21) ((_ extract 42 0) x11_4)))))
(assert (= x14_1 (bvadd x8_42 x6_2)))
(assert (= x14_2 x14_1))
(assert (and (= x14_3 ((_ sign_extend 42) ((_ extract 63 42) x14_2))) (= dc_182 ((_ zero_extend 22) ((_ extract 41 0) x14_2)))))
(assert (= x13_1 (bvadd x8_42 #x0000000000100000)))
(assert (and (= dcH_2 ((_ sign_extend 42) ((_ extract 63 42) x13_1))) (= x13_2 ((_ zero_extend 22) ((_ extract 41 0) x13_1)))))
(assert (= x13_3 (bvshl x13_2 #x0000000000000016)))
(assert (= x13_4 x13_3))
(assert (and (= x13_5 ((_ sign_extend 43) ((_ extract 63 43) x13_4))) (= dc_183 ((_ zero_extend 21) ((_ extract 42 0) x13_4)))))
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert (not (bvsle (bvsub (bvsub #x0000000000000000 x11_5) x12_3) #x0000000000100000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_342d48.smt2
Execution time of boolector: 0.0398 seconds
OUTPUT FROM boolector:
unsat

=== Cut #3 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #3
; Range specification #58: sub x13_5 x14_3 <=s 1048576@64
; Range condition: x13_5 - x14_3 <=s 1048576
; Output file: /tmp/outputqfbv_75c566.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_42 () (_ BitVec 64))
(declare-fun x7_23 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x14_3 () (_ BitVec 64))
(declare-fun x14_2 () (_ BitVec 64))
(declare-fun x14_1 () (_ BitVec 64))
(declare-fun x13_5 () (_ BitVec 64))
(declare-fun x13_4 () (_ BitVec 64))
(declare-fun x13_3 () (_ BitVec 64))
(declare-fun x13_2 () (_ BitVec 64))
(declare-fun x13_1 () (_ BitVec 64))
(declare-fun x12_3 () (_ BitVec 64))
(declare-fun x12_2 () (_ BitVec 64))
(declare-fun x12_1 () (_ BitVec 64))
(declare-fun x11_5 () (_ BitVec 64))
(declare-fun x11_4 () (_ BitVec 64))
(declare-fun x11_3 () (_ BitVec 64))
(declare-fun x11_2 () (_ BitVec 64))
(declare-fun x11_1 () (_ BitVec 64))
(declare-fun v_0_20_2 () (_ BitVec 64))
(declare-fun u_0_20_2 () (_ BitVec 64))
(declare-fun s_0_20_2 () (_ BitVec 64))
(declare-fun r_0_20_2 () (_ BitVec 64))
(declare-fun g_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun dcH_2 () (_ BitVec 64))
(declare-fun dcH_1 () (_ BitVec 64))
(declare-fun dc_183 () (_ BitVec 64))
(declare-fun dc_182 () (_ BitVec 64))
(declare-fun dc_181 () (_ BitVec 64))
(declare-fun dc_180 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_23 (bvadd (bvadd f_0_low60_0_low20_20_1 (bvmul u_0_20_2 #x0000000000200000)) (bvmul v_0_20_2 #x0000040000000000))) (= x8_42 (bvadd (bvadd g_0_low60_0_low20_20_1 (bvmul r_0_20_2 #x0000000000200000)) (bvmul s_0_20_2 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_20_1)) (bvsle f_0_low60_0_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_20_1)) (bvsle g_0_low60_0_low20_20_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) f_0_low60_20_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (bvsle #xFFFFFFFFFFF00000 u_0_20_2)) (bvsle u_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 v_0_20_2)) (bvsle v_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 r_0_20_2)) (bvsle r_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 s_0_20_2)) (bvsle s_0_20_2 #x00000000000FFFFF)) (bvsle (bvadd u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvsub u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvadd r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvsub r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (= x6_2 #x0000020000100000)))
(assert (= x12_1 (bvadd x7_23 x6_2)))
(assert (= x12_2 x12_1))
(assert (and (= x12_3 ((_ sign_extend 42) ((_ extract 63 42) x12_2))) (= dc_180 ((_ zero_extend 22) ((_ extract 41 0) x12_2)))))
(assert (= x11_1 (bvadd x7_23 #x0000000000100000)))
(assert (and (= dcH_1 ((_ sign_extend 42) ((_ extract 63 42) x11_1))) (= x11_2 ((_ zero_extend 22) ((_ extract 41 0) x11_1)))))
(assert (= x11_3 (bvshl x11_2 #x0000000000000016)))
(assert (= x11_4 x11_3))
(assert (and (= x11_5 ((_ sign_extend 43) ((_ extract 63 43) x11_4))) (= dc_181 ((_ zero_extend 21) ((_ extract 42 0) x11_4)))))
(assert (= x14_1 (bvadd x8_42 x6_2)))
(assert (= x14_2 x14_1))
(assert (and (= x14_3 ((_ sign_extend 42) ((_ extract 63 42) x14_2))) (= dc_182 ((_ zero_extend 22) ((_ extract 41 0) x14_2)))))
(assert (= x13_1 (bvadd x8_42 #x0000000000100000)))
(assert (and (= dcH_2 ((_ sign_extend 42) ((_ extract 63 42) x13_1))) (= x13_2 ((_ zero_extend 22) ((_ extract 41 0) x13_1)))))
(assert (= x13_3 (bvshl x13_2 #x0000000000000016)))
(assert (= x13_4 x13_3))
(assert (and (= x13_5 ((_ sign_extend 43) ((_ extract 63 43) x13_4))) (= dc_183 ((_ zero_extend 21) ((_ extract 42 0) x13_4)))))
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert (not (bvsle (bvsub x13_5 x14_3) #x0000000000100000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_0baded.smt2
Execution time of boolector: 0.0292 seconds
OUTPUT FROM boolector:
unsat

=== Cut #3 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #3
; Range specification #59: add (sub 0@64 x13_5) x14_3 <=s 1048576@64
; Range condition: (0 - x13_5) + x14_3 <=s 1048576
; Output file: /tmp/outputqfbv_967d5d.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_42 () (_ BitVec 64))
(declare-fun x7_23 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x14_3 () (_ BitVec 64))
(declare-fun x14_2 () (_ BitVec 64))
(declare-fun x14_1 () (_ BitVec 64))
(declare-fun x13_5 () (_ BitVec 64))
(declare-fun x13_4 () (_ BitVec 64))
(declare-fun x13_3 () (_ BitVec 64))
(declare-fun x13_2 () (_ BitVec 64))
(declare-fun x13_1 () (_ BitVec 64))
(declare-fun x12_3 () (_ BitVec 64))
(declare-fun x12_2 () (_ BitVec 64))
(declare-fun x12_1 () (_ BitVec 64))
(declare-fun x11_5 () (_ BitVec 64))
(declare-fun x11_4 () (_ BitVec 64))
(declare-fun x11_3 () (_ BitVec 64))
(declare-fun x11_2 () (_ BitVec 64))
(declare-fun x11_1 () (_ BitVec 64))
(declare-fun v_0_20_2 () (_ BitVec 64))
(declare-fun u_0_20_2 () (_ BitVec 64))
(declare-fun s_0_20_2 () (_ BitVec 64))
(declare-fun r_0_20_2 () (_ BitVec 64))
(declare-fun g_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun dcH_2 () (_ BitVec 64))
(declare-fun dcH_1 () (_ BitVec 64))
(declare-fun dc_183 () (_ BitVec 64))
(declare-fun dc_182 () (_ BitVec 64))
(declare-fun dc_181 () (_ BitVec 64))
(declare-fun dc_180 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_23 (bvadd (bvadd f_0_low60_0_low20_20_1 (bvmul u_0_20_2 #x0000000000200000)) (bvmul v_0_20_2 #x0000040000000000))) (= x8_42 (bvadd (bvadd g_0_low60_0_low20_20_1 (bvmul r_0_20_2 #x0000000000200000)) (bvmul s_0_20_2 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_20_1)) (bvsle f_0_low60_0_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_20_1)) (bvsle g_0_low60_0_low20_20_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) f_0_low60_20_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (bvsle #xFFFFFFFFFFF00000 u_0_20_2)) (bvsle u_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 v_0_20_2)) (bvsle v_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 r_0_20_2)) (bvsle r_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 s_0_20_2)) (bvsle s_0_20_2 #x00000000000FFFFF)) (bvsle (bvadd u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvsub u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvadd r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvsub r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (= x6_2 #x0000020000100000)))
(assert (= x12_1 (bvadd x7_23 x6_2)))
(assert (= x12_2 x12_1))
(assert (and (= x12_3 ((_ sign_extend 42) ((_ extract 63 42) x12_2))) (= dc_180 ((_ zero_extend 22) ((_ extract 41 0) x12_2)))))
(assert (= x11_1 (bvadd x7_23 #x0000000000100000)))
(assert (and (= dcH_1 ((_ sign_extend 42) ((_ extract 63 42) x11_1))) (= x11_2 ((_ zero_extend 22) ((_ extract 41 0) x11_1)))))
(assert (= x11_3 (bvshl x11_2 #x0000000000000016)))
(assert (= x11_4 x11_3))
(assert (and (= x11_5 ((_ sign_extend 43) ((_ extract 63 43) x11_4))) (= dc_181 ((_ zero_extend 21) ((_ extract 42 0) x11_4)))))
(assert (= x14_1 (bvadd x8_42 x6_2)))
(assert (= x14_2 x14_1))
(assert (and (= x14_3 ((_ sign_extend 42) ((_ extract 63 42) x14_2))) (= dc_182 ((_ zero_extend 22) ((_ extract 41 0) x14_2)))))
(assert (= x13_1 (bvadd x8_42 #x0000000000100000)))
(assert (and (= dcH_2 ((_ sign_extend 42) ((_ extract 63 42) x13_1))) (= x13_2 ((_ zero_extend 22) ((_ extract 41 0) x13_1)))))
(assert (= x13_3 (bvshl x13_2 #x0000000000000016)))
(assert (= x13_4 x13_3))
(assert (and (= x13_5 ((_ sign_extend 43) ((_ extract 63 43) x13_4))) (= dc_183 ((_ zero_extend 21) ((_ extract 42 0) x13_4)))))
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert (not (bvsle (bvadd (bvsub #x0000000000000000 x13_5) x14_3) #x0000000000100000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_b50077.smt2
Execution time of boolector: 0.0382 seconds
OUTPUT FROM boolector:
unsat

=== Cut #3 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #3
; Range specification #60: sub (sub 0@64 x13_5) x14_3 <=s 1048576@64
; Range condition: (0 - x13_5) - x14_3 <=s 1048576
; Output file: /tmp/outputqfbv_17adff.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_42 () (_ BitVec 64))
(declare-fun x7_23 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x14_3 () (_ BitVec 64))
(declare-fun x14_2 () (_ BitVec 64))
(declare-fun x14_1 () (_ BitVec 64))
(declare-fun x13_5 () (_ BitVec 64))
(declare-fun x13_4 () (_ BitVec 64))
(declare-fun x13_3 () (_ BitVec 64))
(declare-fun x13_2 () (_ BitVec 64))
(declare-fun x13_1 () (_ BitVec 64))
(declare-fun x12_3 () (_ BitVec 64))
(declare-fun x12_2 () (_ BitVec 64))
(declare-fun x12_1 () (_ BitVec 64))
(declare-fun x11_5 () (_ BitVec 64))
(declare-fun x11_4 () (_ BitVec 64))
(declare-fun x11_3 () (_ BitVec 64))
(declare-fun x11_2 () (_ BitVec 64))
(declare-fun x11_1 () (_ BitVec 64))
(declare-fun v_0_20_2 () (_ BitVec 64))
(declare-fun u_0_20_2 () (_ BitVec 64))
(declare-fun s_0_20_2 () (_ BitVec 64))
(declare-fun r_0_20_2 () (_ BitVec 64))
(declare-fun g_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_0_low20_20_1 () (_ BitVec 64))
(declare-fun dcH_2 () (_ BitVec 64))
(declare-fun dcH_1 () (_ BitVec 64))
(declare-fun dc_183 () (_ BitVec 64))
(declare-fun dc_182 () (_ BitVec 64))
(declare-fun dc_181 () (_ BitVec 64))
(declare-fun dc_180 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_23 (bvadd (bvadd f_0_low60_0_low20_20_1 (bvmul u_0_20_2 #x0000000000200000)) (bvmul v_0_20_2 #x0000040000000000))) (= x8_42 (bvadd (bvadd g_0_low60_0_low20_20_1 (bvmul r_0_20_2 #x0000000000200000)) (bvmul s_0_20_2 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 f_0_low60_0_low20_20_1)) (bvsle f_0_low60_0_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 g_0_low60_0_low20_20_1)) (bvsle g_0_low60_0_low20_20_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) f_0_low60_20_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (bvsle #xFFFFFFFFFFF00000 u_0_20_2)) (bvsle u_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 v_0_20_2)) (bvsle v_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 r_0_20_2)) (bvsle r_0_20_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 s_0_20_2)) (bvsle s_0_20_2 #x00000000000FFFFF)) (bvsle (bvadd u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvsub u_0_20_2 v_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 u_0_20_2) v_0_20_2) #x0000000000100000)) (bvsle (bvadd r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvsub r_0_20_2 s_0_20_2) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 r_0_20_2) s_0_20_2) #x0000000000100000)) (= x6_2 #x0000020000100000)))
(assert (= x12_1 (bvadd x7_23 x6_2)))
(assert (= x12_2 x12_1))
(assert (and (= x12_3 ((_ sign_extend 42) ((_ extract 63 42) x12_2))) (= dc_180 ((_ zero_extend 22) ((_ extract 41 0) x12_2)))))
(assert (= x11_1 (bvadd x7_23 #x0000000000100000)))
(assert (and (= dcH_1 ((_ sign_extend 42) ((_ extract 63 42) x11_1))) (= x11_2 ((_ zero_extend 22) ((_ extract 41 0) x11_1)))))
(assert (= x11_3 (bvshl x11_2 #x0000000000000016)))
(assert (= x11_4 x11_3))
(assert (and (= x11_5 ((_ sign_extend 43) ((_ extract 63 43) x11_4))) (= dc_181 ((_ zero_extend 21) ((_ extract 42 0) x11_4)))))
(assert (= x14_1 (bvadd x8_42 x6_2)))
(assert (= x14_2 x14_1))
(assert (and (= x14_3 ((_ sign_extend 42) ((_ extract 63 42) x14_2))) (= dc_182 ((_ zero_extend 22) ((_ extract 41 0) x14_2)))))
(assert (= x13_1 (bvadd x8_42 #x0000000000100000)))
(assert (and (= dcH_2 ((_ sign_extend 42) ((_ extract 63 42) x13_1))) (= x13_2 ((_ zero_extend 22) ((_ extract 41 0) x13_1)))))
(assert (= x13_3 (bvshl x13_2 #x0000000000000016)))
(assert (= x13_4 x13_3))
(assert (and (= x13_5 ((_ sign_extend 43) ((_ extract 63 43) x13_4))) (= dc_183 ((_ zero_extend 21) ((_ extract 42 0) x13_4)))))
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert (not (bvsle (bvsub (bvsub #x0000000000000000 x13_5) x14_3) #x0000000000100000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_306dea.smt2
Execution time of boolector: 0.0375 seconds
OUTPUT FROM boolector:
unsat

=== Cut #4 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #4
; Range specification #64: (-1048575)@64 <=s neg_f_0_low60_20_low20_0_1
; Range condition: -1048575 <=s neg_f_0_low60_20_low20_0_1
; Output file: /tmp/outputqfbv_1f245e.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x9_3 () (_ BitVec 64))
(declare-fun x9_2 () (_ BitVec 64))
(declare-fun x9_1 () (_ BitVec 64))
(declare-fun x8_44 () (_ BitVec 64))
(declare-fun x8_43 () (_ BitVec 64))
(declare-fun x7_25 () (_ BitVec 64))
(declare-fun x7_24 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x2_7 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x14_3 () (_ BitVec 64))
(declare-fun x13_5 () (_ BitVec 64))
(declare-fun x12_3 () (_ BitVec 64))
(declare-fun x11_5 () (_ BitVec 64))
(declare-fun x10_42 () (_ BitVec 64))
(declare-fun x10_41 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun tmp_2 () (_ BitVec 64))
(declare-fun tmp_1 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun g_0_low60_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_20_1 () (_ BitVec 64))
(declare-fun dcH_6 () (_ BitVec 64))
(declare-fun dcH_5 () (_ BitVec 64))
(declare-fun dcH_4 () (_ BitVec 64))
(declare-fun dcH_3 () (_ BitVec 64))
(declare-fun dc_187 () (_ BitVec 64))
(declare-fun dc_186 () (_ BitVec 1))
(declare-fun dc_185 () (_ BitVec 64))
(declare-fun dc_184 () (_ BitVec 1))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) f_0_low60_20_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (bvsle #xFFFFFFFFFFF00000 x11_5)) (bvsle x11_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x12_3)) (bvsle x12_3 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x13_5)) (bvsle x13_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x14_3)) (bvsle x14_3 #x00000000000FFFFF)) (bvsle (bvadd x11_5 x12_3) #x0000000000100000)) (bvsle (bvsub x11_5 x12_3) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 x11_5) x12_3) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 x11_5) x12_3) #x0000000000100000)) (bvsle (bvadd x13_5 x14_3) #x0000000000100000)) (bvsle (bvsub x13_5 x14_3) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 x13_5) x14_3) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 x13_5) x14_3) #x0000000000100000)) (= x6_2 #x0000020000100000)))
(assert (and (= dcH_3 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x11_5) ((_ sign_extend 64) x1_2)))) (= x9_1 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x11_5) ((_ sign_extend 64) x1_2))))))
(assert (and (= dcH_4 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x12_3)))) (= tmp_1 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x12_3))))))
(assert (and (= dc_184 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x9_1) ((_ zero_extend 1) tmp_1)))) (= x9_2 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x9_1) ((_ zero_extend 1) tmp_1))))))
(assert true)
(assert (and (= x9_2 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) f_0_low60_20_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x9_2) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x9_3 ((_ zero_extend 20) ((_ extract 63 20) x9_2))) (= dc_185 ((_ zero_extend 44) ((_ extract 19 0) x9_2)))))
(assert (and (= dcH_5 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x13_5) ((_ sign_extend 64) x1_2)))) (= x10_41 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x13_5) ((_ sign_extend 64) x1_2))))))
(assert (and (= dcH_6 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x14_3)))) (= tmp_2 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x14_3))))))
(assert (and (= dc_186 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x10_41) ((_ zero_extend 1) tmp_2)))) (= x10_42 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x10_41) ((_ zero_extend 1) tmp_2))))))
(assert true)
(assert (and (= x10_42 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) g_0_low60_20_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x10_42) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x2_7 ((_ zero_extend 20) ((_ extract 63 20) x10_42))) (= dc_187 ((_ zero_extend 44) ((_ extract 19 0) x10_42)))))
(assert true)
(assert true)
(assert (= x7_24 (bvand x9_3 #x00000000000FFFFF)))
(assert (= x8_43 (bvand x2_7 #x00000000000FFFFF)))
(assert (= x7_25 (bvor x7_24 #xFFFFFE0000000000)))
(assert (= x8_44 (bvor x8_43 #xC000000000000000)))
(assert (= neg_f_0_low60_20_low20_0_1 (bvand x9_3 #x00000000000FFFFF)))
(assert (= neg_g_0_low60_20_low20_0_1 (bvand x2_7 #x00000000000FFFFF)))
(assert (not (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_0_1)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_3e07f2.smt2
Execution time of boolector: 0.0011 seconds
OUTPUT FROM boolector:
unsat

=== Cut #4 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #4
; Range specification #66: (-1048575)@64 <=s neg_g_0_low60_20_low20_0_1
; Range condition: -1048575 <=s neg_g_0_low60_20_low20_0_1
; Output file: /tmp/outputqfbv_f8dcfc.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x9_3 () (_ BitVec 64))
(declare-fun x9_2 () (_ BitVec 64))
(declare-fun x9_1 () (_ BitVec 64))
(declare-fun x8_44 () (_ BitVec 64))
(declare-fun x8_43 () (_ BitVec 64))
(declare-fun x7_25 () (_ BitVec 64))
(declare-fun x7_24 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x2_7 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x14_3 () (_ BitVec 64))
(declare-fun x13_5 () (_ BitVec 64))
(declare-fun x12_3 () (_ BitVec 64))
(declare-fun x11_5 () (_ BitVec 64))
(declare-fun x10_42 () (_ BitVec 64))
(declare-fun x10_41 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun tmp_2 () (_ BitVec 64))
(declare-fun tmp_1 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun g_0_low60_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_20_1 () (_ BitVec 64))
(declare-fun dcH_6 () (_ BitVec 64))
(declare-fun dcH_5 () (_ BitVec 64))
(declare-fun dcH_4 () (_ BitVec 64))
(declare-fun dcH_3 () (_ BitVec 64))
(declare-fun dc_187 () (_ BitVec 64))
(declare-fun dc_186 () (_ BitVec 1))
(declare-fun dc_185 () (_ BitVec 64))
(declare-fun dc_184 () (_ BitVec 1))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) f_0_low60_20_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (bvsle #xFFFFFFFFFFF00000 x11_5)) (bvsle x11_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x12_3)) (bvsle x12_3 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x13_5)) (bvsle x13_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x14_3)) (bvsle x14_3 #x00000000000FFFFF)) (bvsle (bvadd x11_5 x12_3) #x0000000000100000)) (bvsle (bvsub x11_5 x12_3) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 x11_5) x12_3) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 x11_5) x12_3) #x0000000000100000)) (bvsle (bvadd x13_5 x14_3) #x0000000000100000)) (bvsle (bvsub x13_5 x14_3) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 x13_5) x14_3) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 x13_5) x14_3) #x0000000000100000)) (= x6_2 #x0000020000100000)))
(assert (and (= dcH_3 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x11_5) ((_ sign_extend 64) x1_2)))) (= x9_1 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x11_5) ((_ sign_extend 64) x1_2))))))
(assert (and (= dcH_4 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x12_3)))) (= tmp_1 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x12_3))))))
(assert (and (= dc_184 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x9_1) ((_ zero_extend 1) tmp_1)))) (= x9_2 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x9_1) ((_ zero_extend 1) tmp_1))))))
(assert true)
(assert (and (= x9_2 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) f_0_low60_20_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x9_2) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x9_3 ((_ zero_extend 20) ((_ extract 63 20) x9_2))) (= dc_185 ((_ zero_extend 44) ((_ extract 19 0) x9_2)))))
(assert (and (= dcH_5 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x13_5) ((_ sign_extend 64) x1_2)))) (= x10_41 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x13_5) ((_ sign_extend 64) x1_2))))))
(assert (and (= dcH_6 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x14_3)))) (= tmp_2 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x14_3))))))
(assert (and (= dc_186 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x10_41) ((_ zero_extend 1) tmp_2)))) (= x10_42 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x10_41) ((_ zero_extend 1) tmp_2))))))
(assert true)
(assert (and (= x10_42 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) g_0_low60_20_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x10_42) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x2_7 ((_ zero_extend 20) ((_ extract 63 20) x10_42))) (= dc_187 ((_ zero_extend 44) ((_ extract 19 0) x10_42)))))
(assert true)
(assert true)
(assert (= x7_24 (bvand x9_3 #x00000000000FFFFF)))
(assert (= x8_43 (bvand x2_7 #x00000000000FFFFF)))
(assert (= x7_25 (bvor x7_24 #xFFFFFE0000000000)))
(assert (= x8_44 (bvor x8_43 #xC000000000000000)))
(assert (= neg_f_0_low60_20_low20_0_1 (bvand x9_3 #x00000000000FFFFF)))
(assert (= neg_g_0_low60_20_low20_0_1 (bvand x2_7 #x00000000000FFFFF)))
(assert (not (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_0_1)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_64692a.smt2
Execution time of boolector: 0.0012 seconds
OUTPUT FROM boolector:
unsat

=== Cut #4 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #4
; Range specification #63: x8_44 = add (add neg_g_0_low60_20_low20_0_1 (mul 0@64 2097152@64)) (mul (-1048576)@64 4398046511104@64)
; Range condition: x8_44 = (neg_g_0_low60_20_low20_0_1 + (0 * 2097152)) + (-1048576 * 4398046511104)
; Output file: /tmp/outputqfbv_78c4ca.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x9_3 () (_ BitVec 64))
(declare-fun x9_2 () (_ BitVec 64))
(declare-fun x9_1 () (_ BitVec 64))
(declare-fun x8_44 () (_ BitVec 64))
(declare-fun x8_43 () (_ BitVec 64))
(declare-fun x7_25 () (_ BitVec 64))
(declare-fun x7_24 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x2_7 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x14_3 () (_ BitVec 64))
(declare-fun x13_5 () (_ BitVec 64))
(declare-fun x12_3 () (_ BitVec 64))
(declare-fun x11_5 () (_ BitVec 64))
(declare-fun x10_42 () (_ BitVec 64))
(declare-fun x10_41 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun tmp_2 () (_ BitVec 64))
(declare-fun tmp_1 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun g_0_low60_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_20_1 () (_ BitVec 64))
(declare-fun dcH_6 () (_ BitVec 64))
(declare-fun dcH_5 () (_ BitVec 64))
(declare-fun dcH_4 () (_ BitVec 64))
(declare-fun dcH_3 () (_ BitVec 64))
(declare-fun dc_187 () (_ BitVec 64))
(declare-fun dc_186 () (_ BitVec 1))
(declare-fun dc_185 () (_ BitVec 64))
(declare-fun dc_184 () (_ BitVec 1))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) f_0_low60_20_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (bvsle #xFFFFFFFFFFF00000 x11_5)) (bvsle x11_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x12_3)) (bvsle x12_3 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x13_5)) (bvsle x13_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x14_3)) (bvsle x14_3 #x00000000000FFFFF)) (bvsle (bvadd x11_5 x12_3) #x0000000000100000)) (bvsle (bvsub x11_5 x12_3) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 x11_5) x12_3) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 x11_5) x12_3) #x0000000000100000)) (bvsle (bvadd x13_5 x14_3) #x0000000000100000)) (bvsle (bvsub x13_5 x14_3) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 x13_5) x14_3) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 x13_5) x14_3) #x0000000000100000)) (= x6_2 #x0000020000100000)))
(assert (and (= dcH_3 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x11_5) ((_ sign_extend 64) x1_2)))) (= x9_1 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x11_5) ((_ sign_extend 64) x1_2))))))
(assert (and (= dcH_4 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x12_3)))) (= tmp_1 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x12_3))))))
(assert (and (= dc_184 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x9_1) ((_ zero_extend 1) tmp_1)))) (= x9_2 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x9_1) ((_ zero_extend 1) tmp_1))))))
(assert true)
(assert (and (= x9_2 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) f_0_low60_20_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x9_2) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x9_3 ((_ zero_extend 20) ((_ extract 63 20) x9_2))) (= dc_185 ((_ zero_extend 44) ((_ extract 19 0) x9_2)))))
(assert (and (= dcH_5 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x13_5) ((_ sign_extend 64) x1_2)))) (= x10_41 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x13_5) ((_ sign_extend 64) x1_2))))))
(assert (and (= dcH_6 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x14_3)))) (= tmp_2 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x14_3))))))
(assert (and (= dc_186 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x10_41) ((_ zero_extend 1) tmp_2)))) (= x10_42 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x10_41) ((_ zero_extend 1) tmp_2))))))
(assert true)
(assert (and (= x10_42 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) g_0_low60_20_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x10_42) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x2_7 ((_ zero_extend 20) ((_ extract 63 20) x10_42))) (= dc_187 ((_ zero_extend 44) ((_ extract 19 0) x10_42)))))
(assert true)
(assert true)
(assert (= x7_24 (bvand x9_3 #x00000000000FFFFF)))
(assert (= x8_43 (bvand x2_7 #x00000000000FFFFF)))
(assert (= x7_25 (bvor x7_24 #xFFFFFE0000000000)))
(assert (= x8_44 (bvor x8_43 #xC000000000000000)))
(assert (= neg_f_0_low60_20_low20_0_1 (bvand x9_3 #x00000000000FFFFF)))
(assert (= neg_g_0_low60_20_low20_0_1 (bvand x2_7 #x00000000000FFFFF)))
(assert (not (= x8_44 (bvadd (bvadd neg_g_0_low60_20_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_f8d2ad.smt2
Execution time of boolector: 0.0517 seconds
OUTPUT FROM boolector:
unsat

=== Cut #4 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #4
; Range specification #62: x7_25 = add (add neg_f_0_low60_20_low20_0_1 (mul (-1048576)@64 2097152@64)) (mul 0@64 4398046511104@64)
; Range condition: x7_25 = (neg_f_0_low60_20_low20_0_1 + (-1048576 * 2097152)) + (0 * 4398046511104)
; Output file: /tmp/outputqfbv_16234e.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x9_3 () (_ BitVec 64))
(declare-fun x9_2 () (_ BitVec 64))
(declare-fun x9_1 () (_ BitVec 64))
(declare-fun x8_44 () (_ BitVec 64))
(declare-fun x8_43 () (_ BitVec 64))
(declare-fun x7_25 () (_ BitVec 64))
(declare-fun x7_24 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x2_7 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x14_3 () (_ BitVec 64))
(declare-fun x13_5 () (_ BitVec 64))
(declare-fun x12_3 () (_ BitVec 64))
(declare-fun x11_5 () (_ BitVec 64))
(declare-fun x10_42 () (_ BitVec 64))
(declare-fun x10_41 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun tmp_2 () (_ BitVec 64))
(declare-fun tmp_1 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun g_0_low60_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_20_1 () (_ BitVec 64))
(declare-fun dcH_6 () (_ BitVec 64))
(declare-fun dcH_5 () (_ BitVec 64))
(declare-fun dcH_4 () (_ BitVec 64))
(declare-fun dcH_3 () (_ BitVec 64))
(declare-fun dc_187 () (_ BitVec 64))
(declare-fun dc_186 () (_ BitVec 1))
(declare-fun dc_185 () (_ BitVec 64))
(declare-fun dc_184 () (_ BitVec 1))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) f_0_low60_20_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (bvsle #xFFFFFFFFFFF00000 x11_5)) (bvsle x11_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x12_3)) (bvsle x12_3 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x13_5)) (bvsle x13_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x14_3)) (bvsle x14_3 #x00000000000FFFFF)) (bvsle (bvadd x11_5 x12_3) #x0000000000100000)) (bvsle (bvsub x11_5 x12_3) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 x11_5) x12_3) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 x11_5) x12_3) #x0000000000100000)) (bvsle (bvadd x13_5 x14_3) #x0000000000100000)) (bvsle (bvsub x13_5 x14_3) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 x13_5) x14_3) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 x13_5) x14_3) #x0000000000100000)) (= x6_2 #x0000020000100000)))
(assert (and (= dcH_3 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x11_5) ((_ sign_extend 64) x1_2)))) (= x9_1 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x11_5) ((_ sign_extend 64) x1_2))))))
(assert (and (= dcH_4 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x12_3)))) (= tmp_1 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x12_3))))))
(assert (and (= dc_184 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x9_1) ((_ zero_extend 1) tmp_1)))) (= x9_2 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x9_1) ((_ zero_extend 1) tmp_1))))))
(assert true)
(assert (and (= x9_2 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) f_0_low60_20_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x9_2) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x9_3 ((_ zero_extend 20) ((_ extract 63 20) x9_2))) (= dc_185 ((_ zero_extend 44) ((_ extract 19 0) x9_2)))))
(assert (and (= dcH_5 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x13_5) ((_ sign_extend 64) x1_2)))) (= x10_41 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x13_5) ((_ sign_extend 64) x1_2))))))
(assert (and (= dcH_6 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x14_3)))) (= tmp_2 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x14_3))))))
(assert (and (= dc_186 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x10_41) ((_ zero_extend 1) tmp_2)))) (= x10_42 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x10_41) ((_ zero_extend 1) tmp_2))))))
(assert true)
(assert (and (= x10_42 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) g_0_low60_20_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x10_42) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x2_7 ((_ zero_extend 20) ((_ extract 63 20) x10_42))) (= dc_187 ((_ zero_extend 44) ((_ extract 19 0) x10_42)))))
(assert true)
(assert true)
(assert (= x7_24 (bvand x9_3 #x00000000000FFFFF)))
(assert (= x8_43 (bvand x2_7 #x00000000000FFFFF)))
(assert (= x7_25 (bvor x7_24 #xFFFFFE0000000000)))
(assert (= x8_44 (bvor x8_43 #xC000000000000000)))
(assert (= neg_f_0_low60_20_low20_0_1 (bvand x9_3 #x00000000000FFFFF)))
(assert (= neg_g_0_low60_20_low20_0_1 (bvand x2_7 #x00000000000FFFFF)))
(assert (not (= x7_25 (bvadd (bvadd neg_f_0_low60_20_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000)))))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_6d5710.smt2
Execution time of boolector: 0.1073 seconds
OUTPUT FROM boolector:
unsat

=== Cut #4 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #4
; Range specification #67: neg_g_0_low60_20_low20_0_1 <=s 1048575@64
; Range condition: neg_g_0_low60_20_low20_0_1 <=s 1048575
; Output file: /tmp/outputqfbv_ecb5b3.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x9_3 () (_ BitVec 64))
(declare-fun x9_2 () (_ BitVec 64))
(declare-fun x9_1 () (_ BitVec 64))
(declare-fun x8_44 () (_ BitVec 64))
(declare-fun x8_43 () (_ BitVec 64))
(declare-fun x7_25 () (_ BitVec 64))
(declare-fun x7_24 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x2_7 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x14_3 () (_ BitVec 64))
(declare-fun x13_5 () (_ BitVec 64))
(declare-fun x12_3 () (_ BitVec 64))
(declare-fun x11_5 () (_ BitVec 64))
(declare-fun x10_42 () (_ BitVec 64))
(declare-fun x10_41 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun tmp_2 () (_ BitVec 64))
(declare-fun tmp_1 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun g_0_low60_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_20_1 () (_ BitVec 64))
(declare-fun dcH_6 () (_ BitVec 64))
(declare-fun dcH_5 () (_ BitVec 64))
(declare-fun dcH_4 () (_ BitVec 64))
(declare-fun dcH_3 () (_ BitVec 64))
(declare-fun dc_187 () (_ BitVec 64))
(declare-fun dc_186 () (_ BitVec 1))
(declare-fun dc_185 () (_ BitVec 64))
(declare-fun dc_184 () (_ BitVec 1))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) f_0_low60_20_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (bvsle #xFFFFFFFFFFF00000 x11_5)) (bvsle x11_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x12_3)) (bvsle x12_3 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x13_5)) (bvsle x13_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x14_3)) (bvsle x14_3 #x00000000000FFFFF)) (bvsle (bvadd x11_5 x12_3) #x0000000000100000)) (bvsle (bvsub x11_5 x12_3) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 x11_5) x12_3) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 x11_5) x12_3) #x0000000000100000)) (bvsle (bvadd x13_5 x14_3) #x0000000000100000)) (bvsle (bvsub x13_5 x14_3) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 x13_5) x14_3) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 x13_5) x14_3) #x0000000000100000)) (= x6_2 #x0000020000100000)))
(assert (and (= dcH_3 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x11_5) ((_ sign_extend 64) x1_2)))) (= x9_1 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x11_5) ((_ sign_extend 64) x1_2))))))
(assert (and (= dcH_4 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x12_3)))) (= tmp_1 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x12_3))))))
(assert (and (= dc_184 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x9_1) ((_ zero_extend 1) tmp_1)))) (= x9_2 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x9_1) ((_ zero_extend 1) tmp_1))))))
(assert true)
(assert (and (= x9_2 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) f_0_low60_20_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x9_2) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x9_3 ((_ zero_extend 20) ((_ extract 63 20) x9_2))) (= dc_185 ((_ zero_extend 44) ((_ extract 19 0) x9_2)))))
(assert (and (= dcH_5 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x13_5) ((_ sign_extend 64) x1_2)))) (= x10_41 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x13_5) ((_ sign_extend 64) x1_2))))))
(assert (and (= dcH_6 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x14_3)))) (= tmp_2 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x14_3))))))
(assert (and (= dc_186 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x10_41) ((_ zero_extend 1) tmp_2)))) (= x10_42 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x10_41) ((_ zero_extend 1) tmp_2))))))
(assert true)
(assert (and (= x10_42 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) g_0_low60_20_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x10_42) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x2_7 ((_ zero_extend 20) ((_ extract 63 20) x10_42))) (= dc_187 ((_ zero_extend 44) ((_ extract 19 0) x10_42)))))
(assert true)
(assert true)
(assert (= x7_24 (bvand x9_3 #x00000000000FFFFF)))
(assert (= x8_43 (bvand x2_7 #x00000000000FFFFF)))
(assert (= x7_25 (bvor x7_24 #xFFFFFE0000000000)))
(assert (= x8_44 (bvor x8_43 #xC000000000000000)))
(assert (= neg_f_0_low60_20_low20_0_1 (bvand x9_3 #x00000000000FFFFF)))
(assert (= neg_g_0_low60_20_low20_0_1 (bvand x2_7 #x00000000000FFFFF)))
(assert (not (bvsle neg_g_0_low60_20_low20_0_1 #x00000000000FFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_de6da2.smt2
Execution time of boolector: 0.0552 seconds
OUTPUT FROM boolector:
unsat

=== Cut #4 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #4
; Range specification #72: (-1048576)@64 = (-1048576)@64
; Range condition: -1048576 = -1048576
; Output file: /tmp/outputqfbv_c6d5cb.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x9_3 () (_ BitVec 64))
(declare-fun x9_2 () (_ BitVec 64))
(declare-fun x9_1 () (_ BitVec 64))
(declare-fun x8_44 () (_ BitVec 64))
(declare-fun x8_43 () (_ BitVec 64))
(declare-fun x7_25 () (_ BitVec 64))
(declare-fun x7_24 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x2_7 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x14_3 () (_ BitVec 64))
(declare-fun x13_5 () (_ BitVec 64))
(declare-fun x12_3 () (_ BitVec 64))
(declare-fun x11_5 () (_ BitVec 64))
(declare-fun x10_42 () (_ BitVec 64))
(declare-fun x10_41 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun tmp_2 () (_ BitVec 64))
(declare-fun tmp_1 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun g_0_low60_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_20_1 () (_ BitVec 64))
(declare-fun dcH_6 () (_ BitVec 64))
(declare-fun dcH_5 () (_ BitVec 64))
(declare-fun dcH_4 () (_ BitVec 64))
(declare-fun dcH_3 () (_ BitVec 64))
(declare-fun dc_187 () (_ BitVec 64))
(declare-fun dc_186 () (_ BitVec 1))
(declare-fun dc_185 () (_ BitVec 64))
(declare-fun dc_184 () (_ BitVec 1))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) f_0_low60_20_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (bvsle #xFFFFFFFFFFF00000 x11_5)) (bvsle x11_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x12_3)) (bvsle x12_3 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x13_5)) (bvsle x13_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x14_3)) (bvsle x14_3 #x00000000000FFFFF)) (bvsle (bvadd x11_5 x12_3) #x0000000000100000)) (bvsle (bvsub x11_5 x12_3) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 x11_5) x12_3) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 x11_5) x12_3) #x0000000000100000)) (bvsle (bvadd x13_5 x14_3) #x0000000000100000)) (bvsle (bvsub x13_5 x14_3) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 x13_5) x14_3) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 x13_5) x14_3) #x0000000000100000)) (= x6_2 #x0000020000100000)))
(assert (and (= dcH_3 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x11_5) ((_ sign_extend 64) x1_2)))) (= x9_1 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x11_5) ((_ sign_extend 64) x1_2))))))
(assert (and (= dcH_4 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x12_3)))) (= tmp_1 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x12_3))))))
(assert (and (= dc_184 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x9_1) ((_ zero_extend 1) tmp_1)))) (= x9_2 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x9_1) ((_ zero_extend 1) tmp_1))))))
(assert true)
(assert (and (= x9_2 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) f_0_low60_20_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x9_2) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x9_3 ((_ zero_extend 20) ((_ extract 63 20) x9_2))) (= dc_185 ((_ zero_extend 44) ((_ extract 19 0) x9_2)))))
(assert (and (= dcH_5 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x13_5) ((_ sign_extend 64) x1_2)))) (= x10_41 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x13_5) ((_ sign_extend 64) x1_2))))))
(assert (and (= dcH_6 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x14_3)))) (= tmp_2 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x14_3))))))
(assert (and (= dc_186 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x10_41) ((_ zero_extend 1) tmp_2)))) (= x10_42 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x10_41) ((_ zero_extend 1) tmp_2))))))
(assert true)
(assert (and (= x10_42 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) g_0_low60_20_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x10_42) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x2_7 ((_ zero_extend 20) ((_ extract 63 20) x10_42))) (= dc_187 ((_ zero_extend 44) ((_ extract 19 0) x10_42)))))
(assert true)
(assert true)
(assert (= x7_24 (bvand x9_3 #x00000000000FFFFF)))
(assert (= x8_43 (bvand x2_7 #x00000000000FFFFF)))
(assert (= x7_25 (bvor x7_24 #xFFFFFE0000000000)))
(assert (= x8_44 (bvor x8_43 #xC000000000000000)))
(assert (= neg_f_0_low60_20_low20_0_1 (bvand x9_3 #x00000000000FFFFF)))
(assert (= neg_g_0_low60_20_low20_0_1 (bvand x2_7 #x00000000000FFFFF)))
(assert (not (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_dc15a8.smt2
Execution time of boolector: 0.0010 seconds
OUTPUT FROM boolector:
unsat

=== Cut #4 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #4
; Range specification #73: 0@64 = 0@64
; Range condition: 0 = 0
; Output file: /tmp/outputqfbv_a46f1f.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x9_3 () (_ BitVec 64))
(declare-fun x9_2 () (_ BitVec 64))
(declare-fun x9_1 () (_ BitVec 64))
(declare-fun x8_44 () (_ BitVec 64))
(declare-fun x8_43 () (_ BitVec 64))
(declare-fun x7_25 () (_ BitVec 64))
(declare-fun x7_24 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x2_7 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x14_3 () (_ BitVec 64))
(declare-fun x13_5 () (_ BitVec 64))
(declare-fun x12_3 () (_ BitVec 64))
(declare-fun x11_5 () (_ BitVec 64))
(declare-fun x10_42 () (_ BitVec 64))
(declare-fun x10_41 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun tmp_2 () (_ BitVec 64))
(declare-fun tmp_1 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun g_0_low60_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_20_1 () (_ BitVec 64))
(declare-fun dcH_6 () (_ BitVec 64))
(declare-fun dcH_5 () (_ BitVec 64))
(declare-fun dcH_4 () (_ BitVec 64))
(declare-fun dcH_3 () (_ BitVec 64))
(declare-fun dc_187 () (_ BitVec 64))
(declare-fun dc_186 () (_ BitVec 1))
(declare-fun dc_185 () (_ BitVec 64))
(declare-fun dc_184 () (_ BitVec 1))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) f_0_low60_20_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (bvsle #xFFFFFFFFFFF00000 x11_5)) (bvsle x11_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x12_3)) (bvsle x12_3 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x13_5)) (bvsle x13_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x14_3)) (bvsle x14_3 #x00000000000FFFFF)) (bvsle (bvadd x11_5 x12_3) #x0000000000100000)) (bvsle (bvsub x11_5 x12_3) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 x11_5) x12_3) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 x11_5) x12_3) #x0000000000100000)) (bvsle (bvadd x13_5 x14_3) #x0000000000100000)) (bvsle (bvsub x13_5 x14_3) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 x13_5) x14_3) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 x13_5) x14_3) #x0000000000100000)) (= x6_2 #x0000020000100000)))
(assert (and (= dcH_3 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x11_5) ((_ sign_extend 64) x1_2)))) (= x9_1 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x11_5) ((_ sign_extend 64) x1_2))))))
(assert (and (= dcH_4 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x12_3)))) (= tmp_1 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x12_3))))))
(assert (and (= dc_184 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x9_1) ((_ zero_extend 1) tmp_1)))) (= x9_2 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x9_1) ((_ zero_extend 1) tmp_1))))))
(assert true)
(assert (and (= x9_2 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) f_0_low60_20_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x9_2) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x9_3 ((_ zero_extend 20) ((_ extract 63 20) x9_2))) (= dc_185 ((_ zero_extend 44) ((_ extract 19 0) x9_2)))))
(assert (and (= dcH_5 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x13_5) ((_ sign_extend 64) x1_2)))) (= x10_41 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x13_5) ((_ sign_extend 64) x1_2))))))
(assert (and (= dcH_6 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x14_3)))) (= tmp_2 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x14_3))))))
(assert (and (= dc_186 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x10_41) ((_ zero_extend 1) tmp_2)))) (= x10_42 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x10_41) ((_ zero_extend 1) tmp_2))))))
(assert true)
(assert (and (= x10_42 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) g_0_low60_20_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x10_42) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x2_7 ((_ zero_extend 20) ((_ extract 63 20) x10_42))) (= dc_187 ((_ zero_extend 44) ((_ extract 19 0) x10_42)))))
(assert true)
(assert true)
(assert (= x7_24 (bvand x9_3 #x00000000000FFFFF)))
(assert (= x8_43 (bvand x2_7 #x00000000000FFFFF)))
(assert (= x7_25 (bvor x7_24 #xFFFFFE0000000000)))
(assert (= x8_44 (bvor x8_43 #xC000000000000000)))
(assert (= neg_f_0_low60_20_low20_0_1 (bvand x9_3 #x00000000000FFFFF)))
(assert (= neg_g_0_low60_20_low20_0_1 (bvand x2_7 #x00000000000FFFFF)))
(assert (not (= #x0000000000000000 #x0000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_a20fbf.smt2
Execution time of boolector: 0.0009 seconds
OUTPUT FROM boolector:
unsat

=== Cut #4 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #4
; Range specification #74: 0@64 = 0@64
; Range condition: 0 = 0
; Output file: /tmp/outputqfbv_189a43.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x9_3 () (_ BitVec 64))
(declare-fun x9_2 () (_ BitVec 64))
(declare-fun x9_1 () (_ BitVec 64))
(declare-fun x8_44 () (_ BitVec 64))
(declare-fun x8_43 () (_ BitVec 64))
(declare-fun x7_25 () (_ BitVec 64))
(declare-fun x7_24 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x2_7 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x14_3 () (_ BitVec 64))
(declare-fun x13_5 () (_ BitVec 64))
(declare-fun x12_3 () (_ BitVec 64))
(declare-fun x11_5 () (_ BitVec 64))
(declare-fun x10_42 () (_ BitVec 64))
(declare-fun x10_41 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun tmp_2 () (_ BitVec 64))
(declare-fun tmp_1 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun g_0_low60_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_20_1 () (_ BitVec 64))
(declare-fun dcH_6 () (_ BitVec 64))
(declare-fun dcH_5 () (_ BitVec 64))
(declare-fun dcH_4 () (_ BitVec 64))
(declare-fun dcH_3 () (_ BitVec 64))
(declare-fun dc_187 () (_ BitVec 64))
(declare-fun dc_186 () (_ BitVec 1))
(declare-fun dc_185 () (_ BitVec 64))
(declare-fun dc_184 () (_ BitVec 1))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) f_0_low60_20_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (bvsle #xFFFFFFFFFFF00000 x11_5)) (bvsle x11_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x12_3)) (bvsle x12_3 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x13_5)) (bvsle x13_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x14_3)) (bvsle x14_3 #x00000000000FFFFF)) (bvsle (bvadd x11_5 x12_3) #x0000000000100000)) (bvsle (bvsub x11_5 x12_3) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 x11_5) x12_3) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 x11_5) x12_3) #x0000000000100000)) (bvsle (bvadd x13_5 x14_3) #x0000000000100000)) (bvsle (bvsub x13_5 x14_3) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 x13_5) x14_3) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 x13_5) x14_3) #x0000000000100000)) (= x6_2 #x0000020000100000)))
(assert (and (= dcH_3 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x11_5) ((_ sign_extend 64) x1_2)))) (= x9_1 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x11_5) ((_ sign_extend 64) x1_2))))))
(assert (and (= dcH_4 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x12_3)))) (= tmp_1 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x12_3))))))
(assert (and (= dc_184 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x9_1) ((_ zero_extend 1) tmp_1)))) (= x9_2 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x9_1) ((_ zero_extend 1) tmp_1))))))
(assert true)
(assert (and (= x9_2 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) f_0_low60_20_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x9_2) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x9_3 ((_ zero_extend 20) ((_ extract 63 20) x9_2))) (= dc_185 ((_ zero_extend 44) ((_ extract 19 0) x9_2)))))
(assert (and (= dcH_5 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x13_5) ((_ sign_extend 64) x1_2)))) (= x10_41 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x13_5) ((_ sign_extend 64) x1_2))))))
(assert (and (= dcH_6 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x14_3)))) (= tmp_2 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x14_3))))))
(assert (and (= dc_186 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x10_41) ((_ zero_extend 1) tmp_2)))) (= x10_42 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x10_41) ((_ zero_extend 1) tmp_2))))))
(assert true)
(assert (and (= x10_42 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) g_0_low60_20_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x10_42) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x2_7 ((_ zero_extend 20) ((_ extract 63 20) x10_42))) (= dc_187 ((_ zero_extend 44) ((_ extract 19 0) x10_42)))))
(assert true)
(assert true)
(assert (= x7_24 (bvand x9_3 #x00000000000FFFFF)))
(assert (= x8_43 (bvand x2_7 #x00000000000FFFFF)))
(assert (= x7_25 (bvor x7_24 #xFFFFFE0000000000)))
(assert (= x8_44 (bvor x8_43 #xC000000000000000)))
(assert (= neg_f_0_low60_20_low20_0_1 (bvand x9_3 #x00000000000FFFFF)))
(assert (= neg_g_0_low60_20_low20_0_1 (bvand x2_7 #x00000000000FFFFF)))
(assert (not (= #x0000000000000000 #x0000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_74828c.smt2
Execution time of boolector: 0.0009 seconds
OUTPUT FROM boolector:
unsat

=== Cut #4 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #4
; Range specification #75: (-1048576)@64 = (-1048576)@64
; Range condition: -1048576 = -1048576
; Output file: /tmp/outputqfbv_6fc74a.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x9_3 () (_ BitVec 64))
(declare-fun x9_2 () (_ BitVec 64))
(declare-fun x9_1 () (_ BitVec 64))
(declare-fun x8_44 () (_ BitVec 64))
(declare-fun x8_43 () (_ BitVec 64))
(declare-fun x7_25 () (_ BitVec 64))
(declare-fun x7_24 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x2_7 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x14_3 () (_ BitVec 64))
(declare-fun x13_5 () (_ BitVec 64))
(declare-fun x12_3 () (_ BitVec 64))
(declare-fun x11_5 () (_ BitVec 64))
(declare-fun x10_42 () (_ BitVec 64))
(declare-fun x10_41 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun tmp_2 () (_ BitVec 64))
(declare-fun tmp_1 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun g_0_low60_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_20_1 () (_ BitVec 64))
(declare-fun dcH_6 () (_ BitVec 64))
(declare-fun dcH_5 () (_ BitVec 64))
(declare-fun dcH_4 () (_ BitVec 64))
(declare-fun dcH_3 () (_ BitVec 64))
(declare-fun dc_187 () (_ BitVec 64))
(declare-fun dc_186 () (_ BitVec 1))
(declare-fun dc_185 () (_ BitVec 64))
(declare-fun dc_184 () (_ BitVec 1))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) f_0_low60_20_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (bvsle #xFFFFFFFFFFF00000 x11_5)) (bvsle x11_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x12_3)) (bvsle x12_3 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x13_5)) (bvsle x13_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x14_3)) (bvsle x14_3 #x00000000000FFFFF)) (bvsle (bvadd x11_5 x12_3) #x0000000000100000)) (bvsle (bvsub x11_5 x12_3) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 x11_5) x12_3) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 x11_5) x12_3) #x0000000000100000)) (bvsle (bvadd x13_5 x14_3) #x0000000000100000)) (bvsle (bvsub x13_5 x14_3) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 x13_5) x14_3) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 x13_5) x14_3) #x0000000000100000)) (= x6_2 #x0000020000100000)))
(assert (and (= dcH_3 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x11_5) ((_ sign_extend 64) x1_2)))) (= x9_1 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x11_5) ((_ sign_extend 64) x1_2))))))
(assert (and (= dcH_4 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x12_3)))) (= tmp_1 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x12_3))))))
(assert (and (= dc_184 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x9_1) ((_ zero_extend 1) tmp_1)))) (= x9_2 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x9_1) ((_ zero_extend 1) tmp_1))))))
(assert true)
(assert (and (= x9_2 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) f_0_low60_20_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x9_2) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x9_3 ((_ zero_extend 20) ((_ extract 63 20) x9_2))) (= dc_185 ((_ zero_extend 44) ((_ extract 19 0) x9_2)))))
(assert (and (= dcH_5 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x13_5) ((_ sign_extend 64) x1_2)))) (= x10_41 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x13_5) ((_ sign_extend 64) x1_2))))))
(assert (and (= dcH_6 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x14_3)))) (= tmp_2 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x14_3))))))
(assert (and (= dc_186 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x10_41) ((_ zero_extend 1) tmp_2)))) (= x10_42 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x10_41) ((_ zero_extend 1) tmp_2))))))
(assert true)
(assert (and (= x10_42 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) g_0_low60_20_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x10_42) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x2_7 ((_ zero_extend 20) ((_ extract 63 20) x10_42))) (= dc_187 ((_ zero_extend 44) ((_ extract 19 0) x10_42)))))
(assert true)
(assert true)
(assert (= x7_24 (bvand x9_3 #x00000000000FFFFF)))
(assert (= x8_43 (bvand x2_7 #x00000000000FFFFF)))
(assert (= x7_25 (bvor x7_24 #xFFFFFE0000000000)))
(assert (= x8_44 (bvor x8_43 #xC000000000000000)))
(assert (= neg_f_0_low60_20_low20_0_1 (bvand x9_3 #x00000000000FFFFF)))
(assert (= neg_g_0_low60_20_low20_0_1 (bvand x2_7 #x00000000000FFFFF)))
(assert (not (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_dfc6a4.smt2
Execution time of boolector: 0.0010 seconds
OUTPUT FROM boolector:
unsat

=== Cut #4 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #4
; Range specification #65: neg_f_0_low60_20_low20_0_1 <=s 1048575@64
; Range condition: neg_f_0_low60_20_low20_0_1 <=s 1048575
; Output file: /tmp/outputqfbv_211aa7.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x9_3 () (_ BitVec 64))
(declare-fun x9_2 () (_ BitVec 64))
(declare-fun x9_1 () (_ BitVec 64))
(declare-fun x8_44 () (_ BitVec 64))
(declare-fun x8_43 () (_ BitVec 64))
(declare-fun x7_25 () (_ BitVec 64))
(declare-fun x7_24 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x2_7 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x14_3 () (_ BitVec 64))
(declare-fun x13_5 () (_ BitVec 64))
(declare-fun x12_3 () (_ BitVec 64))
(declare-fun x11_5 () (_ BitVec 64))
(declare-fun x10_42 () (_ BitVec 64))
(declare-fun x10_41 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun tmp_2 () (_ BitVec 64))
(declare-fun tmp_1 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun g_0_low60_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_20_1 () (_ BitVec 64))
(declare-fun dcH_6 () (_ BitVec 64))
(declare-fun dcH_5 () (_ BitVec 64))
(declare-fun dcH_4 () (_ BitVec 64))
(declare-fun dcH_3 () (_ BitVec 64))
(declare-fun dc_187 () (_ BitVec 64))
(declare-fun dc_186 () (_ BitVec 1))
(declare-fun dc_185 () (_ BitVec 64))
(declare-fun dc_184 () (_ BitVec 1))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) f_0_low60_20_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (bvsle #xFFFFFFFFFFF00000 x11_5)) (bvsle x11_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x12_3)) (bvsle x12_3 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x13_5)) (bvsle x13_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x14_3)) (bvsle x14_3 #x00000000000FFFFF)) (bvsle (bvadd x11_5 x12_3) #x0000000000100000)) (bvsle (bvsub x11_5 x12_3) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 x11_5) x12_3) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 x11_5) x12_3) #x0000000000100000)) (bvsle (bvadd x13_5 x14_3) #x0000000000100000)) (bvsle (bvsub x13_5 x14_3) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 x13_5) x14_3) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 x13_5) x14_3) #x0000000000100000)) (= x6_2 #x0000020000100000)))
(assert (and (= dcH_3 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x11_5) ((_ sign_extend 64) x1_2)))) (= x9_1 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x11_5) ((_ sign_extend 64) x1_2))))))
(assert (and (= dcH_4 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x12_3)))) (= tmp_1 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x12_3))))))
(assert (and (= dc_184 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x9_1) ((_ zero_extend 1) tmp_1)))) (= x9_2 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x9_1) ((_ zero_extend 1) tmp_1))))))
(assert true)
(assert (and (= x9_2 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) f_0_low60_20_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x9_2) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x9_3 ((_ zero_extend 20) ((_ extract 63 20) x9_2))) (= dc_185 ((_ zero_extend 44) ((_ extract 19 0) x9_2)))))
(assert (and (= dcH_5 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x13_5) ((_ sign_extend 64) x1_2)))) (= x10_41 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x13_5) ((_ sign_extend 64) x1_2))))))
(assert (and (= dcH_6 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x14_3)))) (= tmp_2 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x14_3))))))
(assert (and (= dc_186 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x10_41) ((_ zero_extend 1) tmp_2)))) (= x10_42 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x10_41) ((_ zero_extend 1) tmp_2))))))
(assert true)
(assert (and (= x10_42 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) g_0_low60_20_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x10_42) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x2_7 ((_ zero_extend 20) ((_ extract 63 20) x10_42))) (= dc_187 ((_ zero_extend 44) ((_ extract 19 0) x10_42)))))
(assert true)
(assert true)
(assert (= x7_24 (bvand x9_3 #x00000000000FFFFF)))
(assert (= x8_43 (bvand x2_7 #x00000000000FFFFF)))
(assert (= x7_25 (bvor x7_24 #xFFFFFE0000000000)))
(assert (= x8_44 (bvor x8_43 #xC000000000000000)))
(assert (= neg_f_0_low60_20_low20_0_1 (bvand x9_3 #x00000000000FFFFF)))
(assert (= neg_g_0_low60_20_low20_0_1 (bvand x2_7 #x00000000000FFFFF)))
(assert (not (bvsle neg_f_0_low60_20_low20_0_1 #x00000000000FFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_6dfbfc.smt2
Execution time of boolector: 0.1091 seconds
OUTPUT FROM boolector:
unsat

=== Cut #7 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #7
; Range specification #115: (-1048576)@64 <=s x15_5
; Range condition: -1048576 <=s x15_5
; Output file: /tmp/outputqfbv_29d906.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_82 () (_ BitVec 64))
(declare-fun x7_44 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_79 () (_ BitVec 64))
(declare-fun x20_3 () (_ BitVec 64))
(declare-fun x20_2 () (_ BitVec 64))
(declare-fun x20_1 () (_ BitVec 64))
(declare-fun x17_5 () (_ BitVec 64))
(declare-fun x17_4 () (_ BitVec 64))
(declare-fun x17_3 () (_ BitVec 64))
(declare-fun x17_2 () (_ BitVec 64))
(declare-fun x17_1 () (_ BitVec 64))
(declare-fun x16_3 () (_ BitVec 64))
(declare-fun x16_2 () (_ BitVec 64))
(declare-fun x16_1 () (_ BitVec 64))
(declare-fun x15_5 () (_ BitVec 64))
(declare-fun x15_4 () (_ BitVec 64))
(declare-fun x15_3 () (_ BitVec 64))
(declare-fun x15_2 () (_ BitVec 64))
(declare-fun x15_1 () (_ BitVec 64))
(declare-fun v_20_40_2 () (_ BitVec 64))
(declare-fun u_20_40_2 () (_ BitVec 64))
(declare-fun s_20_40_2 () (_ BitVec 64))
(declare-fun r_20_40_2 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_20_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_40_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_20_1 () (_ BitVec 64))
(declare-fun dcH_8 () (_ BitVec 64))
(declare-fun dcH_7 () (_ BitVec 64))
(declare-fun dc_323 () (_ BitVec 64))
(declare-fun dc_322 () (_ BitVec 64))
(declare-fun dc_321 () (_ BitVec 64))
(declare-fun dc_320 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_44 (bvadd (bvadd neg_f_0_low60_20_low20_20_1 (bvmul u_20_40_2 #x0000000000200000)) (bvmul v_20_40_2 #x0000040000000000))) (= x8_82 (bvadd (bvadd neg_g_0_low60_20_low20_20_1 (bvmul r_20_40_2 #x0000000000200000)) (bvmul s_20_40_2 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_20_1)) (bvsle neg_f_0_low60_20_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_20_1)) (bvsle neg_g_0_low60_20_low20_20_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) neg_f_0_low60_40_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_79) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFB1 x3_79)) (bvsle x3_79 #x0000000000000051)) (bvsle #xFFFFFFFFFFF00000 u_20_40_2)) (bvsle u_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 v_20_40_2)) (bvsle v_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 r_20_40_2)) (bvsle r_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 s_20_40_2)) (bvsle s_20_40_2 #x00000000000FFFFF)) (= x6_2 #x0000020000100000)))
(assert (= x16_1 (bvadd x7_44 x6_2)))
(assert (= x16_2 x16_1))
(assert (and (= x16_3 ((_ sign_extend 42) ((_ extract 63 42) x16_2))) (= dc_320 ((_ zero_extend 22) ((_ extract 41 0) x16_2)))))
(assert (= x15_1 (bvadd x7_44 #x0000000000100000)))
(assert (and (= dcH_7 ((_ sign_extend 42) ((_ extract 63 42) x15_1))) (= x15_2 ((_ zero_extend 22) ((_ extract 41 0) x15_1)))))
(assert (= x15_3 (bvshl x15_2 #x0000000000000016)))
(assert (= x15_4 x15_3))
(assert (and (= x15_5 ((_ sign_extend 43) ((_ extract 63 43) x15_4))) (= dc_321 ((_ zero_extend 21) ((_ extract 42 0) x15_4)))))
(assert (= x20_1 (bvadd x8_82 x6_2)))
(assert (= x20_2 x20_1))
(assert (and (= x20_3 ((_ sign_extend 42) ((_ extract 63 42) x20_2))) (= dc_322 ((_ zero_extend 22) ((_ extract 41 0) x20_2)))))
(assert (= x17_1 (bvadd x8_82 #x0000000000100000)))
(assert (and (= dcH_8 ((_ sign_extend 42) ((_ extract 63 42) x17_1))) (= x17_2 ((_ zero_extend 22) ((_ extract 41 0) x17_1)))))
(assert (= x17_3 (bvshl x17_2 #x0000000000000016)))
(assert (= x17_4 x17_3))
(assert (and (= x17_5 ((_ sign_extend 43) ((_ extract 63 43) x17_4))) (= dc_323 ((_ zero_extend 21) ((_ extract 42 0) x17_4)))))
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert (not (bvsle #xFFFFFFFFFFF00000 x15_5)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_f774ea.smt2
Execution time of boolector: 0.0033 seconds
OUTPUT FROM boolector:
unsat

=== Cut #7 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #7
; Range specification #116: x15_5 <=s 1048575@64
; Range condition: x15_5 <=s 1048575
; Output file: /tmp/outputqfbv_a22948.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_82 () (_ BitVec 64))
(declare-fun x7_44 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_79 () (_ BitVec 64))
(declare-fun x20_3 () (_ BitVec 64))
(declare-fun x20_2 () (_ BitVec 64))
(declare-fun x20_1 () (_ BitVec 64))
(declare-fun x17_5 () (_ BitVec 64))
(declare-fun x17_4 () (_ BitVec 64))
(declare-fun x17_3 () (_ BitVec 64))
(declare-fun x17_2 () (_ BitVec 64))
(declare-fun x17_1 () (_ BitVec 64))
(declare-fun x16_3 () (_ BitVec 64))
(declare-fun x16_2 () (_ BitVec 64))
(declare-fun x16_1 () (_ BitVec 64))
(declare-fun x15_5 () (_ BitVec 64))
(declare-fun x15_4 () (_ BitVec 64))
(declare-fun x15_3 () (_ BitVec 64))
(declare-fun x15_2 () (_ BitVec 64))
(declare-fun x15_1 () (_ BitVec 64))
(declare-fun v_20_40_2 () (_ BitVec 64))
(declare-fun u_20_40_2 () (_ BitVec 64))
(declare-fun s_20_40_2 () (_ BitVec 64))
(declare-fun r_20_40_2 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_20_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_40_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_20_1 () (_ BitVec 64))
(declare-fun dcH_8 () (_ BitVec 64))
(declare-fun dcH_7 () (_ BitVec 64))
(declare-fun dc_323 () (_ BitVec 64))
(declare-fun dc_322 () (_ BitVec 64))
(declare-fun dc_321 () (_ BitVec 64))
(declare-fun dc_320 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_44 (bvadd (bvadd neg_f_0_low60_20_low20_20_1 (bvmul u_20_40_2 #x0000000000200000)) (bvmul v_20_40_2 #x0000040000000000))) (= x8_82 (bvadd (bvadd neg_g_0_low60_20_low20_20_1 (bvmul r_20_40_2 #x0000000000200000)) (bvmul s_20_40_2 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_20_1)) (bvsle neg_f_0_low60_20_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_20_1)) (bvsle neg_g_0_low60_20_low20_20_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) neg_f_0_low60_40_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_79) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFB1 x3_79)) (bvsle x3_79 #x0000000000000051)) (bvsle #xFFFFFFFFFFF00000 u_20_40_2)) (bvsle u_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 v_20_40_2)) (bvsle v_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 r_20_40_2)) (bvsle r_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 s_20_40_2)) (bvsle s_20_40_2 #x00000000000FFFFF)) (= x6_2 #x0000020000100000)))
(assert (= x16_1 (bvadd x7_44 x6_2)))
(assert (= x16_2 x16_1))
(assert (and (= x16_3 ((_ sign_extend 42) ((_ extract 63 42) x16_2))) (= dc_320 ((_ zero_extend 22) ((_ extract 41 0) x16_2)))))
(assert (= x15_1 (bvadd x7_44 #x0000000000100000)))
(assert (and (= dcH_7 ((_ sign_extend 42) ((_ extract 63 42) x15_1))) (= x15_2 ((_ zero_extend 22) ((_ extract 41 0) x15_1)))))
(assert (= x15_3 (bvshl x15_2 #x0000000000000016)))
(assert (= x15_4 x15_3))
(assert (and (= x15_5 ((_ sign_extend 43) ((_ extract 63 43) x15_4))) (= dc_321 ((_ zero_extend 21) ((_ extract 42 0) x15_4)))))
(assert (= x20_1 (bvadd x8_82 x6_2)))
(assert (= x20_2 x20_1))
(assert (and (= x20_3 ((_ sign_extend 42) ((_ extract 63 42) x20_2))) (= dc_322 ((_ zero_extend 22) ((_ extract 41 0) x20_2)))))
(assert (= x17_1 (bvadd x8_82 #x0000000000100000)))
(assert (and (= dcH_8 ((_ sign_extend 42) ((_ extract 63 42) x17_1))) (= x17_2 ((_ zero_extend 22) ((_ extract 41 0) x17_1)))))
(assert (= x17_3 (bvshl x17_2 #x0000000000000016)))
(assert (= x17_4 x17_3))
(assert (and (= x17_5 ((_ sign_extend 43) ((_ extract 63 43) x17_4))) (= dc_323 ((_ zero_extend 21) ((_ extract 42 0) x17_4)))))
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert (not (bvsle x15_5 #x00000000000FFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_672a3a.smt2
Execution time of boolector: 0.0033 seconds
OUTPUT FROM boolector:
unsat

=== Cut #7 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #7
; Range specification #117: (-1048576)@64 <=s x16_3
; Range condition: -1048576 <=s x16_3
; Output file: /tmp/outputqfbv_272c52.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_82 () (_ BitVec 64))
(declare-fun x7_44 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_79 () (_ BitVec 64))
(declare-fun x20_3 () (_ BitVec 64))
(declare-fun x20_2 () (_ BitVec 64))
(declare-fun x20_1 () (_ BitVec 64))
(declare-fun x17_5 () (_ BitVec 64))
(declare-fun x17_4 () (_ BitVec 64))
(declare-fun x17_3 () (_ BitVec 64))
(declare-fun x17_2 () (_ BitVec 64))
(declare-fun x17_1 () (_ BitVec 64))
(declare-fun x16_3 () (_ BitVec 64))
(declare-fun x16_2 () (_ BitVec 64))
(declare-fun x16_1 () (_ BitVec 64))
(declare-fun x15_5 () (_ BitVec 64))
(declare-fun x15_4 () (_ BitVec 64))
(declare-fun x15_3 () (_ BitVec 64))
(declare-fun x15_2 () (_ BitVec 64))
(declare-fun x15_1 () (_ BitVec 64))
(declare-fun v_20_40_2 () (_ BitVec 64))
(declare-fun u_20_40_2 () (_ BitVec 64))
(declare-fun s_20_40_2 () (_ BitVec 64))
(declare-fun r_20_40_2 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_20_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_40_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_20_1 () (_ BitVec 64))
(declare-fun dcH_8 () (_ BitVec 64))
(declare-fun dcH_7 () (_ BitVec 64))
(declare-fun dc_323 () (_ BitVec 64))
(declare-fun dc_322 () (_ BitVec 64))
(declare-fun dc_321 () (_ BitVec 64))
(declare-fun dc_320 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_44 (bvadd (bvadd neg_f_0_low60_20_low20_20_1 (bvmul u_20_40_2 #x0000000000200000)) (bvmul v_20_40_2 #x0000040000000000))) (= x8_82 (bvadd (bvadd neg_g_0_low60_20_low20_20_1 (bvmul r_20_40_2 #x0000000000200000)) (bvmul s_20_40_2 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_20_1)) (bvsle neg_f_0_low60_20_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_20_1)) (bvsle neg_g_0_low60_20_low20_20_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) neg_f_0_low60_40_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_79) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFB1 x3_79)) (bvsle x3_79 #x0000000000000051)) (bvsle #xFFFFFFFFFFF00000 u_20_40_2)) (bvsle u_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 v_20_40_2)) (bvsle v_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 r_20_40_2)) (bvsle r_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 s_20_40_2)) (bvsle s_20_40_2 #x00000000000FFFFF)) (= x6_2 #x0000020000100000)))
(assert (= x16_1 (bvadd x7_44 x6_2)))
(assert (= x16_2 x16_1))
(assert (and (= x16_3 ((_ sign_extend 42) ((_ extract 63 42) x16_2))) (= dc_320 ((_ zero_extend 22) ((_ extract 41 0) x16_2)))))
(assert (= x15_1 (bvadd x7_44 #x0000000000100000)))
(assert (and (= dcH_7 ((_ sign_extend 42) ((_ extract 63 42) x15_1))) (= x15_2 ((_ zero_extend 22) ((_ extract 41 0) x15_1)))))
(assert (= x15_3 (bvshl x15_2 #x0000000000000016)))
(assert (= x15_4 x15_3))
(assert (and (= x15_5 ((_ sign_extend 43) ((_ extract 63 43) x15_4))) (= dc_321 ((_ zero_extend 21) ((_ extract 42 0) x15_4)))))
(assert (= x20_1 (bvadd x8_82 x6_2)))
(assert (= x20_2 x20_1))
(assert (and (= x20_3 ((_ sign_extend 42) ((_ extract 63 42) x20_2))) (= dc_322 ((_ zero_extend 22) ((_ extract 41 0) x20_2)))))
(assert (= x17_1 (bvadd x8_82 #x0000000000100000)))
(assert (and (= dcH_8 ((_ sign_extend 42) ((_ extract 63 42) x17_1))) (= x17_2 ((_ zero_extend 22) ((_ extract 41 0) x17_1)))))
(assert (= x17_3 (bvshl x17_2 #x0000000000000016)))
(assert (= x17_4 x17_3))
(assert (and (= x17_5 ((_ sign_extend 43) ((_ extract 63 43) x17_4))) (= dc_323 ((_ zero_extend 21) ((_ extract 42 0) x17_4)))))
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert (not (bvsle #xFFFFFFFFFFF00000 x16_3)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_31fc0b.smt2
Execution time of boolector: 0.0045 seconds
OUTPUT FROM boolector:
unsat

=== Cut #6 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #6
; Range specification #99: smod (sub (uext x3_79 1) (uext 1@64 1)) (uext 2@64 1) = 0@65
; Range condition: ((x3_79@e1) - (1@e1)) smod (2@e1) = 0
; Output file: /tmp/outputqfbv_980c8e.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_target_37 () (_ BitVec 1))
(declare-fun x8_target_36 () (_ BitVec 1))
(declare-fun x8_target_35 () (_ BitVec 1))
(declare-fun x8_target_34 () (_ BitVec 1))
(declare-fun x8_target_33 () (_ BitVec 1))
(declare-fun x8_target_32 () (_ BitVec 1))
(declare-fun x8_target_31 () (_ BitVec 1))
(declare-fun x8_target_30 () (_ BitVec 1))
(declare-fun x8_target_29 () (_ BitVec 1))
(declare-fun x8_target_28 () (_ BitVec 1))
(declare-fun x8_target_27 () (_ BitVec 1))
(declare-fun x8_target_26 () (_ BitVec 1))
(declare-fun x8_target_25 () (_ BitVec 1))
(declare-fun x8_target_24 () (_ BitVec 1))
(declare-fun x8_target_23 () (_ BitVec 1))
(declare-fun x8_target_22 () (_ BitVec 1))
(declare-fun x8_target_21 () (_ BitVec 1))
(declare-fun x8_target_20 () (_ BitVec 1))
(declare-fun x8_lo_39 () (_ BitVec 2))
(declare-fun x8_lo_38 () (_ BitVec 2))
(declare-fun x8_lo_37 () (_ BitVec 2))
(declare-fun x8_lo_36 () (_ BitVec 2))
(declare-fun x8_lo_35 () (_ BitVec 2))
(declare-fun x8_lo_34 () (_ BitVec 2))
(declare-fun x8_lo_33 () (_ BitVec 2))
(declare-fun x8_lo_32 () (_ BitVec 2))
(declare-fun x8_lo_31 () (_ BitVec 2))
(declare-fun x8_lo_30 () (_ BitVec 2))
(declare-fun x8_lo_29 () (_ BitVec 2))
(declare-fun x8_lo_28 () (_ BitVec 2))
(declare-fun x8_lo_27 () (_ BitVec 2))
(declare-fun x8_lo_26 () (_ BitVec 2))
(declare-fun x8_lo_25 () (_ BitVec 2))
(declare-fun x8_lo_24 () (_ BitVec 2))
(declare-fun x8_lo_23 () (_ BitVec 2))
(declare-fun x8_lo_22 () (_ BitVec 2))
(declare-fun x8_lo_21 () (_ BitVec 1))
(declare-fun x8_82 () (_ BitVec 64))
(declare-fun x8_81 () (_ BitVec 64))
(declare-fun x8_80 () (_ BitVec 64))
(declare-fun x8_79 () (_ BitVec 64))
(declare-fun x8_78 () (_ BitVec 64))
(declare-fun x8_77 () (_ BitVec 64))
(declare-fun x8_76 () (_ BitVec 64))
(declare-fun x8_75 () (_ BitVec 64))
(declare-fun x8_74 () (_ BitVec 64))
(declare-fun x8_73 () (_ BitVec 64))
(declare-fun x8_72 () (_ BitVec 64))
(declare-fun x8_71 () (_ BitVec 64))
(declare-fun x8_70 () (_ BitVec 64))
(declare-fun x8_69 () (_ BitVec 64))
(declare-fun x8_68 () (_ BitVec 64))
(declare-fun x8_67 () (_ BitVec 64))
(declare-fun x8_66 () (_ BitVec 64))
(declare-fun x8_65 () (_ BitVec 64))
(declare-fun x8_64 () (_ BitVec 64))
(declare-fun x8_63 () (_ BitVec 64))
(declare-fun x8_62 () (_ BitVec 64))
(declare-fun x8_61 () (_ BitVec 64))
(declare-fun x8_60 () (_ BitVec 64))
(declare-fun x8_59 () (_ BitVec 64))
(declare-fun x8_58 () (_ BitVec 64))
(declare-fun x8_57 () (_ BitVec 64))
(declare-fun x8_56 () (_ BitVec 64))
(declare-fun x8_55 () (_ BitVec 64))
(declare-fun x8_54 () (_ BitVec 64))
(declare-fun x8_53 () (_ BitVec 64))
(declare-fun x8_52 () (_ BitVec 64))
(declare-fun x8_51 () (_ BitVec 64))
(declare-fun x8_50 () (_ BitVec 64))
(declare-fun x8_49 () (_ BitVec 64))
(declare-fun x8_48 () (_ BitVec 64))
(declare-fun x8_47 () (_ BitVec 64))
(declare-fun x8_46 () (_ BitVec 64))
(declare-fun x8_45 () (_ BitVec 64))
(declare-fun x8_44 () (_ BitVec 64))
(declare-fun x7_44 () (_ BitVec 64))
(declare-fun x7_43 () (_ BitVec 64))
(declare-fun x7_42 () (_ BitVec 64))
(declare-fun x7_41 () (_ BitVec 64))
(declare-fun x7_40 () (_ BitVec 64))
(declare-fun x7_39 () (_ BitVec 64))
(declare-fun x7_38 () (_ BitVec 64))
(declare-fun x7_37 () (_ BitVec 64))
(declare-fun x7_36 () (_ BitVec 64))
(declare-fun x7_35 () (_ BitVec 64))
(declare-fun x7_34 () (_ BitVec 64))
(declare-fun x7_33 () (_ BitVec 64))
(declare-fun x7_32 () (_ BitVec 64))
(declare-fun x7_31 () (_ BitVec 64))
(declare-fun x7_30 () (_ BitVec 64))
(declare-fun x7_29 () (_ BitVec 64))
(declare-fun x7_28 () (_ BitVec 64))
(declare-fun x7_27 () (_ BitVec 64))
(declare-fun x7_26 () (_ BitVec 64))
(declare-fun x7_25 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_neg_39 () (_ BitVec 64))
(declare-fun x3_neg_38 () (_ BitVec 64))
(declare-fun x3_neg_37 () (_ BitVec 64))
(declare-fun x3_neg_36 () (_ BitVec 64))
(declare-fun x3_neg_35 () (_ BitVec 64))
(declare-fun x3_neg_34 () (_ BitVec 64))
(declare-fun x3_neg_33 () (_ BitVec 64))
(declare-fun x3_neg_32 () (_ BitVec 64))
(declare-fun x3_neg_31 () (_ BitVec 64))
(declare-fun x3_neg_30 () (_ BitVec 64))
(declare-fun x3_neg_29 () (_ BitVec 64))
(declare-fun x3_neg_28 () (_ BitVec 64))
(declare-fun x3_neg_27 () (_ BitVec 64))
(declare-fun x3_neg_26 () (_ BitVec 64))
(declare-fun x3_neg_25 () (_ BitVec 64))
(declare-fun x3_neg_24 () (_ BitVec 64))
(declare-fun x3_neg_23 () (_ BitVec 64))
(declare-fun x3_neg_22 () (_ BitVec 64))
(declare-fun x3_neg_21 () (_ BitVec 64))
(declare-fun x3_79 () (_ BitVec 64))
(declare-fun x3_78 () (_ BitVec 64))
(declare-fun x3_77 () (_ BitVec 64))
(declare-fun x3_76 () (_ BitVec 64))
(declare-fun x3_75 () (_ BitVec 64))
(declare-fun x3_74 () (_ BitVec 64))
(declare-fun x3_73 () (_ BitVec 64))
(declare-fun x3_72 () (_ BitVec 64))
(declare-fun x3_71 () (_ BitVec 64))
(declare-fun x3_70 () (_ BitVec 64))
(declare-fun x3_69 () (_ BitVec 64))
(declare-fun x3_68 () (_ BitVec 64))
(declare-fun x3_67 () (_ BitVec 64))
(declare-fun x3_66 () (_ BitVec 64))
(declare-fun x3_65 () (_ BitVec 64))
(declare-fun x3_64 () (_ BitVec 64))
(declare-fun x3_63 () (_ BitVec 64))
(declare-fun x3_62 () (_ BitVec 64))
(declare-fun x3_61 () (_ BitVec 64))
(declare-fun x3_60 () (_ BitVec 64))
(declare-fun x3_59 () (_ BitVec 64))
(declare-fun x3_58 () (_ BitVec 64))
(declare-fun x3_57 () (_ BitVec 64))
(declare-fun x3_56 () (_ BitVec 64))
(declare-fun x3_55 () (_ BitVec 64))
(declare-fun x3_54 () (_ BitVec 64))
(declare-fun x3_53 () (_ BitVec 64))
(declare-fun x3_52 () (_ BitVec 64))
(declare-fun x3_51 () (_ BitVec 64))
(declare-fun x3_50 () (_ BitVec 64))
(declare-fun x3_49 () (_ BitVec 64))
(declare-fun x3_48 () (_ BitVec 64))
(declare-fun x3_47 () (_ BitVec 64))
(declare-fun x3_46 () (_ BitVec 64))
(declare-fun x3_45 () (_ BitVec 64))
(declare-fun x3_44 () (_ BitVec 64))
(declare-fun x3_43 () (_ BitVec 64))
(declare-fun x3_42 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x10_neg_39 () (_ BitVec 64))
(declare-fun x10_neg_38 () (_ BitVec 64))
(declare-fun x10_neg_37 () (_ BitVec 64))
(declare-fun x10_neg_36 () (_ BitVec 64))
(declare-fun x10_neg_35 () (_ BitVec 64))
(declare-fun x10_neg_34 () (_ BitVec 64))
(declare-fun x10_neg_33 () (_ BitVec 64))
(declare-fun x10_neg_32 () (_ BitVec 64))
(declare-fun x10_neg_31 () (_ BitVec 64))
(declare-fun x10_neg_30 () (_ BitVec 64))
(declare-fun x10_neg_29 () (_ BitVec 64))
(declare-fun x10_neg_28 () (_ BitVec 64))
(declare-fun x10_neg_27 () (_ BitVec 64))
(declare-fun x10_neg_26 () (_ BitVec 64))
(declare-fun x10_neg_25 () (_ BitVec 64))
(declare-fun x10_neg_24 () (_ BitVec 64))
(declare-fun x10_neg_23 () (_ BitVec 64))
(declare-fun x10_neg_22 () (_ BitVec 64))
(declare-fun x10_neg_21 () (_ BitVec 64))
(declare-fun x10_80 () (_ BitVec 64))
(declare-fun x10_79 () (_ BitVec 64))
(declare-fun x10_78 () (_ BitVec 64))
(declare-fun x10_77 () (_ BitVec 64))
(declare-fun x10_76 () (_ BitVec 64))
(declare-fun x10_75 () (_ BitVec 64))
(declare-fun x10_74 () (_ BitVec 64))
(declare-fun x10_73 () (_ BitVec 64))
(declare-fun x10_72 () (_ BitVec 64))
(declare-fun x10_71 () (_ BitVec 64))
(declare-fun x10_70 () (_ BitVec 64))
(declare-fun x10_69 () (_ BitVec 64))
(declare-fun x10_68 () (_ BitVec 64))
(declare-fun x10_67 () (_ BitVec 64))
(declare-fun x10_66 () (_ BitVec 64))
(declare-fun x10_65 () (_ BitVec 64))
(declare-fun x10_64 () (_ BitVec 64))
(declare-fun x10_63 () (_ BitVec 64))
(declare-fun x10_62 () (_ BitVec 64))
(declare-fun x10_61 () (_ BitVec 64))
(declare-fun x10_60 () (_ BitVec 64))
(declare-fun x10_59 () (_ BitVec 64))
(declare-fun x10_58 () (_ BitVec 64))
(declare-fun x10_57 () (_ BitVec 64))
(declare-fun x10_56 () (_ BitVec 64))
(declare-fun x10_55 () (_ BitVec 64))
(declare-fun x10_54 () (_ BitVec 64))
(declare-fun x10_53 () (_ BitVec 64))
(declare-fun x10_52 () (_ BitVec 64))
(declare-fun x10_51 () (_ BitVec 64))
(declare-fun x10_50 () (_ BitVec 64))
(declare-fun x10_49 () (_ BitVec 64))
(declare-fun x10_48 () (_ BitVec 64))
(declare-fun x10_47 () (_ BitVec 64))
(declare-fun x10_46 () (_ BitVec 64))
(declare-fun x10_45 () (_ BitVec 64))
(declare-fun x10_44 () (_ BitVec 64))
(declare-fun x10_43 () (_ BitVec 64))
(declare-fun v_20_40_2 () (_ BitVec 64))
(declare-fun u_20_40_2 () (_ BitVec 64))
(declare-fun s_20_40_2 () (_ BitVec 64))
(declare-fun r_20_40_2 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_20_1 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_40_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_20_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun ne_39 () (_ BitVec 1))
(declare-fun ne_38 () (_ BitVec 1))
(declare-fun ne_37 () (_ BitVec 1))
(declare-fun ne_36 () (_ BitVec 1))
(declare-fun ne_35 () (_ BitVec 1))
(declare-fun ne_34 () (_ BitVec 1))
(declare-fun ne_33 () (_ BitVec 1))
(declare-fun ne_32 () (_ BitVec 1))
(declare-fun ne_31 () (_ BitVec 1))
(declare-fun ne_30 () (_ BitVec 1))
(declare-fun ne_29 () (_ BitVec 1))
(declare-fun ne_28 () (_ BitVec 1))
(declare-fun ne_27 () (_ BitVec 1))
(declare-fun ne_26 () (_ BitVec 1))
(declare-fun ne_25 () (_ BitVec 1))
(declare-fun ne_24 () (_ BitVec 1))
(declare-fun ne_23 () (_ BitVec 1))
(declare-fun ne_22 () (_ BitVec 1))
(declare-fun ne_21 () (_ BitVec 1))
(declare-fun ge_117 () (_ BitVec 1))
(declare-fun ge_116 () (_ BitVec 1))
(declare-fun ge_115 () (_ BitVec 1))
(declare-fun ge_114 () (_ BitVec 1))
(declare-fun ge_113 () (_ BitVec 1))
(declare-fun ge_112 () (_ BitVec 1))
(declare-fun ge_111 () (_ BitVec 1))
(declare-fun ge_110 () (_ BitVec 1))
(declare-fun ge_109 () (_ BitVec 1))
(declare-fun ge_108 () (_ BitVec 1))
(declare-fun ge_107 () (_ BitVec 1))
(declare-fun ge_106 () (_ BitVec 1))
(declare-fun ge_105 () (_ BitVec 1))
(declare-fun ge_104 () (_ BitVec 1))
(declare-fun ge_103 () (_ BitVec 1))
(declare-fun ge_102 () (_ BitVec 1))
(declare-fun ge_101 () (_ BitVec 1))
(declare-fun ge_100 () (_ BitVec 1))
(declare-fun ge_99 () (_ BitVec 1))
(declare-fun ge_98 () (_ BitVec 1))
(declare-fun ge_97 () (_ BitVec 1))
(declare-fun ge_96 () (_ BitVec 1))
(declare-fun ge_95 () (_ BitVec 1))
(declare-fun ge_94 () (_ BitVec 1))
(declare-fun ge_93 () (_ BitVec 1))
(declare-fun ge_92 () (_ BitVec 1))
(declare-fun ge_91 () (_ BitVec 1))
(declare-fun ge_90 () (_ BitVec 1))
(declare-fun ge_89 () (_ BitVec 1))
(declare-fun ge_88 () (_ BitVec 1))
(declare-fun ge_87 () (_ BitVec 1))
(declare-fun ge_86 () (_ BitVec 1))
(declare-fun ge_85 () (_ BitVec 1))
(declare-fun ge_84 () (_ BitVec 1))
(declare-fun ge_83 () (_ BitVec 1))
(declare-fun ge_82 () (_ BitVec 1))
(declare-fun ge_81 () (_ BitVec 1))
(declare-fun ge_80 () (_ BitVec 1))
(declare-fun ge_79 () (_ BitVec 1))
(declare-fun ge_78 () (_ BitVec 1))
(declare-fun ge_77 () (_ BitVec 1))
(declare-fun ge_76 () (_ BitVec 1))
(declare-fun ge_75 () (_ BitVec 1))
(declare-fun ge_74 () (_ BitVec 1))
(declare-fun ge_73 () (_ BitVec 1))
(declare-fun ge_72 () (_ BitVec 1))
(declare-fun ge_71 () (_ BitVec 1))
(declare-fun ge_70 () (_ BitVec 1))
(declare-fun ge_69 () (_ BitVec 1))
(declare-fun ge_68 () (_ BitVec 1))
(declare-fun ge_67 () (_ BitVec 1))
(declare-fun ge_66 () (_ BitVec 1))
(declare-fun ge_65 () (_ BitVec 1))
(declare-fun ge_64 () (_ BitVec 1))
(declare-fun ge_63 () (_ BitVec 1))
(declare-fun ge_62 () (_ BitVec 1))
(declare-fun ge_61 () (_ BitVec 1))
(declare-fun dc_319 () (_ BitVec 64))
(declare-fun dc_318 () (_ BitVec 1))
(declare-fun dc_317 () (_ BitVec 1))
(declare-fun dc_316 () (_ BitVec 1))
(declare-fun dc_315 () (_ BitVec 63))
(declare-fun dc_314 () (_ BitVec 64))
(declare-fun dc_313 () (_ BitVec 1))
(declare-fun dc_312 () (_ BitVec 62))
(declare-fun dc_311 () (_ BitVec 1))
(declare-fun dc_310 () (_ BitVec 1))
(declare-fun dc_309 () (_ BitVec 1))
(declare-fun dc_308 () (_ BitVec 63))
(declare-fun dc_307 () (_ BitVec 64))
(declare-fun dc_306 () (_ BitVec 1))
(declare-fun dc_305 () (_ BitVec 62))
(declare-fun dc_304 () (_ BitVec 1))
(declare-fun dc_303 () (_ BitVec 1))
(declare-fun dc_302 () (_ BitVec 1))
(declare-fun dc_301 () (_ BitVec 63))
(declare-fun dc_300 () (_ BitVec 64))
(declare-fun dc_299 () (_ BitVec 1))
(declare-fun dc_298 () (_ BitVec 62))
(declare-fun dc_297 () (_ BitVec 1))
(declare-fun dc_296 () (_ BitVec 1))
(declare-fun dc_295 () (_ BitVec 1))
(declare-fun dc_294 () (_ BitVec 63))
(declare-fun dc_293 () (_ BitVec 64))
(declare-fun dc_292 () (_ BitVec 1))
(declare-fun dc_291 () (_ BitVec 62))
(declare-fun dc_290 () (_ BitVec 1))
(declare-fun dc_289 () (_ BitVec 1))
(declare-fun dc_288 () (_ BitVec 1))
(declare-fun dc_287 () (_ BitVec 63))
(declare-fun dc_286 () (_ BitVec 64))
(declare-fun dc_285 () (_ BitVec 1))
(declare-fun dc_284 () (_ BitVec 62))
(declare-fun dc_283 () (_ BitVec 1))
(declare-fun dc_282 () (_ BitVec 1))
(declare-fun dc_281 () (_ BitVec 1))
(declare-fun dc_280 () (_ BitVec 63))
(declare-fun dc_279 () (_ BitVec 64))
(declare-fun dc_278 () (_ BitVec 1))
(declare-fun dc_277 () (_ BitVec 62))
(declare-fun dc_276 () (_ BitVec 1))
(declare-fun dc_275 () (_ BitVec 1))
(declare-fun dc_274 () (_ BitVec 1))
(declare-fun dc_273 () (_ BitVec 63))
(declare-fun dc_272 () (_ BitVec 64))
(declare-fun dc_271 () (_ BitVec 1))
(declare-fun dc_270 () (_ BitVec 62))
(declare-fun dc_269 () (_ BitVec 1))
(declare-fun dc_268 () (_ BitVec 1))
(declare-fun dc_267 () (_ BitVec 1))
(declare-fun dc_266 () (_ BitVec 63))
(declare-fun dc_265 () (_ BitVec 64))
(declare-fun dc_264 () (_ BitVec 1))
(declare-fun dc_263 () (_ BitVec 62))
(declare-fun dc_262 () (_ BitVec 1))
(declare-fun dc_261 () (_ BitVec 1))
(declare-fun dc_260 () (_ BitVec 1))
(declare-fun dc_259 () (_ BitVec 63))
(declare-fun dc_258 () (_ BitVec 64))
(declare-fun dc_257 () (_ BitVec 1))
(declare-fun dc_256 () (_ BitVec 62))
(declare-fun dc_255 () (_ BitVec 1))
(declare-fun dc_254 () (_ BitVec 1))
(declare-fun dc_253 () (_ BitVec 1))
(declare-fun dc_252 () (_ BitVec 63))
(declare-fun dc_251 () (_ BitVec 64))
(declare-fun dc_250 () (_ BitVec 1))
(declare-fun dc_249 () (_ BitVec 62))
(declare-fun dc_248 () (_ BitVec 1))
(declare-fun dc_247 () (_ BitVec 1))
(declare-fun dc_246 () (_ BitVec 1))
(declare-fun dc_245 () (_ BitVec 63))
(declare-fun dc_244 () (_ BitVec 64))
(declare-fun dc_243 () (_ BitVec 1))
(declare-fun dc_242 () (_ BitVec 62))
(declare-fun dc_241 () (_ BitVec 1))
(declare-fun dc_240 () (_ BitVec 1))
(declare-fun dc_239 () (_ BitVec 1))
(declare-fun dc_238 () (_ BitVec 63))
(declare-fun dc_237 () (_ BitVec 64))
(declare-fun dc_236 () (_ BitVec 1))
(declare-fun dc_235 () (_ BitVec 62))
(declare-fun dc_234 () (_ BitVec 1))
(declare-fun dc_233 () (_ BitVec 1))
(declare-fun dc_232 () (_ BitVec 1))
(declare-fun dc_231 () (_ BitVec 63))
(declare-fun dc_230 () (_ BitVec 64))
(declare-fun dc_229 () (_ BitVec 1))
(declare-fun dc_228 () (_ BitVec 62))
(declare-fun dc_227 () (_ BitVec 1))
(declare-fun dc_226 () (_ BitVec 1))
(declare-fun dc_225 () (_ BitVec 1))
(declare-fun dc_224 () (_ BitVec 63))
(declare-fun dc_223 () (_ BitVec 64))
(declare-fun dc_222 () (_ BitVec 1))
(declare-fun dc_221 () (_ BitVec 62))
(declare-fun dc_220 () (_ BitVec 1))
(declare-fun dc_219 () (_ BitVec 1))
(declare-fun dc_218 () (_ BitVec 1))
(declare-fun dc_217 () (_ BitVec 63))
(declare-fun dc_216 () (_ BitVec 64))
(declare-fun dc_215 () (_ BitVec 1))
(declare-fun dc_214 () (_ BitVec 62))
(declare-fun dc_213 () (_ BitVec 1))
(declare-fun dc_212 () (_ BitVec 1))
(declare-fun dc_211 () (_ BitVec 1))
(declare-fun dc_210 () (_ BitVec 63))
(declare-fun dc_209 () (_ BitVec 64))
(declare-fun dc_208 () (_ BitVec 1))
(declare-fun dc_207 () (_ BitVec 62))
(declare-fun dc_206 () (_ BitVec 1))
(declare-fun dc_205 () (_ BitVec 1))
(declare-fun dc_204 () (_ BitVec 1))
(declare-fun dc_203 () (_ BitVec 63))
(declare-fun dc_202 () (_ BitVec 64))
(declare-fun dc_201 () (_ BitVec 1))
(declare-fun dc_200 () (_ BitVec 62))
(declare-fun dc_199 () (_ BitVec 1))
(declare-fun dc_198 () (_ BitVec 1))
(declare-fun dc_197 () (_ BitVec 1))
(declare-fun dc_196 () (_ BitVec 63))
(declare-fun dc_195 () (_ BitVec 64))
(declare-fun dc_194 () (_ BitVec 1))
(declare-fun dc_193 () (_ BitVec 62))
(declare-fun dc_192 () (_ BitVec 1))
(declare-fun dc_191 () (_ BitVec 1))
(declare-fun dc_190 () (_ BitVec 1))
(declare-fun dc_189 () (_ BitVec 63))
(declare-fun dc_188 () (_ BitVec 63))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_25 (bvadd (bvadd neg_f_0_low60_20_low20_0_1 (bvmul #xFFFFFFFFFFF00000 #x0000000000200000)) (bvmul #x0000000000000000 #x0000040000000000))) (= x8_44 (bvadd (bvadd neg_g_0_low60_20_low20_0_1 (bvmul #x0000000000000000 #x0000000000200000)) (bvmul #xFFFFFFFFFFF00000 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_0_1)) (bvsle neg_f_0_low60_20_low20_0_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_0_1)) (bvsle neg_g_0_low60_20_low20_0_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_25) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= #x0000000000000000 #x0000000000000000)) (= #x0000000000000000 #x0000000000000000)) (= #xFFFFFFFFFFF00000 #xFFFFFFFFFFF00000)) (= x6_2 #x0000020000100000)))
(assert (and (= dc_188 ((_ extract 63 1) x8_44)) (= x8_lo_21 ((_ extract 0 0) x8_44))))
(assert (= ne_21 (bvand x8_lo_21 #b1)))
(assert (= x10_43 (ite (= ne_21 #b1) x7_25 #x0000000000000000)))
(assert (and (= ge_61 ((_ extract 63 63) x3_41)) (= dc_189 ((_ extract 62 0) x3_41))))
(assert (= ge_62 (bvnot ge_61)))
(assert (= ge_63 (ite (= ne_21 #b1) ge_62 #b0)))
(assert (and (= dc_190 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_41))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_42 (ite (= ge_63 #b1) x3_neg_21 x3_41)))
(assert (and (= dc_191 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_21 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_44 (ite (= ge_63 #b1) x10_neg_21 x10_43)))
(assert (= x7_26 (ite (= ge_63 #b1) x8_44 x7_25)))
(assert (and (= dc_192 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44)))) (= x8_45 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_44) ((_ zero_extend 1) x10_44))))))
(assert (= x3_43 (bvadd x3_42 #x0000000000000002)))
(assert (and (= dc_193 ((_ extract 63 2) x8_45)) (= x8_lo_22 ((_ extract 1 0) x8_45))))
(assert (and (= x8_target_20 ((_ extract 1 1) x8_lo_22)) (= dc_194 ((_ extract 0 0) x8_lo_22))))
(assert (= ne_22 (bvand x8_target_20 #b1)))
(assert (and (= x8_46 ((_ sign_extend 1) ((_ extract 63 1) x8_45))) (= dc_195 ((_ zero_extend 63) ((_ extract 0 0) x8_45)))))
(assert true)
(assert (= x10_45 (ite (= ne_22 #b1) x7_26 #x0000000000000000)))
(assert (and (= ge_64 ((_ extract 63 63) x3_43)) (= dc_196 ((_ extract 62 0) x3_43))))
(assert (= ge_65 (bvnot ge_64)))
(assert (= ge_66 (ite (= ne_22 #b1) ge_65 #b0)))
(assert (and (= dc_197 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_43))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_44 (ite (= ge_66 #b1) x3_neg_22 x3_43)))
(assert (and (= dc_198 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_22 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_46 (ite (= ge_66 #b1) x10_neg_22 x10_45)))
(assert (= x7_27 (ite (= ge_66 #b1) x8_46 x7_26)))
(assert (and (= dc_199 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46)))) (= x8_47 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_46) ((_ zero_extend 1) x10_46))))))
(assert (= x3_45 (bvadd x3_44 #x0000000000000002)))
(assert (and (= dc_200 ((_ extract 63 2) x8_47)) (= x8_lo_23 ((_ extract 1 0) x8_47))))
(assert (and (= x8_target_21 ((_ extract 1 1) x8_lo_23)) (= dc_201 ((_ extract 0 0) x8_lo_23))))
(assert (= ne_23 (bvand x8_target_21 #b1)))
(assert (and (= x8_48 ((_ sign_extend 1) ((_ extract 63 1) x8_47))) (= dc_202 ((_ zero_extend 63) ((_ extract 0 0) x8_47)))))
(assert true)
(assert (= x10_47 (ite (= ne_23 #b1) x7_27 #x0000000000000000)))
(assert (and (= ge_67 ((_ extract 63 63) x3_45)) (= dc_203 ((_ extract 62 0) x3_45))))
(assert (= ge_68 (bvnot ge_67)))
(assert (= ge_69 (ite (= ne_23 #b1) ge_68 #b0)))
(assert (and (= dc_204 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_45))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_46 (ite (= ge_69 #b1) x3_neg_23 x3_45)))
(assert (and (= dc_205 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_23 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_47))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_48 (ite (= ge_69 #b1) x10_neg_23 x10_47)))
(assert (= x7_28 (ite (= ge_69 #b1) x8_48 x7_27)))
(assert (and (= dc_206 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48)))) (= x8_49 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_48) ((_ zero_extend 1) x10_48))))))
(assert (= x3_47 (bvadd x3_46 #x0000000000000002)))
(assert (and (= dc_207 ((_ extract 63 2) x8_49)) (= x8_lo_24 ((_ extract 1 0) x8_49))))
(assert (and (= x8_target_22 ((_ extract 1 1) x8_lo_24)) (= dc_208 ((_ extract 0 0) x8_lo_24))))
(assert (= ne_24 (bvand x8_target_22 #b1)))
(assert (and (= x8_50 ((_ sign_extend 1) ((_ extract 63 1) x8_49))) (= dc_209 ((_ zero_extend 63) ((_ extract 0 0) x8_49)))))
(assert true)
(assert (= x10_49 (ite (= ne_24 #b1) x7_28 #x0000000000000000)))
(assert (and (= ge_70 ((_ extract 63 63) x3_47)) (= dc_210 ((_ extract 62 0) x3_47))))
(assert (= ge_71 (bvnot ge_70)))
(assert (= ge_72 (ite (= ne_24 #b1) ge_71 #b0)))
(assert (and (= dc_211 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_47))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_24 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_47))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_48 (ite (= ge_72 #b1) x3_neg_24 x3_47)))
(assert (and (= dc_212 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_49))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_24 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_49))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_50 (ite (= ge_72 #b1) x10_neg_24 x10_49)))
(assert (= x7_29 (ite (= ge_72 #b1) x8_50 x7_28)))
(assert (and (= dc_213 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_50) ((_ zero_extend 1) x10_50)))) (= x8_51 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_50) ((_ zero_extend 1) x10_50))))))
(assert (= x3_49 (bvadd x3_48 #x0000000000000002)))
(assert (and (= dc_214 ((_ extract 63 2) x8_51)) (= x8_lo_25 ((_ extract 1 0) x8_51))))
(assert (and (= x8_target_23 ((_ extract 1 1) x8_lo_25)) (= dc_215 ((_ extract 0 0) x8_lo_25))))
(assert (= ne_25 (bvand x8_target_23 #b1)))
(assert (and (= x8_52 ((_ sign_extend 1) ((_ extract 63 1) x8_51))) (= dc_216 ((_ zero_extend 63) ((_ extract 0 0) x8_51)))))
(assert true)
(assert (= x10_51 (ite (= ne_25 #b1) x7_29 #x0000000000000000)))
(assert (and (= ge_73 ((_ extract 63 63) x3_49)) (= dc_217 ((_ extract 62 0) x3_49))))
(assert (= ge_74 (bvnot ge_73)))
(assert (= ge_75 (ite (= ne_25 #b1) ge_74 #b0)))
(assert (and (= dc_218 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_49))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_25 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_49))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_50 (ite (= ge_75 #b1) x3_neg_25 x3_49)))
(assert (and (= dc_219 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_51))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_25 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_51))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_52 (ite (= ge_75 #b1) x10_neg_25 x10_51)))
(assert (= x7_30 (ite (= ge_75 #b1) x8_52 x7_29)))
(assert (and (= dc_220 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_52) ((_ zero_extend 1) x10_52)))) (= x8_53 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_52) ((_ zero_extend 1) x10_52))))))
(assert (= x3_51 (bvadd x3_50 #x0000000000000002)))
(assert (and (= dc_221 ((_ extract 63 2) x8_53)) (= x8_lo_26 ((_ extract 1 0) x8_53))))
(assert (and (= x8_target_24 ((_ extract 1 1) x8_lo_26)) (= dc_222 ((_ extract 0 0) x8_lo_26))))
(assert (= ne_26 (bvand x8_target_24 #b1)))
(assert (and (= x8_54 ((_ sign_extend 1) ((_ extract 63 1) x8_53))) (= dc_223 ((_ zero_extend 63) ((_ extract 0 0) x8_53)))))
(assert true)
(assert (= x10_53 (ite (= ne_26 #b1) x7_30 #x0000000000000000)))
(assert (and (= ge_76 ((_ extract 63 63) x3_51)) (= dc_224 ((_ extract 62 0) x3_51))))
(assert (= ge_77 (bvnot ge_76)))
(assert (= ge_78 (ite (= ne_26 #b1) ge_77 #b0)))
(assert (and (= dc_225 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_51))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_26 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_51))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_52 (ite (= ge_78 #b1) x3_neg_26 x3_51)))
(assert (and (= dc_226 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_53))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_26 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_53))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_54 (ite (= ge_78 #b1) x10_neg_26 x10_53)))
(assert (= x7_31 (ite (= ge_78 #b1) x8_54 x7_30)))
(assert (and (= dc_227 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_54) ((_ zero_extend 1) x10_54)))) (= x8_55 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_54) ((_ zero_extend 1) x10_54))))))
(assert (= x3_53 (bvadd x3_52 #x0000000000000002)))
(assert (and (= dc_228 ((_ extract 63 2) x8_55)) (= x8_lo_27 ((_ extract 1 0) x8_55))))
(assert (and (= x8_target_25 ((_ extract 1 1) x8_lo_27)) (= dc_229 ((_ extract 0 0) x8_lo_27))))
(assert (= ne_27 (bvand x8_target_25 #b1)))
(assert (and (= x8_56 ((_ sign_extend 1) ((_ extract 63 1) x8_55))) (= dc_230 ((_ zero_extend 63) ((_ extract 0 0) x8_55)))))
(assert true)
(assert (= x10_55 (ite (= ne_27 #b1) x7_31 #x0000000000000000)))
(assert (and (= ge_79 ((_ extract 63 63) x3_53)) (= dc_231 ((_ extract 62 0) x3_53))))
(assert (= ge_80 (bvnot ge_79)))
(assert (= ge_81 (ite (= ne_27 #b1) ge_80 #b0)))
(assert (and (= dc_232 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_53))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_27 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_53))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_54 (ite (= ge_81 #b1) x3_neg_27 x3_53)))
(assert (and (= dc_233 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_55))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_27 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_55))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_56 (ite (= ge_81 #b1) x10_neg_27 x10_55)))
(assert (= x7_32 (ite (= ge_81 #b1) x8_56 x7_31)))
(assert (and (= dc_234 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_56) ((_ zero_extend 1) x10_56)))) (= x8_57 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_56) ((_ zero_extend 1) x10_56))))))
(assert (= x3_55 (bvadd x3_54 #x0000000000000002)))
(assert (and (= dc_235 ((_ extract 63 2) x8_57)) (= x8_lo_28 ((_ extract 1 0) x8_57))))
(assert (and (= x8_target_26 ((_ extract 1 1) x8_lo_28)) (= dc_236 ((_ extract 0 0) x8_lo_28))))
(assert (= ne_28 (bvand x8_target_26 #b1)))
(assert (and (= x8_58 ((_ sign_extend 1) ((_ extract 63 1) x8_57))) (= dc_237 ((_ zero_extend 63) ((_ extract 0 0) x8_57)))))
(assert true)
(assert (= x10_57 (ite (= ne_28 #b1) x7_32 #x0000000000000000)))
(assert (and (= ge_82 ((_ extract 63 63) x3_55)) (= dc_238 ((_ extract 62 0) x3_55))))
(assert (= ge_83 (bvnot ge_82)))
(assert (= ge_84 (ite (= ne_28 #b1) ge_83 #b0)))
(assert (and (= dc_239 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_55))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_28 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_55))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_56 (ite (= ge_84 #b1) x3_neg_28 x3_55)))
(assert (and (= dc_240 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_57))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_28 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_57))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_58 (ite (= ge_84 #b1) x10_neg_28 x10_57)))
(assert (= x7_33 (ite (= ge_84 #b1) x8_58 x7_32)))
(assert (and (= dc_241 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_58) ((_ zero_extend 1) x10_58)))) (= x8_59 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_58) ((_ zero_extend 1) x10_58))))))
(assert (= x3_57 (bvadd x3_56 #x0000000000000002)))
(assert (and (= dc_242 ((_ extract 63 2) x8_59)) (= x8_lo_29 ((_ extract 1 0) x8_59))))
(assert (and (= x8_target_27 ((_ extract 1 1) x8_lo_29)) (= dc_243 ((_ extract 0 0) x8_lo_29))))
(assert (= ne_29 (bvand x8_target_27 #b1)))
(assert (and (= x8_60 ((_ sign_extend 1) ((_ extract 63 1) x8_59))) (= dc_244 ((_ zero_extend 63) ((_ extract 0 0) x8_59)))))
(assert true)
(assert (= x10_59 (ite (= ne_29 #b1) x7_33 #x0000000000000000)))
(assert (and (= ge_85 ((_ extract 63 63) x3_57)) (= dc_245 ((_ extract 62 0) x3_57))))
(assert (= ge_86 (bvnot ge_85)))
(assert (= ge_87 (ite (= ne_29 #b1) ge_86 #b0)))
(assert (and (= dc_246 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_57))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_29 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_57))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_58 (ite (= ge_87 #b1) x3_neg_29 x3_57)))
(assert (and (= dc_247 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_59))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_29 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_59))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_60 (ite (= ge_87 #b1) x10_neg_29 x10_59)))
(assert (= x7_34 (ite (= ge_87 #b1) x8_60 x7_33)))
(assert (and (= dc_248 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_60) ((_ zero_extend 1) x10_60)))) (= x8_61 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_60) ((_ zero_extend 1) x10_60))))))
(assert (= x3_59 (bvadd x3_58 #x0000000000000002)))
(assert (and (= dc_249 ((_ extract 63 2) x8_61)) (= x8_lo_30 ((_ extract 1 0) x8_61))))
(assert (and (= x8_target_28 ((_ extract 1 1) x8_lo_30)) (= dc_250 ((_ extract 0 0) x8_lo_30))))
(assert (= ne_30 (bvand x8_target_28 #b1)))
(assert (and (= x8_62 ((_ sign_extend 1) ((_ extract 63 1) x8_61))) (= dc_251 ((_ zero_extend 63) ((_ extract 0 0) x8_61)))))
(assert true)
(assert (= x10_61 (ite (= ne_30 #b1) x7_34 #x0000000000000000)))
(assert (and (= ge_88 ((_ extract 63 63) x3_59)) (= dc_252 ((_ extract 62 0) x3_59))))
(assert (= ge_89 (bvnot ge_88)))
(assert (= ge_90 (ite (= ne_30 #b1) ge_89 #b0)))
(assert (and (= dc_253 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_59))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_30 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_59))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_60 (ite (= ge_90 #b1) x3_neg_30 x3_59)))
(assert (and (= dc_254 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_61))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_30 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_61))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_62 (ite (= ge_90 #b1) x10_neg_30 x10_61)))
(assert (= x7_35 (ite (= ge_90 #b1) x8_62 x7_34)))
(assert (and (= dc_255 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_62) ((_ zero_extend 1) x10_62)))) (= x8_63 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_62) ((_ zero_extend 1) x10_62))))))
(assert (= x3_61 (bvadd x3_60 #x0000000000000002)))
(assert (and (= dc_256 ((_ extract 63 2) x8_63)) (= x8_lo_31 ((_ extract 1 0) x8_63))))
(assert (and (= x8_target_29 ((_ extract 1 1) x8_lo_31)) (= dc_257 ((_ extract 0 0) x8_lo_31))))
(assert (= ne_31 (bvand x8_target_29 #b1)))
(assert (and (= x8_64 ((_ sign_extend 1) ((_ extract 63 1) x8_63))) (= dc_258 ((_ zero_extend 63) ((_ extract 0 0) x8_63)))))
(assert true)
(assert (= x10_63 (ite (= ne_31 #b1) x7_35 #x0000000000000000)))
(assert (and (= ge_91 ((_ extract 63 63) x3_61)) (= dc_259 ((_ extract 62 0) x3_61))))
(assert (= ge_92 (bvnot ge_91)))
(assert (= ge_93 (ite (= ne_31 #b1) ge_92 #b0)))
(assert (and (= dc_260 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_61))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_31 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_61))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_62 (ite (= ge_93 #b1) x3_neg_31 x3_61)))
(assert (and (= dc_261 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_63))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_31 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_63))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_64 (ite (= ge_93 #b1) x10_neg_31 x10_63)))
(assert (= x7_36 (ite (= ge_93 #b1) x8_64 x7_35)))
(assert (and (= dc_262 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_64) ((_ zero_extend 1) x10_64)))) (= x8_65 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_64) ((_ zero_extend 1) x10_64))))))
(assert (= x3_63 (bvadd x3_62 #x0000000000000002)))
(assert (and (= dc_263 ((_ extract 63 2) x8_65)) (= x8_lo_32 ((_ extract 1 0) x8_65))))
(assert (and (= x8_target_30 ((_ extract 1 1) x8_lo_32)) (= dc_264 ((_ extract 0 0) x8_lo_32))))
(assert (= ne_32 (bvand x8_target_30 #b1)))
(assert (and (= x8_66 ((_ sign_extend 1) ((_ extract 63 1) x8_65))) (= dc_265 ((_ zero_extend 63) ((_ extract 0 0) x8_65)))))
(assert true)
(assert (= x10_65 (ite (= ne_32 #b1) x7_36 #x0000000000000000)))
(assert (and (= ge_94 ((_ extract 63 63) x3_63)) (= dc_266 ((_ extract 62 0) x3_63))))
(assert (= ge_95 (bvnot ge_94)))
(assert (= ge_96 (ite (= ne_32 #b1) ge_95 #b0)))
(assert (and (= dc_267 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_63))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_32 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_63))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_64 (ite (= ge_96 #b1) x3_neg_32 x3_63)))
(assert (and (= dc_268 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_65))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_32 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_65))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_66 (ite (= ge_96 #b1) x10_neg_32 x10_65)))
(assert (= x7_37 (ite (= ge_96 #b1) x8_66 x7_36)))
(assert (and (= dc_269 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_66) ((_ zero_extend 1) x10_66)))) (= x8_67 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_66) ((_ zero_extend 1) x10_66))))))
(assert (= x3_65 (bvadd x3_64 #x0000000000000002)))
(assert (and (= dc_270 ((_ extract 63 2) x8_67)) (= x8_lo_33 ((_ extract 1 0) x8_67))))
(assert (and (= x8_target_31 ((_ extract 1 1) x8_lo_33)) (= dc_271 ((_ extract 0 0) x8_lo_33))))
(assert (= ne_33 (bvand x8_target_31 #b1)))
(assert (and (= x8_68 ((_ sign_extend 1) ((_ extract 63 1) x8_67))) (= dc_272 ((_ zero_extend 63) ((_ extract 0 0) x8_67)))))
(assert true)
(assert (= x10_67 (ite (= ne_33 #b1) x7_37 #x0000000000000000)))
(assert (and (= ge_97 ((_ extract 63 63) x3_65)) (= dc_273 ((_ extract 62 0) x3_65))))
(assert (= ge_98 (bvnot ge_97)))
(assert (= ge_99 (ite (= ne_33 #b1) ge_98 #b0)))
(assert (and (= dc_274 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_65))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_33 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_65))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_66 (ite (= ge_99 #b1) x3_neg_33 x3_65)))
(assert (and (= dc_275 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_67))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_33 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_67))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_68 (ite (= ge_99 #b1) x10_neg_33 x10_67)))
(assert (= x7_38 (ite (= ge_99 #b1) x8_68 x7_37)))
(assert (and (= dc_276 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_68) ((_ zero_extend 1) x10_68)))) (= x8_69 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_68) ((_ zero_extend 1) x10_68))))))
(assert (= x3_67 (bvadd x3_66 #x0000000000000002)))
(assert (and (= dc_277 ((_ extract 63 2) x8_69)) (= x8_lo_34 ((_ extract 1 0) x8_69))))
(assert (and (= x8_target_32 ((_ extract 1 1) x8_lo_34)) (= dc_278 ((_ extract 0 0) x8_lo_34))))
(assert (= ne_34 (bvand x8_target_32 #b1)))
(assert (and (= x8_70 ((_ sign_extend 1) ((_ extract 63 1) x8_69))) (= dc_279 ((_ zero_extend 63) ((_ extract 0 0) x8_69)))))
(assert true)
(assert (= x10_69 (ite (= ne_34 #b1) x7_38 #x0000000000000000)))
(assert (and (= ge_100 ((_ extract 63 63) x3_67)) (= dc_280 ((_ extract 62 0) x3_67))))
(assert (= ge_101 (bvnot ge_100)))
(assert (= ge_102 (ite (= ne_34 #b1) ge_101 #b0)))
(assert (and (= dc_281 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_67))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_34 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_67))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_68 (ite (= ge_102 #b1) x3_neg_34 x3_67)))
(assert (and (= dc_282 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_69))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_34 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_69))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_70 (ite (= ge_102 #b1) x10_neg_34 x10_69)))
(assert (= x7_39 (ite (= ge_102 #b1) x8_70 x7_38)))
(assert (and (= dc_283 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_70) ((_ zero_extend 1) x10_70)))) (= x8_71 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_70) ((_ zero_extend 1) x10_70))))))
(assert (= x3_69 (bvadd x3_68 #x0000000000000002)))
(assert (and (= dc_284 ((_ extract 63 2) x8_71)) (= x8_lo_35 ((_ extract 1 0) x8_71))))
(assert (and (= x8_target_33 ((_ extract 1 1) x8_lo_35)) (= dc_285 ((_ extract 0 0) x8_lo_35))))
(assert (= ne_35 (bvand x8_target_33 #b1)))
(assert (and (= x8_72 ((_ sign_extend 1) ((_ extract 63 1) x8_71))) (= dc_286 ((_ zero_extend 63) ((_ extract 0 0) x8_71)))))
(assert true)
(assert (= x10_71 (ite (= ne_35 #b1) x7_39 #x0000000000000000)))
(assert (and (= ge_103 ((_ extract 63 63) x3_69)) (= dc_287 ((_ extract 62 0) x3_69))))
(assert (= ge_104 (bvnot ge_103)))
(assert (= ge_105 (ite (= ne_35 #b1) ge_104 #b0)))
(assert (and (= dc_288 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_69))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_35 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_69))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_70 (ite (= ge_105 #b1) x3_neg_35 x3_69)))
(assert (and (= dc_289 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_71))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_35 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_71))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_72 (ite (= ge_105 #b1) x10_neg_35 x10_71)))
(assert (= x7_40 (ite (= ge_105 #b1) x8_72 x7_39)))
(assert (and (= dc_290 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_72) ((_ zero_extend 1) x10_72)))) (= x8_73 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_72) ((_ zero_extend 1) x10_72))))))
(assert (= x3_71 (bvadd x3_70 #x0000000000000002)))
(assert (and (= dc_291 ((_ extract 63 2) x8_73)) (= x8_lo_36 ((_ extract 1 0) x8_73))))
(assert (and (= x8_target_34 ((_ extract 1 1) x8_lo_36)) (= dc_292 ((_ extract 0 0) x8_lo_36))))
(assert (= ne_36 (bvand x8_target_34 #b1)))
(assert (and (= x8_74 ((_ sign_extend 1) ((_ extract 63 1) x8_73))) (= dc_293 ((_ zero_extend 63) ((_ extract 0 0) x8_73)))))
(assert true)
(assert (= x10_73 (ite (= ne_36 #b1) x7_40 #x0000000000000000)))
(assert (and (= ge_106 ((_ extract 63 63) x3_71)) (= dc_294 ((_ extract 62 0) x3_71))))
(assert (= ge_107 (bvnot ge_106)))
(assert (= ge_108 (ite (= ne_36 #b1) ge_107 #b0)))
(assert (and (= dc_295 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_71))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_36 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_71))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_72 (ite (= ge_108 #b1) x3_neg_36 x3_71)))
(assert (and (= dc_296 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_73))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_36 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_73))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_74 (ite (= ge_108 #b1) x10_neg_36 x10_73)))
(assert (= x7_41 (ite (= ge_108 #b1) x8_74 x7_40)))
(assert (and (= dc_297 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_74) ((_ zero_extend 1) x10_74)))) (= x8_75 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_74) ((_ zero_extend 1) x10_74))))))
(assert (= x3_73 (bvadd x3_72 #x0000000000000002)))
(assert (and (= dc_298 ((_ extract 63 2) x8_75)) (= x8_lo_37 ((_ extract 1 0) x8_75))))
(assert (and (= x8_target_35 ((_ extract 1 1) x8_lo_37)) (= dc_299 ((_ extract 0 0) x8_lo_37))))
(assert (= ne_37 (bvand x8_target_35 #b1)))
(assert (and (= x8_76 ((_ sign_extend 1) ((_ extract 63 1) x8_75))) (= dc_300 ((_ zero_extend 63) ((_ extract 0 0) x8_75)))))
(assert true)
(assert (= x10_75 (ite (= ne_37 #b1) x7_41 #x0000000000000000)))
(assert (and (= ge_109 ((_ extract 63 63) x3_73)) (= dc_301 ((_ extract 62 0) x3_73))))
(assert (= ge_110 (bvnot ge_109)))
(assert (= ge_111 (ite (= ne_37 #b1) ge_110 #b0)))
(assert (and (= dc_302 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_73))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_37 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_73))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_74 (ite (= ge_111 #b1) x3_neg_37 x3_73)))
(assert (and (= dc_303 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_75))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_37 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_75))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_76 (ite (= ge_111 #b1) x10_neg_37 x10_75)))
(assert (= x7_42 (ite (= ge_111 #b1) x8_76 x7_41)))
(assert (and (= dc_304 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_76) ((_ zero_extend 1) x10_76)))) (= x8_77 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_76) ((_ zero_extend 1) x10_76))))))
(assert (= x3_75 (bvadd x3_74 #x0000000000000002)))
(assert (and (= dc_305 ((_ extract 63 2) x8_77)) (= x8_lo_38 ((_ extract 1 0) x8_77))))
(assert (and (= x8_target_36 ((_ extract 1 1) x8_lo_38)) (= dc_306 ((_ extract 0 0) x8_lo_38))))
(assert (= ne_38 (bvand x8_target_36 #b1)))
(assert (and (= x8_78 ((_ sign_extend 1) ((_ extract 63 1) x8_77))) (= dc_307 ((_ zero_extend 63) ((_ extract 0 0) x8_77)))))
(assert true)
(assert (= x10_77 (ite (= ne_38 #b1) x7_42 #x0000000000000000)))
(assert (and (= ge_112 ((_ extract 63 63) x3_75)) (= dc_308 ((_ extract 62 0) x3_75))))
(assert (= ge_113 (bvnot ge_112)))
(assert (= ge_114 (ite (= ne_38 #b1) ge_113 #b0)))
(assert (and (= dc_309 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_75))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_38 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_75))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_76 (ite (= ge_114 #b1) x3_neg_38 x3_75)))
(assert (and (= dc_310 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_77))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_38 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_77))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_78 (ite (= ge_114 #b1) x10_neg_38 x10_77)))
(assert (= x7_43 (ite (= ge_114 #b1) x8_78 x7_42)))
(assert (and (= dc_311 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_78) ((_ zero_extend 1) x10_78)))) (= x8_79 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_78) ((_ zero_extend 1) x10_78))))))
(assert (= x3_77 (bvadd x3_76 #x0000000000000002)))
(assert (and (= dc_312 ((_ extract 63 2) x8_79)) (= x8_lo_39 ((_ extract 1 0) x8_79))))
(assert (and (= x8_target_37 ((_ extract 1 1) x8_lo_39)) (= dc_313 ((_ extract 0 0) x8_lo_39))))
(assert (= ne_39 (bvand x8_target_37 #b1)))
(assert (and (= x8_80 ((_ sign_extend 1) ((_ extract 63 1) x8_79))) (= dc_314 ((_ zero_extend 63) ((_ extract 0 0) x8_79)))))
(assert true)
(assert (= x10_79 (ite (= ne_39 #b1) x7_43 #x0000000000000000)))
(assert (and (= ge_115 ((_ extract 63 63) x3_77)) (= dc_315 ((_ extract 62 0) x3_77))))
(assert (= ge_116 (bvnot ge_115)))
(assert (= ge_117 (ite (= ne_39 #b1) ge_116 #b0)))
(assert (and (= dc_316 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_77))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x3_neg_39 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x3_77))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x3_78 (ite (= ge_117 #b1) x3_neg_39 x3_77)))
(assert (and (= dc_317 ((_ extract 64 64) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_79))) #b00000000000000000000000000000000000000000000000000000000000000001))) (= x10_neg_39 ((_ extract 63 0) (bvadd (bvadd ((_ zero_extend 1) #x0000000000000000) ((_ zero_extend 1) (bvnot x10_79))) #b00000000000000000000000000000000000000000000000000000000000000001)))))
(assert (= x10_80 (ite (= ge_117 #b1) x10_neg_39 x10_79)))
(assert (= x7_44 (ite (= ge_117 #b1) x8_80 x7_43)))
(assert (and (= dc_318 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x8_80) ((_ zero_extend 1) x10_80)))) (= x8_81 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x8_80) ((_ zero_extend 1) x10_80))))))
(assert (= x3_79 (bvadd x3_78 #x0000000000000002)))
(assert (and (= x8_82 ((_ sign_extend 1) ((_ extract 63 1) x8_81))) (= dc_319 ((_ zero_extend 63) ((_ extract 0 0) x8_81)))))
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (bvsle s_20_40_2 #x00000000000FFFFF) (bvsle #xFFFFFFFFFFF00000 s_20_40_2)) (bvsle r_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 r_20_40_2)) (bvsle v_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 v_20_40_2)) (bvsle u_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 u_20_40_2)) (bvsle neg_g_0_low60_20_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_20_1)) (bvsle neg_f_0_low60_20_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_20_1)) (bvsle x3_79 #x0000000000000051)) (bvsle #xFFFFFFFFFFFFFFB1 x3_79)) (= (bvsmod (bvsub ((_ zero_extend 1) x7_44) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= x8_82 (bvadd (bvadd neg_g_0_low60_20_low20_20_1 (bvmul r_20_40_2 #x0000000000200000)) (bvmul s_20_40_2 #x0000040000000000)))) (= x7_44 (bvadd (bvadd neg_f_0_low60_20_low20_20_1 (bvmul u_20_40_2 #x0000000000200000)) (bvmul v_20_40_2 #x0000040000000000)))))
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert (= (bvsmod (bvsub ((_ zero_extend 1) neg_f_0_low60_40_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000))
(assert (not (= (bvsmod (bvsub ((_ zero_extend 1) x3_79) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_257732.smt2
Execution time of boolector: 0.0259 seconds
OUTPUT FROM boolector:
unsat

=== Cut #4 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #4
; Range specification #68: smod (sub (uext x7_25 1) (uext 1@64 1)) (uext 2@64 1) = 0@65
; Range condition: ((x7_25@e1) - (1@e1)) smod (2@e1) = 0
; Output file: /tmp/outputqfbv_868e14.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x9_3 () (_ BitVec 64))
(declare-fun x9_2 () (_ BitVec 64))
(declare-fun x9_1 () (_ BitVec 64))
(declare-fun x8_44 () (_ BitVec 64))
(declare-fun x8_43 () (_ BitVec 64))
(declare-fun x7_25 () (_ BitVec 64))
(declare-fun x7_24 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_41 () (_ BitVec 64))
(declare-fun x2_7 () (_ BitVec 64))
(declare-fun x2_6 () (_ BitVec 64))
(declare-fun x14_3 () (_ BitVec 64))
(declare-fun x13_5 () (_ BitVec 64))
(declare-fun x12_3 () (_ BitVec 64))
(declare-fun x11_5 () (_ BitVec 64))
(declare-fun x10_42 () (_ BitVec 64))
(declare-fun x10_41 () (_ BitVec 64))
(declare-fun x1_2 () (_ BitVec 64))
(declare-fun tmp_2 () (_ BitVec 64))
(declare-fun tmp_1 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_0_1 () (_ BitVec 64))
(declare-fun g_0_low60_20_1 () (_ BitVec 64))
(declare-fun f_0_low60_20_1 () (_ BitVec 64))
(declare-fun dcH_6 () (_ BitVec 64))
(declare-fun dcH_5 () (_ BitVec 64))
(declare-fun dcH_4 () (_ BitVec 64))
(declare-fun dcH_3 () (_ BitVec 64))
(declare-fun dc_187 () (_ BitVec 64))
(declare-fun dc_186 () (_ BitVec 1))
(declare-fun dc_185 () (_ BitVec 64))
(declare-fun dc_184 () (_ BitVec 1))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= (bvsmod (bvsub ((_ zero_extend 1) f_0_low60_20_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000) (= (bvsmod (bvsub ((_ zero_extend 1) x3_41) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFD9 x3_41)) (bvsle x3_41 #x0000000000000029)) (bvsle #xFFFFFFFFFFF00000 x11_5)) (bvsle x11_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x12_3)) (bvsle x12_3 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x13_5)) (bvsle x13_5 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 x14_3)) (bvsle x14_3 #x00000000000FFFFF)) (bvsle (bvadd x11_5 x12_3) #x0000000000100000)) (bvsle (bvsub x11_5 x12_3) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 x11_5) x12_3) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 x11_5) x12_3) #x0000000000100000)) (bvsle (bvadd x13_5 x14_3) #x0000000000100000)) (bvsle (bvsub x13_5 x14_3) #x0000000000100000)) (bvsle (bvadd (bvsub #x0000000000000000 x13_5) x14_3) #x0000000000100000)) (bvsle (bvsub (bvsub #x0000000000000000 x13_5) x14_3) #x0000000000100000)) (= x6_2 #x0000020000100000)))
(assert (and (= dcH_3 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x11_5) ((_ sign_extend 64) x1_2)))) (= x9_1 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x11_5) ((_ sign_extend 64) x1_2))))))
(assert (and (= dcH_4 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x12_3)))) (= tmp_1 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x12_3))))))
(assert (and (= dc_184 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x9_1) ((_ zero_extend 1) tmp_1)))) (= x9_2 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x9_1) ((_ zero_extend 1) tmp_1))))))
(assert true)
(assert (and (= x9_2 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) f_0_low60_20_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x9_2) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x9_3 ((_ zero_extend 20) ((_ extract 63 20) x9_2))) (= dc_185 ((_ zero_extend 44) ((_ extract 19 0) x9_2)))))
(assert (and (= dcH_5 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x13_5) ((_ sign_extend 64) x1_2)))) (= x10_41 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x13_5) ((_ sign_extend 64) x1_2))))))
(assert (and (= dcH_6 ((_ extract 127 64) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x14_3)))) (= tmp_2 ((_ extract 63 0) (bvmul ((_ sign_extend 64) x2_6) ((_ sign_extend 64) x14_3))))))
(assert (and (= dc_186 ((_ extract 64 64) (bvadd ((_ zero_extend 1) x10_41) ((_ zero_extend 1) tmp_2)))) (= x10_42 ((_ extract 63 0) (bvadd ((_ zero_extend 1) x10_41) ((_ zero_extend 1) tmp_2))))))
(assert true)
(assert (and (= x10_42 (bvmul (bvmul #xFFFFFFFFFFFFFFFF #x0000000000100000) g_0_low60_20_1)) (= (bvsmod (bvsub ((_ zero_extend 1) x10_42) ((_ zero_extend 1) #x0000000000000000)) ((_ zero_extend 1) #x0000000000100000)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(assert (and (= x2_7 ((_ zero_extend 20) ((_ extract 63 20) x10_42))) (= dc_187 ((_ zero_extend 44) ((_ extract 19 0) x10_42)))))
(assert true)
(assert true)
(assert (= x7_24 (bvand x9_3 #x00000000000FFFFF)))
(assert (= x8_43 (bvand x2_7 #x00000000000FFFFF)))
(assert (= x7_25 (bvor x7_24 #xFFFFFE0000000000)))
(assert (= x8_44 (bvor x8_43 #xC000000000000000)))
(assert (= neg_f_0_low60_20_low20_0_1 (bvand x9_3 #x00000000000FFFFF)))
(assert (= neg_g_0_low60_20_low20_0_1 (bvand x2_7 #x00000000000FFFFF)))
(assert (not (= (bvsmod (bvsub ((_ zero_extend 1) x7_25) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_25412c.smt2
Execution time of boolector: 0.1057 seconds
OUTPUT FROM boolector:
unsat

=== Cut #7 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #7
; Range specification #118: x16_3 <=s 1048575@64
; Range condition: x16_3 <=s 1048575
; Output file: /tmp/outputqfbv_ea1b87.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_82 () (_ BitVec 64))
(declare-fun x7_44 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_79 () (_ BitVec 64))
(declare-fun x20_3 () (_ BitVec 64))
(declare-fun x20_2 () (_ BitVec 64))
(declare-fun x20_1 () (_ BitVec 64))
(declare-fun x17_5 () (_ BitVec 64))
(declare-fun x17_4 () (_ BitVec 64))
(declare-fun x17_3 () (_ BitVec 64))
(declare-fun x17_2 () (_ BitVec 64))
(declare-fun x17_1 () (_ BitVec 64))
(declare-fun x16_3 () (_ BitVec 64))
(declare-fun x16_2 () (_ BitVec 64))
(declare-fun x16_1 () (_ BitVec 64))
(declare-fun x15_5 () (_ BitVec 64))
(declare-fun x15_4 () (_ BitVec 64))
(declare-fun x15_3 () (_ BitVec 64))
(declare-fun x15_2 () (_ BitVec 64))
(declare-fun x15_1 () (_ BitVec 64))
(declare-fun v_20_40_2 () (_ BitVec 64))
(declare-fun u_20_40_2 () (_ BitVec 64))
(declare-fun s_20_40_2 () (_ BitVec 64))
(declare-fun r_20_40_2 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_20_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_40_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_20_1 () (_ BitVec 64))
(declare-fun dcH_8 () (_ BitVec 64))
(declare-fun dcH_7 () (_ BitVec 64))
(declare-fun dc_323 () (_ BitVec 64))
(declare-fun dc_322 () (_ BitVec 64))
(declare-fun dc_321 () (_ BitVec 64))
(declare-fun dc_320 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_44 (bvadd (bvadd neg_f_0_low60_20_low20_20_1 (bvmul u_20_40_2 #x0000000000200000)) (bvmul v_20_40_2 #x0000040000000000))) (= x8_82 (bvadd (bvadd neg_g_0_low60_20_low20_20_1 (bvmul r_20_40_2 #x0000000000200000)) (bvmul s_20_40_2 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_20_1)) (bvsle neg_f_0_low60_20_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_20_1)) (bvsle neg_g_0_low60_20_low20_20_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) neg_f_0_low60_40_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_79) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFB1 x3_79)) (bvsle x3_79 #x0000000000000051)) (bvsle #xFFFFFFFFFFF00000 u_20_40_2)) (bvsle u_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 v_20_40_2)) (bvsle v_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 r_20_40_2)) (bvsle r_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 s_20_40_2)) (bvsle s_20_40_2 #x00000000000FFFFF)) (= x6_2 #x0000020000100000)))
(assert (= x16_1 (bvadd x7_44 x6_2)))
(assert (= x16_2 x16_1))
(assert (and (= x16_3 ((_ sign_extend 42) ((_ extract 63 42) x16_2))) (= dc_320 ((_ zero_extend 22) ((_ extract 41 0) x16_2)))))
(assert (= x15_1 (bvadd x7_44 #x0000000000100000)))
(assert (and (= dcH_7 ((_ sign_extend 42) ((_ extract 63 42) x15_1))) (= x15_2 ((_ zero_extend 22) ((_ extract 41 0) x15_1)))))
(assert (= x15_3 (bvshl x15_2 #x0000000000000016)))
(assert (= x15_4 x15_3))
(assert (and (= x15_5 ((_ sign_extend 43) ((_ extract 63 43) x15_4))) (= dc_321 ((_ zero_extend 21) ((_ extract 42 0) x15_4)))))
(assert (= x20_1 (bvadd x8_82 x6_2)))
(assert (= x20_2 x20_1))
(assert (and (= x20_3 ((_ sign_extend 42) ((_ extract 63 42) x20_2))) (= dc_322 ((_ zero_extend 22) ((_ extract 41 0) x20_2)))))
(assert (= x17_1 (bvadd x8_82 #x0000000000100000)))
(assert (and (= dcH_8 ((_ sign_extend 42) ((_ extract 63 42) x17_1))) (= x17_2 ((_ zero_extend 22) ((_ extract 41 0) x17_1)))))
(assert (= x17_3 (bvshl x17_2 #x0000000000000016)))
(assert (= x17_4 x17_3))
(assert (and (= x17_5 ((_ sign_extend 43) ((_ extract 63 43) x17_4))) (= dc_323 ((_ zero_extend 21) ((_ extract 42 0) x17_4)))))
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert (not (bvsle x16_3 #x00000000000FFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_6a3d16.smt2
Execution time of boolector: 0.0045 seconds
OUTPUT FROM boolector:
unsat

=== Cut #7 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #7
; Range specification #119: (-1048576)@64 <=s x17_5
; Range condition: -1048576 <=s x17_5
; Output file: /tmp/outputqfbv_da4197.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_82 () (_ BitVec 64))
(declare-fun x7_44 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_79 () (_ BitVec 64))
(declare-fun x20_3 () (_ BitVec 64))
(declare-fun x20_2 () (_ BitVec 64))
(declare-fun x20_1 () (_ BitVec 64))
(declare-fun x17_5 () (_ BitVec 64))
(declare-fun x17_4 () (_ BitVec 64))
(declare-fun x17_3 () (_ BitVec 64))
(declare-fun x17_2 () (_ BitVec 64))
(declare-fun x17_1 () (_ BitVec 64))
(declare-fun x16_3 () (_ BitVec 64))
(declare-fun x16_2 () (_ BitVec 64))
(declare-fun x16_1 () (_ BitVec 64))
(declare-fun x15_5 () (_ BitVec 64))
(declare-fun x15_4 () (_ BitVec 64))
(declare-fun x15_3 () (_ BitVec 64))
(declare-fun x15_2 () (_ BitVec 64))
(declare-fun x15_1 () (_ BitVec 64))
(declare-fun v_20_40_2 () (_ BitVec 64))
(declare-fun u_20_40_2 () (_ BitVec 64))
(declare-fun s_20_40_2 () (_ BitVec 64))
(declare-fun r_20_40_2 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_20_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_40_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_20_1 () (_ BitVec 64))
(declare-fun dcH_8 () (_ BitVec 64))
(declare-fun dcH_7 () (_ BitVec 64))
(declare-fun dc_323 () (_ BitVec 64))
(declare-fun dc_322 () (_ BitVec 64))
(declare-fun dc_321 () (_ BitVec 64))
(declare-fun dc_320 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_44 (bvadd (bvadd neg_f_0_low60_20_low20_20_1 (bvmul u_20_40_2 #x0000000000200000)) (bvmul v_20_40_2 #x0000040000000000))) (= x8_82 (bvadd (bvadd neg_g_0_low60_20_low20_20_1 (bvmul r_20_40_2 #x0000000000200000)) (bvmul s_20_40_2 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_20_1)) (bvsle neg_f_0_low60_20_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_20_1)) (bvsle neg_g_0_low60_20_low20_20_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) neg_f_0_low60_40_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_79) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFB1 x3_79)) (bvsle x3_79 #x0000000000000051)) (bvsle #xFFFFFFFFFFF00000 u_20_40_2)) (bvsle u_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 v_20_40_2)) (bvsle v_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 r_20_40_2)) (bvsle r_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 s_20_40_2)) (bvsle s_20_40_2 #x00000000000FFFFF)) (= x6_2 #x0000020000100000)))
(assert (= x16_1 (bvadd x7_44 x6_2)))
(assert (= x16_2 x16_1))
(assert (and (= x16_3 ((_ sign_extend 42) ((_ extract 63 42) x16_2))) (= dc_320 ((_ zero_extend 22) ((_ extract 41 0) x16_2)))))
(assert (= x15_1 (bvadd x7_44 #x0000000000100000)))
(assert (and (= dcH_7 ((_ sign_extend 42) ((_ extract 63 42) x15_1))) (= x15_2 ((_ zero_extend 22) ((_ extract 41 0) x15_1)))))
(assert (= x15_3 (bvshl x15_2 #x0000000000000016)))
(assert (= x15_4 x15_3))
(assert (and (= x15_5 ((_ sign_extend 43) ((_ extract 63 43) x15_4))) (= dc_321 ((_ zero_extend 21) ((_ extract 42 0) x15_4)))))
(assert (= x20_1 (bvadd x8_82 x6_2)))
(assert (= x20_2 x20_1))
(assert (and (= x20_3 ((_ sign_extend 42) ((_ extract 63 42) x20_2))) (= dc_322 ((_ zero_extend 22) ((_ extract 41 0) x20_2)))))
(assert (= x17_1 (bvadd x8_82 #x0000000000100000)))
(assert (and (= dcH_8 ((_ sign_extend 42) ((_ extract 63 42) x17_1))) (= x17_2 ((_ zero_extend 22) ((_ extract 41 0) x17_1)))))
(assert (= x17_3 (bvshl x17_2 #x0000000000000016)))
(assert (= x17_4 x17_3))
(assert (and (= x17_5 ((_ sign_extend 43) ((_ extract 63 43) x17_4))) (= dc_323 ((_ zero_extend 21) ((_ extract 42 0) x17_4)))))
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert (not (bvsle #xFFFFFFFFFFF00000 x17_5)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_ec4ea5.smt2
Execution time of boolector: 0.0029 seconds
OUTPUT FROM boolector:
unsat

=== Cut #7 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #7
; Range specification #120: x17_5 <=s 1048575@64
; Range condition: x17_5 <=s 1048575
; Output file: /tmp/outputqfbv_0c8397.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_82 () (_ BitVec 64))
(declare-fun x7_44 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_79 () (_ BitVec 64))
(declare-fun x20_3 () (_ BitVec 64))
(declare-fun x20_2 () (_ BitVec 64))
(declare-fun x20_1 () (_ BitVec 64))
(declare-fun x17_5 () (_ BitVec 64))
(declare-fun x17_4 () (_ BitVec 64))
(declare-fun x17_3 () (_ BitVec 64))
(declare-fun x17_2 () (_ BitVec 64))
(declare-fun x17_1 () (_ BitVec 64))
(declare-fun x16_3 () (_ BitVec 64))
(declare-fun x16_2 () (_ BitVec 64))
(declare-fun x16_1 () (_ BitVec 64))
(declare-fun x15_5 () (_ BitVec 64))
(declare-fun x15_4 () (_ BitVec 64))
(declare-fun x15_3 () (_ BitVec 64))
(declare-fun x15_2 () (_ BitVec 64))
(declare-fun x15_1 () (_ BitVec 64))
(declare-fun v_20_40_2 () (_ BitVec 64))
(declare-fun u_20_40_2 () (_ BitVec 64))
(declare-fun s_20_40_2 () (_ BitVec 64))
(declare-fun r_20_40_2 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_20_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_40_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_20_1 () (_ BitVec 64))
(declare-fun dcH_8 () (_ BitVec 64))
(declare-fun dcH_7 () (_ BitVec 64))
(declare-fun dc_323 () (_ BitVec 64))
(declare-fun dc_322 () (_ BitVec 64))
(declare-fun dc_321 () (_ BitVec 64))
(declare-fun dc_320 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_44 (bvadd (bvadd neg_f_0_low60_20_low20_20_1 (bvmul u_20_40_2 #x0000000000200000)) (bvmul v_20_40_2 #x0000040000000000))) (= x8_82 (bvadd (bvadd neg_g_0_low60_20_low20_20_1 (bvmul r_20_40_2 #x0000000000200000)) (bvmul s_20_40_2 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_20_1)) (bvsle neg_f_0_low60_20_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_20_1)) (bvsle neg_g_0_low60_20_low20_20_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) neg_f_0_low60_40_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_79) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFB1 x3_79)) (bvsle x3_79 #x0000000000000051)) (bvsle #xFFFFFFFFFFF00000 u_20_40_2)) (bvsle u_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 v_20_40_2)) (bvsle v_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 r_20_40_2)) (bvsle r_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 s_20_40_2)) (bvsle s_20_40_2 #x00000000000FFFFF)) (= x6_2 #x0000020000100000)))
(assert (= x16_1 (bvadd x7_44 x6_2)))
(assert (= x16_2 x16_1))
(assert (and (= x16_3 ((_ sign_extend 42) ((_ extract 63 42) x16_2))) (= dc_320 ((_ zero_extend 22) ((_ extract 41 0) x16_2)))))
(assert (= x15_1 (bvadd x7_44 #x0000000000100000)))
(assert (and (= dcH_7 ((_ sign_extend 42) ((_ extract 63 42) x15_1))) (= x15_2 ((_ zero_extend 22) ((_ extract 41 0) x15_1)))))
(assert (= x15_3 (bvshl x15_2 #x0000000000000016)))
(assert (= x15_4 x15_3))
(assert (and (= x15_5 ((_ sign_extend 43) ((_ extract 63 43) x15_4))) (= dc_321 ((_ zero_extend 21) ((_ extract 42 0) x15_4)))))
(assert (= x20_1 (bvadd x8_82 x6_2)))
(assert (= x20_2 x20_1))
(assert (and (= x20_3 ((_ sign_extend 42) ((_ extract 63 42) x20_2))) (= dc_322 ((_ zero_extend 22) ((_ extract 41 0) x20_2)))))
(assert (= x17_1 (bvadd x8_82 #x0000000000100000)))
(assert (and (= dcH_8 ((_ sign_extend 42) ((_ extract 63 42) x17_1))) (= x17_2 ((_ zero_extend 22) ((_ extract 41 0) x17_1)))))
(assert (= x17_3 (bvshl x17_2 #x0000000000000016)))
(assert (= x17_4 x17_3))
(assert (and (= x17_5 ((_ sign_extend 43) ((_ extract 63 43) x17_4))) (= dc_323 ((_ zero_extend 21) ((_ extract 42 0) x17_4)))))
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert (not (bvsle x17_5 #x00000000000FFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_43a899.smt2
Execution time of boolector: 0.0029 seconds
OUTPUT FROM boolector:
unsat

=== Cut #7 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #7
; Range specification #121: (-1048576)@64 <=s x20_3
; Range condition: -1048576 <=s x20_3
; Output file: /tmp/outputqfbv_0f66d2.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_82 () (_ BitVec 64))
(declare-fun x7_44 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_79 () (_ BitVec 64))
(declare-fun x20_3 () (_ BitVec 64))
(declare-fun x20_2 () (_ BitVec 64))
(declare-fun x20_1 () (_ BitVec 64))
(declare-fun x17_5 () (_ BitVec 64))
(declare-fun x17_4 () (_ BitVec 64))
(declare-fun x17_3 () (_ BitVec 64))
(declare-fun x17_2 () (_ BitVec 64))
(declare-fun x17_1 () (_ BitVec 64))
(declare-fun x16_3 () (_ BitVec 64))
(declare-fun x16_2 () (_ BitVec 64))
(declare-fun x16_1 () (_ BitVec 64))
(declare-fun x15_5 () (_ BitVec 64))
(declare-fun x15_4 () (_ BitVec 64))
(declare-fun x15_3 () (_ BitVec 64))
(declare-fun x15_2 () (_ BitVec 64))
(declare-fun x15_1 () (_ BitVec 64))
(declare-fun v_20_40_2 () (_ BitVec 64))
(declare-fun u_20_40_2 () (_ BitVec 64))
(declare-fun s_20_40_2 () (_ BitVec 64))
(declare-fun r_20_40_2 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_20_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_40_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_20_1 () (_ BitVec 64))
(declare-fun dcH_8 () (_ BitVec 64))
(declare-fun dcH_7 () (_ BitVec 64))
(declare-fun dc_323 () (_ BitVec 64))
(declare-fun dc_322 () (_ BitVec 64))
(declare-fun dc_321 () (_ BitVec 64))
(declare-fun dc_320 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_44 (bvadd (bvadd neg_f_0_low60_20_low20_20_1 (bvmul u_20_40_2 #x0000000000200000)) (bvmul v_20_40_2 #x0000040000000000))) (= x8_82 (bvadd (bvadd neg_g_0_low60_20_low20_20_1 (bvmul r_20_40_2 #x0000000000200000)) (bvmul s_20_40_2 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_20_1)) (bvsle neg_f_0_low60_20_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_20_1)) (bvsle neg_g_0_low60_20_low20_20_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) neg_f_0_low60_40_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_79) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFB1 x3_79)) (bvsle x3_79 #x0000000000000051)) (bvsle #xFFFFFFFFFFF00000 u_20_40_2)) (bvsle u_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 v_20_40_2)) (bvsle v_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 r_20_40_2)) (bvsle r_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 s_20_40_2)) (bvsle s_20_40_2 #x00000000000FFFFF)) (= x6_2 #x0000020000100000)))
(assert (= x16_1 (bvadd x7_44 x6_2)))
(assert (= x16_2 x16_1))
(assert (and (= x16_3 ((_ sign_extend 42) ((_ extract 63 42) x16_2))) (= dc_320 ((_ zero_extend 22) ((_ extract 41 0) x16_2)))))
(assert (= x15_1 (bvadd x7_44 #x0000000000100000)))
(assert (and (= dcH_7 ((_ sign_extend 42) ((_ extract 63 42) x15_1))) (= x15_2 ((_ zero_extend 22) ((_ extract 41 0) x15_1)))))
(assert (= x15_3 (bvshl x15_2 #x0000000000000016)))
(assert (= x15_4 x15_3))
(assert (and (= x15_5 ((_ sign_extend 43) ((_ extract 63 43) x15_4))) (= dc_321 ((_ zero_extend 21) ((_ extract 42 0) x15_4)))))
(assert (= x20_1 (bvadd x8_82 x6_2)))
(assert (= x20_2 x20_1))
(assert (and (= x20_3 ((_ sign_extend 42) ((_ extract 63 42) x20_2))) (= dc_322 ((_ zero_extend 22) ((_ extract 41 0) x20_2)))))
(assert (= x17_1 (bvadd x8_82 #x0000000000100000)))
(assert (and (= dcH_8 ((_ sign_extend 42) ((_ extract 63 42) x17_1))) (= x17_2 ((_ zero_extend 22) ((_ extract 41 0) x17_1)))))
(assert (= x17_3 (bvshl x17_2 #x0000000000000016)))
(assert (= x17_4 x17_3))
(assert (and (= x17_5 ((_ sign_extend 43) ((_ extract 63 43) x17_4))) (= dc_323 ((_ zero_extend 21) ((_ extract 42 0) x17_4)))))
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert (not (bvsle #xFFFFFFFFFFF00000 x20_3)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_32a68c.smt2
Execution time of boolector: 0.0041 seconds
OUTPUT FROM boolector:
unsat

=== Cut #7 ===
INPUT IN SMTLIB2 FORMAT:
; Verify: range specifications
; Track: default
; Cut: #7
; Range specification #122: x20_3 <=s 1048575@64
; Range condition: x20_3 <=s 1048575
; Output file: /tmp/outputqfbv_6d5547.log
(set-logic QF_BV)
(set-info :smt-lib-version 2.0)
(declare-fun x8_82 () (_ BitVec 64))
(declare-fun x7_44 () (_ BitVec 64))
(declare-fun x6_2 () (_ BitVec 64))
(declare-fun x3_79 () (_ BitVec 64))
(declare-fun x20_3 () (_ BitVec 64))
(declare-fun x20_2 () (_ BitVec 64))
(declare-fun x20_1 () (_ BitVec 64))
(declare-fun x17_5 () (_ BitVec 64))
(declare-fun x17_4 () (_ BitVec 64))
(declare-fun x17_3 () (_ BitVec 64))
(declare-fun x17_2 () (_ BitVec 64))
(declare-fun x17_1 () (_ BitVec 64))
(declare-fun x16_3 () (_ BitVec 64))
(declare-fun x16_2 () (_ BitVec 64))
(declare-fun x16_1 () (_ BitVec 64))
(declare-fun x15_5 () (_ BitVec 64))
(declare-fun x15_4 () (_ BitVec 64))
(declare-fun x15_3 () (_ BitVec 64))
(declare-fun x15_2 () (_ BitVec 64))
(declare-fun x15_1 () (_ BitVec 64))
(declare-fun v_20_40_2 () (_ BitVec 64))
(declare-fun u_20_40_2 () (_ BitVec 64))
(declare-fun s_20_40_2 () (_ BitVec 64))
(declare-fun r_20_40_2 () (_ BitVec 64))
(declare-fun neg_g_0_low60_20_low20_20_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_40_1 () (_ BitVec 64))
(declare-fun neg_f_0_low60_20_low20_20_1 () (_ BitVec 64))
(declare-fun dcH_8 () (_ BitVec 64))
(declare-fun dcH_7 () (_ BitVec 64))
(declare-fun dc_323 () (_ BitVec 64))
(declare-fun dc_322 () (_ BitVec 64))
(declare-fun dc_321 () (_ BitVec 64))
(declare-fun dc_320 () (_ BitVec 64))
(assert (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (and (= x7_44 (bvadd (bvadd neg_f_0_low60_20_low20_20_1 (bvmul u_20_40_2 #x0000000000200000)) (bvmul v_20_40_2 #x0000040000000000))) (= x8_82 (bvadd (bvadd neg_g_0_low60_20_low20_20_1 (bvmul r_20_40_2 #x0000000000200000)) (bvmul s_20_40_2 #x0000040000000000)))) (bvsle #xFFFFFFFFFFF00001 neg_f_0_low60_20_low20_20_1)) (bvsle neg_f_0_low60_20_low20_20_1 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00001 neg_g_0_low60_20_low20_20_1)) (bvsle neg_g_0_low60_20_low20_20_1 #x00000000000FFFFF)) (= (bvsmod (bvsub ((_ zero_extend 1) neg_f_0_low60_40_1) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (= (bvsmod (bvsub ((_ zero_extend 1) x3_79) ((_ zero_extend 1) #x0000000000000001)) ((_ zero_extend 1) #x0000000000000002)) #b00000000000000000000000000000000000000000000000000000000000000000)) (bvsle #xFFFFFFFFFFFFFFB1 x3_79)) (bvsle x3_79 #x0000000000000051)) (bvsle #xFFFFFFFFFFF00000 u_20_40_2)) (bvsle u_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 v_20_40_2)) (bvsle v_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 r_20_40_2)) (bvsle r_20_40_2 #x00000000000FFFFF)) (bvsle #xFFFFFFFFFFF00000 s_20_40_2)) (bvsle s_20_40_2 #x00000000000FFFFF)) (= x6_2 #x0000020000100000)))
(assert (= x16_1 (bvadd x7_44 x6_2)))
(assert (= x16_2 x16_1))
(assert (and (= x16_3 ((_ sign_extend 42) ((_ extract 63 42) x16_2))) (= dc_320 ((_ zero_extend 22) ((_ extract 41 0) x16_2)))))
(assert (= x15_1 (bvadd x7_44 #x0000000000100000)))
(assert (and (= dcH_7 ((_ sign_extend 42) ((_ extract 63 42) x15_1))) (= x15_2 ((_ zero_extend 22) ((_ extract 41 0) x15_1)))))
(assert (= x15_3 (bvshl x15_2 #x0000000000000016)))
(assert (= x15_4 x15_3))
(assert (and (= x15_5 ((_ sign_extend 43) ((_ extract 63 43) x15_4))) (= dc_321 ((_ zero_extend 21) ((_ extract 42 0) x15_4)))))
(assert (= x20_1 (bvadd x8_82 x6_2)))
(assert (= x20_2 x20_1))
(assert (and (= x20_3 ((_ sign_extend 42) ((_ extract 63 42) x20_2))) (= dc_322 ((_ zero_extend 22) ((_ extract 41 0) x20_2)))))
(assert (= x17_1 (bvadd x8_82 #x0000000000100000)))
(assert (and (= dcH_8 ((_ sign_extend 42) ((_ extract 63 42) x17_1))) (= x17_2 ((_ zero_extend 22) ((_ extract 41 0) x17_1)))))
(assert (= x17_3 (bvshl x17_2 #x0000000000000016)))
(assert (= x17_4 x17_3))
(assert (and (= x17_5 ((_ sign_extend 43) ((_ extract 63 43) x17_4))) (= dc_323 ((_ zero_extend 21) ((_ extract 42 0) x17_4)))))
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert true)
(assert (not (bvsle x20_3 #x00000000000FFFFF)))
(check-sat)
(exit)

Run boolector with command: boolector  /tmp/inputqfbv_8fb625.smt2
Execution time of boolector: 0.0042 seconds
OUTPUT FROM boolector:
unsat

===== Verifying algebraic assertions =====
=== Cut #4 ===
INPUT TO SINGULAR:
// Verify: algebraic assertions
// Track: default
// Cut: #4
// Algebraic assertion #30: x10_42 = 0 (mod 2 ** 20)
// Algebraic condition: x10_42 = 0 (mod 2 ** 20)
// Try: #0 (pure equality)
// Output file: /tmp/outputfgb_5bde1d
proc is_generator(poly p, ideal I) {
  int idx;
  for (idx=1; idx<=size(I); idx++) {
    if (p == I[idx]) { return (0==0); }
  }
  return (0==1);
}

ring r = integer, (dcH_6,dcH_5,dc_186,dc_184,g_0_low60_20_1,x14_3,x13_5,f_0_low60_20_1,x12_3,x11_5,x2_6,x1_2), lp;
ideal gs = 0;
poly p = x13_5 * x1_2 - dcH_5 * bigint(18446744073709551616) + x2_6 * x14_3 - dcH_6 * bigint(18446744073709551616) - dc_186 * bigint(18446744073709551616) - bigint(0);
if (is_generator(p, gs) || reduce(p, gs) == 0) {
  0;
} else {
  ideal I = groebner(gs);
  reduce(p, I);
}
exit;

Execution time of Singular: 0.0048 seconds
OUTPUT FROM SINGULAR:
-18446744073709551616*dcH_6-18446744073709551616*dcH_5-18446744073709551616*dc_186+x14_3*x2_6+x13_5*x1_2

=== Cut #4 ===
INPUT TO SINGULAR:
// Verify: algebraic assertions
// Track: default
// Cut: #4
// Algebraic assertion #29: x10_42 = (-1) * 2 ** 20 * g_0_low60_20_1 (mod 2 ** 64)
// Algebraic condition: x10_42 = (-1) * 2 ** 20 * g_0_low60_20_1 (mod 2 ** 64)
// Try: #0 (pure equality)
// Output file: /tmp/outputfgb_b9273a
proc is_generator(poly p, ideal I) {
  int idx;
  for (idx=1; idx<=size(I); idx++) {
    if (p == I[idx]) { return (0==0); }
  }
  return (0==1);
}

ring r = integer, (dcH_6,dcH_5,dc_186,dc_184,g_0_low60_20_1,x14_3,x13_5,f_0_low60_20_1,x12_3,x11_5,x2_6,x1_2), lp;
ideal gs = 0;
poly p = x13_5 * x1_2 - dcH_5 * bigint(18446744073709551616) + x2_6 * x14_3 - dcH_6 * bigint(18446744073709551616) - dc_186 * bigint(18446744073709551616) - (-bigint(1)) * bigint(2)^20 * g_0_low60_20_1;
if (is_generator(p, gs) || reduce(p, gs) == 0) {
  0;
} else {
  ideal I = groebner(gs);
  reduce(p, I);
}
exit;

Execution time of Singular: 0.0050 seconds
OUTPUT FROM SINGULAR:
-18446744073709551616*dcH_6-18446744073709551616*dcH_5-18446744073709551616*dc_186+1048576*g_0_low60_20_1+x14_3*x2_6+x13_5*x1_2

=== Cut #4 ===
INPUT TO SINGULAR:
// Verify: algebraic assertions
// Track: default
// Cut: #4
// Algebraic assertion #28: x9_2 = 0 (mod 2 ** 20)
// Algebraic condition: x9_2 = 0 (mod 2 ** 20)
// Try: #0 (pure equality)
// Output file: /tmp/outputfgb_221b8c
proc is_generator(poly p, ideal I) {
  int idx;
  for (idx=1; idx<=size(I); idx++) {
    if (p == I[idx]) { return (0==0); }
  }
  return (0==1);
}

ring r = integer, (dcH_4,dcH_3,dc_184,g_0_low60_20_1,x14_3,x13_5,f_0_low60_20_1,x12_3,x11_5,x2_6,x1_2), lp;
ideal gs = 0;
poly p = x11_5 * x1_2 - dcH_3 * bigint(18446744073709551616) + x2_6 * x12_3 - dcH_4 * bigint(18446744073709551616) - dc_184 * bigint(18446744073709551616) - bigint(0);
if (is_generator(p, gs) || reduce(p, gs) == 0) {
  0;
} else {
  ideal I = groebner(gs);
  reduce(p, I);
}
exit;

Execution time of Singular: 0.0051 seconds
OUTPUT FROM SINGULAR:
-18446744073709551616*dcH_4-18446744073709551616*dcH_3-18446744073709551616*dc_184+x12_3*x2_6+x11_5*x1_2

=== Cut #4 ===
INPUT TO SINGULAR:
// Verify: algebraic assertions
// Track: default
// Cut: #4
// Algebraic assertion #27: x9_2 = (-1) * 2 ** 20 * f_0_low60_20_1 (mod 2 ** 64)
// Algebraic condition: x9_2 = (-1) * 2 ** 20 * f_0_low60_20_1 (mod 2 ** 64)
// Try: #0 (pure equality)
// Output file: /tmp/outputfgb_1dce8e
proc is_generator(poly p, ideal I) {
  int idx;
  for (idx=1; idx<=size(I); idx++) {
    if (p == I[idx]) { return (0==0); }
  }
  return (0==1);
}

ring r = integer, (dcH_4,dcH_3,dc_184,g_0_low60_20_1,x14_3,x13_5,f_0_low60_20_1,x12_3,x11_5,x2_6,x1_2), lp;
ideal gs = 0;
poly p = x11_5 * x1_2 - dcH_3 * bigint(18446744073709551616) + x2_6 * x12_3 - dcH_4 * bigint(18446744073709551616) - dc_184 * bigint(18446744073709551616) - (-bigint(1)) * bigint(2)^20 * f_0_low60_20_1;
if (is_generator(p, gs) || reduce(p, gs) == 0) {
  0;
} else {
  ideal I = groebner(gs);
  reduce(p, I);
}
exit;

Execution time of Singular: 0.0049 seconds
OUTPUT FROM SINGULAR:
-18446744073709551616*dcH_4-18446744073709551616*dcH_3-18446744073709551616*dc_184+1048576*f_0_low60_20_1+x12_3*x2_6+x11_5*x1_2

=== Cut #4 ===
INPUT TO SINGULAR:
// Verify: algebraic assertions
// Track: default
// Cut: #4
// Algebraic assertion #30: x10_42 = 0 (mod 2 ** 20)
// Algebraic condition: x10_42 = 0 (mod 2 ** 20)
// Try: #1 (modular equality)
// Output file: /tmp/outputfgb_2b9d39
proc is_generator(poly p, ideal I) {
  int idx;
  for (idx=1; idx<=size(I); idx++) {
    if (p == I[idx]) { return (0==0); }
  }
  return (0==1);
}

ring r = integer, (dcH_6,dcH_5,dc_186,dc_184,g_0_low60_20_1,x14_3,x13_5,f_0_low60_20_1,x12_3,x11_5,x2_6,x1_2), lp;
ideal gs = bigint(2)^20,
  x11_5 * x1_2 + x12_3 * x2_6 - f_0_low60_20_1 * (- (bigint(2)^20)),
  x13_5 * x1_2 + x14_3 * x2_6 - g_0_low60_20_1 * (- (bigint(2)^20)),
  dc_184 * (dc_184 - bigint(1)),
  dc_186 * (dc_186 - bigint(1));
poly p = x13_5 * x1_2 - dcH_5 * bigint(18446744073709551616) + x2_6 * x14_3 - dcH_6 * bigint(18446744073709551616) - dc_186 * bigint(18446744073709551616) - bigint(0);
if (is_generator(p, gs) || reduce(p, gs) == 0) {
  0;
} else {
  ideal I = groebner(gs);
  reduce(p, I);
}
exit;

Execution time of Singular: 0.0032 seconds
OUTPUT FROM SINGULAR:
// ** gs is no standard basis
0

=== Cut #4 ===
INPUT TO SINGULAR:
// Verify: algebraic assertions
// Track: default
// Cut: #4
// Algebraic assertion #29: x10_42 = (-1) * 2 ** 20 * g_0_low60_20_1 (mod 2 ** 64)
// Algebraic condition: x10_42 = (-1) * 2 ** 20 * g_0_low60_20_1 (mod 2 ** 64)
// Try: #1 (modular equality)
// Output file: /tmp/outputfgb_8edef0
proc is_generator(poly p, ideal I) {
  int idx;
  for (idx=1; idx<=size(I); idx++) {
    if (p == I[idx]) { return (0==0); }
  }
  return (0==1);
}

ring r = integer, (dcH_6,dcH_5,dc_186,dc_184,g_0_low60_20_1,x14_3,x13_5,f_0_low60_20_1,x12_3,x11_5,x2_6,x1_2), lp;
ideal gs = bigint(2)^64,
  x11_5 * x1_2 + x12_3 * x2_6 - f_0_low60_20_1 * (- (bigint(2)^20)),
  x13_5 * x1_2 + x14_3 * x2_6 - g_0_low60_20_1 * (- (bigint(2)^20)),
  dc_184 * (dc_184 - bigint(1)),
  dc_186 * (dc_186 - bigint(1));
poly p = x13_5 * x1_2 - dcH_5 * bigint(18446744073709551616) + x2_6 * x14_3 - dcH_6 * bigint(18446744073709551616) - dc_186 * bigint(18446744073709551616) - (-bigint(1)) * bigint(2)^20 * g_0_low60_20_1;
if (is_generator(p, gs) || reduce(p, gs) == 0) {
  0;
} else {
  ideal I = groebner(gs);
  reduce(p, I);
}
exit;

Execution time of Singular: 0.0028 seconds
OUTPUT FROM SINGULAR:
// ** gs is no standard basis
0

=== Cut #4 ===
INPUT TO SINGULAR:
// Verify: algebraic assertions
// Track: default
// Cut: #4
// Algebraic assertion #28: x9_2 = 0 (mod 2 ** 20)
// Algebraic condition: x9_2 = 0 (mod 2 ** 20)
// Try: #1 (modular equality)
// Output file: /tmp/outputfgb_573d33
proc is_generator(poly p, ideal I) {
  int idx;
  for (idx=1; idx<=size(I); idx++) {
    if (p == I[idx]) { return (0==0); }
  }
  return (0==1);
}

ring r = integer, (dcH_4,dcH_3,dc_184,g_0_low60_20_1,x14_3,x13_5,f_0_low60_20_1,x12_3,x11_5,x2_6,x1_2), lp;
ideal gs = bigint(2)^20,
  x11_5 * x1_2 + x12_3 * x2_6 - f_0_low60_20_1 * (- (bigint(2)^20)),
  x13_5 * x1_2 + x14_3 * x2_6 - g_0_low60_20_1 * (- (bigint(2)^20)),
  dc_184 * (dc_184 - bigint(1));
poly p = x11_5 * x1_2 - dcH_3 * bigint(18446744073709551616) + x2_6 * x12_3 - dcH_4 * bigint(18446744073709551616) - dc_184 * bigint(18446744073709551616) - bigint(0);
if (is_generator(p, gs) || reduce(p, gs) == 0) {
  0;
} else {
  ideal I = groebner(gs);
  reduce(p, I);
}
exit;

Execution time of Singular: 0.0032 seconds
OUTPUT FROM SINGULAR:
// ** gs is no standard basis
0

=== Cut #4 ===
INPUT TO SINGULAR:
// Verify: algebraic assertions
// Track: default
// Cut: #4
// Algebraic assertion #27: x9_2 = (-1) * 2 ** 20 * f_0_low60_20_1 (mod 2 ** 64)
// Algebraic condition: x9_2 = (-1) * 2 ** 20 * f_0_low60_20_1 (mod 2 ** 64)
// Try: #1 (modular equality)
// Output file: /tmp/outputfgb_4a7c80
proc is_generator(poly p, ideal I) {
  int idx;
  for (idx=1; idx<=size(I); idx++) {
    if (p == I[idx]) { return (0==0); }
  }
  return (0==1);
}

ring r = integer, (dcH_4,dcH_3,dc_184,g_0_low60_20_1,x14_3,x13_5,f_0_low60_20_1,x12_3,x11_5,x2_6,x1_2), lp;
ideal gs = bigint(2)^64,
  x11_5 * x1_2 + x12_3 * x2_6 - f_0_low60_20_1 * (- (bigint(2)^20)),
  x13_5 * x1_2 + x14_3 * x2_6 - g_0_low60_20_1 * (- (bigint(2)^20)),
  dc_184 * (dc_184 - bigint(1));
poly p = x11_5 * x1_2 - dcH_3 * bigint(18446744073709551616) + x2_6 * x12_3 - dcH_4 * bigint(18446744073709551616) - dc_184 * bigint(18446744073709551616) - (-bigint(1)) * bigint(2)^20 * f_0_low60_20_1;
if (is_generator(p, gs) || reduce(p, gs) == 0) {
  0;
} else {
  ideal I = groebner(gs);
  reduce(p, I);
}
exit;

Execution time of Singular: 0.0027 seconds
OUTPUT FROM SINGULAR:
// ** gs is no standard basis
0

=== Cut #8 ===
INPUT TO SINGULAR:
// Verify: algebraic assertions
// Track: default
// Cut: #8
// Algebraic assertion #56: x9_5 = (-1) * 2 ** 20 * neg_f_0_low60_40_1 (mod 2 ** 64)
// Algebraic condition: x9_5 = (-1) * 2 ** 20 * neg_f_0_low60_40_1 (mod 2 ** 64)
// Try: #0 (pure equality)
// Output file: /tmp/outputfgb_b0f14c
proc is_generator(poly p, ideal I) {
  int idx;
  for (idx=1; idx<=size(I); idx++) {
    if (p == I[idx]) { return (0==0); }
  }
  return (0==1);
}

ring r = integer, (dcH_11,dcH_10,dc_324,g_0_low60_40_1,f_0_low60_40_1,g_0_low60_20_2,f_0_low60_20_2,neg_g_0_low60_40_1,x20_3,x17_5,neg_f_0_low60_40_1,tmp187213094_1,tmp187213094_0,x2_9,x16_3,x1_5,x15_5), lp;
ideal gs = 0;
poly p = x15_5 * x1_5 - dcH_10 * bigint(18446744073709551616) + x2_9 * x16_3 - dcH_11 * bigint(18446744073709551616) - dc_324 * bigint(18446744073709551616) - (-bigint(1)) * bigint(2)^20 * neg_f_0_low60_40_1;
if (is_generator(p, gs) || reduce(p, gs) == 0) {
  0;
} else {
  ideal I = groebner(gs);
  reduce(p, I);
}
exit;

Execution time of Singular: 0.0030 seconds
OUTPUT FROM SINGULAR:
-18446744073709551616*dcH_11-18446744073709551616*dcH_10-18446744073709551616*dc_324+1048576*neg_f_0_low60_40_1+x2_9*x16_3+x1_5*x15_5

=== Cut #8 ===
INPUT TO SINGULAR:
// Verify: algebraic assertions
// Track: default
// Cut: #8
// Algebraic assertion #57: x9_5 = 0 (mod 2 ** 20)
// Algebraic condition: x9_5 = 0 (mod 2 ** 20)
// Try: #0 (pure equality)
// Output file: /tmp/outputfgb_8e5e5b
proc is_generator(poly p, ideal I) {
  int idx;
  for (idx=1; idx<=size(I); idx++) {
    if (p == I[idx]) { return (0==0); }
  }
  return (0==1);
}

ring r = integer, (dcH_11,dcH_10,dc_324,g_0_low60_40_1,f_0_low60_40_1,g_0_low60_20_2,f_0_low60_20_2,neg_g_0_low60_40_1,x20_3,x17_5,neg_f_0_low60_40_1,tmp187213094_1,tmp187213094_0,x2_9,x16_3,x1_5,x15_5), lp;
ideal gs = 0;
poly p = x15_5 * x1_5 - dcH_10 * bigint(18446744073709551616) + x2_9 * x16_3 - dcH_11 * bigint(18446744073709551616) - dc_324 * bigint(18446744073709551616) - bigint(0);
if (is_generator(p, gs) || reduce(p, gs) == 0) {
  0;
} else {
  ideal I = groebner(gs);
  reduce(p, I);
}
exit;

Execution time of Singular: 0.0031 seconds
OUTPUT FROM SINGULAR:
-18446744073709551616*dcH_11-18446744073709551616*dcH_10-18446744073709551616*dc_324+x2_9*x16_3+x1_5*x15_5

=== Cut #8 ===
INPUT TO SINGULAR:
// Verify: algebraic assertions
// Track: default
// Cut: #8
// Algebraic assertion #60: x10_82 = (-1) * 2 ** 20 * neg_g_0_low60_40_1 (mod 2 ** 64)
// Algebraic condition: x10_82 = (-1) * 2 ** 20 * neg_g_0_low60_40_1 (mod 2 ** 64)
// Try: #0 (pure equality)
// Output file: /tmp/outputfgb_5db8f8
proc is_generator(poly p, ideal I) {
  int idx;
  for (idx=1; idx<=size(I); idx++) {
    if (p == I[idx]) { return (0==0); }
  }
  return (0==1);
}

ring r = integer, (dcH_13,dcH_12,dc_326,dc_324,g_0_low60_40_1,f_0_low60_40_1,g_0_low60_20_2,f_0_low60_20_2,neg_g_0_low60_40_1,x20_3,x17_5,neg_f_0_low60_40_1,tmp187213094_1,x16_3,tmp187213094_0,x15_5,x2_9,x1_5), lp;
ideal gs = 0;
poly p = x17_5 * x1_5 - dcH_12 * bigint(18446744073709551616) + x2_9 * x20_3 - dcH_13 * bigint(18446744073709551616) - dc_326 * bigint(18446744073709551616) - (-bigint(1)) * bigint(2)^20 * neg_g_0_low60_40_1;
if (is_generator(p, gs) || reduce(p, gs) == 0) {
  0;
} else {
  ideal I = groebner(gs);
  reduce(p, I);
}
exit;

Execution time of Singular: 0.0028 seconds
OUTPUT FROM SINGULAR:
-18446744073709551616*dcH_13-18446744073709551616*dcH_12-18446744073709551616*dc_326+1048576*neg_g_0_low60_40_1+x20_3*x2_9+x17_5*x1_5

=== Cut #8 ===
INPUT TO SINGULAR:
// Verify: algebraic assertions
// Track: default
// Cut: #8
// Algebraic assertion #61: x10_82 = 0 (mod 2 ** 20)
// Algebraic condition: x10_82 = 0 (mod 2 ** 20)
// Try: #0 (pure equality)
// Output file: /tmp/outputfgb_251de6
proc is_generator(poly p, ideal I) {
  int idx;
  for (idx=1; idx<=size(I); idx++) {
    if (p == I[idx]) { return (0==0); }
  }
  return (0==1);
}

ring r = integer, (dcH_13,dcH_12,dc_326,dc_324,g_0_low60_40_1,f_0_low60_40_1,g_0_low60_20_2,f_0_low60_20_2,neg_g_0_low60_40_1,x20_3,x17_5,neg_f_0_low60_40_1,tmp187213094_1,x16_3,tmp187213094_0,x15_5,x2_9,x1_5), lp;
ideal gs = 0;
poly p = x17_5 * x1_5 - dcH_12 * bigint(18446744073709551616) + x2_9 * x20_3 - dcH_13 * bigint(18446744073709551616) - dc_326 * bigint(18446744073709551616) - bigint(0);
if (is_generator(p, gs) || reduce(p, gs) == 0) {
  0;
} else {
  ideal I = groebner(gs);
  reduce(p, I);
}
exit;

Execution time of Singular: 0.0028 seconds
OUTPUT FROM SINGULAR:
-18446744073709551616*dcH_13-18446744073709551616*dcH_12-18446744073709551616*dc_326+x20_3*x2_9+x17_5*x1_5

=== Cut #8 ===
INPUT TO SINGULAR:
// Verify: algebraic assertions
// Track: default
// Cut: #8
// Algebraic assertion #56: x9_5 = (-1) * 2 ** 20 * neg_f_0_low60_40_1 (mod 2 ** 64)
// Algebraic condition: x9_5 = (-1) * 2 ** 20 * neg_f_0_low60_40_1 (mod 2 ** 64)
// Try: #1 (modular equality)
// Output file: /tmp/outputfgb_126d41
proc is_generator(poly p, ideal I) {
  int idx;
  for (idx=1; idx<=size(I); idx++) {
    if (p == I[idx]) { return (0==0); }
  }
  return (0==1);
}

ring r = integer, (dcH_11,dcH_10,dc_324,g_0_low60_40_1,f_0_low60_40_1,g_0_low60_20_2,f_0_low60_20_2,neg_g_0_low60_40_1,x20_3,x17_5,neg_f_0_low60_40_1,tmp187213094_1,tmp187213094_0,x2_9,x16_3,x1_5,x15_5), lp;
ideal gs = bigint(2)^64,
  x15_5 * (x1_5 + tmp187213094_0 * bigint(18446744073709551616)) + x16_3 * (x2_9 + tmp187213094_1 * bigint(18446744073709551616)) - neg_f_0_low60_40_1 * (- (bigint(2)^20)),
  x17_5 * (x1_5 + tmp187213094_0 * bigint(18446744073709551616)) + x20_3 * (x2_9 + tmp187213094_1 * bigint(18446744073709551616)) - neg_g_0_low60_40_1 * (- (bigint(2)^20)),
  x15_5 * f_0_low60_20_2 + x16_3 * g_0_low60_20_2 - f_0_low60_40_1 * (- (bigint(2)^20)),
  x17_5 * f_0_low60_20_2 + x20_3 * g_0_low60_20_2 - g_0_low60_40_1 * (- (bigint(2)^20)),
  dc_324 * (dc_324 - bigint(1));
poly p = x15_5 * x1_5 - dcH_10 * bigint(18446744073709551616) + x2_9 * x16_3 - dcH_11 * bigint(18446744073709551616) - dc_324 * bigint(18446744073709551616) - (-bigint(1)) * bigint(2)^20 * neg_f_0_low60_40_1;
if (is_generator(p, gs) || reduce(p, gs) == 0) {
  0;
} else {
  ideal I = groebner(gs);
  reduce(p, I);
}
exit;

Execution time of Singular: 0.0029 seconds
OUTPUT FROM SINGULAR:
// ** gs is no standard basis
0

=== Cut #8 ===
INPUT TO SINGULAR:
// Verify: algebraic assertions
// Track: default
// Cut: #8
// Algebraic assertion #57: x9_5 = 0 (mod 2 ** 20)
// Algebraic condition: x9_5 = 0 (mod 2 ** 20)
// Try: #1 (modular equality)
// Output file: /tmp/outputfgb_dc5f87
proc is_generator(poly p, ideal I) {
  int idx;
  for (idx=1; idx<=size(I); idx++) {
    if (p == I[idx]) { return (0==0); }
  }
  return (0==1);
}

ring r = integer, (dcH_11,dcH_10,dc_324,g_0_low60_40_1,f_0_low60_40_1,g_0_low60_20_2,f_0_low60_20_2,neg_g_0_low60_40_1,x20_3,x17_5,neg_f_0_low60_40_1,tmp187213094_1,tmp187213094_0,x2_9,x16_3,x1_5,x15_5), lp;
ideal gs = bigint(2)^20,
  x15_5 * (x1_5 + tmp187213094_0 * bigint(18446744073709551616)) + x16_3 * (x2_9 + tmp187213094_1 * bigint(18446744073709551616)) - neg_f_0_low60_40_1 * (- (bigint(2)^20)),
  x17_5 * (x1_5 + tmp187213094_0 * bigint(18446744073709551616)) + x20_3 * (x2_9 + tmp187213094_1 * bigint(18446744073709551616)) - neg_g_0_low60_40_1 * (- (bigint(2)^20)),
  x15_5 * f_0_low60_20_2 + x16_3 * g_0_low60_20_2 - f_0_low60_40_1 * (- (bigint(2)^20)),
  x17_5 * f_0_low60_20_2 + x20_3 * g_0_low60_20_2 - g_0_low60_40_1 * (- (bigint(2)^20)),
  dc_324 * (dc_324 - bigint(1));
poly p = x15_5 * x1_5 - dcH_10 * bigint(18446744073709551616) + x2_9 * x16_3 - dcH_11 * bigint(18446744073709551616) - dc_324 * bigint(18446744073709551616) - bigint(0);
if (is_generator(p, gs) || reduce(p, gs) == 0) {
  0;
} else {
  ideal I = groebner(gs);
  reduce(p, I);
}
exit;

Execution time of Singular: 0.0030 seconds
OUTPUT FROM SINGULAR:
// ** gs is no standard basis
0

=== Cut #8 ===
INPUT TO SINGULAR:
// Verify: algebraic assertions
// Track: default
// Cut: #8
// Algebraic assertion #60: x10_82 = (-1) * 2 ** 20 * neg_g_0_low60_40_1 (mod 2 ** 64)
// Algebraic condition: x10_82 = (-1) * 2 ** 20 * neg_g_0_low60_40_1 (mod 2 ** 64)
// Try: #1 (modular equality)
// Output file: /tmp/outputfgb_0561cc
proc is_generator(poly p, ideal I) {
  int idx;
  for (idx=1; idx<=size(I); idx++) {
    if (p == I[idx]) { return (0==0); }
  }
  return (0==1);
}

ring r = integer, (dcH_13,dcH_12,dc_326,dc_324,g_0_low60_40_1,f_0_low60_40_1,g_0_low60_20_2,f_0_low60_20_2,neg_g_0_low60_40_1,x20_3,x17_5,neg_f_0_low60_40_1,tmp187213094_1,x16_3,tmp187213094_0,x15_5,x2_9,x1_5), lp;
ideal gs = bigint(2)^64,
  x15_5 * (x1_5 + tmp187213094_0 * bigint(18446744073709551616)) + x16_3 * (x2_9 + tmp187213094_1 * bigint(18446744073709551616)) - neg_f_0_low60_40_1 * (- (bigint(2)^20)),
  x17_5 * (x1_5 + tmp187213094_0 * bigint(18446744073709551616)) + x20_3 * (x2_9 + tmp187213094_1 * bigint(18446744073709551616)) - neg_g_0_low60_40_1 * (- (bigint(2)^20)),
  x15_5 * f_0_low60_20_2 + x16_3 * g_0_low60_20_2 - f_0_low60_40_1 * (- (bigint(2)^20)),
  x17_5 * f_0_low60_20_2 + x20_3 * g_0_low60_20_2 - g_0_low60_40_1 * (- (bigint(2)^20)),
  dc_324 * (dc_324 - bigint(1)),
  dc_326 * (dc_326 - bigint(1));
poly p = x17_5 * x1_5 - dcH_12 * bigint(18446744073709551616) + x2_9 * x20_3 - dcH_13 * bigint(18446744073709551616) - dc_326 * bigint(18446744073709551616) - (-bigint(1)) * bigint(2)^20 * neg_g_0_low60_40_1;
if (is_generator(p, gs) || reduce(p, gs) == 0) {
  0;
} else {
  ideal I = groebner(gs);
  reduce(p, I);
}
exit;

Execution time of Singular: 0.0029 seconds
OUTPUT FROM SINGULAR:
// ** gs is no standard basis
0

=== Cut #8 ===
INPUT TO SINGULAR:
// Verify: algebraic assertions
// Track: default
// Cut: #8
// Algebraic assertion #61: x10_82 = 0 (mod 2 ** 20)
// Algebraic condition: x10_82 = 0 (mod 2 ** 20)
// Try: #1 (modular equality)
// Output file: /tmp/outputfgb_e06ba1
proc is_generator(poly p, ideal I) {
  int idx;
  for (idx=1; idx<=size(I); idx++) {
    if (p == I[idx]) { return (0==0); }
  }
  return (0==1);
}

ring r = integer, (dcH_13,dcH_12,dc_326,dc_324,g_0_low60_40_1,f_0_low60_40_1,g_0_low60_20_2,f_0_low60_20_2,neg_g_0_low60_40_1,x20_3,x17_5,neg_f_0_low60_40_1,tmp187213094_1,x16_3,tmp187213094_0,x15_5,x2_9,x1_5), lp;
ideal gs = bigint(2)^20,
  x15_5 * (x1_5 + tmp187213094_0 * bigint(18446744073709551616)) + x16_3 * (x2_9 + tmp187213094_1 * bigint(18446744073709551616)) - neg_f_0_low60_40_1 * (- (bigint(2)^20)),
  x17_5 * (x1_5 + tmp187213094_0 * bigint(18446744073709551616)) + x20_3 * (x2_9 + tmp187213094_1 * bigint(18446744073709551616)) - neg_g_0_low60_40_1 * (- (bigint(2)^20)),
  x15_5 * f_0_low60_20_2 + x16_3 * g_0_low60_20_2 - f_0_low60_40_1 * (- (bigint(2)^20)),
  x17_5 * f_0_low60_20_2 + x20_3 * g_0_low60_20_2 - g_0_low60_40_1 * (- (bigint(2)^20)),
  dc_324 * (dc_324 - bigint(1)),
  dc_326 * (dc_326 - bigint(1));
poly p = x17_5 * x1_5 - dcH_12 * bigint(18446744073709551616) + x2_9 * x20_3 - dcH_13 * bigint(18446744073709551616) - dc_326 * bigint(18446744073709551616) - bigint(0);
if (is_generator(p, gs) || reduce(p, gs) == 0) {
  0;
} else {
  ideal I = groebner(gs);
  reduce(p, I);
}
exit;

Execution time of Singular: 0.0030 seconds
OUTPUT FROM SINGULAR:
// ** gs is no standard basis
0

=== Cut #8 ===
INPUT TO SMT Solver:
; Verify: algebraic assertions
; Track: default
; Cut: #8
; Algebraic assertion #67: u_0_40_1 <= 2 ** 41 prove with [algebra solver smt::"z3":nia]
; Algebraic condition: u_0_40_1 <= 2 ** 41 prove with [algebra solver smt::"z3":nia]
; Output file: /tmp/outputfgb_661a57
(set-logic NIA)
(define-fun-rec expn ((x Int) (n Int)) Int (ite (= n 0) 1 (* x (expn x (- n 1)))))
(declare-fun dc_324 () Int)
(declare-fun dc_325 () Int)
(declare-fun dc_326 () Int)
(declare-fun dc_327 () Int)
(declare-fun dcH_10 () Int)
(declare-fun dcH_11 () Int)
(declare-fun dcH_12 () Int)
(declare-fun dcH_13 () Int)
(declare-fun f_0_low60_20_2 () Int)
(declare-fun f_0_low60_40_1 () Int)
(declare-fun g_0_low60_20_2 () Int)
(declare-fun g_0_low60_40_1 () Int)
(declare-fun neg_f_0_low60_40_1 () Int)
(declare-fun neg_g_0_low60_40_1 () Int)
(declare-fun r_0_40_1 () Int)
(declare-fun s_0_40_1 () Int)
(declare-fun tmp_3 () Int)
(declare-fun tmp_4 () Int)
(declare-fun tmp187213094_0 () Int)
(declare-fun tmp187213094_1 () Int)
(declare-fun u_0_40_1 () Int)
(declare-fun v_0_40_1 () Int)
(declare-fun x1_5 () Int)
(declare-fun x10_81 () Int)
(declare-fun x10_82 () Int)
(declare-fun x11_5 () Int)
(declare-fun x12_3 () Int)
(declare-fun x13_5 () Int)
(declare-fun x14_3 () Int)
(declare-fun x15_5 () Int)
(declare-fun x16_3 () Int)
(declare-fun x17_5 () Int)
(declare-fun x2_7 () Int)
(declare-fun x2_9 () Int)
(declare-fun x2_10 () Int)
(declare-fun x20_3 () Int)
(declare-fun x9_3 () Int)
(declare-fun x9_4 () Int)
(declare-fun x9_5 () Int)
(declare-fun x9_6 () Int)
(assert (and (<= 0 x9_6) (<= x9_6 18446744073709551615)))
(assert (and (<= 0 x9_5) (<= x9_5 18446744073709551615)))
(assert (and (<= 0 x9_4) (<= x9_4 18446744073709551615)))
(assert (and (<= 0 x9_3) (<= x9_3 18446744073709551615)))
(assert (and (<= (- 9223372036854775808) x20_3) (<= x20_3 9223372036854775807)))
(assert (and (<= 0 x2_10) (<= x2_10 18446744073709551615)))
(assert (and (<= (- 9223372036854775808) x2_9) (<= x2_9 9223372036854775807)))
(assert (and (<= 0 x2_7) (<= x2_7 18446744073709551615)))
(assert (and (<= (- 9223372036854775808) x17_5) (<= x17_5 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) x16_3) (<= x16_3 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) x15_5) (<= x15_5 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) x14_3) (<= x14_3 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) x13_5) (<= x13_5 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) x12_3) (<= x12_3 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) x11_5) (<= x11_5 9223372036854775807)))
(assert (and (<= 0 x10_82) (<= x10_82 18446744073709551615)))
(assert (and (<= 0 x10_81) (<= x10_81 18446744073709551615)))
(assert (and (<= (- 9223372036854775808) x1_5) (<= x1_5 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) v_0_40_1) (<= v_0_40_1 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) u_0_40_1) (<= u_0_40_1 9223372036854775807)))
(assert (and (<= 0 tmp187213094_1) (<= tmp187213094_1 1)))
(assert (and (<= 0 tmp187213094_0) (<= tmp187213094_0 1)))
(assert (and (<= 0 tmp_4) (<= tmp_4 18446744073709551615)))
(assert (and (<= 0 tmp_3) (<= tmp_3 18446744073709551615)))
(assert (and (<= (- 9223372036854775808) s_0_40_1) (<= s_0_40_1 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) r_0_40_1) (<= r_0_40_1 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) neg_g_0_low60_40_1) (<= neg_g_0_low60_40_1 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) neg_f_0_low60_40_1) (<= neg_f_0_low60_40_1 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) g_0_low60_40_1) (<= g_0_low60_40_1 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) g_0_low60_20_2) (<= g_0_low60_20_2 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) f_0_low60_40_1) (<= f_0_low60_40_1 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) f_0_low60_20_2) (<= f_0_low60_20_2 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) dcH_13) (<= dcH_13 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) dcH_12) (<= dcH_12 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) dcH_11) (<= dcH_11 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) dcH_10) (<= dcH_10 9223372036854775807)))
(assert (and (<= 0 dc_327) (<= dc_327 18446744073709551615)))
(assert (and (<= 0 dc_326) (<= dc_326 1)))
(assert (and (<= 0 dc_325) (<= dc_325 18446744073709551615)))
(assert (and (<= 0 dc_324) (<= dc_324 1)))
(assert (and (and (and (= (+ (* x15_5 x9_3) (* x16_3 x2_7)) (* neg_f_0_low60_40_1 (- (expn 2 20)))) (= (+ (* x17_5 x9_3) (* x20_3 x2_7)) (* neg_g_0_low60_40_1 (- (expn 2 20))))) (= (+ (* x15_5 f_0_low60_20_2) (* x16_3 g_0_low60_20_2)) (* f_0_low60_40_1 (- (expn 2 20))))) (= (+ (* x17_5 f_0_low60_20_2) (* x20_3 g_0_low60_20_2)) (* g_0_low60_40_1 (- (expn 2 20))))))
(assert (= (+ x1_5 (* tmp187213094_0 18446744073709551616)) x9_3))
(assert (= (+ x2_9 (* tmp187213094_1 18446744073709551616)) x2_7))
(assert (= (+ x9_4 (* dcH_10 18446744073709551616)) (* x15_5 x1_5)))
(assert (= (+ tmp_3 (* dcH_11 18446744073709551616)) (* x2_9 x16_3)))
(assert (= (+ x9_5 (* dc_324 18446744073709551616)) (+ x9_4 tmp_3)))
(assert (= (* dc_324 (- dc_324 1)) 0))
(assert true)
(assert (= (+ dc_325 (* x9_6 1048576)) x9_5))
(assert (= (+ x10_81 (* dcH_12 18446744073709551616)) (* x17_5 x1_5)))
(assert (= (+ tmp_4 (* dcH_13 18446744073709551616)) (* x2_9 x20_3)))
(assert (= (+ x10_82 (* dc_326 18446744073709551616)) (+ x10_81 tmp_4)))
(assert (= (* dc_326 (- dc_326 1)) 0))
(assert true)
(assert (= (+ dc_327 (* x2_10 1048576)) x10_82))
(assert (= (+ (* x17_5 x12_3) (* x20_3 x14_3)) s_0_40_1))
(assert (= (+ (* x17_5 x11_5) (* x20_3 x13_5)) r_0_40_1))
(assert (= (+ (* x15_5 x12_3) (* x16_3 x14_3)) v_0_40_1))
(assert (= (+ (* x15_5 x11_5) (* x16_3 x13_5)) u_0_40_1))
(assert (<= x20_3 (- (expn 2 20) 1)))
(assert (<= (- (expn 2 20)) x20_3))
(assert (<= x14_3 (- (expn 2 20) 1)))
(assert (<= (- (expn 2 20)) x14_3))
(assert (<= x17_5 (- (expn 2 20) 1)))
(assert (<= (- (expn 2 20)) x17_5))
(assert (<= x13_5 (- (expn 2 20) 1)))
(assert (<= (- (expn 2 20)) x13_5))
(assert (<= x16_3 (- (expn 2 20) 1)))
(assert (<= (- (expn 2 20)) x16_3))
(assert (<= x12_3 (- (expn 2 20) 1)))
(assert (<= (- (expn 2 20)) x12_3))
(assert (<= x15_5 (- (expn 2 20) 1)))
(assert (<= (- (expn 2 20)) x15_5))
(assert (<= x11_5 (- (expn 2 20) 1)))
(assert (<= (- (expn 2 20)) x11_5))
(assert (not (<= u_0_40_1 (expn 2 41))))
(check-sat)
Execution time of SMT Solver z3: 0.0157 seconds
OUTPUT FROM SMT SOLVER:
unsat

=== Cut #8 ===
INPUT TO SMT Solver:
; Verify: algebraic assertions
; Track: default
; Cut: #8
; Algebraic assertion #68: - (2 ** 41) <= u_0_40_1 prove with [algebra solver smt::"z3":nia]
; Algebraic condition: - (2 ** 41) <= u_0_40_1 prove with [algebra solver smt::"z3":nia]
; Output file: /tmp/outputfgb_359c6f
(set-logic NIA)
(define-fun-rec expn ((x Int) (n Int)) Int (ite (= n 0) 1 (* x (expn x (- n 1)))))
(declare-fun dc_324 () Int)
(declare-fun dc_325 () Int)
(declare-fun dc_326 () Int)
(declare-fun dc_327 () Int)
(declare-fun dcH_10 () Int)
(declare-fun dcH_11 () Int)
(declare-fun dcH_12 () Int)
(declare-fun dcH_13 () Int)
(declare-fun f_0_low60_20_2 () Int)
(declare-fun f_0_low60_40_1 () Int)
(declare-fun g_0_low60_20_2 () Int)
(declare-fun g_0_low60_40_1 () Int)
(declare-fun neg_f_0_low60_40_1 () Int)
(declare-fun neg_g_0_low60_40_1 () Int)
(declare-fun r_0_40_1 () Int)
(declare-fun s_0_40_1 () Int)
(declare-fun tmp_3 () Int)
(declare-fun tmp_4 () Int)
(declare-fun tmp187213094_0 () Int)
(declare-fun tmp187213094_1 () Int)
(declare-fun u_0_40_1 () Int)
(declare-fun v_0_40_1 () Int)
(declare-fun x1_5 () Int)
(declare-fun x10_81 () Int)
(declare-fun x10_82 () Int)
(declare-fun x11_5 () Int)
(declare-fun x12_3 () Int)
(declare-fun x13_5 () Int)
(declare-fun x14_3 () Int)
(declare-fun x15_5 () Int)
(declare-fun x16_3 () Int)
(declare-fun x17_5 () Int)
(declare-fun x2_7 () Int)
(declare-fun x2_9 () Int)
(declare-fun x2_10 () Int)
(declare-fun x20_3 () Int)
(declare-fun x9_3 () Int)
(declare-fun x9_4 () Int)
(declare-fun x9_5 () Int)
(declare-fun x9_6 () Int)
(assert (and (<= 0 x9_6) (<= x9_6 18446744073709551615)))
(assert (and (<= 0 x9_5) (<= x9_5 18446744073709551615)))
(assert (and (<= 0 x9_4) (<= x9_4 18446744073709551615)))
(assert (and (<= 0 x9_3) (<= x9_3 18446744073709551615)))
(assert (and (<= (- 9223372036854775808) x20_3) (<= x20_3 9223372036854775807)))
(assert (and (<= 0 x2_10) (<= x2_10 18446744073709551615)))
(assert (and (<= (- 9223372036854775808) x2_9) (<= x2_9 9223372036854775807)))
(assert (and (<= 0 x2_7) (<= x2_7 18446744073709551615)))
(assert (and (<= (- 9223372036854775808) x17_5) (<= x17_5 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) x16_3) (<= x16_3 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) x15_5) (<= x15_5 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) x14_3) (<= x14_3 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) x13_5) (<= x13_5 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) x12_3) (<= x12_3 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) x11_5) (<= x11_5 9223372036854775807)))
(assert (and (<= 0 x10_82) (<= x10_82 18446744073709551615)))
(assert (and (<= 0 x10_81) (<= x10_81 18446744073709551615)))
(assert (and (<= (- 9223372036854775808) x1_5) (<= x1_5 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) v_0_40_1) (<= v_0_40_1 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) u_0_40_1) (<= u_0_40_1 9223372036854775807)))
(assert (and (<= 0 tmp187213094_1) (<= tmp187213094_1 1)))
(assert (and (<= 0 tmp187213094_0) (<= tmp187213094_0 1)))
(assert (and (<= 0 tmp_4) (<= tmp_4 18446744073709551615)))
(assert (and (<= 0 tmp_3) (<= tmp_3 18446744073709551615)))
(assert (and (<= (- 9223372036854775808) s_0_40_1) (<= s_0_40_1 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) r_0_40_1) (<= r_0_40_1 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) neg_g_0_low60_40_1) (<= neg_g_0_low60_40_1 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) neg_f_0_low60_40_1) (<= neg_f_0_low60_40_1 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) g_0_low60_40_1) (<= g_0_low60_40_1 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) g_0_low60_20_2) (<= g_0_low60_20_2 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) f_0_low60_40_1) (<= f_0_low60_40_1 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) f_0_low60_20_2) (<= f_0_low60_20_2 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) dcH_13) (<= dcH_13 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) dcH_12) (<= dcH_12 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) dcH_11) (<= dcH_11 9223372036854775807)))
(assert (and (<= (- 9223372036854775808) dcH_10) (<= dcH_10 9223372036854775807)))
(assert (and (<= 0 dc_327) (<= dc_327 18446744073709551615)))
(assert (and (<= 0 dc_326) (<= dc_326 1)))
(assert (and (<= 0 dc_325) (<= dc_325 18446744073709551615)))
(assert (and (<= 0 dc_324) (<= dc_324 1)))
(assert (and (and (and (= (+ (* x15_5 x9_3) (* x16_3 x2_7)) (* neg_f_0_low60_40_1 (- (expn 2 20)))) (= (+ (* x17_5 x9_3) (* x20_3 x2_7)) (* neg_g_0_low60_40_1 (- (expn 2 20))))) (= (+ (* x15_5 f_0_low60_20_2) (* x16_3 g_0_low60_20_2)) (* f_0_low60_40_1 (- (expn 2 20))))) (= (+ (* x17_5 f_0_low60_20_2) (* x20_3 g_0_low60_20_2)) (* g_0_low60_40_1 (- (expn 2 20))))))
(assert (= (+ x1_5 (* tmp187213094_0 18446744073709551616)) x9_3))
(assert (= (+ x2_9 (* tmp187213094_1 18446744073709551616)) x2_7))
(assert (= (+ x9_4 (* dcH_10 18446744073709551616)) (* x15_5 x1_5)))
(assert (= (+ tmp_3 (* dcH_11 18446744073709551616)) (* x2_9 x16_3)))
(assert (= (+ x9_5 (* dc_324 18446744073709551616)) (+ x9_4 tmp_3)))
(assert (= (* dc_324 (- dc_324 1)) 0))
(assert true)
(assert (= (+ dc_325 (* x9_6 1048576)) x9_5))
(assert (= (+ x10_81 (* dcH_12 18446744073709551616)) (* x17_5 x1_5)))
(assert (= (+ tmp_4 (* dcH_13 18446744073709551616)) (* x2_9 x20_3)))
(assert (= (+ x10_82 (* dc_326 18446744073709551616)) (+ x10_81 tmp_4)))
(assert (= (* dc_326 (- dc_326 1)) 0))
(assert true)
(assert (= (+ dc_327 (* x2_10 1048576)) x10_82))
(assert (= (+ (* x17_5 x12_3) (* x20_3 x14_3)) s_0_40_1))
(assert (= (+ (* x17_5 x11_5) (* x20_3 x13_5)) r_0_40_1))
(assert (= (+ (* x15_5 x12_3) (* x16_3 x14_3)) v_0_40_1))
(assert (= (+ (* x15_5 x11_5) (* x16_3 x13_5)) u_0_40_1))
(assert (<= x20_3 (- (expn 2 20) 1)))
(assert (<= (- (expn 2 20)) x20_3))
(assert (<= x14_3 (- (expn 2 20) 1)))
(assert (<= (- (expn 2 20)) x14_3))
(assert (<= x17_5 (- (expn 2 20) 1)))
(assert (<= (- (expn 2 20)) x17_5))
(assert (<= x13_5 (- (expn 2 20) 1)))
(assert (<= (- (expn 2 20)) x13_5))
(assert (<= x16_3 (- (expn 2 20) 1)))
(assert (<= (- (expn 2 20)) x16_3))
(assert (<= x12_3 (- (expn 2 20) 1)))
(assert (<= (- (expn 2 20)) x12_3))
(assert (<= x15_5 (- (expn 2 20) 1)))
(assert (<= (- (expn 2 20)) x15_5))
(assert (<= x11_5 (- (expn 2 20) 1)))
(assert (<= (- (expn 2 20)) x11_5))
(assert (not (<= (- (expn 2 41)) u_0_40_1)))
(check-sat)
Execution time of SMT Solver z3: 0.0125 seconds
OUTPUT FROM SMT SOLVER:
unsat

===== Verifying algebraic specifications =====
=== Cut #1 ===
INPUT TO SINGULAR:
// Verify: algebraic specifications
// Track: default
// Cut: #1
// Algebraic specification #2: 0 * f_0_low60_0_low20_0_1 + (-1048576) * g_0_low60_0_low20_0_1 = g_0_low60_0_low20_0_1 * (- (2 ** 20))
// Algebraic condition: 0 * f_0_low60_0_low20_0_1 + (-1048576) * g_0_low60_0_low20_0_1 = g_0_low60_0_low20_0_1 * (- (2 ** 20))
// Try: #0 (pure equality)
// Output file: /tmp/outputfgb_209bc4
proc is_generator(poly p, ideal I) {
  int idx;
  for (idx=1; idx<=size(I); idx++) {
    if (p == I[idx]) { return (0==0); }
  }
  return (0==1);
}

ring r = integer, (f_0_low60_0_low20_0_1,g_0_low60_0_low20_0_1), lp;
ideal gs = 0;
poly p = bigint(0) * f_0_low60_0_low20_0_1 + bigint(-1048576) * g_0_low60_0_low20_0_1 - g_0_low60_0_low20_0_1 * (- (bigint(2)^20));
if (is_generator(p, gs) || reduce(p, gs) == 0) {
  0;
} else {
  ideal I = groebner(gs);
  reduce(p, I);
}
exit;

Execution time of Singular: 0.0034 seconds
OUTPUT FROM SINGULAR:
0

=== Cut #1 ===
INPUT TO SINGULAR:
// Verify: algebraic specifications
// Track: default
// Cut: #1
// Algebraic specification #1: (-1048576) * f_0_low60_0_low20_0_1 + 0 * g_0_low60_0_low20_0_1 = f_0_low60_0_low20_0_1 * (- (2 ** 20))
// Algebraic condition: (-1048576) * f_0_low60_0_low20_0_1 + 0 * g_0_low60_0_low20_0_1 = f_0_low60_0_low20_0_1 * (- (2 ** 20))
// Try: #0 (pure equality)
// Output file: /tmp/outputfgb_7cc7a7
proc is_generator(poly p, ideal I) {
  int idx;
  for (idx=1; idx<=size(I); idx++) {
    if (p == I[idx]) { return (0==0); }
  }
  return (0==1);
}

ring r = integer, (g_0_low60_0_low20_0_1,f_0_low60_0_low20_0_1), lp;
ideal gs = 0;
poly p = bigint(-1048576) * f_0_low60_0_low20_0_1 + bigint(0) * g_0_low60_0_low20_0_1 - f_0_low60_0_low20_0_1 * (- (bigint(2)^20));
if (is_generator(p, gs) || reduce(p, gs) == 0) {
  0;
} else {
  ideal I = groebner(gs);
  reduce(p, I);
}
exit;

Execution time of Singular: 0.0038 seconds
OUTPUT FROM SINGULAR:
0

=== Cut #3 ===
INPUT TO SINGULAR:
// Verify: algebraic specifications
// Track: default
// Cut: #3
// Algebraic specification #5: x11_5 * x1_2 + x12_3 * x2_6 = f_0_low60_20_1 * (- (2 ** 20))
// Algebraic condition: x11_5 * x1_2 + x12_3 * x2_6 = f_0_low60_20_1 * (- (2 ** 20))
// Try: #0 (pure equality)
// Output file: /tmp/outputfgb_2fb37b
proc is_generator(poly p, ideal I) {
  int idx;
  for (idx=1; idx<=size(I); idx++) {
    if (p == I[idx]) { return (0==0); }
  }
  return (0==1);
}

ring r = integer, (g_0_low60_20_1,s_0_20_2,r_0_20_2,f_0_low60_20_1,v_0_20_2,u_0_20_2,x2_6,x1_2), lp;
ideal gs = 0;
poly p = u_0_20_2 * x1_2 + v_0_20_2 * x2_6 - f_0_low60_20_1 * (- (bigint(2)^20));
if (is_generator(p, gs) || reduce(p, gs) == 0) {
  0;
} else {
  ideal I = groebner(gs);
  reduce(p, I);
}
exit;

Execution time of Singular: 0.0037 seconds
OUTPUT FROM SINGULAR:
1048576*f_0_low60_20_1+v_0_20_2*x2_6+u_0_20_2*x1_2

=== Cut #3 ===
INPUT TO SINGULAR:
// Verify: algebraic specifications
// Track: default
// Cut: #3
// Algebraic specification #6: x13_5 * x1_2 + x14_3 * x2_6 = g_0_low60_20_1 * (- (2 ** 20))
// Algebraic condition: x13_5 * x1_2 + x14_3 * x2_6 = g_0_low60_20_1 * (- (2 ** 20))
// Try: #0 (pure equality)
// Output file: /tmp/outputfgb_f5c8a6
proc is_generator(poly p, ideal I) {
  int idx;
  for (idx=1; idx<=size(I); idx++) {
    if (p == I[idx]) { return (0==0); }
  }
  return (0==1);
}

ring r = integer, (g_0_low60_20_1,s_0_20_2,r_0_20_2,f_0_low60_20_1,v_0_20_2,u_0_20_2,x2_6,x1_2), lp;
ideal gs = 0;
poly p = r_0_20_2 * x1_2 + s_0_20_2 * x2_6 - g_0_low60_20_1 * (- (bigint(2)^20));
if (is_generator(p, gs) || reduce(p, gs) == 0) {
  0;
} else {
  ideal I = groebner(gs);
  reduce(p, I);
}
exit;

Execution time of Singular: 0.0040 seconds
OUTPUT FROM SINGULAR:
1048576*g_0_low60_20_1+s_0_20_2*x2_6+r_0_20_2*x1_2

=== Cut #4 ===
INPUT TO SINGULAR:
// Verify: algebraic specifications
// Track: default
// Cut: #4
// Algebraic specification #7: (-1048576) * neg_f_0_low60_20_low20_0_1 + 0 * neg_g_0_low60_20_low20_0_1 = neg_f_0_low60_20_low20_0_1 * (- (2 ** 20))
// Algebraic condition: (-1048576) * neg_f_0_low60_20_low20_0_1 + 0 * neg_g_0_low60_20_low20_0_1 = neg_f_0_low60_20_low20_0_1 * (- (2 ** 20))
// Try: #0 (pure equality)
// Output file: /tmp/outputfgb_cac5de
proc is_generator(poly p, ideal I) {
  int idx;
  for (idx=1; idx<=size(I); idx++) {
    if (p == I[idx]) { return (0==0); }
  }
  return (0==1);
}

ring r = integer, (neg_g_0_low60_20_low20_0_1,neg_f_0_low60_20_low20_0_1,dc_186,dc_184,g_0_low60_20_1,x14_3,x13_5,f_0_low60_20_1,x12_3,x11_5,x2_6,x1_2), lp;
ideal gs = 0;
poly p = bigint(-1048576) * neg_f_0_low60_20_low20_0_1 + bigint(0) * neg_g_0_low60_20_low20_0_1 - neg_f_0_low60_20_low20_0_1 * (- (bigint(2)^20));
if (is_generator(p, gs) || reduce(p, gs) == 0) {
  0;
} else {
  ideal I = groebner(gs);
  reduce(p, I);
}
exit;

Execution time of Singular: 0.0028 seconds
OUTPUT FROM SINGULAR:
0

=== Cut #4 ===
INPUT TO SINGULAR:
// Verify: algebraic specifications
// Track: default
// Cut: #4
// Algebraic specification #8: 0 * neg_f_0_low60_20_low20_0_1 + (-1048576) * neg_g_0_low60_20_low20_0_1 = neg_g_0_low60_20_low20_0_1 * (- (2 ** 20))
// Algebraic condition: 0 * neg_f_0_low60_20_low20_0_1 + (-1048576) * neg_g_0_low60_20_low20_0_1 = neg_g_0_low60_20_low20_0_1 * (- (2 ** 20))
// Try: #0 (pure equality)
// Output file: /tmp/outputfgb_52d64f
proc is_generator(poly p, ideal I) {
  int idx;
  for (idx=1; idx<=size(I); idx++) {
    if (p == I[idx]) { return (0==0); }
  }
  return (0==1);
}

ring r = integer, (neg_f_0_low60_20_low20_0_1,neg_g_0_low60_20_low20_0_1,dc_186,dc_184,g_0_low60_20_1,x14_3,x13_5,f_0_low60_20_1,x12_3,x11_5,x2_6,x1_2), lp;
ideal gs = 0;
poly p = bigint(0) * neg_f_0_low60_20_low20_0_1 + bigint(-1048576) * neg_g_0_low60_20_low20_0_1 - neg_g_0_low60_20_low20_0_1 * (- (bigint(2)^20));
if (is_generator(p, gs) || reduce(p, gs) == 0) {
  0;
} else {
  ideal I = groebner(gs);
  reduce(p, I);
}
exit;

Execution time of Singular: 0.0029 seconds
OUTPUT FROM SINGULAR:
0

=== Cut #3 ===
INPUT TO SINGULAR:
// Verify: algebraic specifications
// Track: default
// Cut: #3
// Algebraic specification #5: x11_5 * x1_2 + x12_3 * x2_6 = f_0_low60_20_1 * (- (2 ** 20))
// Algebraic condition: x11_5 * x1_2 + x12_3 * x2_6 = f_0_low60_20_1 * (- (2 ** 20))
// Try: #1 (modular equality)
// Output file: /tmp/outputfgb_4e8a72
proc is_generator(poly p, ideal I) {
  int idx;
  for (idx=1; idx<=size(I); idx++) {
    if (p == I[idx]) { return (0==0); }
  }
  return (0==1);
}

ring r = integer, (g_0_low60_20_1,s_0_20_2,r_0_20_2,f_0_low60_20_1,v_0_20_2,u_0_20_2,x2_6,x1_2), lp;
ideal gs = u_0_20_2 * x1_2 + v_0_20_2 * x2_6 - f_0_low60_20_1 * (- (bigint(2)^20)),
  r_0_20_2 * x1_2 + s_0_20_2 * x2_6 - g_0_low60_20_1 * (- (bigint(2)^20));
poly p = u_0_20_2 * x1_2 + v_0_20_2 * x2_6 - f_0_low60_20_1 * (- (bigint(2)^20));
if (is_generator(p, gs) || reduce(p, gs) == 0) {
  0;
} else {
  ideal I = groebner(gs);
  reduce(p, I);
}
exit;

Execution time of Singular: 0.0029 seconds
OUTPUT FROM SINGULAR:
// ** gs is no standard basis
0

=== Cut #3 ===
INPUT TO SINGULAR:
// Verify: algebraic specifications
// Track: default
// Cut: #3
// Algebraic specification #6: x13_5 * x1_2 + x14_3 * x2_6 = g_0_low60_20_1 * (- (2 ** 20))
// Algebraic condition: x13_5 * x1_2 + x14_3 * x2_6 = g_0_low60_20_1 * (- (2 ** 20))
// Try: #1 (modular equality)
// Output file: /tmp/outputfgb_394325
proc is_generator(poly p, ideal I) {
  int idx;
  for (idx=1; idx<=size(I); idx++) {
    if (p == I[idx]) { return (0==0); }
  }
  return (0==1);
}

ring r = integer, (g_0_low60_20_1,s_0_20_2,r_0_20_2,f_0_low60_20_1,v_0_20_2,u_0_20_2,x2_6,x1_2), lp;
ideal gs = u_0_20_2 * x1_2 + v_0_20_2 * x2_6 - f_0_low60_20_1 * (- (bigint(2)^20)),
  r_0_20_2 * x1_2 + s_0_20_2 * x2_6 - g_0_low60_20_1 * (- (bigint(2)^20));
poly p = r_0_20_2 * x1_2 + s_0_20_2 * x2_6 - g_0_low60_20_1 * (- (bigint(2)^20));
if (is_generator(p, gs) || reduce(p, gs) == 0) {
  0;
} else {
  ideal I = groebner(gs);
  reduce(p, I);
}
exit;

Execution time of Singular: 0.0027 seconds
OUTPUT FROM SINGULAR:
// ** gs is no standard basis
0

=== Cut #7 ===
INPUT TO SINGULAR:
// Verify: algebraic specifications
// Track: default
// Cut: #7
// Algebraic specification #15: x15_5 * x9_3 + x16_3 * x2_7 = neg_f_0_low60_40_1 * (- (2 ** 20))
// Algebraic condition: x15_5 * x9_3 + x16_3 * x2_7 = neg_f_0_low60_40_1 * (- (2 ** 20))
// Try: #0 (pure equality)
// Output file: /tmp/outputfgb_258076
proc is_generator(poly p, ideal I) {
  int idx;
  for (idx=1; idx<=size(I); idx++) {
    if (p == I[idx]) { return (0==0); }
  }
  return (0==1);
}

ring r = integer, (g_0_low60_40_1,f_0_low60_40_1,g_0_low60_20_2,f_0_low60_20_2,neg_g_0_low60_40_1,s_20_40_2,r_20_40_2,neg_f_0_low60_40_1,x2_7,v_20_40_2,x9_3,u_20_40_2), lp;
ideal gs = 0;
poly p = u_20_40_2 * x9_3 + v_20_40_2 * x2_7 - neg_f_0_low60_40_1 * (- (bigint(2)^20));
if (is_generator(p, gs) || reduce(p, gs) == 0) {
  0;
} else {
  ideal I = groebner(gs);
  reduce(p, I);
}
exit;

Execution time of Singular: 0.0028 seconds
OUTPUT FROM SINGULAR:
1048576*neg_f_0_low60_40_1+x2_7*v_20_40_2+x9_3*u_20_40_2

=== Cut #7 ===
INPUT TO SINGULAR:
// Verify: algebraic specifications
// Track: default
// Cut: #7
// Algebraic specification #16: x17_5 * x9_3 + x20_3 * x2_7 = neg_g_0_low60_40_1 * (- (2 ** 20))
// Algebraic condition: x17_5 * x9_3 + x20_3 * x2_7 = neg_g_0_low60_40_1 * (- (2 ** 20))
// Try: #0 (pure equality)
// Output file: /tmp/outputfgb_513c0e
proc is_generator(poly p, ideal I) {
  int idx;
  for (idx=1; idx<=size(I); idx++) {
    if (p == I[idx]) { return (0==0); }
  }
  return (0==1);
}

ring r = integer, (g_0_low60_40_1,f_0_low60_40_1,g_0_low60_20_2,f_0_low60_20_2,neg_g_0_low60_40_1,s_20_40_2,r_20_40_2,neg_f_0_low60_40_1,v_20_40_2,u_20_40_2,x2_7,x9_3), lp;
ideal gs = 0;
poly p = r_20_40_2 * x9_3 + s_20_40_2 * x2_7 - neg_g_0_low60_40_1 * (- (bigint(2)^20));
if (is_generator(p, gs) || reduce(p, gs) == 0) {
  0;
} else {
  ideal I = groebner(gs);
  reduce(p, I);
}
exit;

Execution time of Singular: 0.0029 seconds
OUTPUT FROM SINGULAR:
1048576*neg_g_0_low60_40_1+s_20_40_2*x2_7+r_20_40_2*x9_3

=== Cut #7 ===
INPUT TO SINGULAR:
// Verify: algebraic specifications
// Track: default
// Cut: #7
// Algebraic specification #17: x15_5 * f_0_low60_20_2 + x16_3 * g_0_low60_20_2 = f_0_low60_40_1 * (- (2 ** 20))
// Algebraic condition: x15_5 * f_0_low60_20_2 + x16_3 * g_0_low60_20_2 = f_0_low60_40_1 * (- (2 ** 20))
// Try: #0 (pure equality)
// Output file: /tmp/outputfgb_0e19ef
proc is_generator(poly p, ideal I) {
  int idx;
  for (idx=1; idx<=size(I); idx++) {
    if (p == I[idx]) { return (0==0); }
  }
  return (0==1);
}

ring r = integer, (g_0_low60_40_1,f_0_low60_40_1,g_0_low60_20_2,f_0_low60_20_2,neg_g_0_low60_40_1,s_20_40_2,r_20_40_2,neg_f_0_low60_40_1,x2_7,x9_3,v_20_40_2,u_20_40_2), lp;
ideal gs = 0;
poly p = u_20_40_2 * f_0_low60_20_2 + v_20_40_2 * g_0_low60_20_2 - f_0_low60_40_1 * (- (bigint(2)^20));
if (is_generator(p, gs) || reduce(p, gs) == 0) {
  0;
} else {
  ideal I = groebner(gs);
  reduce(p, I);
}
exit;

Execution time of Singular: 0.0029 seconds
OUTPUT FROM SINGULAR:
1048576*f_0_low60_40_1+g_0_low60_20_2*v_20_40_2+f_0_low60_20_2*u_20_40_2

=== Cut #7 ===
INPUT TO SINGULAR:
// Verify: algebraic specifications
// Track: default
// Cut: #7
// Algebraic specification #18: x17_5 * f_0_low60_20_2 + x20_3 * g_0_low60_20_2 = g_0_low60_40_1 * (- (2 ** 20))
// Algebraic condition: x17_5 * f_0_low60_20_2 + x20_3 * g_0_low60_20_2 = g_0_low60_40_1 * (- (2 ** 20))
// Try: #0 (pure equality)
// Output file: /tmp/outputfgb_48a07c
proc is_generator(poly p, ideal I) {
  int idx;
  for (idx=1; idx<=size(I); idx++) {
    if (p == I[idx]) { return (0==0); }
  }
  return (0==1);
}

ring r = integer, (g_0_low60_40_1,f_0_low60_40_1,g_0_low60_20_2,f_0_low60_20_2,neg_g_0_low60_40_1,s_20_40_2,r_20_40_2,neg_f_0_low60_40_1,x2_7,v_20_40_2,x9_3,u_20_40_2), lp;
ideal gs = 0;
poly p = r_20_40_2 * f_0_low60_20_2 + s_20_40_2 * g_0_low60_20_2 - g_0_low60_40_1 * (- (bigint(2)^20));
if (is_generator(p, gs) || reduce(p, gs) == 0) {
  0;
} else {
  ideal I = groebner(gs);
  reduce(p, I);
}
exit;

Execution time of Singular: 0.0027 seconds
OUTPUT FROM SINGULAR:
1048576*g_0_low60_40_1+g_0_low60_20_2*s_20_40_2+f_0_low60_20_2*r_20_40_2

=== Cut #7 ===
INPUT TO SINGULAR:
// Verify: algebraic specifications
// Track: default
// Cut: #7
// Algebraic specification #15: x15_5 * x9_3 + x16_3 * x2_7 = neg_f_0_low60_40_1 * (- (2 ** 20))
// Algebraic condition: x15_5 * x9_3 + x16_3 * x2_7 = neg_f_0_low60_40_1 * (- (2 ** 20))
// Try: #1 (modular equality)
// Output file: /tmp/outputfgb_8b6a9b
proc is_generator(poly p, ideal I) {
  int idx;
  for (idx=1; idx<=size(I); idx++) {
    if (p == I[idx]) { return (0==0); }
  }
  return (0==1);
}

ring r = integer, (g_0_low60_40_1,f_0_low60_40_1,g_0_low60_20_2,f_0_low60_20_2,neg_g_0_low60_40_1,s_20_40_2,r_20_40_2,neg_f_0_low60_40_1,x2_7,v_20_40_2,x9_3,u_20_40_2), lp;
ideal gs = u_20_40_2 * x9_3 + v_20_40_2 * x2_7 - neg_f_0_low60_40_1 * (- (bigint(2)^20)),
  r_20_40_2 * x9_3 + s_20_40_2 * x2_7 - neg_g_0_low60_40_1 * (- (bigint(2)^20)),
  u_20_40_2 * f_0_low60_20_2 + v_20_40_2 * g_0_low60_20_2 - f_0_low60_40_1 * (- (bigint(2)^20)),
  r_20_40_2 * f_0_low60_20_2 + s_20_40_2 * g_0_low60_20_2 - g_0_low60_40_1 * (- (bigint(2)^20));
poly p = u_20_40_2 * x9_3 + v_20_40_2 * x2_7 - neg_f_0_low60_40_1 * (- (bigint(2)^20));
if (is_generator(p, gs) || reduce(p, gs) == 0) {
  0;
} else {
  ideal I = groebner(gs);
  reduce(p, I);
}
exit;

Execution time of Singular: 0.0029 seconds
OUTPUT FROM SINGULAR:
// ** gs is no standard basis
0

=== Cut #7 ===
INPUT TO SINGULAR:
// Verify: algebraic specifications
// Track: default
// Cut: #7
// Algebraic specification #16: x17_5 * x9_3 + x20_3 * x2_7 = neg_g_0_low60_40_1 * (- (2 ** 20))
// Algebraic condition: x17_5 * x9_3 + x20_3 * x2_7 = neg_g_0_low60_40_1 * (- (2 ** 20))
// Try: #1 (modular equality)
// Output file: /tmp/outputfgb_6a5d86
proc is_generator(poly p, ideal I) {
  int idx;
  for (idx=1; idx<=size(I); idx++) {
    if (p == I[idx]) { return (0==0); }
  }
  return (0==1);
}

ring r = integer, (g_0_low60_40_1,f_0_low60_40_1,g_0_low60_20_2,f_0_low60_20_2,neg_g_0_low60_40_1,s_20_40_2,r_20_40_2,neg_f_0_low60_40_1,v_20_40_2,u_20_40_2,x2_7,x9_3), lp;
ideal gs = u_20_40_2 * x9_3 + v_20_40_2 * x2_7 - neg_f_0_low60_40_1 * (- (bigint(2)^20)),
  r_20_40_2 * x9_3 + s_20_40_2 * x2_7 - neg_g_0_low60_40_1 * (- (bigint(2)^20)),
  u_20_40_2 * f_0_low60_20_2 + v_20_40_2 * g_0_low60_20_2 - f_0_low60_40_1 * (- (bigint(2)^20)),
  r_20_40_2 * f_0_low60_20_2 + s_20_40_2 * g_0_low60_20_2 - g_0_low60_40_1 * (- (bigint(2)^20));
poly p = r_20_40_2 * x9_3 + s_20_40_2 * x2_7 - neg_g_0_low60_40_1 * (- (bigint(2)^20));
if (is_generator(p, gs) || reduce(p, gs) == 0) {
  0;
} else {
  ideal I = groebner(gs);
  reduce(p, I);
}
exit;

Execution time of Singular: 0.0028 seconds
OUTPUT FROM SINGULAR:
// ** gs is no standard basis
0

=== Cut #7 ===
INPUT TO SINGULAR:
// Verify: algebraic specifications
// Track: default
// Cut: #7
// Algebraic specification #17: x15_5 * f_0_low60_20_2 + x16_3 * g_0_low60_20_2 = f_0_low60_40_1 * (- (2 ** 20))
// Algebraic condition: x15_5 * f_0_low60_20_2 + x16_3 * g_0_low60_20_2 = f_0_low60_40_1 * (- (2 ** 20))
// Try: #1 (modular equality)
// Output file: /tmp/outputfgb_cedda4
proc is_generator(poly p, ideal I) {
  int idx;
  for (idx=1; idx<=size(I); idx++) {
    if (p == I[idx]) { return (0==0); }
  }
  return (0==1);
}

ring r = integer, (g_0_low60_40_1,f_0_low60_40_1,g_0_low60_20_2,f_0_low60_20_2,neg_g_0_low60_40_1,s_20_40_2,r_20_40_2,neg_f_0_low60_40_1,x2_7,x9_3,v_20_40_2,u_20_40_2), lp;
ideal gs = u_20_40_2 * x9_3 + v_20_40_2 * x2_7 - neg_f_0_low60_40_1 * (- (bigint(2)^20)),
  r_20_40_2 * x9_3 + s_20_40_2 * x2_7 - neg_g_0_low60_40_1 * (- (bigint(2)^20)),
  u_20_40_2 * f_0_low60_20_2 + v_20_40_2 * g_0_low60_20_2 - f_0_low60_40_1 * (- (bigint(2)^20)),
  r_20_40_2 * f_0_low60_20_2 + s_20_40_2 * g_0_low60_20_2 - g_0_low60_40_1 * (- (bigint(2)^20));
poly p = u_20_40_2 * f_0_low60_20_2 + v_20_40_2 * g_0_low60_20_2 - f_0_low60_40_1 * (- (bigint(2)^20));
if (is_generator(p, gs) || reduce(p, gs) == 0) {
  0;
} else {
  ideal I = groebner(gs);
  reduce(p, I);
}
exit;

Execution time of Singular: 0.0028 seconds
OUTPUT FROM SINGULAR:
// ** gs is no standard basis
0

=== Cut #7 ===
INPUT TO SINGULAR:
// Verify: algebraic specifications
// Track: default
// Cut: #7
// Algebraic specification #18: x17_5 * f_0_low60_20_2 + x20_3 * g_0_low60_20_2 = g_0_low60_40_1 * (- (2 ** 20))
// Algebraic condition: x17_5 * f_0_low60_20_2 + x20_3 * g_0_low60_20_2 = g_0_low60_40_1 * (- (2 ** 20))
// Try: #1 (modular equality)
// Output file: /tmp/outputfgb_945d2e
proc is_generator(poly p, ideal I) {
  int idx;
  for (idx=1; idx<=size(I); idx++) {
    if (p == I[idx]) { return (0==0); }
  }
  return (0==1);
}

ring r = integer, (g_0_low60_40_1,f_0_low60_40_1,g_0_low60_20_2,f_0_low60_20_2,neg_g_0_low60_40_1,s_20_40_2,r_20_40_2,neg_f_0_low60_40_1,x2_7,v_20_40_2,x9_3,u_20_40_2), lp;
ideal gs = u_20_40_2 * x9_3 + v_20_40_2 * x2_7 - neg_f_0_low60_40_1 * (- (bigint(2)^20)),
  r_20_40_2 * x9_3 + s_20_40_2 * x2_7 - neg_g_0_low60_40_1 * (- (bigint(2)^20)),
  u_20_40_2 * f_0_low60_20_2 + v_20_40_2 * g_0_low60_20_2 - f_0_low60_40_1 * (- (bigint(2)^20)),
  r_20_40_2 * f_0_low60_20_2 + s_20_40_2 * g_0_low60_20_2 - g_0_low60_40_1 * (- (bigint(2)^20));
poly p = r_20_40_2 * f_0_low60_20_2 + s_20_40_2 * g_0_low60_20_2 - g_0_low60_40_1 * (- (bigint(2)^20));
if (is_generator(p, gs) || reduce(p, gs) == 0) {
  0;
} else {
  ideal I = groebner(gs);
  reduce(p, I);
}
exit;

Execution time of Singular: 0.0028 seconds
OUTPUT FROM SINGULAR:
// ** gs is no standard basis
0

